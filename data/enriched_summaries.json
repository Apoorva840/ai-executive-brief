[
  {
    "title": "Dynamic Expert Quantization for Scalable Mixture-of-Experts Inference",
    "url": "https://arxiv.org/abs/2511.15015",
    "source": "Arxiv AI",
    "score": 8,
    "what_happened": "arXiv:2511.15015v3 Announce Type: replace-cross Abstract: Mixture-of-Experts (MoE) has become a practical architecture for scaling LLM capacity while keeping per-token compute modest, but deploying MoE models on a single, memory-limited GPU remains difficult because expert weights dominate the HBM footprint. Existing expert offloading and prefetchi",
    "technical_takeaway": null,
    "primary_risk": "Compute scaling limited by physical and energy infrastructure.",
    "primary_opportunity": "Efficiency-driven architectures and workload-aware scheduling.",
    "who_should_care": [
      "AI Infrastructure Engineers",
      "Sustainability Leaders"
    ],
    "technical_angle": "Hardware and energy constraints now shape model design decisions."
  },
  {
    "title": "Understanding LLM Evaluator Behavior: A Structured Multi-Evaluator Framework for Merchant Risk Assessment",
    "url": "https://arxiv.org/abs/2602.05110",
    "source": "Arxiv AI",
    "score": 7,
    "what_happened": "arXiv:2602.05110v1 Announce Type: new Abstract: Large Language Models (LLMs) are increasingly used as evaluators of reasoning quality, yet their reliability and bias in payments-risk settings remain poorly understood. We introduce a structured multi-evaluator framework for assessing LLM reasoning in Merchant Category Code (MCC)-based merchant risk",
    "technical_takeaway": null,
    "primary_risk": "Risk of overfitting conclusions to narrow benchmarks.",
    "primary_opportunity": "Selective adoption in niche use cases with clear ROI.",
    "who_should_care": [
      "Research Scientists",
      "ML Engineers"
    ],
    "technical_angle": "Signals incremental evolution rather than a paradigm shift in current AI systems."
  },
  {
    "title": "Hallucination-Resistant Security Planning with a Large Language Model",
    "url": "https://arxiv.org/abs/2602.05279",
    "source": "Arxiv AI",
    "score": 7,
    "what_happened": "arXiv:2602.05279v1 Announce Type: new Abstract: Large language models (LLMs) are promising tools for supporting security management tasks, such as incident response planning. However, their unreliability and tendency to hallucinate remain significant challenges. In this paper, we address these challenges by introducing a principled framework for us",
    "technical_takeaway": null,
    "primary_risk": "Risk of overfitting conclusions to narrow benchmarks.",
    "primary_opportunity": "Foundation for future optimization rather than immediate disruption.",
    "who_should_care": [
      "Research Scientists",
      "ML Engineers"
    ],
    "technical_angle": "Adds empirical validation to approaches already used in production AI stacks."
  },
  {
    "title": "ProAct: Agentic Lookahead in Interactive Environments",
    "url": "https://arxiv.org/abs/2602.05327",
    "source": "Arxiv AI",
    "score": 7,
    "what_happened": "arXiv:2602.05327v1 Announce Type: new Abstract: Existing Large Language Model (LLM) agents struggle in interactive environments requiring long-horizon planning, primarily due to compounding errors when simulating future states. To address this, we propose ProAct, a framework that enables agents to internalize accurate lookahead reasoning through a",
    "technical_takeaway": null,
    "primary_risk": "Debugging complexity and cascading failures in agentic systems.",
    "primary_opportunity": "End-to-end automation of complex cognitive workflows.",
    "who_should_care": [
      "CTOs",
      "Engineering Leaders"
    ],
    "technical_angle": "Agent orchestration is emerging as a new software abstraction layer."
  },
  {
    "title": "AgentXRay: White-Boxing Agentic Systems via Workflow Reconstruction",
    "url": "https://arxiv.org/abs/2602.05353",
    "source": "Arxiv AI",
    "score": 7,
    "what_happened": "arXiv:2602.05353v1 Announce Type: new Abstract: Large Language Models have shown strong capabilities in complex problem solving, yet many agentic systems remain difficult to interpret and control due to opaque internal workflows. While some frameworks offer explicit architectures for collaboration, many deployed agentic systems operate as black box",
    "technical_takeaway": null,
    "primary_risk": "Debugging complexity and cascading failures in agentic systems.",
    "primary_opportunity": "End-to-end automation of complex cognitive workflows.",
    "who_should_care": [
      "CTOs",
      "Engineering Leaders"
    ],
    "technical_angle": "Agent orchestration is emerging as a new software abstraction layer."
  }
]