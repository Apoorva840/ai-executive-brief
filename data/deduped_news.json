[
  {
    "title": "AI Safety Meets the War Machine",
    "summary": "Anthropic doesn’t want its AI used in autonomous weapons or government surveillance. Those carve-outs could cost it a major military contract.",
    "url": "https://www.wired.com/story/backchannel-anthropic-dispute-with-the-pentagon/",
    "source": "Wired AI",
    "published_at": "2026-02-20T17:00:00+00:00"
  },
  {
    "title": "Could AI Data Centers Be Moved to Outer Space?",
    "summary": "Massive data centers for generative AI are bad for the Earth. How about launching them into orbit?",
    "url": "https://www.wired.com/story/could-we-put-ai-data-centers-in-space/",
    "source": "Wired AI",
    "published_at": "2026-02-20T12:00:00+00:00"
  },
  {
    "title": "The Search Engine for OnlyFans Models Who Look Like Your Crush",
    "summary": "Presearch’s “Doppelgänger” is trying to help people discover adult creators rather than use nonconsensual deepfakes.",
    "url": "https://www.wired.com/story/the-search-engine-for-onlyfans-models-who-look-like-your-crush/",
    "source": "Wired AI",
    "published_at": "2026-02-20T11:00:00+00:00"
  },
  {
    "title": "AIdentifyAGE Ontology for Decision Support in Forensic Dental Age Assessment",
    "summary": "arXiv:2602.16714v1 Announce Type: new Abstract: Age assessment is crucial in forensic and judicial decision-making, particularly in cases involving undocumented individuals and unaccompanied minors, where legal thresholds determine access to protection, healthcare, and judicial procedures. Dental age assessment is widely recognized as one of the mo",
    "url": "https://arxiv.org/abs/2602.16714",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Retrieval Augmented (Knowledge Graph), and Large Language Model-Driven Design Structure Matrix (DSM) Generation of Cyber-Physical Systems",
    "summary": "arXiv:2602.16715v1 Announce Type: new Abstract: We explore the potential of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG), and Graph-based RAG (GraphRAG) for generating Design Structure Matrices (DSMs). We test these methods on two distinct use cases -- a power screwdriver and a CubeSat with known architectural references -- ev",
    "url": "https://arxiv.org/abs/2602.16715",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Contextuality from Single-State Representations: An Information-Theoretic Principle for Adaptive Intelligence",
    "summary": "arXiv:2602.16716v1 Announce Type: new Abstract: Adaptive systems often operate across multiple contexts while reusing a fixed internal state space due to constraints on memory, representation, or physical resources. Such single-state reuse is ubiquitous in natural and artificial intelligence, yet its fundamental representational consequences remain",
    "url": "https://arxiv.org/abs/2602.16716",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Mobility-Aware Cache Framework for Scalable LLM-Based Human Mobility Simulation",
    "summary": "arXiv:2602.16727v1 Announce Type: new Abstract: Large-scale human mobility simulation is critical for applications such as urban planning, epidemiology, and transportation analysis. Recent works treat large language models (LLMs) as human agents to simulate realistic mobility behaviors using structured reasoning, but their high computational cost l",
    "url": "https://arxiv.org/abs/2602.16727",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "When AI Benchmarks Plateau: A Systematic Study of Benchmark Saturation",
    "summary": "arXiv:2602.16763v1 Announce Type: new Abstract: Artificial Intelligence (AI) benchmarks play a central role in measuring progress in model development and guiding deployment decisions. However, many benchmarks quickly become saturated, meaning that they can no longer differentiate between the best-performing models, diminishing their long-term valu",
    "url": "https://arxiv.org/abs/2602.16763",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Simple Baselines are Competitive with Code Evolution",
    "summary": "arXiv:2602.16805v1 Announce Type: new Abstract: Code evolution is a family of techniques that rely on large language models to search through possible computer programs by evolving or mutating existing code. Many proposed code evolution pipelines show impressive performance but are often not compared to simpler baselines. We test how well two simpl",
    "url": "https://arxiv.org/abs/2602.16805",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Improved Upper Bounds for Slicing the Hypercube",
    "summary": "arXiv:2602.16807v1 Announce Type: new Abstract: A collection of hyperplanes $\\mathcal{H}$ slices all edges of the $n$-dimensional hypercube $Q_n$ with vertex set $\\{-1,1\\}^n$ if, for every edge $e$ in the hypercube, there exists a hyperplane in $\\mathcal{H}$ intersecting $e$ in its interior. Let $S(n)$ be the minimum number of hyperplanes needed to",
    "url": "https://arxiv.org/abs/2602.16807",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "NeuDiff Agent: A Governed AI Workflow for Single-Crystal Neutron Crystallography",
    "summary": "arXiv:2602.16812v1 Announce Type: new Abstract: Large-scale facilities increasingly face analysis and reporting latency as the limiting step in scientific throughput, particularly for structurally and magnetically complex samples that require iterative reduction, integration, refinement, and validation. To improve time-to-result and analysis effici",
    "url": "https://arxiv.org/abs/2602.16812",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Node Learning: A Framework for Adaptive, Decentralised and Collaborative Network Edge AI",
    "summary": "arXiv:2602.16814v1 Announce Type: new Abstract: The expansion of AI toward the edge increasingly exposes the cost and fragility of cen- tralised intelligence. Data transmission, latency, energy consumption, and dependence on large data centres create bottlenecks that scale poorly across heterogeneous, mobile, and resource-constrained environments. ",
    "url": "https://arxiv.org/abs/2602.16814",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "An order-oriented approach to scoring hesitant fuzzy elements",
    "summary": "arXiv:2602.16827v1 Announce Type: new Abstract: Traditional scoring approaches on hesitant fuzzy sets often lack a formal base in order theory. This paper proposes a unified framework, where each score is explicitly defined with respect to a given order. This order-oriented perspective enables more flexible and coherent scoring mechanisms. We exami",
    "url": "https://arxiv.org/abs/2602.16827",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "IndicJR: A Judge-Free Benchmark of Jailbreak Robustness in South Asian Languages",
    "summary": "arXiv:2602.16832v1 Announce Type: new Abstract: Safety alignment of large language models (LLMs) is mostly evaluated in English and contract-bound, leaving multilingual vulnerabilities understudied. We introduce \\textbf{Indic Jailbreak Robustness (IJR)}, a judge-free benchmark for adversarial safety across 12 Indic and South Asian languages (2.1 Bi",
    "url": "https://arxiv.org/abs/2602.16832",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Mobile-Agent-v3.5: Multi-platform Fundamental GUI Agents",
    "summary": "arXiv:2602.16855v1 Announce Type: new Abstract: The paper introduces GUI-Owl-1.5, the latest native GUI agent model that features instruct/thinking variants in multiple sizes (2B/4B/8B/32B/235B) and supports a range of platforms (desktop, mobile, browser, and more) to enable cloud-edge collaboration and real-time interaction. GUI-Owl-1.5 achieves s",
    "url": "https://arxiv.org/abs/2602.16855",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "OpenSage: Self-programming Agent Generation Engine",
    "summary": "arXiv:2602.16891v1 Announce Type: new Abstract: Agent development kits (ADKs) provide effective platforms and tooling for constructing agents, and their designs are critical to the constructed agents' performance, especially the functionality for agent topology, tools, and memory. However, current ADKs either lack sufficient functional support or r",
    "url": "https://arxiv.org/abs/2602.16891",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "AgentLAB: Benchmarking LLM Agents against Long-Horizon Attacks",
    "summary": "arXiv:2602.16901v1 Announce Type: new Abstract: LLM agents are increasingly deployed in long-horizon, complex environments to solve challenging problems, but this expansion exposes them to long-horizon attacks that exploit multi-turn user-agent-environment interactions to achieve objectives infeasible in single-turn settings. To measure agent vulne",
    "url": "https://arxiv.org/abs/2602.16901",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "LLM-WikiRace: Benchmarking Long-term Planning and Reasoning over Real-World Knowledge Graphs",
    "summary": "arXiv:2602.16902v1 Announce Type: new Abstract: We introduce LLM-Wikirace, a benchmark for evaluating planning, reasoning, and world knowledge in large language models (LLMs). In LLM-Wikirace, models must efficiently navigate Wikipedia hyperlinks step by step to reach a target page from a given source, requiring look-ahead planning and the ability ",
    "url": "https://arxiv.org/abs/2602.16902",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Narrow fine-tuning erodes safety alignment in vision-language agents",
    "summary": "arXiv:2602.16931v1 Announce Type: new Abstract: Lifelong multimodal agents must continuously adapt to new tasks through post-training, but this creates fundamental tension between acquiring capabilities and preserving safety alignment. We demonstrate that fine-tuning aligned vision-language models on narrow-domain harmful datasets induces severe em",
    "url": "https://arxiv.org/abs/2602.16931",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "DeepContext: Stateful Real-Time Detection of Multi-Turn Adversarial Intent Drift in LLMs",
    "summary": "arXiv:2602.16935v1 Announce Type: new Abstract: While Large Language Model (LLM) capabilities have scaled, safety guardrails remain largely stateless, treating multi-turn dialogues as a series of disconnected events. This lack of temporal awareness facilitates a \"Safety Gap\" where adversarial tactics, like Crescendo and ActorAttack, slowly bleed ma",
    "url": "https://arxiv.org/abs/2602.16935",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "SourceBench: Can AI Answers Reference Quality Web Sources?",
    "summary": "arXiv:2602.16942v1 Announce Type: new Abstract: Large language models (LLMs) increasingly answer queries by citing web sources, but existing evaluations emphasize answer correctness rather than evidence quality. We introduce SourceBench, a benchmark for measuring the quality of cited web sources across 100 real-world queries spanning informational,",
    "url": "https://arxiv.org/abs/2602.16942",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Mind the GAP: Text Safety Does Not Transfer to Tool-Call Safety in LLM Agents",
    "summary": "arXiv:2602.16943v1 Announce Type: new Abstract: Large language models deployed as agents increasingly interact with external systems through tool calls--actions with real-world consequences that text outputs alone do not carry. Safety evaluations, however, overwhelmingly measure text-level refusal behavior, leaving a critical question unanswered: d",
    "url": "https://arxiv.org/abs/2602.16943",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "LLM4Cov: Execution-Aware Agentic Learning for High-coverage Testbench Generation",
    "summary": "arXiv:2602.16953v1 Announce Type: new Abstract: Execution-aware LLM agents offer a promising paradigm for learning from tool feedback, but such feedback is often expensive and slow to obtain, making online reinforcement learning (RL) impractical. High-coverage hardware verification exemplifies this challenge due to its reliance on industrial simula",
    "url": "https://arxiv.org/abs/2602.16953",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Automating Agent Hijacking via Structural Template Injection",
    "summary": "arXiv:2602.16958v1 Announce Type: new Abstract: Agent hijacking, highlighted by OWASP as a critical threat to the Large Language Model (LLM) ecosystem, enables adversaries to manipulate execution by injecting malicious instructions into retrieved content. Most existing attacks rely on manually crafted, semantics-driven prompt manipulation, which of",
    "url": "https://arxiv.org/abs/2602.16958",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "HQFS: Hybrid Quantum Classical Financial Security with VQC Forecasting, QUBO Annealing, and Audit-Ready Post-Quantum Signing",
    "summary": "arXiv:2602.16976v1 Announce Type: new Abstract: Here's the corrected paragraph with all punctuation and formatting issues fixed: Financial risk systems usually follow a two-step routine: a model predicts return or risk, and then an optimizer makes a decision such as a portfolio rebalance. In practice, this split can break under real constraints. Th",
    "url": "https://arxiv.org/abs/2602.16976",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Fundamental Limits of Black-Box Safety Evaluation: Information-Theoretic and Computational Barriers from Latent Context Conditioning",
    "summary": "arXiv:2602.16984v1 Announce Type: new Abstract: Black-box safety evaluation of AI systems assumes model behavior on test distributions reliably predicts deployment performance. We formalize and challenge this assumption through latent context-conditioned policies -- models whose outputs depend on unobserved internal variables that are rare under ev",
    "url": "https://arxiv.org/abs/2602.16984",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Conv-FinRe: A Conversational and Longitudinal Benchmark for Utility-Grounded Financial Recommendation",
    "summary": "arXiv:2602.16990v1 Announce Type: new Abstract: Most recommendation benchmarks evaluate how well a model imitates user behavior. In financial advisory, however, observed actions can be noisy or short-sighted under market volatility and may conflict with a user's long-term goals. Treating what users chose as the sole ground truth, therefore, conflat",
    "url": "https://arxiv.org/abs/2602.16990",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Sonar-TS: Search-Then-Verify Natural Language Querying for Time Series Databases",
    "summary": "arXiv:2602.17001v1 Announce Type: new Abstract: Natural Language Querying for Time Series Databases (NLQ4TSDB) aims to assist non-expert users retrieve meaningful events, intervals, and summaries from massive temporal records. However, existing Text-to-SQL methods are not designed for continuous morphological intents such as shapes or anomalies, wh",
    "url": "https://arxiv.org/abs/2602.17001",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Cinder: A fast and fair matchmaking system",
    "summary": "arXiv:2602.17015v1 Announce Type: new Abstract: A fair and fast matchmaking system is an important component of modern multiplayer online games, directly impacting player retention and satisfaction. However, creating fair matches between lobbies (pre-made teams) of heterogeneous skill levels presents a significant challenge. Matching based simply o",
    "url": "https://arxiv.org/abs/2602.17015",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "M2F: Automated Formalization of Mathematical Literature at Scale",
    "summary": "arXiv:2602.17016v1 Announce Type: new Abstract: Automated formalization of mathematics enables mechanical verification but remains limited to isolated theorems and short snippets. Scaling to textbooks and research papers is largely unaddressed, as it requires managing cross-file dependencies, resolving imports, and ensuring that entire projects com",
    "url": "https://arxiv.org/abs/2602.17016",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Sales Research Agent and Sales Research Bench",
    "summary": "arXiv:2602.17017v1 Announce Type: new Abstract: Enterprises increasingly need AI systems that can answer sales-leader questions over live, customized CRM data, but most available models do not expose transparent, repeatable evidence of quality. This paper describes the Sales Research Agent in Microsoft Dynamics 365 Sales, an AI-first application th",
    "url": "https://arxiv.org/abs/2602.17017",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Phase-Aware Mixture of Experts for Agentic Reinforcement Learning",
    "summary": "arXiv:2602.17038v1 Announce Type: new Abstract: Reinforcement learning (RL) has equipped LLM agents with a strong ability to solve complex tasks. However, existing RL methods normally use a \\emph{single} policy network, causing \\emph{simplicity bias} where simple tasks occupy most parameters and dominate gradient updates, leaving insufficient capac",
    "url": "https://arxiv.org/abs/2602.17038",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Dynamic System Instructions and Tool Exposure for Efficient Agentic LLMs",
    "summary": "arXiv:2602.17046v1 Announce Type: new Abstract: Large Language Model (LLM) agents often run for many steps while re-ingesting long system instructions and large tool catalogs each turn. This increases cost, agent derailment probability, latency, and tool-selection errors. We propose Instruction-Tool Retrieval (ITR), a RAG variant that retrieves, pe",
    "url": "https://arxiv.org/abs/2602.17046",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "IntentCUA: Learning Intent-level Representations for Skill Abstraction and Multi-Agent Planning in Computer-Use Agents",
    "summary": "arXiv:2602.17049v1 Announce Type: new Abstract: Computer-use agents operate over long horizons under noisy perception, multi-window contexts, evolving environment states. Existing approaches, from RL-based planners to trajectory retrieval, often drift from user intent and repeatedly solve routine subproblems, leading to error accumulation and ineff",
    "url": "https://arxiv.org/abs/2602.17049",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "RFEval: Benchmarking Reasoning Faithfulness under Counterfactual Reasoning Intervention in Large Reasoning Models",
    "summary": "arXiv:2602.17053v1 Announce Type: new Abstract: Large Reasoning Models (LRMs) exhibit strong performance, yet often produce rationales that sound plausible but fail to reflect their true decision process, undermining reliability and trust. We introduce a formal framework for reasoning faithfulness, defined by two testable conditions: stance consist",
    "url": "https://arxiv.org/abs/2602.17053",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Retaining Suboptimal Actions to Follow Shifting Optima in Multi-Agent Reinforcement Learning",
    "summary": "arXiv:2602.17062v1 Announce Type: new Abstract: Value decomposition is a core approach for cooperative multi-agent reinforcement learning (MARL). However, existing methods still rely on a single optimal action and struggle to adapt when the underlying value function shifts during training, often converging to suboptimal policies. To address this li",
    "url": "https://arxiv.org/abs/2602.17062",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Predictive Batch Scheduling: Accelerating Language Model Training Through Loss-Aware Sample Prioritization",
    "summary": "arXiv:2602.17066v1 Announce Type: new Abstract: We introduce Predictive Batch Scheduling (PBS), a novel training optimization technique that accelerates language model convergence by dynamically prioritizing high-loss samples during batch construction. Unlike curriculum learning approaches that require predefined difficulty metrics or hard example ",
    "url": "https://arxiv.org/abs/2602.17066",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "How AI Coding Agents Communicate: A Study of Pull Request Description Characteristics and Human Review Responses",
    "summary": "arXiv:2602.17084v1 Announce Type: new Abstract: The rapid adoption of large language models has led to the emergence of AI coding agents that autonomously create pull requests on GitHub. However, how these agents differ in their pull request description characteristics, and how human reviewers respond to them, remains underexplored. In this study, ",
    "url": "https://arxiv.org/abs/2602.17084",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Agentic Wireless Communication for 6G: Intent-Aware and Continuously Evolving Physical-Layer Intelligence",
    "summary": "arXiv:2602.17096v1 Announce Type: new Abstract: As 6G wireless systems evolve, growing functional complexity and diverse service demands are driving a shift from rule-based control to intent-driven autonomous intelligence. User requirements are no longer captured by a single metric (e.g., throughput or reliability), but by multi-dimensional objecti",
    "url": "https://arxiv.org/abs/2602.17096",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Toward Trustworthy Evaluation of Sustainability Rating Methodologies: A Human-AI Collaborative Framework for Benchmark Dataset Construction",
    "summary": "arXiv:2602.17106v1 Announce Type: new Abstract: Sustainability or ESG rating agencies use company disclosures and external data to produce scores or ratings that assess the environmental, social, and governance performance of a company. However, sustainability ratings across agencies for a single company vary widely, limiting their comparability, c",
    "url": "https://arxiv.org/abs/2602.17106",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Owen-based Semantics and Hierarchy-Aware Explanation (O-Shap)",
    "summary": "arXiv:2602.17107v1 Announce Type: new Abstract: Shapley value-based methods have become foundational in explainable artificial intelligence (XAI), offering theoretically grounded feature attributions through cooperative game theory. However, in practice, particularly in vision tasks, the assumption of feature independence breaks down, as features (",
    "url": "https://arxiv.org/abs/2602.17107",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Instructor-Aligned Knowledge Graphs for Personalized Learning",
    "summary": "arXiv:2602.17111v1 Announce Type: new Abstract: Mastering educational concepts requires understanding both their prerequisites (e.g., recursion before merge sort) and sub-concepts (e.g., merge sort as part of sorting algorithms). Capturing these dependencies is critical for identifying students' knowledge gaps and enabling targeted intervention for",
    "url": "https://arxiv.org/abs/2602.17111",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Epistemology of Generative AI: The Geometry of Knowing",
    "summary": "arXiv:2602.17116v1 Announce Type: new Abstract: Generative AI presents an unprecedented challenge to our understanding of knowledge and its production. Unlike previous technological transformations, where engineering understanding preceded or accompanied deployment, generative AI operates through mechanisms whose epistemic character remains obscure",
    "url": "https://arxiv.org/abs/2602.17116",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Efficient Parallel Algorithm for Decomposing Hard CircuitSAT Instances",
    "summary": "arXiv:2602.17130v1 Announce Type: new Abstract: We propose a novel parallel algorithm for decomposing hard CircuitSAT instances. The technique employs specialized constraints to partition an original SAT instance into a family of weakened formulas. Our approach is implemented as a parameterized parallel algorithm, where adjusting the parameters all",
    "url": "https://arxiv.org/abs/2602.17130",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Bonsai: A Framework for Convolutional Neural Network Acceleration Using Criterion-Based Pruning",
    "summary": "arXiv:2602.17145v1 Announce Type: new Abstract: As the need for more accurate and powerful Convolutional Neural Networks (CNNs) increases, so too does the size, execution time, memory footprint, and power consumption. To overcome this, solutions such as pruning have been proposed with their own metrics and methodologies, or criteria, for how weight",
    "url": "https://arxiv.org/abs/2602.17145",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "JEPA-DNA: Grounding Genomic Foundation Models through Joint-Embedding Predictive Architectures",
    "summary": "arXiv:2602.17162v1 Announce Type: new Abstract: Genomic Foundation Models (GFMs) have largely relied on Masked Language Modeling (MLM) or Next Token Prediction (NTP) to learn the language of life. While these paradigms excel at capturing local genomic syntax and fine-grained motif patterns, they often fail to capture the broader functional context,",
    "url": "https://arxiv.org/abs/2602.17162",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Texo: Formula Recognition within 20M Parameters",
    "summary": "arXiv:2602.17189v1 Announce Type: new Abstract: In this paper we present Texo, a minimalist yet highperformance formula recognition model that contains only 20 million parameters. By attentive design, distillation and transfer of the vocabulary and the tokenizer, Texo achieves comparable performance to state-of-the-art models such as UniMERNet-T an",
    "url": "https://arxiv.org/abs/2602.17189",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Continual learning and refinement of causal models through dynamic predicate invention",
    "summary": "arXiv:2602.17217v1 Announce Type: new Abstract: Efficiently navigating complex environments requires agents to internalize the underlying logic of their world, yet standard world modelling methods often struggle with sample inefficiency, lack of transparency, and poor scalability. We propose a framework for constructing symbolic causal world models",
    "url": "https://arxiv.org/abs/2602.17217",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "From Labor to Collaboration: A Methodological Experiment Using AI Agents to Augment Research Perspectives in Taiwan's Humanities and Social Sciences",
    "summary": "arXiv:2602.17221v1 Announce Type: new Abstract: Generative AI is reshaping knowledge work, yet existing research focuses predominantly on software engineering and the natural sciences, with limited methodological exploration for the humanities and social sciences. Positioned as a \"methodological experiment,\" this study proposes an AI Agent-based co",
    "url": "https://arxiv.org/abs/2602.17221",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Decoding the Human Factor: High Fidelity Behavioral Prediction for Strategic Foresight",
    "summary": "arXiv:2602.17222v1 Announce Type: new Abstract: Predicting human decision-making in high-stakes environments remains a central challenge for artificial intelligence. While large language models (LLMs) demonstrate strong general reasoning, they often struggle to generate consistent, individual-specific behavior, particularly when accurate prediction",
    "url": "https://arxiv.org/abs/2602.17222",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Mechanistic Interpretability of Cognitive Complexity in LLMs via Linear Probing using Bloom's Taxonomy",
    "summary": "arXiv:2602.17229v1 Announce Type: new Abstract: The black-box nature of Large Language Models necessitates novel evaluation frameworks that transcend surface-level performance metrics. This study investigates the internal neural representations of cognitive complexity using Bloom's Taxonomy as a hierarchical lens. By analyzing high-dimensional acti",
    "url": "https://arxiv.org/abs/2602.17229",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "All Leaks Count, Some Count More: Interpretable Temporal Contamination Detection in LLM Backtesting",
    "summary": "arXiv:2602.17234v1 Announce Type: new Abstract: To evaluate whether LLMs can accurately predict future events, we need the ability to \\textit{backtest} them on events that have already resolved. This requires models to reason only with information available at a specified past date. Yet LLMs may inadvertently leak post-cutoff knowledge encoded duri",
    "url": "https://arxiv.org/abs/2602.17234",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Web Verbs: Typed Abstractions for Reliable Task Composition on the Agentic Web",
    "summary": "arXiv:2602.17245v1 Announce Type: new Abstract: The Web is evolving from a medium that humans browse to an environment where software agents act on behalf of users. Advances in large language models (LLMs) make natural language a practical interface for goal-directed tasks, yet most current web agents operate on low-level primitives such as clicks ",
    "url": "https://arxiv.org/abs/2602.17245",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "ArXiv-to-Model: A Practical Study of Scientific LM Training",
    "summary": "arXiv:2602.17288v1 Announce Type: new Abstract: While frontier large language models demonstrate strong reasoning and mathematical capabilities, the practical process of training domain-specialized scientific language models from raw sources remains under-documented. In this work, we present a detailed case study of training a 1.36B-parameter scien",
    "url": "https://arxiv.org/abs/2602.17288",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "MedClarify: An information-seeking AI agent for medical diagnosis with case-specific follow-up questions",
    "summary": "arXiv:2602.17308v1 Announce Type: new Abstract: Large language models (LLMs) are increasingly used for diagnostic tasks in medicine. In clinical practice, the correct diagnosis can rarely be immediately inferred from the initial patient presentation alone. Rather, reaching a diagnosis often involves systematic history taking, during which clinician",
    "url": "https://arxiv.org/abs/2602.17308",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Dataless Weight Disentanglement in Task Arithmetic via Kronecker-Factored Approximate Curvature",
    "summary": "arXiv:2602.17385v1 Announce Type: new Abstract: Task Arithmetic yields a modular, scalable way to adapt foundation models. Combining multiple task vectors, however, can lead to cross-task interference, causing representation drift and degraded performance. Representation drift regularization provides a natural remedy to disentangle task vectors; ho",
    "url": "https://arxiv.org/abs/2602.17385",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Visual Model Checking: Graph-Based Inference of Visual Routines for Image Retrieval",
    "summary": "arXiv:2602.17386v1 Announce Type: new Abstract: Information retrieval lies at the foundation of the modern digital industry. While natural language search has seen dramatic progress in recent years largely driven by embedding-based models and large-scale pretraining, the field still faces significant challenges. Specifically, queries that involve c",
    "url": "https://arxiv.org/abs/2602.17386",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "A Contrastive Variational AutoEncoder for NSCLC Survival Prediction with Missing Modalities",
    "summary": "arXiv:2602.17402v1 Announce Type: new Abstract: Predicting survival outcomes for non-small cell lung cancer (NSCLC) patients is challenging due to the different individual prognostic features. This task can benefit from the integration of whole-slide images, bulk transcriptomics, and DNA methylation, which offer complementary views of the patient's",
    "url": "https://arxiv.org/abs/2602.17402",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "A Privacy by Design Framework for Large Language Model-Based Applications for Children",
    "summary": "arXiv:2602.17418v1 Announce Type: new Abstract: Children are increasingly using technologies powered by Artificial Intelligence (AI). However, there are growing concerns about privacy risks, particularly for children. Although existing privacy regulations require companies and organizations to implement protections, doing so can be challenging in p",
    "url": "https://arxiv.org/abs/2602.17418",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "WarpRec: Unifying Academic Rigor and Industrial Scale for Responsible, Reproducible, and Efficient Recommendation",
    "summary": "arXiv:2602.17442v1 Announce Type: new Abstract: Innovation in Recommender Systems is currently impeded by a fractured ecosystem, where researchers must choose between the ease of in-memory experimentation and the costly, complex rewriting required for distributed industrial engines. To bridge this gap, we present WarpRec, a high-performance framewo",
    "url": "https://arxiv.org/abs/2602.17442",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Pareto Optimal Benchmarking of AI Models on ARM Cortex Processors for Sustainable Embedded Systems",
    "summary": "arXiv:2602.17508v1 Announce Type: new Abstract: This work presents a practical benchmarking framework for optimizing artificial intelligence (AI) models on ARM Cortex processors (M0+, M4, M7), focusing on energy efficiency, accuracy, and resource utilization in embedded systems. Through the design of an automated test bench, we provide a systematic",
    "url": "https://arxiv.org/abs/2602.17508",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Enhancing Large Language Models (LLMs) for Telecom using Dynamic Knowledge Graphs and Explainable Retrieval-Augmented Generation",
    "summary": "arXiv:2602.17529v1 Announce Type: new Abstract: Large language models (LLMs) have shown strong potential across a variety of tasks, but their application in the telecom field remains challenging due to domain complexity, evolving standards, and specialized terminology. Therefore, general-domain LLMs may struggle to provide accurate and reliable out",
    "url": "https://arxiv.org/abs/2602.17529",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Evaluating Chain-of-Thought Reasoning through Reusability and Verifiability",
    "summary": "arXiv:2602.17544v1 Announce Type: new Abstract: In multi-agent IR pipelines for tasks such as search and ranking, LLM-based agents exchange intermediate reasoning in terms of Chain-of-Thought (CoT) with each other. Current CoT evaluation narrowly focuses on target task accuracy. However, this metric fails to assess the quality or utility of the rea",
    "url": "https://arxiv.org/abs/2602.17544",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "KLong: Training LLM Agent for Extremely Long-horizon Tasks",
    "summary": "arXiv:2602.17547v1 Announce Type: new Abstract: This paper introduces KLong, an open-source LLM agent trained to solve extremely long-horizon tasks. The principle is to first cold-start the model via trajectory-splitting SFT, then scale it via progressive RL training. Specifically, we first activate basic agentic abilities of a base model with a co",
    "url": "https://arxiv.org/abs/2602.17547",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "ODESteer: A Unified ODE-Based Steering Framework for LLM Alignment",
    "summary": "arXiv:2602.17560v1 Announce Type: new Abstract: Activation steering, or representation engineering, offers a lightweight approach to align large language models (LLMs) by manipulating their internal activations at inference time. However, current methods suffer from two key limitations: \\textit{(i)} the lack of a unified theoretical framework for g",
    "url": "https://arxiv.org/abs/2602.17560",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "A Hybrid Federated Learning Based Ensemble Approach for Lung Disease Diagnosis Leveraging Fusion of SWIN Transformer and CNN",
    "summary": "arXiv:2602.17566v1 Announce Type: new Abstract: The significant advancements in computational power cre- ate a vast opportunity for using Artificial Intelligence in different ap- plications of healthcare and medical science. A Hybrid FL-Enabled Ensemble Approach For Lung Disease Diagnosis Leveraging a Combination of SWIN Transformer and CNN is the ",
    "url": "https://arxiv.org/abs/2602.17566",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "AI Gamestore: Scalable, Open-Ended Evaluation of Machine General Intelligence with Human Games",
    "summary": "arXiv:2602.17594v1 Announce Type: new Abstract: Rigorously evaluating machine intelligence against the broad spectrum of human general intelligence has become increasingly important and challenging in this era of rapid technological advance. Conventional AI benchmarks typically assess only narrow capabilities in a limited range of human activity. M",
    "url": "https://arxiv.org/abs/2602.17594",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "MolHIT: Advancing Molecular-Graph Generation with Hierarchical Discrete Diffusion Models",
    "summary": "arXiv:2602.17602v1 Announce Type: new Abstract: Molecular generation with diffusion models has emerged as a promising direction for AI-driven drug discovery and materials science. While graph diffusion models have been widely adopted due to the discrete nature of 2D molecular graphs, existing models suffer from low chemical validity and struggle to",
    "url": "https://arxiv.org/abs/2602.17602",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "AutoNumerics: An Autonomous, PDE-Agnostic Multi-Agent Pipeline for Scientific Computing",
    "summary": "arXiv:2602.17607v1 Announce Type: new Abstract: PDEs are central to scientific and engineering modeling, yet designing accurate numerical solvers typically requires substantial mathematical expertise and manual tuning. Recent neural network-based approaches improve flexibility but often demand high computational cost and suffer from limited interpr",
    "url": "https://arxiv.org/abs/2602.17607",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "CLEF HIPE-2026: Evaluating Accurate and Efficient Person-Place Relation Extraction from Multilingual Historical Texts",
    "summary": "arXiv:2602.17663v1 Announce Type: new Abstract: HIPE-2026 is a CLEF evaluation lab dedicated to person-place relation extraction from noisy, multilingual historical texts. Building on the HIPE-2020 and HIPE-2022 campaigns, it extends the series toward semantic relation extraction by targeting the task of identifying person--place associations in mu",
    "url": "https://arxiv.org/abs/2602.17663",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "GPU-Accelerated Algorithms for Graph Vector Search: Taxonomy, Empirical Study, and Research Directions",
    "summary": "arXiv:2602.16719v1 Announce Type: cross Abstract: Approximate Nearest Neighbor Search (ANNS) underpins many large-scale data mining and machine learning applications, with efficient retrieval increasingly hinging on GPU acceleration as dataset sizes grow. Although graph-based approaches represent the state of the art in approximate nearest neighbor",
    "url": "https://arxiv.org/abs/2602.16719",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "APEX-SQL: Talking to the data via Agentic Exploration for Text-to-SQL",
    "summary": "arXiv:2602.16720v1 Announce Type: cross Abstract: Text-to-SQL systems powered by Large Language Models have excelled on academic benchmarks but struggle in complex enterprise environments. The primary limitation lies in their reliance on static schema representations, which fails to resolve semantic ambiguity and scale effectively to large, complex",
    "url": "https://arxiv.org/abs/2602.16720",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Is Mamba Reliable for Medical Imaging?",
    "summary": "arXiv:2602.16723v1 Announce Type: cross Abstract: State-space models like Mamba offer linear-time sequence processing and low memory, making them attractive for medical imaging. However, their robustness under realistic software and hardware threat models remains underexplored. This paper evaluates Mamba on multiple MedM-NIST classification benchma",
    "url": "https://arxiv.org/abs/2602.16723",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Intent Laundering: AI Safety Datasets Are Not What They Seem",
    "summary": "arXiv:2602.16729v1 Announce Type: cross Abstract: We systematically evaluate the quality of widely used AI safety datasets from two perspectives: in isolation and in practice. In isolation, we examine how well these datasets reflect real-world attacks based on three key properties: driven by ulterior intent, well-crafted, and out-of-distribution. W",
    "url": "https://arxiv.org/abs/2602.16729",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "The Compute ICE-AGE: Invariant Compute Envelope under Addressable Graph Evolution",
    "summary": "arXiv:2602.16736v1 Announce Type: cross Abstract: This paper presents empirical results from a production-grade C++ implementation of a deterministic semantic state substrate derived from prior formal work on Bounded Local Generator Classes (Martin, 2026). The system was mathematically specified prior to implementation and realized as a CPU-residen",
    "url": "https://arxiv.org/abs/2602.16736",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Quantifying LLM Attention-Head Stability: Implications for Circuit Universality",
    "summary": "arXiv:2602.16740v1 Announce Type: cross Abstract: In mechanistic interpretability, recent work scrutinizes transformer \"circuits\" - sparse, mono or multi layer sub computations, that may reflect human understandable functions. Yet, these network circuits are rarely acid-tested for their stability across different instances of the same deep learning",
    "url": "https://arxiv.org/abs/2602.16740",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Can Adversarial Code Comments Fool AI Security Reviewers -- Large-Scale Empirical Study of Comment-Based Attacks and Defenses Against LLM Code Analysis",
    "summary": "arXiv:2602.16741v1 Announce Type: cross Abstract: AI-assisted code review is widely used to detect vulnerabilities before production release. Prior work shows that adversarial prompt manipulation can degrade large language model (LLM) performance in code generation. We test whether similar comment-based manipulation misleads LLMs during vulnerabili",
    "url": "https://arxiv.org/abs/2602.16741",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "DeepVision-103K: A Visually Diverse, Broad-Coverage, and Verifiable Mathematical Dataset for Multimodal Reasoning",
    "summary": "arXiv:2602.16742v1 Announce Type: cross Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has been shown effective in enhancing the visual reflection and reasoning capabilities of Large Multimodal Models (LMMs). However, existing datasets are predominantly derived from either small-scale manual construction or recombination of prior r",
    "url": "https://arxiv.org/abs/2602.16742",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "PETS: A Principled Framework Towards Optimal Trajectory Allocation for Efficient Test-Time Self-Consistency",
    "summary": "arXiv:2602.16745v1 Announce Type: cross Abstract: Test-time scaling can improve model performance by aggregating stochastic reasoning trajectories. However, achieving sample-efficient test-time self-consistency under a limited budget remains an open challenge. We introduce PETS (Principled and Efficient Test-TimeSelf-Consistency), which initiates a",
    "url": "https://arxiv.org/abs/2602.16745",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Low-Dimensional and Transversely Curved Optimization Dynamics in Grokking",
    "summary": "arXiv:2602.16746v1 Announce Type: cross Abstract: Grokking -- the delayed transition from memorization to generalization in small algorithmic tasks -- remains poorly understood. We present a geometric analysis of optimization dynamics in transformers trained on modular arithmetic. PCA of attention weight trajectories reveals that training evolves p",
    "url": "https://arxiv.org/abs/2602.16746",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "LiveClin: A Live Clinical Benchmark without Leakage",
    "summary": "arXiv:2602.16747v1 Announce Type: cross Abstract: The reliability of medical LLM evaluation is critically undermined by data contamination and knowledge obsolescence, leading to inflated scores on static benchmarks. To address these challenges, we introduce LiveClin, a live benchmark designed for approximating real-world clinical practice. Built fr",
    "url": "https://arxiv.org/abs/2602.16747",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "PREFER: An Ontology for the PREcision FERmentation Community",
    "summary": "arXiv:2602.16755v1 Announce Type: cross Abstract: Precision fermentation relies on microbial cell factories to produce sustainable food, pharmaceuticals, chemicals, and biofuels. Specialized laboratories such as biofoundries are advancing these processes using high-throughput bioreactor platforms, which generate vast datasets. However, the lack of ",
    "url": "https://arxiv.org/abs/2602.16755",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Attending to Routers Aids Indoor Wireless Localization",
    "summary": "arXiv:2602.16762v1 Announce Type: cross Abstract: Modern machine learning-based wireless localization using Wi-Fi signals continues to face significant challenges in achieving groundbreaking performance across diverse environments. A major limitation is that most existing algorithms do not appropriately weight the information from different routers",
    "url": "https://arxiv.org/abs/2602.16762",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Large-scale online deanonymization with LLMs",
    "summary": "arXiv:2602.16800v1 Announce Type: cross Abstract: We show that large language models can be used to perform at-scale deanonymization. With full Internet access, our agent can re-identify Hacker News users and Anthropic Interviewer participants at high precision, given pseudonymous online profiles and conversations alone, matching what would take ho",
    "url": "https://arxiv.org/abs/2602.16800",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "References Improve LLM Alignment in Non-Verifiable Domains",
    "summary": "arXiv:2602.16802v1 Announce Type: cross Abstract: While Reinforcement Learning with Verifiable Rewards (RLVR) has shown strong effectiveness in reasoning tasks, it cannot be directly applied to non-verifiable domains lacking ground-truth verifiers, such as LLM alignment. In this work, we investigate whether reference-guided LLM-evaluators can bridg",
    "url": "https://arxiv.org/abs/2602.16802",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Evaluating Monolingual and Multilingual Large Language Models for Greek Question Answering: The DemosQA Benchmark",
    "summary": "arXiv:2602.16811v1 Announce Type: cross Abstract: Recent advancements in Natural Language Processing and Deep Learning have enabled the development of Large Language Models (LLMs), which have significantly advanced the state-of-the-art across a wide range of tasks, including Question Answering (QA). Despite these advancements, research on LLMs has ",
    "url": "https://arxiv.org/abs/2602.16811",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "One-step Language Modeling via Continuous Denoising",
    "summary": "arXiv:2602.16813v1 Announce Type: cross Abstract: Language models based on discrete diffusion have attracted widespread interest for their potential to provide faster generation than autoregressive models. In practice, however, they exhibit a sharp degradation of sample quality in the few-step regime, failing to realize this promise. Here we show t",
    "url": "https://arxiv.org/abs/2602.16813",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "AI-Mediated Feedback Improves Student Revisions: A Randomized Trial with FeedbackWriter in a Large Undergraduate Course",
    "summary": "arXiv:2602.16820v1 Announce Type: cross Abstract: Despite growing interest in using LLMs to generate feedback on students' writing, little is known about how students respond to AI-mediated versus human-provided feedback. We address this gap through a randomized controlled trial in a large introductory economics course (N=354), where we introduce a",
    "url": "https://arxiv.org/abs/2602.16820",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "HiVAE: Hierarchical Latent Variables for Scalable Theory of Mind",
    "summary": "arXiv:2602.16826v1 Announce Type: cross Abstract: Theory of mind (ToM) enables AI systems to infer agents' hidden goals and mental states, but existing approaches focus mainly on small human understandable gridworld spaces. We introduce HiVAE, a hierarchical variational architecture that scales ToM reasoning to realistic spatiotemporal domains. Ins",
    "url": "https://arxiv.org/abs/2602.16826",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Learning under noisy supervision is governed by a feedback-truth gap",
    "summary": "arXiv:2602.16829v1 Announce Type: cross Abstract: When feedback is absorbed faster than task structure can be evaluated, the learner will favor feedback over truth. A two-timescale model shows this feedback-truth gap is inevitable whenever the two rates differ and vanishes only when they match. We test this prediction across neural networks trained",
    "url": "https://arxiv.org/abs/2602.16829",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "VAM: Verbalized Action Masking for Controllable Exploration in RL Post-Training -- A Chess Case Study",
    "summary": "arXiv:2602.16833v1 Announce Type: cross Abstract: Exploration remains a key bottleneck for reinforcement learning (RL) post-training of large language models (LLMs), where sparse feedback and large action spaces can lead to premature collapse into repetitive behaviors. We propose Verbalized Action Masking (VAM), which verbalizes an action mask in t",
    "url": "https://arxiv.org/abs/2602.16833",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Overseeing Agents Without Constant Oversight: Challenges and Opportunities",
    "summary": "arXiv:2602.16844v1 Announce Type: cross Abstract: To enable human oversight, agentic AI systems often provide a trace of reasoning and action steps. Designing traces to have an informative, but not overwhelming, level of detail remains a critical challenge. In three user studies on a Computer User Agent, we investigate the utility of basic action t",
    "url": "https://arxiv.org/abs/2602.16844",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "SimToolReal: An Object-Centric Policy for Zero-Shot Dexterous Tool Manipulation",
    "summary": "arXiv:2602.16863v1 Announce Type: cross Abstract: The ability to manipulate tools significantly expands the set of tasks a robot can perform. Yet, tool manipulation represents a challenging class of dexterity, requiring grasping thin objects, in-hand object rotations, and forceful interactions. Since collecting teleoperation data for these behavior",
    "url": "https://arxiv.org/abs/2602.16863",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Position: Why a Dynamical Systems Perspective is Needed to Advance Time Series Modeling",
    "summary": "arXiv:2602.16864v1 Announce Type: cross Abstract: Time series (TS) modeling has come a long way from early statistical, mainly linear, approaches to the current trend in TS foundation models. With a lot of hype and industrial demand in this field, it is not always clear how much progress there really is. To advance TS forecasting and analysis to th",
    "url": "https://arxiv.org/abs/2602.16864",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "AdaptOrch: Task-Adaptive Multi-Agent Orchestration in the Era of LLM Performance Convergence",
    "summary": "arXiv:2602.16873v1 Announce Type: cross Abstract: As large language models from diverse providers converge toward comparable benchmark performance, the traditional paradigm of selecting a single best model per task yields diminishing returns. We argue that orchestration topology -- the structural composition of how multiple agents are coordinated, ",
    "url": "https://arxiv.org/abs/2602.16873",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "MALLVI: a multi agent framework for integrated generalized robotics manipulation",
    "summary": "arXiv:2602.16898v1 Announce Type: cross Abstract: Task planning for robotic manipulation with large language models (LLMs) is an emerging area. Prior approaches rely on specialized models, fine tuning, or prompt tuning, and often operate in an open loop manner without robust environmental feedback, making them fragile in dynamic settings.We present",
    "url": "https://arxiv.org/abs/2602.16898",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "A Reversible Semantics for Janus",
    "summary": "arXiv:2602.16913v1 Announce Type: cross Abstract: Janus is a paradigmatic example of reversible programming language. Indeed, Janus programs can be executed backwards as well as forwards. However, its small-step semantics (useful, e.g., for debugging or as a basis for extensions with concurrency primitives) is not reversible, since it loses informa",
    "url": "https://arxiv.org/abs/2602.16913",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Xray-Visual Models: Scaling Vision models on Industry Scale Data",
    "summary": "arXiv:2602.16918v1 Announce Type: cross Abstract: We present Xray-Visual, a unified vision model architecture for large-scale image and video understanding trained on industry-scale social media data. Our model leverages over 15 billion curated image-text pairs and 10 billion video-hashtag pairs from Facebook and Instagram, employing robust data cu",
    "url": "https://arxiv.org/abs/2602.16918",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Discovering Multiagent Learning Algorithms with Large Language Models",
    "summary": "arXiv:2602.16928v1 Announce Type: cross Abstract: Much of the advancement of Multi-Agent Reinforcement Learning (MARL) in imperfect-information games has historically depended on manual iterative refinement of baselines. While foundational families like Counterfactual Regret Minimization (CFR) and Policy Space Response Oracles (PSRO) rest on solid ",
    "url": "https://arxiv.org/abs/2602.16928",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Say It My Way: Exploring Control in Conversational Visual Question Answering with Blind Users",
    "summary": "arXiv:2602.16930v1 Announce Type: cross Abstract: Prompting and steering techniques are well established in general-purpose generative AI, yet assistive visual question answering (VQA) tools for blind users still follow rigid interaction patterns with limited opportunities for customization. User control can be helpful when system responses are mis",
    "url": "https://arxiv.org/abs/2602.16930",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "RankEvolve: Automating the Discovery of Retrieval Algorithms via LLM-Driven Evolution",
    "summary": "arXiv:2602.16932v1 Announce Type: cross Abstract: Retrieval algorithms like BM25 and query likelihood with Dirichlet smoothing remain strong and efficient first-stage rankers, yet improvements have mostly relied on parameter tuning and human intuition. We investigate whether a large language model, guided by an evaluator and evolutionary search, ca",
    "url": "https://arxiv.org/abs/2602.16932",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Beyond Message Passing: A Symbolic Alternative for Expressive and Interpretable Graph Learning",
    "summary": "arXiv:2602.16947v1 Announce Type: cross Abstract: Graph Neural Networks (GNNs) have become essential in high-stakes domains such as drug discovery, yet their black-box nature remains a significant barrier to trustworthiness. While self-explainable GNNs attempt to bridge this gap, they often rely on standard message-passing backbones that inherit fu",
    "url": "https://arxiv.org/abs/2602.16947",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "When Semantic Overlap Is Not Enough: Cross-Lingual Euphemism Transfer Between Turkish and English",
    "summary": "arXiv:2602.16957v1 Announce Type: cross Abstract: Euphemisms substitute socially sensitive expressions, often softening or reframing meaning, and their reliance on cultural and pragmatic context complicates modeling across languages. In this study, we investigate how cross-lingual equivalence influences transfer in multilingual euphemism detection.",
    "url": "https://arxiv.org/abs/2602.16957",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Eigenmood Space: Uncertainty-Aware Spectral Graph Analysis of Psychological Patterns in Classical Persian Poetry",
    "summary": "arXiv:2602.16959v1 Announce Type: cross Abstract: Classical Persian poetry is a historically sustained archive in which affective life is expressed through metaphor, intertextual convention, and rhetorical indirection. These properties make close reading indispensable while limiting reproducible comparison at scale. We present an uncertainty-aware ",
    "url": "https://arxiv.org/abs/2602.16959",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "A Unified Framework for Locality in Scalable MARL",
    "summary": "arXiv:2602.16966v1 Announce Type: cross Abstract: Scalable Multi-Agent Reinforcement Learning (MARL) is fundamentally challenged by the curse of dimensionality. A common solution is to exploit locality, which hinges on an Exponential Decay Property (EDP) of the value function. However, existing conditions that guarantee the EDP are often conservati",
    "url": "https://arxiv.org/abs/2602.16966",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Early-Warning Signals of Grokking via Loss-Landscape Geometry",
    "summary": "arXiv:2602.16967v1 Announce Type: cross Abstract: Grokking -- the abrupt transition from memorization to generalization after prolonged training -- has been linked to confinement on low-dimensional execution manifolds in modular arithmetic. Whether this mechanism extends beyond arithmetic remains open. We study two sequence-learning benchmarks: SCA",
    "url": "https://arxiv.org/abs/2602.16967",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers",
    "summary": "arXiv:2602.16968v1 Announce Type: cross Abstract: Diffusion Transformers (DiTs) have achieved state-of-the-art performance in image and video generation, but their success comes at the cost of heavy computation. This inefficiency is largely due to the fixed tokenization process, which uses constant-sized patches throughout the entire denoising phas",
    "url": "https://arxiv.org/abs/2602.16968",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Exploring LLMs for User Story Extraction from Mockups",
    "summary": "arXiv:2602.16997v1 Announce Type: cross Abstract: User stories are one of the most widely used artifacts in the software industry to define functional requirements. In parallel, the use of high-fidelity mockups facilitates end-user participation in defining their needs. In this work, we explore how combining these techniques with large language mod",
    "url": "https://arxiv.org/abs/2602.16997",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Persona2Web: Benchmarking Personalized Web Agents for Contextual Reasoning with User History",
    "summary": "arXiv:2602.17003v1 Announce Type: cross Abstract: Large language models have advanced web agents, yet current agents lack personalization capabilities. Since users rarely specify every detail of their intent, practical web agents must be able to interpret ambiguous queries by inferring user preferences and contexts. To address this challenge, we pr",
    "url": "https://arxiv.org/abs/2602.17003",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "ReIn: Conversational Error Recovery with Reasoning Inception",
    "summary": "arXiv:2602.17022v1 Announce Type: cross Abstract: Conversational agents powered by large language models (LLMs) with tool integration achieve strong performance on fixed task-oriented dialogue datasets but remain vulnerable to unanticipated, user-induced errors. Rather than focusing on error prevention, this work focuses on error recovery, which ne",
    "url": "https://arxiv.org/abs/2602.17022",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Transforming Behavioral Neuroscience Discovery with In-Context Learning and AI-Enhanced Tensor Methods",
    "summary": "arXiv:2602.17027v1 Announce Type: cross Abstract: Scientific discovery pipelines typically involve complex, rigid, and time-consuming processes, from data preparation to analyzing and interpreting findings. Recent advances in AI have the potential to transform such pipelines in a way that domain experts can focus on interpreting and understanding f",
    "url": "https://arxiv.org/abs/2602.17027",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Forecasting Anomaly Precursors via Uncertainty-Aware Time-Series Ensembles",
    "summary": "arXiv:2602.17028v1 Announce Type: cross Abstract: Detecting anomalies in time-series data is critical in domains such as industrial operations, finance, and cybersecurity, where early identification of abnormal patterns is essential for ensuring system reliability and enabling preventive maintenance. However, most existing methods are reactive: the",
    "url": "https://arxiv.org/abs/2602.17028",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Wink: Recovering from Misbehaviors in Coding Agents",
    "summary": "arXiv:2602.17037v1 Announce Type: cross Abstract: Autonomous coding agents, powered by large language models (LLMs), are increasingly being adopted in the software industry to automate complex engineering tasks. However, these agents are prone to a wide range of misbehaviors, such as deviating from the user's instructions, getting stuck in repetiti",
    "url": "https://arxiv.org/abs/2602.17037",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Evaluating Cross-Lingual Classification Approaches Enabling Topic Discovery for Multilingual Social Media Data",
    "summary": "arXiv:2602.17051v1 Announce Type: cross Abstract: Analysing multilingual social media discourse remains a major challenge in natural language processing, particularly when large-scale public debates span across diverse languages. This study investigates how different approaches for cross-lingual text classification can support reliable analysis of ",
    "url": "https://arxiv.org/abs/2602.17051",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "ALPS: A Diagnostic Challenge Set for Arabic Linguistic & Pragmatic Reasoning",
    "summary": "arXiv:2602.17054v1 Announce Type: cross Abstract: While recent Arabic NLP benchmarks focus on scale, they often rely on synthetic or translated data which may benefit from deeper linguistic verification. We introduce ALPS (Arabic Linguistic & Pragmatic Suite), a native, expert-curated diagnostic challenge set probing Deep Semantics and Pragmatics, ",
    "url": "https://arxiv.org/abs/2602.17054",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Sign Lock-In: Randomly Initialized Weight Signs Persist and Bottleneck Sub-Bit Model Compression",
    "summary": "arXiv:2602.17063v1 Announce Type: cross Abstract: Sub-bit model compression seeks storage below one bit per weight; as magnitudes are aggressively compressed, the sign bit becomes a fixed-cost bottleneck. Across Transformers, CNNs, and MLPs, learned sign matrices resist low-rank approximation and are spectrally indistinguishable from an i.i.d. Rade",
    "url": "https://arxiv.org/abs/2602.17063",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "General sample size analysis for probabilities of causation: a delta method approach",
    "summary": "arXiv:2602.17070v1 Announce Type: cross Abstract: Probabilities of causation (PoCs), such as the probability of necessity and sufficiency (PNS), are important tools for decision making but are generally not point identifiable. Existing work has derived bounds for these quantities using combinations of experimental and observational data. However, t",
    "url": "https://arxiv.org/abs/2602.17070",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "AdvSynGNN: Structure-Adaptive Graph Neural Nets via Adversarial Synthesis and Self-Corrective Propagation",
    "summary": "arXiv:2602.17071v1 Announce Type: cross Abstract: Graph neural networks frequently encounter significant performance degradation when confronted with structural noise or non-homophilous topologies. To address these systemic vulnerabilities, we present AdvSynGNN, a comprehensive architecture designed for resilient node-level representation learning.",
    "url": "https://arxiv.org/abs/2602.17071",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "FLoRG: Federated Fine-tuning with Low-rank Gram Matrices and Procrustes Alignment",
    "summary": "arXiv:2602.17095v1 Announce Type: cross Abstract: Parameter-efficient fine-tuning techniques such as low-rank adaptation (LoRA) enable large language models (LLMs) to adapt to downstream tasks efficiently. Federated learning (FL) further facilitates this process by enabling collaborative fine-tuning across distributed clients without sharing privat",
    "url": "https://arxiv.org/abs/2602.17095",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Deep Reinforcement Learning for Optimal Portfolio Allocation: A Comparative Study with Mean-Variance Optimization",
    "summary": "arXiv:2602.17098v1 Announce Type: cross Abstract: Portfolio Management is the process of overseeing a group of investments, referred to as a portfolio, with the objective of achieving predetermined investment goals. Portfolio optimization is a key component that involves allocating the portfolio assets so as to maximize returns while minimizing ris",
    "url": "https://arxiv.org/abs/2602.17098",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "TIFO: Time-Invariant Frequency Operator for Stationarity-Aware Representation Learning in Time Series",
    "summary": "arXiv:2602.17122v1 Announce Type: cross Abstract: Nonstationary time series forecasting suffers from the distribution shift issue due to the different distributions that produce the training and test data. Existing methods attempt to alleviate the dependence by, e.g., removing low-order moments from each individual sample. These solutions fail to c",
    "url": "https://arxiv.org/abs/2602.17122",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "3D Scene Rendering with Multimodal Gaussian Splatting",
    "summary": "arXiv:2602.17124v1 Announce Type: cross Abstract: 3D scene reconstruction and rendering are core tasks in computer vision, with applications spanning industrial monitoring, robotics, and autonomous driving. Recent advances in 3D Gaussian Splatting (GS) and its variants have achieved impressive rendering fidelity while maintaining high computational",
    "url": "https://arxiv.org/abs/2602.17124",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "VP-VAE: Rethinking Vector Quantization via Adaptive Vector Perturbation",
    "summary": "arXiv:2602.17133v1 Announce Type: cross Abstract: Vector Quantized Variational Autoencoders (VQ-VAEs) are fundamental to modern generative modeling, yet they often suffer from training instability and \"codebook collapse\" due to the inherent coupling of representation learning and discrete codebook optimization. In this paper, we propose VP-VAE (Vec",
    "url": "https://arxiv.org/abs/2602.17133",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "TimeOmni-VL: Unified Models for Time Series Understanding and Generation",
    "summary": "arXiv:2602.17149v1 Announce Type: cross Abstract: Recent time series modeling faces a sharp divide between numerical generation and semantic understanding, with research showing that generation models often rely on superficial pattern matching, while understanding-oriented models struggle with high-fidelity numerical output. Although unified multim",
    "url": "https://arxiv.org/abs/2602.17149",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "In-Context Learning in Linear vs. Quadratic Attention Models: An Empirical Study on Regression Tasks",
    "summary": "arXiv:2602.17171v1 Announce Type: cross Abstract: Recent work has demonstrated that transformers and linear attention models can perform in-context learning (ICL) on simple function classes, such as linear regression. In this paper, we empirically study how these two attention mechanisms differ in their ICL behavior on the canonical linear-regressi",
    "url": "https://arxiv.org/abs/2602.17171",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Continual uncertainty learning",
    "summary": "arXiv:2602.17174v1 Announce Type: cross Abstract: Robust control of mechanical systems with multiple uncertainties remains a fundamental challenge, particularly when nonlinear dynamics and operating-condition variations are intricately intertwined. While deep reinforcement learning (DRL) combined with domain randomization has shown promise in mitig",
    "url": "https://arxiv.org/abs/2602.17174",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Universal Fine-Grained Symmetry Inference and Enforcement for Rigorous Crystal Structure Prediction",
    "summary": "arXiv:2602.17176v1 Announce Type: cross Abstract: Crystal structure prediction (CSP), which aims to predict the three-dimensional atomic arrangement of a crystal from its composition, is central to materials discovery and mechanistic understanding. Existing deep learning models often treat crystallographic symmetry only as a soft heuristic or rely ",
    "url": "https://arxiv.org/abs/2602.17176",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Robustness and Reasoning Fidelity of Large Language Models in Long-Context Code Question Answering",
    "summary": "arXiv:2602.17183v1 Announce Type: cross Abstract: Large language models (LLMs) increasingly assist software engineering tasks that require reasoning over long code contexts, yet their robustness under varying input conditions remains unclear. We conduct a systematic study of long-context code question answering using controlled ablations that test ",
    "url": "https://arxiv.org/abs/2602.17183",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "The Bots of Persuasion: Examining How Conversational Agents' Linguistic Expressions of Personality Affect User Perceptions and Decisions",
    "summary": "arXiv:2602.17185v1 Announce Type: cross Abstract: Large Language Model-powered conversational agents (CAs) are increasingly capable of projecting sophisticated personalities through language, but how these projections affect users is unclear. We thus examine how CA personalities expressed linguistically affect user decisions and perceptions in the ",
    "url": "https://arxiv.org/abs/2602.17185",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Deeper detection limits in astronomical imaging using self-supervised spatiotemporal denoising",
    "summary": "arXiv:2602.17205v1 Announce Type: cross Abstract: The detection limit of astronomical imaging observations is limited by several noise sources. Some of that noise is correlated between neighbouring image pixels and exposures, so in principle could be learned and corrected. We present an astronomical self-supervised transformer-based denoising algor",
    "url": "https://arxiv.org/abs/2602.17205",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Extending quantum theory with AI-assisted deterministic game theory",
    "summary": "arXiv:2602.17213v1 Announce Type: cross Abstract: We present an AI-assisted framework for predicting individual runs of complex quantum experiments, including contextuality and causality (adaptive measurements), within our long-term programme of discovering a local hidden-variable theory that extends quantum theory. In order to circumvent impossibi",
    "url": "https://arxiv.org/abs/2602.17213",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "TAPO-Structured Description Logic for Information Behavior: Procedural and Oracle-Based Extensions",
    "summary": "arXiv:2602.17242v1 Announce Type: cross Abstract: We introduce \\emph{TAPO-Structured Description Logic} (TAPO--DL), a formal extension of classical description logic designed to model \\emph{information behavior} as a structured, dynamic process. TAPO--DL extends the standard T--Box/A--Box architecture with two additional layers: a \\emph{Procedural ",
    "url": "https://arxiv.org/abs/2602.17242",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Federated Latent Space Alignment for Multi-user Semantic Communications",
    "summary": "arXiv:2602.17271v1 Announce Type: cross Abstract: Semantic communication aims to convey meaning for effective task execution, but differing latent representations in AI-native devices can cause semantic mismatches that hinder mutual understanding. This paper introduces a novel approach to mitigating latent space misalignment in multi-agent AI- nati",
    "url": "https://arxiv.org/abs/2602.17271",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Towards Cross-lingual Values Assessment: A Consensus-Pluralism Perspective",
    "summary": "arXiv:2602.17283v1 Announce Type: cross Abstract: While large language models (LLMs) have become pivotal to content safety, current evaluation paradigms primarily focus on detecting explicit harms (e.g., violence or hate speech), neglecting the subtler value dimensions conveyed in digital content. To bridge this gap, we introduce X-Value, a novel C",
    "url": "https://arxiv.org/abs/2602.17283",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Flickering Multi-Armed Bandits",
    "summary": "arXiv:2602.17315v1 Announce Type: cross Abstract: We introduce Flickering Multi-Armed Bandits (FMAB), a new MAB framework where the set of available arms (or actions) can change at each round, and the available set at any time may depend on the agent's previously selected arm. We model this constrained, evolving availability using random graph proc",
    "url": "https://arxiv.org/abs/2602.17315",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Same Meaning, Different Scores: Lexical and Syntactic Sensitivity in LLM Evaluation",
    "summary": "arXiv:2602.17316v1 Announce Type: cross Abstract: The rapid advancement of Large Language Models (LLMs) has established standardized evaluation benchmarks as the primary instrument for model comparison. Yet, their reliability is increasingly questioned due to sensitivity to shallow variations in input prompts. This paper examines how controlled, tr",
    "url": "https://arxiv.org/abs/2602.17316",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "WebFAQ 2.0: A Multilingual QA Dataset with Mined Hard Negatives for Dense Retrieval",
    "summary": "arXiv:2602.17327v1 Announce Type: cross Abstract: We introduce WebFAQ 2.0, a new version of the WebFAQ dataset, containing 198 million FAQ-based natural question-answer pairs across 108 languages. Compared to the previous version, it significantly expands multilingual coverage and the number of bilingual aligned QA pairs to over 14.3M, making it th",
    "url": "https://arxiv.org/abs/2602.17327",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "SubQuad: Near-Quadratic-Free Structure Inference with Distribution-Balanced Objectives in Adaptive Receptor framework",
    "summary": "arXiv:2602.17330v1 Announce Type: cross Abstract: Comparative analysis of adaptive immune repertoires at population scale is hampered by two practical bottlenecks: the near-quadratic cost of pairwise affinity evaluations and dataset imbalances that obscure clinically important minority clonotypes. We introduce SubQuad, an end-to-end pipeline that a",
    "url": "https://arxiv.org/abs/2602.17330",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "From Subtle to Significant: Prompt-Driven Self-Improving Optimization in Test-Time Graph OOD Detection",
    "summary": "arXiv:2602.17342v1 Announce Type: cross Abstract: Graph Out-of-Distribution (OOD) detection aims to identify whether a test graph deviates from the distribution of graphs observed during training, which is critical for ensuring the reliability of Graph Neural Networks (GNNs) when deployed in open-world scenarios. Recent advances in graph OOD detect",
    "url": "https://arxiv.org/abs/2602.17342",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "What Breaks Embodied AI Security:LLM Vulnerabilities, CPS Flaws,or Something Else?",
    "summary": "arXiv:2602.17345v1 Announce Type: cross Abstract: Embodied AI systems (e.g., autonomous vehicles, service robots, and LLM-driven interactive agents) are rapidly transitioning from controlled environments to safety critical real-world deployments. Unlike disembodied AI, failures in embodied intelligence lead to irreversible physical consequences, ra",
    "url": "https://arxiv.org/abs/2602.17345",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "A feature-stable and explainable machine learning framework for trustworthy decision-making under incomplete clinical data",
    "summary": "arXiv:2602.17364v1 Announce Type: cross Abstract: Machine learning models are increasingly applied to biomedical data, yet their adoption in high stakes domains remains limited by poor robustness, limited interpretability, and instability of learned features under realistic data perturbations, such as missingness. In particular, models that achieve",
    "url": "https://arxiv.org/abs/2602.17364",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Voice-Driven Semantic Perception for UAV-Assisted Emergency Networks",
    "summary": "arXiv:2602.17394v1 Announce Type: cross Abstract: Unmanned Aerial Vehicle (UAV)-assisted networks are increasingly foreseen as a promising approach for emergency response, providing rapid, flexible, and resilient communications in environments where terrestrial infrastructure is degraded or unavailable. In such scenarios, voice radio communications",
    "url": "https://arxiv.org/abs/2602.17394",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "SpectralGCD: Spectral Concept Selection and Cross-modal Representation Learning for Generalized Category Discovery",
    "summary": "arXiv:2602.17395v1 Announce Type: cross Abstract: Generalized Category Discovery (GCD) aims to identify novel categories in unlabeled data while leveraging a small labeled subset of known classes. Training a parametric classifier solely on image features often leads to overfitting to old classes, and recent multimodal approaches improve performance",
    "url": "https://arxiv.org/abs/2602.17395",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "A High-Level Survey of Optical Remote Sensing",
    "summary": "arXiv:2602.17397v1 Announce Type: cross Abstract: In recent years, significant advances in computer vision have also propelled progress in remote sensing. Concurrently, the use of drones has expanded, with many organizations incorporating them into their operations. Most drones are equipped by default with RGB cameras, which are both robust and amo",
    "url": "https://arxiv.org/abs/2602.17397",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Improving LLM-based Recommendation with Self-Hard Negatives from Intermediate Layers",
    "summary": "arXiv:2602.17410v1 Announce Type: cross Abstract: Large language models (LLMs) have shown great promise in recommender systems, where supervised fine-tuning (SFT) is commonly used for adaptation. Subsequent studies further introduce preference learning to incorporate negative samples into the training process. However, existing methods rely on sequ",
    "url": "https://arxiv.org/abs/2602.17410",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Convergence Analysis of Two-Layer Neural Networks under Gaussian Input Masking",
    "summary": "arXiv:2602.17423v1 Announce Type: cross Abstract: We investigate the convergence guarantee of two-layer neural network training with Gaussian randomly masked inputs. This scenario corresponds to Gaussian dropout at the input level, or noisy input training common in sensor networks, privacy-preserving training, and federated learning, where each use",
    "url": "https://arxiv.org/abs/2602.17423",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Fine-Grained Uncertainty Quantification for Long-Form Language Model Outputs: A Comparative Study",
    "summary": "arXiv:2602.17431v1 Announce Type: cross Abstract: Uncertainty quantification has emerged as an effective approach to closed-book hallucination detection for LLMs, but existing methods are largely designed for short-form outputs and do not generalize well to long-form generation. We introduce a taxonomy for fine-grained uncertainty quantification in",
    "url": "https://arxiv.org/abs/2602.17431",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Beyond Pipelines: A Fundamental Study on the Rise of Generative-Retrieval Architectures in Web Research",
    "summary": "arXiv:2602.17450v1 Announce Type: cross Abstract: Web research and practices have evolved significantly over time, offering users diverse and accessible solutions across a wide range of tasks. While advanced concepts such as Web 4.0 have emerged from mature technologies, the introduction of large language models (LLMs) has profoundly influenced bot",
    "url": "https://arxiv.org/abs/2602.17450",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Jolt Atlas: Verifiable Inference via Lookup Arguments in Zero Knowledge",
    "summary": "arXiv:2602.17452v1 Announce Type: cross Abstract: We present Jolt Atlas, a zero-knowledge machine learning (zkML) framework that extends the Jolt proving system to model inference. Unlike zkVMs (zero-knowledge virtual machines), which emulate CPU instruction execution, Jolt Atlas adapts Jolt's lookup-centric approach and applies it directly to ONNX",
    "url": "https://arxiv.org/abs/2602.17452",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "What Do LLMs Associate with Your Name? A Human-Centered Black-Box Audit of Personal Data",
    "summary": "arXiv:2602.17483v1 Announce Type: cross Abstract: Large language models (LLMs), and conversational agents based on them, are exposed to personal data (PD) during pre-training and during user interactions. Prior work shows that PD can resurface, yet users lack insight into how strongly models associate specific information to their identity. We audi",
    "url": "https://arxiv.org/abs/2602.17483",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Tracing Copied Pixels and Regularizing Patch Affinity in Copy Detection",
    "summary": "arXiv:2602.17484v1 Announce Type: cross Abstract: Image Copy Detection (ICD) aims to identify manipulated content between image pairs through robust feature representation learning. While self-supervised learning (SSL) has advanced ICD systems, existing view-level contrastive methods struggle with sophisticated edits due to insufficient fine-graine",
    "url": "https://arxiv.org/abs/2602.17484",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Learning with Boolean threshold functions",
    "summary": "arXiv:2602.17493v1 Announce Type: cross Abstract: We develop a method for training neural networks on Boolean data in which the values at all nodes are strictly $\\pm 1$, and the resulting models are typically equivalent to networks whose nonzero weights are also $\\pm 1$. The method replaces loss minimization with a nonconvex constraint formulation.",
    "url": "https://arxiv.org/abs/2602.17493",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "LORA-CRAFT: Cross-layer Rank Adaptation via Frozen Tucker Decomposition of Pre-trained Attention Weights",
    "summary": "arXiv:2602.17510v1 Announce Type: cross Abstract: We introduce CRAFT (Cross-layer Rank Adaptation via Frozen Tucker), a parameter-efficient fine-tuning (PEFT) method that applies Tucker tensor decomposition to pre-trained attention weight matrices stacked across transformer layers and trains only small square adaptation matrices on the resulting fr",
    "url": "https://arxiv.org/abs/2602.17510",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "The Anxiety of Influence: Bloom Filters in Transformer Attention Heads",
    "summary": "arXiv:2602.17526v1 Announce Type: cross Abstract: Some transformer attention heads appear to function as membership testers, dedicating themselves to answering the question \"has this token appeared before in the context?\" We identify these heads across four language models (GPT-2 small, medium, and large; Pythia-160M) and show that they form a spec",
    "url": "https://arxiv.org/abs/2602.17526",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Position: Evaluation of ECG Representations Must Be Fixed",
    "summary": "arXiv:2602.17531v1 Announce Type: cross Abstract: This position paper argues that current benchmarking practice in 12-lead ECG representation learning must be fixed to ensure progress is reliable and aligned with clinically meaningful objectives. The field has largely converged on three public multi-label benchmarks (PTB-XL, CPSC2018, CSN) dominate",
    "url": "https://arxiv.org/abs/2602.17531",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Systematic Evaluation of Single-Cell Foundation Model Interpretability Reveals Attention Captures Co-Expression Rather Than Unique Regulatory Signal",
    "summary": "arXiv:2602.17532v1 Announce Type: cross Abstract: We present a systematic evaluation framework - thirty-seven analyses, 153 statistical tests, four cell types, two perturbation modalities - for assessing mechanistic interpretability in single-cell foundation models. Applying this framework to scGPT and Geneformer, we find that attention patterns en",
    "url": "https://arxiv.org/abs/2602.17532",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Toward a Fully Autonomous, AI-Native Particle Accelerator",
    "summary": "arXiv:2602.17536v1 Announce Type: cross Abstract: This position paper presents a vision for self-driving particle accelerators that operate autonomously with minimal human intervention. We propose that future facilities be designed through artificial intelligence (AI) co-design, where AI jointly optimizes the accelerator lattice, diagnostics, and s",
    "url": "https://arxiv.org/abs/2602.17536",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "MASPO: Unifying Gradient Utilization, Probability Mass, and Signal Reliability for Robust and Sample-Efficient LLM Reasoning",
    "summary": "arXiv:2602.17550v1 Announce Type: cross Abstract: Existing Reinforcement Learning with Verifiable Rewards (RLVR) algorithms, such as GRPO, rely on rigid, uniform, and symmetric trust region mechanisms that are fundamentally misaligned with the complex optimization dynamics of Large Language Models (LLMs). In this paper, we identify three critical c",
    "url": "https://arxiv.org/abs/2602.17550",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Probability-Invariant Random Walk Learning on Gyral Folding-Based Cortical Similarity Networks for Alzheimer's and Lewy Body Dementia Diagnosis",
    "summary": "arXiv:2602.17557v1 Announce Type: cross Abstract: Alzheimer's disease (AD) and Lewy body dementia (LBD) present overlapping clinical features yet require distinct diagnostic strategies. While neuroimaging-based brain network analysis is promising, atlas-based representations may obscure individualized anatomy. Gyral folding-based networks using thr",
    "url": "https://arxiv.org/abs/2602.17557",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Be Wary of Your Time Series Preprocessing",
    "summary": "arXiv:2602.17568v1 Announce Type: cross Abstract: Normalization and scaling are fundamental preprocessing steps in time series modeling, yet their role in Transformer-based models remains underexplored from a theoretical perspective. In this work, we present the first formal analysis of how different normalization strategies, specifically instance-",
    "url": "https://arxiv.org/abs/2602.17568",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Conditional Flow Matching for Continuous Anomaly Detection in Autonomous Driving on a Manifold-Aware Spectral Space",
    "summary": "arXiv:2602.17586v1 Announce Type: cross Abstract: Safety validation for Level 4 autonomous vehicles (AVs) is currently bottlenecked by the inability to scale the detection of rare, high-risk long-tail scenarios using traditional rule-based heuristics. We present Deep-Flow, an unsupervised framework for safety-critical anomaly detection that utilize",
    "url": "https://arxiv.org/abs/2602.17586",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "The Cascade Equivalence Hypothesis: When Do Speech LLMs Behave Like ASR$\\rightarrow$LLM Pipelines?",
    "summary": "arXiv:2602.17598v1 Announce Type: cross Abstract: Current speech LLMs largely perform implicit ASR: on tasks solvable from a transcript, they are behaviorally and mechanistically equivalent to simple Whisper$\\to$LLM cascades. We show this through matched-backbone testing across four speech LLMs and six tasks, controlling for the LLM backbone for th",
    "url": "https://arxiv.org/abs/2602.17598",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Adapting Actively on the Fly: Relevance-Guided Online Meta-Learning with Latent Concepts for Geospatial Discovery",
    "summary": "arXiv:2602.17605v1 Announce Type: cross Abstract: In many real-world settings, such as environmental monitoring, disaster response, or public health, with costly and difficult data collection and dynamic environments, strategically sampling from unobserved regions is essential for efficiently uncovering hidden targets under tight resource constrain",
    "url": "https://arxiv.org/abs/2602.17605",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Towards Anytime-Valid Statistical Watermarking",
    "summary": "arXiv:2602.17608v1 Announce Type: cross Abstract: The proliferation of Large Language Models (LLMs) necessitates efficient mechanisms to distinguish machine-generated content from human text. While statistical watermarking has emerged as a promising solution, existing methods suffer from two critical limitations: the lack of a principled approach f",
    "url": "https://arxiv.org/abs/2602.17608",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Stable Asynchrony: Variance-Controlled Off-Policy RL for LLMs",
    "summary": "arXiv:2602.17616v1 Announce Type: cross Abstract: Reinforcement learning (RL) is widely used to improve large language models on reasoning tasks, and asynchronous RL training is attractive because it increases end-to-end throughput. However, for widely adopted critic-free policy-gradient methods such as REINFORCE and GRPO, high asynchrony makes the",
    "url": "https://arxiv.org/abs/2602.17616",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "SMAC: Score-Matched Actor-Critics for Robust Offline-to-Online Transfer",
    "summary": "arXiv:2602.17632v1 Announce Type: cross Abstract: Modern offline Reinforcement Learning (RL) methods find performant actor-critics, however, fine-tuning these actor-critics online with value-based RL algorithms typically causes immediate drops in performance. We provide evidence consistent with the hypothesis that, in the loss landscape, offline ma",
    "url": "https://arxiv.org/abs/2602.17632",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "When to Trust the Cheap Check: Weak and Strong Verification for Reasoning",
    "summary": "arXiv:2602.17633v1 Announce Type: cross Abstract: Reasoning with LLMs increasingly unfolds inside a broader verification loop. Internally, systems use cheap checks, such as self-consistency or proxy rewards, which we call weak verification. Externally, users inspect outputs and steer the model through feedback until results are trustworthy, which w",
    "url": "https://arxiv.org/abs/2602.17633",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Reverso: Efficient Time Series Foundation Models for Zero-shot Forecasting",
    "summary": "arXiv:2602.17634v1 Announce Type: cross Abstract: Learning time series foundation models has been shown to be a promising approach for zero-shot time series forecasting across diverse time series domains. Insofar as scaling has been a critical driver of performance of foundation models in other modalities such as language and vision, much recent wo",
    "url": "https://arxiv.org/abs/2602.17634",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "FAMOSE: A ReAct Approach to Automated Feature Discovery",
    "summary": "arXiv:2602.17641v1 Announce Type: cross Abstract: Feature engineering remains a critical yet challenging bottleneck in machine learning, particularly for tabular data, as identifying optimal features from an exponentially large feature space traditionally demands substantial domain expertise. To address this challenge, we introduce FAMOSE (Feature ",
    "url": "https://arxiv.org/abs/2602.17641",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Pushing the Frontier of Black-Box LVLM Attacks via Fine-Grained Detail Targeting",
    "summary": "arXiv:2602.17645v1 Announce Type: cross Abstract: Black-box adversarial attacks on Large Vision-Language Models (LVLMs) are challenging due to missing gradients and complex multimodal boundaries. While prior state-of-the-art transfer-based approaches like M-Attack perform well using local crop-level matching between source and target images, we fin",
    "url": "https://arxiv.org/abs/2602.17645",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "MARS: Margin-Aware Reward-Modeling with Self-Refinement",
    "summary": "arXiv:2602.17658v1 Announce Type: cross Abstract: Reward modeling is a core component of modern alignment pipelines including RLHF and RLAIF, underpinning policy optimization methods including PPO and TRPO. However, training reliable reward models relies heavily on human-labeled preference data, which is costly and limited, motivating the use of da",
    "url": "https://arxiv.org/abs/2602.17658",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Sink-Aware Pruning for Diffusion Language Models",
    "summary": "arXiv:2602.17664v1 Announce Type: cross Abstract: Diffusion Language Models (DLMs) incur high inference cost due to iterative denoising, motivating efficient pruning. Existing pruning heuristics largely inherited from autoregressive (AR) LLMs, typically preserve attention sink tokens because AR sinks serve as stable global anchors. We show that thi",
    "url": "https://arxiv.org/abs/2602.17664",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Goal Inference from Open-Ended Dialog",
    "summary": "arXiv:2410.13957v2 Announce Type: replace Abstract: Embodied AI Agents are quickly becoming important and common tools in society. These embodied agents should be able to learn about and accomplish a wide range of user goals and preferences efficiently and robustly. Large Language Models (LLMs) are often used as they allow for opportunities for ric",
    "url": "https://arxiv.org/abs/2410.13957",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "GAI: Generative Agents for Innovation",
    "summary": "arXiv:2412.18899v3 Announce Type: replace Abstract: This study examines whether collective reasoning among generative agents can facilitate novel and coherent thinking that leads to innovation. To achieve this, it proposes GAI, a new LLM-empowered framework designed for reflection and interaction among multiple generative agents to replicate the pr",
    "url": "https://arxiv.org/abs/2412.18899",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "AI-Assisted Decision Making with Human Learning",
    "summary": "arXiv:2502.13062v2 Announce Type: replace Abstract: AI systems increasingly support human decision-making. In many cases, despite the algorithm's superior performance, the final decision remains in human hands. For example, an AI may assist doctors in determining which diagnostic tests to run, but the doctor ultimately makes the diagnosis. This pap",
    "url": "https://arxiv.org/abs/2502.13062",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Capturing Individual Human Preferences with Reward Features",
    "summary": "arXiv:2503.17338v2 Announce Type: replace Abstract: Reinforcement learning from human feedback usually models preferences using a reward function that does not distinguish between people. We argue that this is unlikely to be a good design choice in contexts with high potential for disagreement, like in the training of large language models. We form",
    "url": "https://arxiv.org/abs/2503.17338",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "A Scalable Framework for Evaluating Health Language Models",
    "summary": "arXiv:2503.23339v3 Announce Type: replace Abstract: Large language models (LLMs) have emerged as powerful tools for analyzing complex datasets. Recent studies demonstrate their potential to generate useful, personalized responses when provided with patient-specific health information that encompasses lifestyle, biomarkers, and context. As LLM-drive",
    "url": "https://arxiv.org/abs/2503.23339",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "The Correspondence Between Bounded Graph Neural Networks and Fragments of First-Order Logic",
    "summary": "arXiv:2505.08021v4 Announce Type: replace Abstract: Graph Neural Networks (GNNs) address two key challenges in applying deep learning to graph-structured data: they handle varying size input graphs and ensure invariance under graph isomorphism. While GNNs have demonstrated broad applicability, understanding their expressive power remains an importa",
    "url": "https://arxiv.org/abs/2505.08021",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Beyond Needle(s) in the Embodied Haystack: Environment, Architecture, and Training Considerations for Long Context Reasoning",
    "summary": "arXiv:2505.16928v3 Announce Type: replace Abstract: We introduce $\\infty$-THOR, a new framework for long-horizon embodied tasks that advances long-context understanding in embodied AI. $\\infty$-THOR provides: (1) a generation framework for synthesizing scalable, reproducible, and unlimited long-horizon trajectories; (2) a novel embodied QA task, Ne",
    "url": "https://arxiv.org/abs/2505.16928",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "$\\texttt{SPECS}$: Faster Test-Time Scaling through Speculative Drafts",
    "summary": "arXiv:2506.15733v2 Announce Type: replace Abstract: Scaling test-time compute has driven the recent advances in the reasoning capabilities of large language models (LLMs), typically by allocating additional computation for more thorough exploration. However, increased compute often comes at the expense of higher user-facing latency, directly impact",
    "url": "https://arxiv.org/abs/2506.15733",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Sufficient, Necessary and Complete Causal Explanations in Image Classification",
    "summary": "arXiv:2507.23497v2 Announce Type: replace Abstract: Existing algorithms for explaining the outputs of image classifiers are based on a variety of approaches and produce explanations that frequently lack formal rigour. On the other hand, logic-based explanations are formally and rigorously defined but their computability relies on strict assumptions",
    "url": "https://arxiv.org/abs/2507.23497",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Bongard-RWR+: Real-World Representations of Fine-Grained Concepts in Bongard Problems",
    "summary": "arXiv:2508.12026v2 Announce Type: replace Abstract: Bongard Problems (BPs) provide a challenging testbed for abstract visual reasoning (AVR), requiring models to identify visual concepts fromjust a few examples and describe them in natural language. Early BP benchmarks featured synthetic black-and-white drawings, which might not fully capture the c",
    "url": "https://arxiv.org/abs/2508.12026",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Drones that Think on their Feet: Sudden Landing Decisions with Embodied AI",
    "summary": "arXiv:2510.00167v2 Announce Type: replace Abstract: Autonomous drones must often respond to sudden events, such as alarms, faults, or unexpected changes in their environment, that require immediate and adaptive decision-making. Traditional approaches rely on safety engineers hand-coding large sets of recovery rules, but this strategy cannot anticip",
    "url": "https://arxiv.org/abs/2510.00167",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Beyond Reactivity: Measuring Proactive Problem Solving in LLM Agents",
    "summary": "arXiv:2510.19771v3 Announce Type: replace Abstract: LLM-based agents are increasingly moving towards proactivity: rather than awaiting instruction, they exercise agency to anticipate user needs and solve them autonomously. However, evaluating proactivity is challenging; current benchmarks are constrained to localized context, limiting their ability",
    "url": "https://arxiv.org/abs/2510.19771",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Bridging Symbolic Control and Neural Reasoning in LLM Agents: Structured Cognitive Loop with a Governance Layer",
    "summary": "arXiv:2511.17673v5 Announce Type: replace Abstract: Large language model agents suffer from fundamental architectural problems: entangled reasoning and execution, memory volatility, and uncontrolled action sequences. We introduce Structured Cognitive Loop (SCL), a modular architecture that explicitly separates agent cognition into five phases: Retr",
    "url": "https://arxiv.org/abs/2511.17673",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "CaveAgent: Transforming LLMs into Stateful Runtime Operators",
    "summary": "arXiv:2601.01569v3 Announce Type: replace Abstract: LLM-based agents are increasingly capable of complex task execution, yet current agentic systems remain constrained by text-centric paradigms that struggle with long-horizon tasks due to fragile multi-turn dependencies and context drift. We present CaveAgent, a framework that shifts tool use from ",
    "url": "https://arxiv.org/abs/2601.01569",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning",
    "summary": "arXiv:2601.07463v2 Announce Type: replace Abstract: Offline multi-agent reinforcement learning (MARL) aims to solve cooperative decision-making problems in multi-agent systems using pre-collected datasets. Existing offline MARL methods primarily constrain training within the dataset distribution, resulting in overly conservative policies that strug",
    "url": "https://arxiv.org/abs/2601.07463",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Autonomous Business System via Neuro-symbolic AI",
    "summary": "arXiv:2601.15599v2 Announce Type: replace Abstract: Current business environments demand continuous reconfiguration of cross-functional processes, yet enterprise systems remain organized around siloed departments, rigid workflows, and hard-coded automation. Meanwhile, large language models (LLMs) excel at interpreting natural language and unstructu",
    "url": "https://arxiv.org/abs/2601.15599",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Beyond In-Domain Detection: SpikeScore for Cross-Domain Hallucination Detection",
    "summary": "arXiv:2601.19245v5 Announce Type: replace Abstract: Hallucination detection is critical for deploying large language models (LLMs) in real-world applications. Existing hallucination detection methods achieve strong performance when the training and test data come from the same domain, but they suffer from poor cross-domain generalization. In this p",
    "url": "https://arxiv.org/abs/2601.19245",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Autonomous Data Processing using Meta-Agents",
    "summary": "arXiv:2602.00307v2 Announce Type: replace Abstract: Traditional data processing pipelines are typically static and handcrafted for specific tasks, limiting their adaptability to evolving requirements. While general-purpose agents and coding assistants can generate code for well-understood data pipelines, they lack the ability to autonomously monito",
    "url": "https://arxiv.org/abs/2602.00307",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "An Adaptive Differentially Private Federated Learning Framework with Bi-level Optimization",
    "summary": "arXiv:2602.06838v2 Announce Type: replace Abstract: Federated learning enables collaborative model training across distributed clients while preserving data privacy. However, in practical deployments, device heterogeneity, non-independent, and identically distributed (Non-IID) data often lead to highly unstable and biased gradient updates. When dif",
    "url": "https://arxiv.org/abs/2602.06838",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "EduEVAL-DB: A Role-Based Dataset for Pedagogical Risk Evaluation in Educational Explanations",
    "summary": "arXiv:2602.15531v2 Announce Type: replace Abstract: This work introduces EduEVAL-DB, a dataset based on teacher roles designed to support the evaluation and training of automatic pedagogical evaluators and AI tutors for instructional explanations. The dataset comprises 854 explanations corresponding to 139 questions from a curated subset of the Sci",
    "url": "https://arxiv.org/abs/2602.15531",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "EnterpriseBench Corecraft: Training Generalizable Agents on High-Fidelity RL Environments",
    "summary": "arXiv:2602.16179v2 Announce Type: replace Abstract: We show that training AI agents on high-fidelity reinforcement learning environments produces capabilities that generalize beyond the training distribution. We introduce CoreCraft, the first environment in EnterpriseBench, Surge AI's suite of agentic RL environments. CoreCraft is a fully operation",
    "url": "https://arxiv.org/abs/2602.16179",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Defining and Evaluating Physical Safety for Large Language Models",
    "summary": "arXiv:2411.02317v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are increasingly used to control robotic systems such as drones, but their risks of causing physical threats and harm in real-world applications remain unexplored. Our study addresses the critical gap in evaluating LLM physical safety by developing a comprehensiv",
    "url": "https://arxiv.org/abs/2411.02317",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Multi-View 3D Reconstruction using Knowledge Distillation",
    "summary": "arXiv:2412.02039v2 Announce Type: replace-cross Abstract: Large Foundation Models like Dust3r can produce high quality outputs such as pointmaps, camera intrinsics, and depth estimation, given stereo-image pairs as input. However, the application of these outputs on tasks like Visual Localization requires a large amount of inference time and comput",
    "url": "https://arxiv.org/abs/2412.02039",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Point-DeepONet: Predicting Nonlinear Fields on Non-Parametric Geometries under Variable Load Conditions",
    "summary": "arXiv:2412.18362v2 Announce Type: replace-cross Abstract: Nonlinear structural analyses in engineering often require extensive finite element simulations, limiting their applicability in design optimization and real-time control. Conventional deep learning surrogates often struggle with complex, non-parametric three-dimensional (3D) geometries and ",
    "url": "https://arxiv.org/abs/2412.18362",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Self-Improving Skill Learning for Robust Skill-based Meta-Reinforcement Learning",
    "summary": "arXiv:2502.03752v4 Announce Type: replace-cross Abstract: Meta-reinforcement learning (Meta-RL) facilitates rapid adaptation to unseen tasks but faces challenges in long-horizon environments. Skill-based approaches tackle this by decomposing state-action sequences into reusable skills and employing hierarchical decision-making. However, these metho",
    "url": "https://arxiv.org/abs/2502.03752",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Rex: A Family of Reversible Exponential (Stochastic) Runge-Kutta Solvers",
    "summary": "arXiv:2502.08834v3 Announce Type: replace-cross Abstract: Deep generative models based on neural differential equations have quickly become the state-of-the-art for numerous generation tasks across many different applications. These models rely on ODE/SDE solvers which integrate from a prior distribution to the data distribution. In many applicatio",
    "url": "https://arxiv.org/abs/2502.08834",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Simple Self Organizing Map with Vision Transformers",
    "summary": "arXiv:2503.04121v4 Announce Type: replace-cross Abstract: Vision Transformers (ViTs) have demonstrated exceptional performance in various vision tasks. However, they tend to underperform on smaller datasets due to their inherent lack of inductive biases. Current approaches address this limitation implicitly-often by pairing ViTs with pretext tasks ",
    "url": "https://arxiv.org/abs/2503.04121",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Cert-SSBD: Certified Backdoor Defense with Sample-Specific Smoothing Noises",
    "summary": "arXiv:2504.21730v2 Announce Type: replace-cross Abstract: Deep neural networks (DNNs) are vulnerable to backdoor attacks, where an attacker manipulates a small portion of the training data to implant hidden backdoors into the model. The compromised model behaves normally on clean samples but misclassifies backdoored samples into the attacker-specif",
    "url": "https://arxiv.org/abs/2504.21730",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "ReplaceMe: Network Simplification via Depth Pruning and Transformer Block Linearization",
    "summary": "arXiv:2505.02819v4 Announce Type: replace-cross Abstract: We introduce ReplaceMe, a generalized training-free depth pruning method that effectively replaces transformer blocks with a linear operation, while maintaining high performance for low compression ratios. In contrast to conventional pruning approaches that require additional training or fin",
    "url": "https://arxiv.org/abs/2505.02819",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Attention-Enhanced U-Net for Accurate Segmentation of COVID-19 Infected Lung Regions in CT Scans",
    "summary": "arXiv:2505.12298v2 Announce Type: replace-cross Abstract: In this study, we propose a robust methodology for automatic segmentation of infected lung regions in COVID-19 CT scans using convolutional neural networks. The approach is based on a modified U-Net architecture enhanced with attention mechanisms, data augmentation, and postprocessing techni",
    "url": "https://arxiv.org/abs/2505.12298",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Oversmoothing, Oversquashing, Heterophily, Long-Range, and more: Demystifying Common Beliefs in Graph Machine Learning",
    "summary": "arXiv:2505.15547v3 Announce Type: replace-cross Abstract: After a renaissance phase in which researchers revisited the message-passing paradigm through the lens of deep learning, the graph machine learning community shifted its attention towards a deeper and practical understanding of message-passing's benefits and limitations. In this paper, we no",
    "url": "https://arxiv.org/abs/2505.15547",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "On the Design of KL-Regularized Policy Gradient Algorithms for LLM Reasoning",
    "summary": "arXiv:2505.17508v4 Announce Type: replace-cross Abstract: Policy gradient algorithms have been successfully applied to enhance the reasoning capabilities of large language models (LLMs). KL regularization is ubiquitous, yet the design surface, choice of KL direction (forward vs. reverse), normalization (normalized vs. unnormalized), and estimator (",
    "url": "https://arxiv.org/abs/2505.17508",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Explanation User Interfaces: A Systematic Literature Review",
    "summary": "arXiv:2505.20085v2 Announce Type: replace-cross Abstract: Artificial Intelligence (AI) is one of the major technological advancements of this century, bearing incredible potential for users through AI-powered applications and tools in numerous domains. Being often black-box (i.e., its decision-making process is unintelligible), developers typically",
    "url": "https://arxiv.org/abs/2505.20085",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "FinTagging: Benchmarking LLMs for Extracting and Structuring Financial Information",
    "summary": "arXiv:2505.20650v4 Announce Type: replace-cross Abstract: Accurate interpretation of numerical data in financial reports is critical for markets and regulators. Although XBRL (eXtensible Business Reporting Language) provides a standard for tagging financial figures, mapping thousands of facts to over 10k US GAAP concepts remains costly and error pr",
    "url": "https://arxiv.org/abs/2505.20650",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Automated Web Application Testing: End-to-End Test Case Generation with Large Language Models and Screen Transition Graphs",
    "summary": "arXiv:2506.02529v2 Announce Type: replace-cross Abstract: Web applications are critical to modern software ecosystems, yet ensuring their reliability remains challenging due to the complexity and dynamic nature of web interfaces. Recent advances in large language models (LLMs) have shown promise in automating complex tasks, but limitations persist ",
    "url": "https://arxiv.org/abs/2506.02529",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Persona-driven Simulation of Voting Behavior in the European Parliament with Large Language Models",
    "summary": "arXiv:2506.11798v3 Announce Type: replace-cross Abstract: Large Language Models (LLMs) display remarkable capabilities to understand or even produce political discourse but have been found to consistently exhibit a progressive left-leaning bias. At the same time, so-called persona or identity prompts have been shown to produce LLM behavior that ali",
    "url": "https://arxiv.org/abs/2506.11798",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "DeepQuark: A Deep-Neural-Network Approach to Multiquark Bound States",
    "summary": "arXiv:2506.20555v2 Announce Type: replace-cross Abstract: For the first time, we implement the deep-neural-network-based variational Monte Carlo approach for the multiquark bound states, whose complexity surpasses that of electron or nucleon systems due to strong SU(3) color interactions. We design a novel and high-efficiency architecture, DeepQuar",
    "url": "https://arxiv.org/abs/2506.20555",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Strict Subgoal Execution: Reliable Long-Horizon Planning in Hierarchical Reinforcement Learning",
    "summary": "arXiv:2506.21039v2 Announce Type: replace-cross Abstract: Long-horizon goal-conditioned tasks pose fundamental challenges for reinforcement learning (RL), particularly when goals are distant and rewards are sparse. While hierarchical and graph-based methods offer partial solutions, their reliance on conventional hindsight relabeling often fails to ",
    "url": "https://arxiv.org/abs/2506.21039",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "MCIF: Multimodal Crosslingual Instruction-Following Benchmark from Scientific Talks",
    "summary": "arXiv:2507.19634v3 Announce Type: replace-cross Abstract: Recent advances in large language models have laid the foundation for multimodal LLMs (MLLMs), which unify text, speech, and vision within a single framework. As these models are rapidly evolving toward general-purpose instruction following across diverse and complex tasks, a key frontier is",
    "url": "https://arxiv.org/abs/2507.19634",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "CareerPooler: AI-Powered Metaphorical Pool Simulation Improves Experience and Outcomes in Career Exploration",
    "summary": "arXiv:2509.11461v2 Announce Type: replace-cross Abstract: Career exploration is uncertain, requiring decisions with limited information and unpredictable outcomes. While generative AI offers new opportunities for career guidance, most systems rely on linear chat interfaces that produce overly comprehensive and idealized suggestions, overlooking the",
    "url": "https://arxiv.org/abs/2509.11461",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Discrete optimal transport is a strong audio adversarial attack",
    "summary": "arXiv:2509.14959v2 Announce Type: replace-cross Abstract: In this paper, we introduce the discrete optimal transport voice conversion ($k$DOT-VC) method. Comparison with $k$NN-VC, SinkVC, and Gaussian optimal transport (MKL) demonstrates stronger domain adaptation abilities of our method. We use the probabilistic nature of optimal transport (OT) an",
    "url": "https://arxiv.org/abs/2509.14959",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Advancing Universal Deep Learning for Electronic-Structure Hamiltonian Prediction of Materials",
    "summary": "arXiv:2509.19877v4 Announce Type: replace-cross Abstract: Deep learning methods for electronic-structure Hamiltonian prediction has offered significant computational efficiency advantages over traditional DFT methods, yet the diversity of atomic types, structural patterns, and the high-dimensional complexity of Hamiltonians pose substantial challen",
    "url": "https://arxiv.org/abs/2509.19877",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "CoSpaDi: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning",
    "summary": "arXiv:2509.22075v4 Announce Type: replace-cross Abstract: Post-training compression of large language models (LLMs) often relies on low-rank weight approximations that represent each column of the weight matrix in a shared low-dimensional subspace. This strategy is computationally efficient but the underlying constraint can be overly rigid for hete",
    "url": "https://arxiv.org/abs/2509.22075",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Watermarking Diffusion Language Models",
    "summary": "arXiv:2509.24368v2 Announce Type: replace-cross Abstract: We introduce the first watermark tailored for diffusion language models (DLMs), an emergent LLM paradigm able to generate tokens in arbitrary order, in contrast to standard autoregressive language models (ARLMs) which generate tokens sequentially. While there has been much work in ARLM water",
    "url": "https://arxiv.org/abs/2509.24368",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Inference-Time Search Using Side Information for Diffusion-Based Image Reconstruction",
    "summary": "arXiv:2510.03352v2 Announce Type: replace-cross Abstract: Diffusion models have been widely used as powerful priors for solving inverse problems. However, existing approaches typically overlook side information that could significantly improve reconstruction quality, especially in severely ill-posed settings. In this work, we propose a novel infere",
    "url": "https://arxiv.org/abs/2510.03352",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for MLLMs",
    "summary": "arXiv:2510.09201v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have shown remarkable success, and their multimodal expansions (MLLMs) further unlock capabilities spanning images, videos, and other modalities beyond text. However, despite this shift, prompt optimization approaches, designed to reduce the burden of manual prom",
    "url": "https://arxiv.org/abs/2510.09201",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "pi-Flow: Policy-Based Few-Step Generation via Imitation Distillation",
    "summary": "arXiv:2510.14974v3 Announce Type: replace-cross Abstract: Few-step diffusion or flow-based generative models typically distill a velocity-predicting teacher into a student that predicts a shortcut towards denoised data. This format mismatch has led to complex distillation procedures that often suffer from a quality-diversity trade-off. To address t",
    "url": "https://arxiv.org/abs/2510.14974",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "VERA-MH Concept Paper",
    "summary": "arXiv:2510.15297v3 Announce Type: replace-cross Abstract: We introduce VERA-MH (Validation of Ethical and Responsible AI in Mental Health), an automated evaluation of the safety of AI chatbots used in mental health contexts, with an initial focus on suicide risk. Practicing clinicians and academic experts developed a rubric informed by best practic",
    "url": "https://arxiv.org/abs/2510.15297",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "LRT-Diffusion: Calibrated Risk-Aware Guidance for Diffusion Policies",
    "summary": "arXiv:2510.24983v2 Announce Type: replace-cross Abstract: Diffusion policies are competitive for offline reinforcement learning (RL) but are typically guided at sampling time by heuristics that lack a statistical notion of risk. We introduce LRT-Diffusion, a risk-aware sampling rule that treats each denoising step as a sequential hypothesis test be",
    "url": "https://arxiv.org/abs/2510.24983",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "VeriStruct: AI-assisted Automated Verification of Data-Structure Modules in Verus",
    "summary": "arXiv:2510.25015v3 Announce Type: replace-cross Abstract: We introduce VeriStruct, a novel framework that extends AI-assisted automated verification from single functions to more complex data structure modules in Verus. VeriStruct employs a planner module to orchestrate the systematic generation of abstractions, type invariants, specifications, and",
    "url": "https://arxiv.org/abs/2510.25015",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Semi-Supervised Preference Optimization with Limited Feedback",
    "summary": "arXiv:2511.00040v3 Announce Type: replace-cross Abstract: The field of preference optimization has made outstanding contributions to the alignment of language models with human preferences. Despite these advancements, recent methods still rely heavily on substantial paired (labeled) feedback data, leading to substantial resource expenditures. To ad",
    "url": "https://arxiv.org/abs/2511.00040",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Efficient Reinforcement Learning for Large Language Models with Intrinsic Exploration",
    "summary": "arXiv:2511.00794v3 Announce Type: replace-cross Abstract: Reinforcement learning with verifiable rewards (RLVR) has improved the reasoning ability of large language models, yet training remains costly because many rollouts contribute little to optimization, considering the amount of computation required. This study investigates how simply leveragin",
    "url": "https://arxiv.org/abs/2511.00794",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "State of the Art in Text Classification for South Slavic Languages: Fine-Tuning or Prompting?",
    "summary": "arXiv:2511.07989v2 Announce Type: replace-cross Abstract: Until recently, fine-tuned BERT-like models provided state-of-the-art performance on text classification tasks. With the rise of instruction-tuned decoder-only models, commonly known as large language models (LLMs), the field has increasingly moved toward zero-shot and few-shot prompting. Ho",
    "url": "https://arxiv.org/abs/2511.07989",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Improving segmentation of retinal arteries and veins using cardiac signal in doppler holograms",
    "summary": "arXiv:2511.14654v2 Announce Type: replace-cross Abstract: Doppler holography is an emerging retinal imaging technique that captures the dynamic behavior of blood flow with high temporal resolution, enabling quantitative assessment of retinal hemodynamics. This requires accurate segmentation of retinal arteries and veins, but traditional segmentatio",
    "url": "https://arxiv.org/abs/2511.14654",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Multimodal Wireless Foundation Models",
    "summary": "arXiv:2511.15162v2 Announce Type: replace-cross Abstract: Wireless foundation models (WFMs) have recently demonstrated promising capabilities, jointly performing multiple wireless functions and adapting effectively to new environments. However, while current WFMs process only one modality, depending on the task and operating conditions, the most in",
    "url": "https://arxiv.org/abs/2511.15162",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Empathetic Cascading Networks: A Multi-Stage Prompting Technique for Reducing Social Biases in Large Language Models",
    "summary": "arXiv:2511.18696v2 Announce Type: replace-cross Abstract: This report presents the Empathetic Cascading Networks (ECN) framework, a multi-stage prompting method designed to enhance the empathetic and inclusive capabilities of large language models. ECN employs four stages: Perspective Adoption, Emotional Resonance, Reflective Understanding, and Int",
    "url": "https://arxiv.org/abs/2511.18696",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "AI/ML based Joint Source and Channel Coding for HARQ-ACK Payload",
    "summary": "arXiv:2511.19943v2 Announce Type: replace-cross Abstract: Channel coding from 2G to 5G has assumed the inputs bits at the physical layer to be uniformly distributed. However, hybrid automatic repeat request acknowledgement (HARQ-ACK) bits transmitted in the uplink are inherently non-uniformly distributed. For such sources, significant performance g",
    "url": "https://arxiv.org/abs/2511.19943",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Beyond Linear Surrogates: High-Fidelity Local Explanations for Black-Box Models",
    "summary": "arXiv:2512.05556v2 Announce Type: replace-cross Abstract: With the increasing complexity of black-box machine learning models and their adoption in high-stakes areas, it is critical to provide explanations for their predictions. Existing local explanation methods lack in generating high-fidelity explanations. This paper proposes a novel local model",
    "url": "https://arxiv.org/abs/2512.05556",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Restrictive Hierarchical Semantic Segmentation for Stratified Tooth Layer Detection",
    "summary": "arXiv:2512.07984v4 Announce Type: replace-cross Abstract: Accurate understanding of anatomical structures is essential for reliably staging certain dental diseases. A way of introducing this within semantic segmentation models is by utilising hierarchy-aware methodologies. However, existing hierarchy-aware segmentation methods largely encode anatom",
    "url": "https://arxiv.org/abs/2512.07984",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Explanation Bias is a Product: Revealing the Hidden Lexical and Position Preferences in Post-Hoc Feature Attribution",
    "summary": "arXiv:2512.11108v2 Announce Type: replace-cross Abstract: Good quality explanations strengthen the understanding of language models and data. Feature attribution methods, such as Integrated Gradient, are a type of post-hoc explainer that can provide token-level insights. However, explanations on the same input may vary greatly due to underlying bia",
    "url": "https://arxiv.org/abs/2512.11108",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Block-Recurrent Dynamics in Vision Transformers",
    "summary": "arXiv:2512.19941v5 Announce Type: replace-cross Abstract: As Vision Transformers (ViTs) become standard vision backbones, a mechanistic account of their computational phenomenology is essential. Despite architectural cues that hint at dynamical structure, there is no settled framework that interprets Transformer depth as a well-characterized flow. ",
    "url": "https://arxiv.org/abs/2512.19941",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "On the Existence and Behavior of Secondary Attention Sinks",
    "summary": "arXiv:2512.22213v2 Announce Type: replace-cross Abstract: Attention sinks are tokens, often the beginning-of-sequence (BOS) token, that receive disproportionately high attention despite limited semantic relevance. In this work, we identify a class of attention sinks, which we term secondary sinks, that differ fundamentally from the sinks studied in",
    "url": "https://arxiv.org/abs/2512.22213",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Theory of Mind for Explainable Human-Robot Interaction",
    "summary": "arXiv:2512.23482v3 Announce Type: replace-cross Abstract: Within the context of human-robot interaction (HRI), Theory of Mind (ToM) is intended to serve as a user-friendly backend to the interface of robotic systems, enabling robots to infer and respond to human mental states. When integrated into robots, ToM allows them to adapt their internal mod",
    "url": "https://arxiv.org/abs/2512.23482",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Improved Object-Centric Diffusion Learning with Registers and Contrastive Alignment",
    "summary": "arXiv:2601.01224v2 Announce Type: replace-cross Abstract: Slot Attention (SA) with pretrained diffusion models has recently shown promise for object-centric learning (OCL), but suffers from slot entanglement and weak alignment between object slots and image content. We propose Contrastive Object-centric Diffusion Alignment (CODA), a simple extensio",
    "url": "https://arxiv.org/abs/2601.01224",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Symphonym: Universal Phonetic Embeddings for Cross-Script Name Matching",
    "summary": "arXiv:2601.06932v2 Announce Type: replace-cross Abstract: Linking names across historical sources, languages, and writing systems remains a fundamental challenge in digital humanities and geographic information retrieval. Existing approaches require language-specific phonetic algorithms or fail to capture phonetic relationships across different scr",
    "url": "https://arxiv.org/abs/2601.06932",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Auditing Student-AI Collaboration: A Case Study of Online Graduate CS Students",
    "summary": "arXiv:2601.08697v3 Announce Type: replace-cross Abstract: As generative AI becomes embedded in higher education, it increasingly shapes how students complete academic tasks. While these systems offer efficiency and support, concerns persist regarding over-automation, diminished student agency, and the potential for unreliable or hallucinated output",
    "url": "https://arxiv.org/abs/2601.08697",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Temporal Graph Pattern Machine",
    "summary": "arXiv:2601.22454v2 Announce Type: replace-cross Abstract: Temporal graph learning is pivotal for deciphering dynamic systems, where the core challenge lies in explicitly modeling the underlying evolving patterns that govern network transformation. However, prevailing methods are predominantly task-centric and rely on restrictive assumptions -- such",
    "url": "https://arxiv.org/abs/2601.22454",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Fixed Budget is No Harder Than Fixed Confidence in Best-Arm Identification up to Logarithmic Factors",
    "summary": "arXiv:2602.03972v2 Announce Type: replace-cross Abstract: The best-arm identification (BAI) problem is one of the most fundamental problems in interactive machine learning, which has two flavors: the fixed-budget setting (FB) and the fixed-confidence setting (FC). For $K$-armed bandits with the unique best arm, the optimal sample complexities for b",
    "url": "https://arxiv.org/abs/2602.03972",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Di3PO - Diptych Diffusion DPO for Targeted Improvements in Image Generation",
    "summary": "arXiv:2602.06355v2 Announce Type: replace-cross Abstract: Existing methods for preference tuning of text-to-image (T2I) diffusion models often rely on computationally expensive generation steps to create positive and negative pairs of images. These approaches frequently yield training pairs that either lack meaningful differences, are expensive to ",
    "url": "https://arxiv.org/abs/2602.06355",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "SoK: DARPA's AI Cyber Challenge (AIxCC): Competition Design, Architectures, and Lessons Learned",
    "summary": "arXiv:2602.07666v2 Announce Type: replace-cross Abstract: DARPA's AI Cyber Challenge (AIxCC, 2023--2025) is the largest competition to date for building fully autonomous cyber reasoning systems (CRSs) that leverage recent advances in AI -- particularly large language models (LLMs) -- to discover and remediate vulnerabilities in real-world open-sour",
    "url": "https://arxiv.org/abs/2602.07666",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "The Chicken and Egg Dilemma: Co-optimizing Data and Model Configurations for LLMs",
    "summary": "arXiv:2602.08351v2 Announce Type: replace-cross Abstract: Co-optimizing data and model configurations for training LLMs presents a classic chicken-and-egg dilemma: The best training data configuration (e.g., data mixture) for a downstream task depends on the chosen model configuration (e.g., model architecture), and vice versa. However, jointly opt",
    "url": "https://arxiv.org/abs/2602.08351",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Diffusion-Guided Pretraining for Brain Graph Foundation Models",
    "summary": "arXiv:2602.09437v2 Announce Type: replace-cross Abstract: With the growing interest in foundation models for brain signals, graph-based pretraining has emerged as a promising paradigm for learning transferable representations from connectome data. However, existing contrastive and masked autoencoder methods typically rely on naive random dropping o",
    "url": "https://arxiv.org/abs/2602.09437",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Biases in the Blind Spot: Detecting What LLMs Fail to Mention",
    "summary": "arXiv:2602.10117v3 Announce Type: replace-cross Abstract: Large Language Models (LLMs) often provide chain-of-thought (CoT) reasoning traces that appear plausible, but may hide internal biases. We call these *unverbalized biases*. Monitoring models via their stated reasoning is therefore unreliable, and existing bias evaluations typically require p",
    "url": "https://arxiv.org/abs/2602.10117",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "LoRA-Squeeze: Simple and Effective Post-Tuning and In-Tuning Compression of LoRA Modules",
    "summary": "arXiv:2602.10993v2 Announce Type: replace-cross Abstract: Despite its huge number of variants, standard Low-Rank Adaptation (LoRA) is still a dominant technique for parameter-efficient fine-tuning (PEFT). Nonetheless, it faces persistent challenges, including the pre-selection of an optimal rank and rank-specific hyper-parameters, as well as the de",
    "url": "https://arxiv.org/abs/2602.10993",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "MolmoSpaces: A Large-Scale Open Ecosystem for Robot Navigation and Manipulation",
    "summary": "arXiv:2602.11337v2 Announce Type: replace-cross Abstract: Deploying robots at scale demands robustness to the long tail of everyday situations. The countless variations in scene layout, object geometry, and task specifications that characterize real environments are vast and underrepresented in existing robot benchmarks. Measuring this level of gen",
    "url": "https://arxiv.org/abs/2602.11337",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "SCOPE: Selective Conformal Optimized Pairwise LLM Judging",
    "summary": "arXiv:2602.13110v2 Announce Type: replace-cross Abstract: Large language models (LLMs) are increasingly used as judges to replace costly human preference labels in pairwise evaluation. Despite their practicality, LLM judges remain prone to miscalibration and systematic biases. This paper proposes SCOPE (Selective Conformal Optimized Pairwise Evalua",
    "url": "https://arxiv.org/abs/2602.13110",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "GraFSTNet: Graph-based Frequency SpatioTemporal Network for Cellular Traffic Prediction",
    "summary": "arXiv:2602.13282v2 Announce Type: replace-cross Abstract: With rapid expansion of cellular networks and the proliferation of mobile devices, cellular traffic data exhibits complex temporal dynamics and spatial correlations, posing challenges to accurate traffic prediction. Previous methods often focus predominantly on temporal modeling or depend on",
    "url": "https://arxiv.org/abs/2602.13282",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "VisPhyWorld: Probing Physical Reasoning via Code-Driven Video Reconstruction",
    "summary": "arXiv:2602.13294v2 Announce Type: replace-cross Abstract: Evaluating whether Multimodal Large Language Models (MLLMs) genuinely reason about physical dynamics remains challenging. Most existing benchmarks rely on recognition-style protocols such as Visual Question Answering (VQA) and Violation of Expectation (VoE), which can often be answered witho",
    "url": "https://arxiv.org/abs/2602.13294",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "How Multimodal Large Language Models Support Access to Visual Information: A Diary Study With Blind and Low Vision People",
    "summary": "arXiv:2602.13469v2 Announce Type: replace-cross Abstract: Multimodal large language models (MLLMs) are changing how Blind and Low Vision (BLV) people access visual information. Unlike traditional visual interpretation tools that only provide descriptions, MLLM-enabled applications offer conversational assistance, where users can ask questions to ob",
    "url": "https://arxiv.org/abs/2602.13469",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "CT-Bench: A Benchmark for Multimodal Lesion Understanding in Computed Tomography",
    "summary": "arXiv:2602.14879v2 Announce Type: replace-cross Abstract: Artificial intelligence (AI) can automatically delineate lesions on computed tomography (CT) and generate radiology report content, yet progress is limited by the scarcity of publicly available CT datasets with lesion-level annotations. To bridge this gap, we introduce CT-Bench, a first-of-i",
    "url": "https://arxiv.org/abs/2602.14879",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Accelerating Large-Scale Dataset Distillation via Exploration-Exploitation Optimization",
    "summary": "arXiv:2602.15277v2 Announce Type: replace-cross Abstract: Dataset distillation compresses the original data into compact synthetic datasets, reducing training time and storage while retaining model performance, enabling deployment under limited resources. Although recent decoupling-based distillation methods enable dataset distillation at large sca",
    "url": "https://arxiv.org/abs/2602.15277",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Logit Distance Bounds Representational Similarity",
    "summary": "arXiv:2602.15438v2 Announce Type: replace-cross Abstract: For a broad family of discriminative models that includes autoregressive language models, identifiability results imply that if two models induce the same conditional distributions, then their internal representations agree up to an invertible linear transformation. We ask whether an analogo",
    "url": "https://arxiv.org/abs/2602.15438",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Intracoronary Optical Coherence Tomography Image Processing and Vessel Classification Using Machine Learning",
    "summary": "arXiv:2602.15579v2 Announce Type: replace-cross Abstract: Intracoronary Optical Coherence Tomography (OCT) enables high-resolution visualization of coronary vessel anatomy but presents challenges due to noise, imaging artifacts, and complex tissue structures. This paper proposes a fully automated pipeline for vessel segmentation and classification ",
    "url": "https://arxiv.org/abs/2602.15579",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Building Safe and Deployable Clinical Natural Language Processing under Temporal Leakage Constraints",
    "summary": "arXiv:2602.15852v2 Announce Type: replace-cross Abstract: Clinical natural language processing (NLP) models have shown promise for supporting hospital discharge planning by leveraging narrative clinical documentation. However, note-based models are particularly vulnerable to temporal and lexical leakage, where documentation artifacts encode future ",
    "url": "https://arxiv.org/abs/2602.15852",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Resp-Agent: An Agent-Based System for Multimodal Respiratory Sound Generation and Disease Diagnosis",
    "summary": "arXiv:2602.15909v2 Announce Type: replace-cross Abstract: Deep learning-based respiratory auscultation is currently hindered by two fundamental challenges: (i) inherent information loss, as converting signals into spectrograms discards transient acoustic events and clinical context; (ii) limited data availability, exacerbated by severe class imbala",
    "url": "https://arxiv.org/abs/2602.15909",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Omni-iEEG: A Large-Scale, Comprehensive iEEG Dataset and Benchmark for Epilepsy Research",
    "summary": "arXiv:2602.16072v2 Announce Type: replace-cross Abstract: Epilepsy affects over 50 million people worldwide, and one-third of patients suffer drug-resistant seizures where surgery offers the best chance of seizure freedom. Accurate localization of the epileptogenic zone (EZ) relies on intracranial EEG (iEEG). Clinical workflows, however, remain con",
    "url": "https://arxiv.org/abs/2602.16072",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Conjugate Learning Theory: Uncovering the Mechanisms of Trainability and Generalization in Deep Neural Networks",
    "summary": "arXiv:2602.16177v2 Announce Type: replace-cross Abstract: In this work, we propose a notion of practical learnability grounded in finite sample settings, and develop a conjugate learning theoretical framework based on convex conjugate duality to characterize this learnability property. Building on this foundation, we demonstrate that training deep ",
    "url": "https://arxiv.org/abs/2602.16177",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Are LLMs Ready to Replace Bangla Annotators?",
    "summary": "arXiv:2602.16241v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are increasingly used as automated annotators to scale dataset creation, yet their reliability as unbiased annotators--especially for low-resource and identity-sensitive settings--remains poorly understood. In this work, we study the behavior of LLMs as zero-shot",
    "url": "https://arxiv.org/abs/2602.16241",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "RoboGene: Boosting VLA Pre-training via Diversity-Driven Agentic Framework for Real-World Task Generation",
    "summary": "arXiv:2602.16444v2 Announce Type: replace-cross Abstract: The pursuit of general-purpose robotic manipulation is hindered by the scarcity of diverse, real-world interaction data. Unlike data collection from web in vision or language, robotic data collection is an active process incurring prohibitive physical costs. Consequently, automated task cura",
    "url": "https://arxiv.org/abs/2602.16444",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents",
    "summary": "arXiv:2602.16699v2 Announce Type: replace-cross Abstract: LLMs are increasingly being used for complex problems which are not necessarily resolved in a single response, but require interacting with an environment to acquire information. In these scenarios, LLMs must reason about inherent cost-uncertainty tradeoffs in when to stop exploring and comm",
    "url": "https://arxiv.org/abs/2602.16699",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  },
  {
    "title": "Policy Compiler for Secure Agentic Systems",
    "summary": "arXiv:2602.16708v2 Announce Type: replace-cross Abstract: LLM-based agents are increasingly being deployed in contexts requiring complex authorization policies: customer service protocols, approval workflows, data access restrictions, and regulatory compliance. Embedding these policies in prompts provides no enforcement guarantees. We present PCAS,",
    "url": "https://arxiv.org/abs/2602.16708",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00"
  }
]