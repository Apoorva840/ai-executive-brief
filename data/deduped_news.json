[
  {
    "title": "The Technologies Changing How You’ll Watch the 2026 Winter Olympic Games",
    "summary": "From drones with “first-person” visualization to real-time 360-degree replays and Olympics GPT, get ready to immerse yourself in the Winter Games in Milan and Cortina.",
    "url": "https://www.wired.com/story/the-technologies-changing-how-youll-watch-the-2026-winter-olympic-games/",
    "source": "Wired AI",
    "published_at": "2026-02-07T12:00:00+00:00"
  },
  {
    "title": "Moltbook, the Social Network for AI Agents, Exposed Real Humans’ Data",
    "summary": "Plus: Apple’s Lockdown mode keeps the FBI out of a reporter’s phone, Elon Musk’s Starlink cuts off Russian forces, and more.",
    "url": "https://www.wired.com/story/security-news-this-week-moltbook-the-social-network-for-ai-agents-exposed-real-humans-data/",
    "source": "Wired AI",
    "published_at": "2026-02-07T11:30:00+00:00"
  },
  {
    "title": "Artificial Intelligence as Strange Intelligence: Against Linear Models of Intelligence",
    "summary": "arXiv:2602.04986v1 Announce Type: new Abstract: We endorse and expand upon Susan Schneider's critique of the linear model of AI progress and introduce two novel concepts: \"familiar intelligence\" and \"strange intelligence\". AI intelligence is likely to be strange intelligence, defying familiar patterns of ability and inability, combining superhuman ",
    "url": "https://arxiv.org/abs/2602.04986",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "DeepRead: Document Structure-Aware Reasoning to Enhance Agentic Search",
    "summary": "arXiv:2602.05014v1 Announce Type: new Abstract: With the rapid progress of tool-using and agentic large language models (LLMs), Retrieval-Augmented Generation (RAG) is evolving from one-shot, passive retrieval into multi-turn, decision-driven evidence acquisition. Despite strong results in open-domain settings, existing agentic search frameworks co",
    "url": "https://arxiv.org/abs/2602.05014",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "MINT: Minimal Information Neuro-Symbolic Tree for Objective-Driven Knowledge-Gap Reasoning and Active Elicitation",
    "summary": "arXiv:2602.05048v1 Announce Type: new Abstract: Joint planning through language-based interactions is a key area of human-AI teaming. Planning problems in the open world often involve various aspects of incomplete information and unknowns, e.g., objects involved, human goals/intents -- thus leading to knowledge gaps in joint planning. We consider t",
    "url": "https://arxiv.org/abs/2602.05048",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Evaluating Large Language Models on Solved and Unsolved Problems in Graph Theory: Implications for Computing Education",
    "summary": "arXiv:2602.05059v1 Announce Type: new Abstract: Large Language Models are increasingly used by students to explore advanced material in computer science, including graph theory. As these tools become integrated into undergraduate and graduate coursework, it is important to understand how reliably they support mathematically rigorous thinking. This ",
    "url": "https://arxiv.org/abs/2602.05059",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Towards Reducible Uncertainty Modeling for Reliable Large Language Model Agents",
    "summary": "arXiv:2602.05073v1 Announce Type: new Abstract: Uncertainty quantification (UQ) for large language models (LLMs) is a key building block for safety guardrails of daily LLM applications. Yet, even as LLM agents are increasingly deployed in highly complex tasks, most UQ research still centers on single-turn question-answering. We argue that UQ resear",
    "url": "https://arxiv.org/abs/2602.05073",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Optimizing Mission Planning for Multi-Debris Rendezvous Using Reinforcement Learning with Refueling and Adaptive Collision Avoidance",
    "summary": "arXiv:2602.05075v1 Announce Type: new Abstract: As the orbital environment around Earth becomes increasingly crowded with debris, active debris removal (ADR) missions face significant challenges in ensuring safe operations while minimizing the risk of in-orbit collisions. This study presents a reinforcement learning (RL) based framework to enhance ",
    "url": "https://arxiv.org/abs/2602.05075",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "VERA-MH: Reliability and Validity of an Open-Source AI Safety Evaluation in Mental Health",
    "summary": "arXiv:2602.05088v1 Announce Type: new Abstract: Millions now use leading generative AI chatbots for psychological support. Despite the promise related to availability and scale, the single most pressing question in AI for mental health is whether these tools are safe. The Validation of Ethical and Responsible AI in Mental Health (VERA-MH) evaluatio",
    "url": "https://arxiv.org/abs/2602.05088",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Evaluating Robustness and Adaptability in Learning-Based Mission Planning for Active Debris Removal",
    "summary": "arXiv:2602.05091v1 Announce Type: new Abstract: Autonomous mission planning for Active Debris Removal (ADR) must balance efficiency, adaptability, and strict feasibility constraints on fuel and mission duration. This work compares three planners for the constrained multi-debris rendezvous problem in Low Earth Orbit: a nominal Masked Proximal Policy",
    "url": "https://arxiv.org/abs/2602.05091",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "GAMMS: Graph based Adversarial Multiagent Modeling Simulator",
    "summary": "arXiv:2602.05105v1 Announce Type: new Abstract: As intelligent systems and multi-agent coordination become increasingly central to real-world applications, there is a growing need for simulation tools that are both scalable and accessible. Existing high-fidelity simulators, while powerful, are often computationally expensive and ill-suited for rapi",
    "url": "https://arxiv.org/abs/2602.05105",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Understanding LLM Evaluator Behavior: A Structured Multi-Evaluator Framework for Merchant Risk Assessment",
    "summary": "arXiv:2602.05110v1 Announce Type: new Abstract: Large Language Models (LLMs) are increasingly used as evaluators of reasoning quality, yet their reliability and bias in payments-risk settings remain poorly understood. We introduce a structured multi-evaluator framework for assessing LLM reasoning in Merchant Category Code (MCC)-based merchant risk ",
    "url": "https://arxiv.org/abs/2602.05110",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Democratic Preference Alignment via Sortition-Weighted RLHF",
    "summary": "arXiv:2602.05113v1 Announce Type: new Abstract: Whose values should AI systems learn? Preference based alignment methods like RLHF derive their training signal from human raters, yet these rater pools are typically convenience samples that systematically over represent some demographics and under represent others. We introduce Democratic Preference",
    "url": "https://arxiv.org/abs/2602.05113",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "SocialVeil: Probing Social Intelligence of Language Agents under Communication Barriers",
    "summary": "arXiv:2602.05115v1 Announce Type: new Abstract: Large language models (LLMs) are increasingly evaluated in interactive environments to test their social intelligence. However, existing benchmarks often assume idealized communication between agents, limiting our ability to diagnose whether LLMs can maintain and repair interactions in more realistic,",
    "url": "https://arxiv.org/abs/2602.05115",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "CAST-CKT: Chaos-Aware Spatio-Temporal and Cross-City Knowledge Transfer for Traffic Flow Prediction",
    "summary": "arXiv:2602.05133v1 Announce Type: new Abstract: Traffic prediction in data-scarce, cross-city settings is challenging due to complex nonlinear dynamics and domain shifts. Existing methods often fail to capture traffic's inherent chaotic nature for effective few-shot learning. We propose CAST-CKT, a novel Chaos-Aware Spatio-Temporal and Cross-City K",
    "url": "https://arxiv.org/abs/2602.05133",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "HugRAG: Hierarchical Causal Knowledge Graph Design for RAG",
    "summary": "arXiv:2602.05143v1 Announce Type: new Abstract: Retrieval augmented generation (RAG) has enhanced large language models by enabling access to external knowledge, with graph-based RAG emerging as a powerful paradigm for structured retrieval and reasoning. However, existing graph-based methods often over-rely on surface-level node matching and lack e",
    "url": "https://arxiv.org/abs/2602.05143",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "First Proof",
    "summary": "arXiv:2602.05192v1 Announce Type: new Abstract: To assess the ability of current AI systems to correctly answer research-level mathematics questions, we share a set of ten math questions which have arisen naturally in the research process of the authors. The questions had not been shared publicly until now; the answers are known to the authors of t",
    "url": "https://arxiv.org/abs/2602.05192",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Traceable Cross-Source RAG for Chinese Tibetan Medicine Question Answering",
    "summary": "arXiv:2602.05195v1 Announce Type: new Abstract: Retrieval-augmented generation (RAG) promises grounded question answering, yet domain settings with multiple heterogeneous knowledge bases (KBs) remain challenging. In Chinese Tibetan medicine, encyclopedia entries are often dense and easy to match, which can dominate retrieval even when classics or c",
    "url": "https://arxiv.org/abs/2602.05195",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Surgery: Mitigating Harmful Fine-Tuning for Large Language Models via Attention Sink",
    "summary": "arXiv:2602.05228v1 Announce Type: new Abstract: Harmful fine-tuning can invalidate safety alignment of large language models, exposing significant safety risks. In this paper, we utilize the attention sink mechanism to mitigate harmful fine-tuning. Specifically, we first measure a statistic named \\emph{sink divergence} for each attention head and o",
    "url": "https://arxiv.org/abs/2602.05228",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Explainable AI: A Combined XAI Framework for Explaining Brain Tumour Detection Models",
    "summary": "arXiv:2602.05240v1 Announce Type: new Abstract: This study explores the integration of multiple Explainable AI (XAI) techniques to enhance the interpretability of deep learning models for brain tumour detection. A custom Convolutional Neural Network (CNN) was developed and trained on the BraTS 2021 dataset, achieving 91.24% accuracy in distinguishi",
    "url": "https://arxiv.org/abs/2602.05240",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Automatic Cognitive Task Generation for In-Situ Evaluation of Embodied Agents",
    "summary": "arXiv:2602.05249v1 Announce Type: new Abstract: As general intelligent agents are poised for widespread deployment in diverse households, evaluation tailored to each unique unseen 3D environment has become a critical prerequisite. However, existing benchmarks suffer from severe data contamination and a lack of scene specificity, inadequate for asse",
    "url": "https://arxiv.org/abs/2602.05249",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Beyond Cosine Similarity",
    "summary": "arXiv:2602.05266v1 Announce Type: new Abstract: Cosine similarity, the standard metric for measuring semantic similarity in vector spaces, is mathematically grounded in the Cauchy-Schwarz inequality, which inherently limits it to capturing linear relationships--a constraint that fails to model the complex, nonlinear structures of real-world semanti",
    "url": "https://arxiv.org/abs/2602.05266",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Hallucination-Resistant Security Planning with a Large Language Model",
    "summary": "arXiv:2602.05279v1 Announce Type: new Abstract: Large language models (LLMs) are promising tools for supporting security management tasks, such as incident response planning. However, their unreliability and tendency to hallucinate remain significant challenges. In this paper, we address these challenges by introducing a principled framework for us",
    "url": "https://arxiv.org/abs/2602.05279",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Position: Universal Time Series Foundation Models Rest on a Category Error",
    "summary": "arXiv:2602.05287v1 Announce Type: new Abstract: This position paper argues that the pursuit of \"Universal Foundation Models for Time Series\" rests on a fundamental category error, mistaking a structural Container for a semantic Modality. We contend that because time series hold incompatible generative processes (e.g., finance vs. fluid dynamics), m",
    "url": "https://arxiv.org/abs/2602.05287",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Aspect-Aware MOOC Recommendation in a Heterogeneous Network",
    "summary": "arXiv:2602.05297v1 Announce Type: new Abstract: MOOC recommendation systems have received increasing attention to help learners navigate and select preferred learning content. Traditional methods such as collaborative filtering and content-based filtering suffer from data sparsity and over-specialization. To alleviate these limitations, graph-based",
    "url": "https://arxiv.org/abs/2602.05297",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "PieArena: Frontier Language Agents Achieve MBA-Level Negotiation Performance and Reveal Novel Behavioral Differences",
    "summary": "arXiv:2602.05302v1 Announce Type: new Abstract: We present an in-depth evaluation of LLMs' ability to negotiate, a central business task that requires strategic reasoning, theory of mind, and economic value creation. To do so, we introduce PieArena, a large-scale negotiation benchmark grounded in multi-agent interactions over realistic scenarios dr",
    "url": "https://arxiv.org/abs/2602.05302",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "ProAct: Agentic Lookahead in Interactive Environments",
    "summary": "arXiv:2602.05327v1 Announce Type: new Abstract: Existing Large Language Model (LLM) agents struggle in interactive environments requiring long-horizon planning, primarily due to compounding errors when simulating future states. To address this, we propose ProAct, a framework that enables agents to internalize accurate lookahead reasoning through a ",
    "url": "https://arxiv.org/abs/2602.05327",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "AgentXRay: White-Boxing Agentic Systems via Workflow Reconstruction",
    "summary": "arXiv:2602.05353v1 Announce Type: new Abstract: Large Language Models have shown strong capabilities in complex problem solving, yet many agentic systems remain difficult to interpret and control due to opaque internal workflows. While some frameworks offer explicit architectures for collaboration, many deployed agentic systems operate as black box",
    "url": "https://arxiv.org/abs/2602.05353",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "PATHWAYS: Evaluating Investigation and Context Discovery in AI Web Agents",
    "summary": "arXiv:2602.05354v1 Announce Type: new Abstract: We introduce PATHWAYS, a benchmark of 250 multi-step decision tasks that test whether web-based agents can discover and correctly use hidden contextual information. Across both closed and open models, agents typically navigate to relevant pages but retrieve decisive hidden evidence in only a small fra",
    "url": "https://arxiv.org/abs/2602.05354",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "RaBiT: Residual-Aware Binarization Training for Accurate and Efficient LLMs",
    "summary": "arXiv:2602.05367v1 Announce Type: new Abstract: Efficient deployment of large language models (LLMs) requires extreme quantization, forcing a critical trade-off between low-bit efficiency and performance. Residual binarization enables hardware-friendly, matmul-free inference by stacking binary ($\\pm$1) layers, but is plagued by pathological feature",
    "url": "https://arxiv.org/abs/2602.05367",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Clinical Validation of Medical-based Large Language Model Chatbots on Ophthalmic Patient Queries with LLM-based Evaluation",
    "summary": "arXiv:2602.05381v1 Announce Type: new Abstract: Domain specific large language models are increasingly used to support patient education, triage, and clinical decision making in ophthalmology, making rigorous evaluation essential to ensure safety and accuracy. This study evaluated four small medical LLMs Meerkat-7B, BioMistral-7B, OpenBioLLM-8B, an",
    "url": "https://arxiv.org/abs/2602.05381",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Advancing Opinion Dynamics Modeling with Neural Diffusion-Convection-Reaction Equation",
    "summary": "arXiv:2602.05403v1 Announce Type: new Abstract: Advanced opinion dynamics modeling is vital for deciphering social behavior, emphasizing its role in mitigating polarization and securing cyberspace. To synergize mechanistic interpretability with data-driven flexibility, recent studies have explored the integration of Physics-Informed Neural Networks",
    "url": "https://arxiv.org/abs/2602.05403",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "H-AdminSim: A Multi-Agent Simulator for Realistic Hospital Administrative Workflows with FHIR Integration",
    "summary": "arXiv:2602.05407v1 Announce Type: new Abstract: Hospital administration departments handle a wide range of operational tasks and, in large hospitals, process over 10,000 requests per day, driving growing interest in LLM-based automation. However, prior work has focused primarily on patient--physician interactions or isolated administrative subtasks",
    "url": "https://arxiv.org/abs/2602.05407",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "THOR: Inductive Link Prediction over Hyper-Relational Knowledge Graphs",
    "summary": "arXiv:2602.05424v1 Announce Type: new Abstract: Knowledge graphs (KGs) have become a key ingredient supporting a variety of applications. Beyond the traditional triplet representation of facts where a relation connects two entities, modern KGs observe an increasing number of hyper-relational facts, where an arbitrary number of qualifiers associated",
    "url": "https://arxiv.org/abs/2602.05424",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "M$^2$-Miner: Multi-Agent Enhanced MCTS for Mobile GUI Agent Data Mining",
    "summary": "arXiv:2602.05429v1 Announce Type: new Abstract: Graphical User Interface (GUI) agent is pivotal to advancing intelligent human-computer interaction paradigms. Constructing powerful GUI agents necessitates the large-scale annotation of high-quality user-behavior trajectory data (i.e., intent-trajectory pairs) for training. However, manual annotation",
    "url": "https://arxiv.org/abs/2602.05429",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Day-Ahead Electricity Price Forecasting for Volatile Markets Using Foundation Models with Regularization Strategy",
    "summary": "arXiv:2602.05430v1 Announce Type: new Abstract: Electricity price forecasting (EPF) is essential for energy markets stakeholders (e.g. grid operators, energy traders, policymakers) but remains challenging due to the inherent volatility and nonlinearity of price signals. Traditional statistical and deep learning (DL) models often struggle to capture",
    "url": "https://arxiv.org/abs/2602.05430",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Refine and Purify: Orthogonal Basis Optimization with Null-Space Denoising for Conditional Representation Learning",
    "summary": "arXiv:2602.05464v1 Announce Type: new Abstract: Conditional representation learning aims to extract criterion-specific features for customized tasks. Recent studies project universal features onto the conditional feature subspace spanned by an LLM-generated text basis to obtain conditional representations. However, such methods face two key limitat",
    "url": "https://arxiv.org/abs/2602.05464",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "ALIVE: Awakening LLM Reasoning via Adversarial Learning and Instructive Verbal Evaluation",
    "summary": "arXiv:2602.05472v1 Announce Type: new Abstract: The quest for expert-level reasoning in Large Language Models (LLMs) has been hampered by a persistent \\textit{reward bottleneck}: traditional reinforcement learning (RL) relies on scalar rewards that are \\textbf{costly} to scale, \\textbf{brittle} across domains, and \\textbf{blind} to the underlying l",
    "url": "https://arxiv.org/abs/2602.05472",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Phi-Former: A Pairwise Hierarchical Approach for Compound-Protein Interactions Prediction",
    "summary": "arXiv:2602.05479v1 Announce Type: new Abstract: Drug discovery remains time-consuming, labor-intensive, and expensive, often requiring years and substantial investment per drug candidate. Predicting compound-protein interactions (CPIs) is a critical component in this process, enabling the identification of molecular interactions between drug candid",
    "url": "https://arxiv.org/abs/2602.05479",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "SDFP: Speculative Decoding with FIT-Pruned Models for Training-Free and Plug-and-Play LLM Acceleration",
    "summary": "arXiv:2602.05499v1 Announce Type: new Abstract: Large language models (LLMs) underpin interactive multimedia applications such as captioning, retrieval, recommendation, and creative content generation, yet their autoregressive decoding incurs substantial latency. Speculative decoding reduces latency using a lightweight draft model, but deployment i",
    "url": "https://arxiv.org/abs/2602.05499",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "A Unified Multimodal Framework for Dataset Construction and Model-Based Diagnosis of Ameloblastoma",
    "summary": "arXiv:2602.05515v1 Announce Type: new Abstract: Artificial intelligence (AI)-enabled diagnostics in maxillofacial pathology require structured, high-quality multimodal datasets. However, existing resources provide limited ameloblastoma coverage and lack the format consistency needed for direct model training. We present a newly curated multimodal d",
    "url": "https://arxiv.org/abs/2602.05515",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Split Personality Training: Revealing Latent Knowledge Through Alternate Personalities",
    "summary": "arXiv:2602.05532v1 Announce Type: new Abstract: Detecting misalignment in large language models is challenging because models may learn to conceal misbehavior during training. Standard auditing techniques fall short: black-box methods often cannot distinguish misaligned outputs from benign ones, and mechanistic interpretability does not scale with ",
    "url": "https://arxiv.org/abs/2602.05532",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Conditional Diffusion Guidance under Hard Constraint: A Stochastic Analysis Approach",
    "summary": "arXiv:2602.05533v1 Announce Type: new Abstract: We study conditional generation in diffusion models under hard constraints, where generated samples must satisfy prescribed events with probability one. Such constraints arise naturally in safety-critical applications and in rare-event simulation, where soft or reward-based guidance methods offer no g",
    "url": "https://arxiv.org/abs/2602.05533",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Reasoning-guided Collaborative Filtering with Language Models for Explainable Recommendation",
    "summary": "arXiv:2602.05544v1 Announce Type: new Abstract: Large Language Models (LLMs) exhibit potential for explainable recommendation systems but overlook collaborative signals, while prevailing methods treat recommendation and explanation as separate tasks, resulting in a memory footprint. We present RGCF-XRec, a hybrid framework that introduces reasoning",
    "url": "https://arxiv.org/abs/2602.05544",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "TangramSR: Can Vision-Language Models Reason in Continuous Geometric Space?",
    "summary": "arXiv:2602.05570v1 Announce Type: new Abstract: Humans excel at spatial reasoning tasks like Tangram puzzle assembly through cognitive processes involving mental rotation, iterative refinement, and visual feedback. Inspired by how humans solve Tangram puzzles through trial-and-error, observation, and correction, we design a framework that models th",
    "url": "https://arxiv.org/abs/2602.05570",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Emulating Aggregate Human Choice Behavior and Biases with GPT Conversational Agents",
    "summary": "arXiv:2602.05597v1 Announce Type: new Abstract: Cognitive biases often shape human decisions. While large language models (LLMs) have been shown to reproduce well-known biases, a more critical question is whether LLMs can predict biases at the individual level and emulate the dynamics of biased human behavior when contextual factors, such as cognit",
    "url": "https://arxiv.org/abs/2602.05597",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "BhashaSetu: Cross-Lingual Knowledge Transfer from High-Resource to Extreme Low-Resource Languages",
    "summary": "arXiv:2602.05599v1 Announce Type: new Abstract: Despite remarkable advances in natural language processing, developing effective systems for low-resource languages remains a formidable challenge, with performances typically lagging far behind high-resource counterparts due to data scarcity and insufficient linguistic resources. Cross-lingual knowle",
    "url": "https://arxiv.org/abs/2602.05599",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Reactive Knowledge Representation and Asynchronous Reasoning",
    "summary": "arXiv:2602.05625v1 Announce Type: new Abstract: Exact inference in complex probabilistic models often incurs prohibitive computational costs. This challenge is particularly acute for autonomous agents in dynamic environments that require frequent, real-time belief updates. Existing methods are often inefficient for ongoing reasoning, as they re-eva",
    "url": "https://arxiv.org/abs/2602.05625",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Generative Ontology: When Structured Knowledge Learns to Create",
    "summary": "arXiv:2602.05636v1 Announce Type: new Abstract: Traditional ontologies excel at describing domain structure but cannot generate novel artifacts. Large language models generate fluently but produce outputs that lack structural validity, hallucinating mechanisms without components, goals without end conditions. We introduce Generative Ontology, a fra",
    "url": "https://arxiv.org/abs/2602.05636",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Graph-based Agent Memory: Taxonomy, Techniques, and Applications",
    "summary": "arXiv:2602.05665v1 Announce Type: new Abstract: Memory emerges as the core module in the Large Language Model (LLM)-based agents for long-horizon complex tasks (e.g., multi-turn dialogue, game playing, scientific discovery), where memory can enable knowledge accumulation, iterative reasoning and self-evolution. Among diverse paradigms, graph stands",
    "url": "https://arxiv.org/abs/2602.05665",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Determining Energy Efficiency Sweet Spots in Production LLM Inference",
    "summary": "arXiv:2602.05695v1 Announce Type: new Abstract: Large Language Models (LLMs) inference is central in modern AI applications, making it critical to understand their energy footprint. Existing approaches typically estimate energy consumption through simple linear functions of input and output sequence lengths, yet our observations reveal clear Energy",
    "url": "https://arxiv.org/abs/2602.05695",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Nonlinearity as Rank: Generative Low-Rank Adapter with Radial Basis Functions",
    "summary": "arXiv:2602.05709v1 Announce Type: new Abstract: Low-rank adaptation (LoRA) approximates the update of a pretrained weight matrix using the product of two low-rank matrices. However, standard LoRA follows an explicit-rank paradigm, where increasing model capacity requires adding more rows or columns (i.e., basis vectors) to the low-rank matrices, le",
    "url": "https://arxiv.org/abs/2602.05709",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Anchored Policy Optimization: Mitigating Exploration Collapse Via Support-Constrained Rectification",
    "summary": "arXiv:2602.05717v1 Announce Type: new Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is increasingly viewed as a tree pruning mechanism. However, we identify a systemic pathology termed Recursive Space Contraction (RSC), an irreversible collapse driven by the combined dynamics of positive sharpening and negative squeezing, where th",
    "url": "https://arxiv.org/abs/2602.05717",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Mitigating Hallucination in Financial Retrieval-Augmented Generation via Fine-Grained Knowledge Verification",
    "summary": "arXiv:2602.05723v1 Announce Type: new Abstract: In financial Retrieval-Augmented Generation (RAG) systems, models frequently rely on retrieved documents to generate accurate responses due to the time-sensitive nature of the financial domain. While retrieved documents help address knowledge gaps, model-generated responses still suffer from hallucina",
    "url": "https://arxiv.org/abs/2602.05723",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "LeakBoost: Perceptual-Loss-Based Membership Inference Attack",
    "summary": "arXiv:2602.05748v1 Announce Type: new Abstract: Membership inference attacks (MIAs) aim to determine whether a sample was part of a model's training set, posing serious privacy risks for modern machine-learning systems. Existing MIAs primarily rely on static indicators, such as loss or confidence, and do not fully leverage the dynamic behavior of m",
    "url": "https://arxiv.org/abs/2602.05748",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "RocqSmith: Can Automatic Optimization Forge Better Proof Agents?",
    "summary": "arXiv:2602.05762v1 Announce Type: new Abstract: This work studies the applicability of automatic AI agent optimization methods to real-world agents in formal verification settings, focusing on automated theorem proving in Rocq as a representative and challenging domain. We evaluate how different automatic agent optimizers perform when applied to th",
    "url": "https://arxiv.org/abs/2602.05762",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "RL-VLA$^3$: Reinforcement Learning VLA Accelerating via Full Asynchronism",
    "summary": "arXiv:2602.05765v1 Announce Type: new Abstract: In recent years, Vision-Language-Action (VLA) models have emerged as a crucial pathway towards general embodied intelligence, yet their training efficiency has become a key bottleneck. Although existing reinforcement learning (RL)-based training frameworks like RLinf can enhance model generalization, ",
    "url": "https://arxiv.org/abs/2602.05765",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "FiMI: A Domain-Specific Language Model for Indian Finance Ecosystem",
    "summary": "arXiv:2602.05794v1 Announce Type: new Abstract: We present FiMI (Finance Model for India), a domain-specialized financial language model developed for Indian digital payment systems. We develop two model variants: FiMI Base and FiMI Instruct. FiMI adapts the Mistral Small 24B architecture through a multi-stage training pipeline, beginning with cont",
    "url": "https://arxiv.org/abs/2602.05794",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "NEX: Neuron Explore-Exploit Scoring for Label-Free Chain-of-Thought Selection and Model Ranking",
    "summary": "arXiv:2602.05805v1 Announce Type: new Abstract: Large language models increasingly spend inference compute sampling multiple chain-of-thought traces or searching over merged checkpoints. This shifts the bottleneck from generation to selection, often without supervision on the target distribution. We show entropy-based exploration proxies follow an ",
    "url": "https://arxiv.org/abs/2602.05805",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "STProtein: predicting spatial protein expression from multi-omics data",
    "summary": "arXiv:2602.05811v1 Announce Type: new Abstract: The integration of spatial multi-omics data from single tissues is crucial for advancing biological research. However, a significant data imbalance impedes progress: while spatial transcriptomics data is relatively abundant, spatial proteomics data remains scarce due to technical limitations and high ",
    "url": "https://arxiv.org/abs/2602.05811",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "TKG-Thinker: Towards Dynamic Reasoning over Temporal Knowledge Graphs via Agentic Reinforcement Learning",
    "summary": "arXiv:2602.05818v1 Announce Type: new Abstract: Temporal knowledge graph question answering (TKGQA) aims to answer time-sensitive questions by leveraging temporal knowledge bases. While Large Language Models (LLMs) demonstrate significant potential in TKGQA, current prompting strategies constrain their efficacy in two primary ways. First, they are ",
    "url": "https://arxiv.org/abs/2602.05818",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Learning Compact Boolean Networks",
    "summary": "arXiv:2602.05830v1 Announce Type: new Abstract: Floating-point neural networks dominate modern machine learning but incur substantial inference cost, motivating interest in Boolean networks for resource-constrained settings. However, learning compact and accurate Boolean networks is challenging due to their combinatorial nature. In this work, we ad",
    "url": "https://arxiv.org/abs/2602.05830",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "OmniVideo-R1: Reinforcing Audio-visual Reasoning with Query Intention and Modality Attention",
    "summary": "arXiv:2602.05847v1 Announce Type: new Abstract: While humans perceive the world through diverse modalities that operate synergistically to support a holistic understanding of their surroundings, existing omnivideo models still face substantial challenges on audio-visual understanding tasks. In this paper, we propose OmniVideo-R1, a novel reinforced",
    "url": "https://arxiv.org/abs/2602.05847",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "BABE: Biology Arena BEnchmark",
    "summary": "arXiv:2602.05857v1 Announce Type: new Abstract: The rapid evolution of large language models (LLMs) has expanded their capabilities from basic dialogue to advanced scientific reasoning. However, existing benchmarks in biology often fail to assess a critical skill required of researchers: the ability to integrate experimental results with contextual",
    "url": "https://arxiv.org/abs/2602.05857",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Beyond Manual Planning: Seating Allocation for Large Organizations",
    "summary": "arXiv:2602.05875v1 Announce Type: new Abstract: We introduce the Hierarchical Seating Allocation Problem (HSAP) which addresses the optimal assignment of hierarchically structured organizational teams to physical seating arrangements on a floor plan. This problem is driven by the necessity for large organizations with large hierarchies to ensure th",
    "url": "https://arxiv.org/abs/2602.05875",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Agent2Agent Threats in Safety-Critical LLM Assistants: A Human-Centric Taxonomy",
    "summary": "arXiv:2602.05877v1 Announce Type: new Abstract: The integration of Large Language Model (LLM)-based conversational agents into vehicles creates novel security challenges at the intersection of agentic AI, automotive safety, and inter-agent communication. As these intelligent assistants coordinate with external services via protocols such as Google'",
    "url": "https://arxiv.org/abs/2602.05877",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "A Guide to Large Language Models in Modeling and Simulation: From Core Techniques to Critical Challenges",
    "summary": "arXiv:2602.05883v1 Announce Type: new Abstract: Large language models (LLMs) have rapidly become familiar tools to researchers and practitioners. Concepts such as prompting, temperature, or few-shot examples are now widely recognized, and LLMs are increasingly used in Modeling & Simulation (M&amp;S) workflows. However, practices that appear straigh",
    "url": "https://arxiv.org/abs/2602.05883",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Quantum Reinforcement Learning with Transformers for the Capacitated Vehicle Routing Problem",
    "summary": "arXiv:2602.05920v1 Announce Type: new Abstract: This paper addresses the Capacitated Vehicle Routing Problem (CVRP) by comparing classical and quantum Reinforcement Learning (RL) approaches. An Advantage Actor-Critic (A2C) agent is implemented in classical, full quantum, and hybrid variants, integrating transformer architectures to capture the rela",
    "url": "https://arxiv.org/abs/2602.05920",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Geographically-aware Transformer-based Traffic Forecasting for Urban Motorway Digital Twins",
    "summary": "arXiv:2602.05983v1 Announce Type: new Abstract: The operational effectiveness of digital-twin technology in motorway traffic management depends on the availability of a continuous flow of high-resolution real-time traffic data. To function as a proactive decision-making support layer within traffic management, a digital twin must also incorporate p",
    "url": "https://arxiv.org/abs/2602.05983",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Speech Emotion Recognition Leveraging OpenAI's Whisper Representations and Attentive Pooling Methods",
    "summary": "arXiv:2602.06000v1 Announce Type: new Abstract: Speech Emotion Recognition (SER) research has faced limitations due to the lack of standard and sufficiently large datasets. Recent studies have leveraged pre-trained models to extract features for downstream tasks such as SER. This work explores the capabilities of Whisper, a pre-trained ASR system, ",
    "url": "https://arxiv.org/abs/2602.06000",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions",
    "summary": "arXiv:2602.06008v1 Announce Type: new Abstract: Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We introduce AgenticPay, a benchmark and simulation frame",
    "url": "https://arxiv.org/abs/2602.06008",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Learning Event-Based Shooter Models from Virtual Reality Experiments",
    "summary": "arXiv:2602.06023v1 Announce Type: new Abstract: Virtual reality (VR) has emerged as a powerful tool for evaluating school security measures in high-risk scenarios such as school shootings, offering experimental control and high behavioral fidelity. However, assessing new interventions in VR requires recruiting new participant cohorts for each condi",
    "url": "https://arxiv.org/abs/2602.06023",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "DyTopo: Dynamic Topology Routing for Multi-Agent Reasoning via Semantic Matching",
    "summary": "arXiv:2602.06039v1 Announce Type: new Abstract: Multi-agent systems built from prompted large language models can improve multi-round reasoning, yet most existing pipelines rely on fixed, trajectory-wide communication patterns that are poorly matched to the stage-dependent needs of iterative problem solving. We introduce DyTopo, a manager-guided mu",
    "url": "https://arxiv.org/abs/2602.06039",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Cold Start Problem: An Experimental Study of Knowledge Tracing Models with New Students",
    "summary": "arXiv:2505.21517v1 Announce Type: cross Abstract: KnowledgeTracing (KT) involves predicting students' knowledge states based on their interactions with Intelligent Tutoring Systems (ITS). A key challenge is the cold start problem, accurately predicting knowledge for new students with minimal interaction data. Unlike prior work, which typically trai",
    "url": "https://arxiv.org/abs/2505.21517",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Denoising diffusion networks for normative modeling in neuroimaging",
    "summary": "arXiv:2602.04886v1 Announce Type: cross Abstract: Normative modeling estimates reference distributions of biological measures conditional on covariates, enabling centiles and clinically interpretable deviation scores to be derived. Most neuroimaging pipelines fit one model per imaging-derived phenotype (IDP), which scales well but discards multivar",
    "url": "https://arxiv.org/abs/2602.04886",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "A General-Purpose Diversified 2D Seismic Image Dataset from NAMSS",
    "summary": "arXiv:2602.04890v1 Announce Type: cross Abstract: We introduce the Unicamp-NAMSS dataset, a large, diverse, and geographically distributed collection of migrated 2D seismic sections designed to support modern machine learning research in geophysics. We constructed the dataset from the National Archive of Marine Seismic Surveys (NAMSS), which contai",
    "url": "https://arxiv.org/abs/2602.04890",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Doc2Spec: Synthesizing Formal Programming Specifications from Natural Language via Grammar Induction",
    "summary": "arXiv:2602.04892v1 Announce Type: cross Abstract: Ensuring that API implementations and usage comply with natural language programming rules is critical for software correctness, security, and reliability. Formal verification can provide strong guarantees but requires precise specifications, which are difficult and costly to write manually. To addr",
    "url": "https://arxiv.org/abs/2602.04892",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "A Causal Perspective for Enhancing Jailbreak Attack and Defense",
    "summary": "arXiv:2602.04893v1 Announce Type: cross Abstract: Uncovering the mechanisms behind \"jailbreaks\" in large language models (LLMs) is crucial for enhancing their safety and reliability, yet these mechanisms remain poorly understood. Existing studies predominantly analyze jailbreak prompts by probing latent representations, often overlooking the causal",
    "url": "https://arxiv.org/abs/2602.04893",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Extracting Recurring Vulnerabilities from Black-Box LLM-Generated Software",
    "summary": "arXiv:2602.04894v1 Announce Type: cross Abstract: LLMs are increasingly used for code generation, but their outputs often follow recurring templates that can induce predictable vulnerabilities. We study \\emph{vulnerability persistence} in LLM-generated software and introduce \\emph{Feature--Security Table (FSTab)} with two components. First, FSTab e",
    "url": "https://arxiv.org/abs/2602.04894",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Steering Externalities: Benign Activation Steering Unintentionally Increases Jailbreak Risk for Large Language Models",
    "summary": "arXiv:2602.04896v1 Announce Type: cross Abstract: Activation steering is a practical post-training model alignment technique to enhance the utility of Large Language Models (LLMs). Prior to deploying a model as a service, developers can steer a pre-trained model toward specific behavioral objectives, such as compliance or instruction adherence, wit",
    "url": "https://arxiv.org/abs/2602.04896",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Semantic-level Backdoor Attack against Text-to-Image Diffusion Models",
    "summary": "arXiv:2602.04898v1 Announce Type: cross Abstract: Text-to-image (T2I) diffusion models are widely adopted for their strong generative capabilities, yet remain vulnerable to backdoor attacks. Existing attacks typically rely on fixed textual triggers and single-entity backdoor targets, making them highly susceptible to enumeration-based input defense",
    "url": "https://arxiv.org/abs/2602.04898",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Phantom Transfer: Data-level Defences are Insufficient Against Data Poisoning",
    "summary": "arXiv:2602.04899v1 Announce Type: cross Abstract: We present a data poisoning attack -- Phantom Transfer -- with the property that, even if you know precisely how the poison was placed into an otherwise benign dataset, you cannot filter it out. We achieve this by modifying subliminal learning to work in real-world contexts and demonstrate that the ",
    "url": "https://arxiv.org/abs/2602.04899",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Evaluating Kubernetes Performance for GenAI Inference: From Automatic Speech Recognition to LLM Summarization",
    "summary": "arXiv:2602.04900v1 Announce Type: cross Abstract: As Generative AI (GenAI), particularly inference, rapidly emerges as a dominant workload category, the Kubernetes ecosystem is proactively evolving to natively support its unique demands. This industry paper demonstrates how emerging Kubernetes-native projects can be combined to deliver the benefits",
    "url": "https://arxiv.org/abs/2602.04900",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Momentum Attention: The Physics of In-Context Learning and Spectral Forensics for Mechanistic Interpretability",
    "summary": "arXiv:2602.04902v1 Announce Type: cross Abstract: The Mechanistic Interpretability (MI) program has mapped the Transformer as a precise computational graph. We extend this graph with a conservation law and time-varying AC dynamics, viewing it as a physical circuit. We introduce Momentum Attention, a symplectic augmentation embedding physical priors",
    "url": "https://arxiv.org/abs/2602.04902",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "DCER: Dual-Stage Compression and Energy-Based Reconstruction",
    "summary": "arXiv:2602.04904v1 Announce Type: cross Abstract: Multimodal fusion faces two robustness challenges: noisy inputs degrade representation quality, and missing modalities cause prediction failures. We propose DCER, a unified framework addressing both challenges through dual-stage compression and energy-based reconstruction. The compression stage oper",
    "url": "https://arxiv.org/abs/2602.04904",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Physics as the Inductive Bias for Causal Discovery",
    "summary": "arXiv:2602.04907v1 Announce Type: cross Abstract: Causal discovery is often a data-driven paradigm to analyze complex real-world systems. In parallel, physics-based models such as ordinary differential equations (ODEs) provide mechanistic structure for many dynamical processes. Integrating these paradigms potentially allows physical knowledge to ac",
    "url": "https://arxiv.org/abs/2602.04907",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Temporal Pair Consistency for Variance-Reduced Flow Matching",
    "summary": "arXiv:2602.04908v1 Announce Type: cross Abstract: Continuous-time generative models, such as diffusion models, flow matching, and rectified flow, learn time-dependent vector fields but are typically trained with objectives that treat timesteps independently, leading to high estimator variance and inefficient sampling. Prior approaches mitigate this",
    "url": "https://arxiv.org/abs/2602.04908",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "A logical re-conception of neural networks: Hamiltonian bitwise part-whole architecture",
    "summary": "arXiv:2602.04911v1 Announce Type: cross Abstract: We introduce a simple initial working system in which relations (such as part-whole) are directly represented via an architecture with operating and learning rules fundamentally distinct from standard artificial neural network methods. Arbitrary data are straightforwardly encoded as graphs whose edg",
    "url": "https://arxiv.org/abs/2602.04911",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "A$^2$-LLM: An End-to-end Conversational Audio Avatar Large Language Model",
    "summary": "arXiv:2602.04913v1 Announce Type: cross Abstract: Developing expressive and responsive conversational digital humans is a cornerstone of next-generation human-computer interaction. While large language models (LLMs) have significantly enhanced dialogue capabilities, most current systems still rely on cascaded architectures that connect independent ",
    "url": "https://arxiv.org/abs/2602.04913",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "SLAY: Geometry-Aware Spherical Linearized Attention with Yat-Kernel",
    "summary": "arXiv:2602.04915v1 Announce Type: cross Abstract: We propose a new class of linear-time attention mechanisms based on a relaxed and computationally efficient formulation of the recently introduced E-Product, often referred to as the Yat-kernel (Bouhsine, 2025). The resulting interactions are geometry-aware and inspired by inverse-square interaction",
    "url": "https://arxiv.org/abs/2602.04915",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Internalizing LLM Reasoning via Discovery and Replay of Latent Actions",
    "summary": "arXiv:2602.04925v1 Announce Type: cross Abstract: The internalization of chain-of-thought processes into hidden states has emerged as a highly efficient paradigm for scaling test-time compute. However, existing activation steering methods rely on static control vectors that fail to adapt to the non-stationary evolution of complex reasoning tasks. T",
    "url": "https://arxiv.org/abs/2602.04925",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "PriMod4AI: Lifecycle-Aware Privacy Threat Modeling for AI Systems using LLM",
    "summary": "arXiv:2602.04927v1 Announce Type: cross Abstract: Artificial intelligence systems introduce complex privacy risks throughout their lifecycle, especially when processing sensitive or high-dimensional data. Beyond the seven traditional privacy threat categories defined by the LINDDUN framework, AI systems are also exposed to model-centric privacy att",
    "url": "https://arxiv.org/abs/2602.04927",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Attack Selection Reduces Safety in Concentrated AI Control Settings against Trusted Monitoring",
    "summary": "arXiv:2602.04930v1 Announce Type: cross Abstract: Future AI deployments will likely be monitored for malicious behaviour. The ability of these AIs to subvert monitors by adversarially selecting against them - attack selection - is particularly concerning. To study this, we let a red team create attack policies that attempt to insert attacks into co",
    "url": "https://arxiv.org/abs/2602.04930",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Depth-Wise Emergence of Prediction-Centric Geometry in Large Language Models",
    "summary": "arXiv:2602.04931v1 Announce Type: cross Abstract: We show that decoder-only large language models exhibit a depth-wise transition from context-processing to prediction-forming phases of computation accompanied by a reorganization of representational geometry. Using a unified framework combining geometric analysis with mechanistic intervention, we d",
    "url": "https://arxiv.org/abs/2602.04931",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "ASA: Activation Steering for Tool-Calling Domain Adaptation",
    "summary": "arXiv:2602.04935v1 Announce Type: cross Abstract: For real-world deployment of general-purpose LLM agents, the core challenge is often not tool use itself, but efficient domain adaptation under rapidly evolving toolsets, APIs, and protocols. Repeated LoRA or SFT across domains incurs exponentially growing training and maintenance costs, while promp",
    "url": "https://arxiv.org/abs/2602.04935",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Linear Model Merging Unlocks Simple and Scalable Multimodal Data Mixture Optimization",
    "summary": "arXiv:2602.04937v1 Announce Type: cross Abstract: Selecting the best data mixture is critical for successful Supervised Fine-Tuning (SFT) of Multimodal Large Language Models. However, determining the optimal mixture weights across multiple domain-specific datasets remains a significant bottleneck due to the combinatorial search space and the high c",
    "url": "https://arxiv.org/abs/2602.04937",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Privileged Information Distillation for Language Models",
    "summary": "arXiv:2602.04942v1 Announce Type: cross Abstract: Training-time privileged information (PI) can enable language models to succeed on tasks they would otherwise fail, making it a powerful tool for reinforcement learning in hard, long-horizon settings. However, transferring capabilities learned with PI to policies that must act without it at inferenc",
    "url": "https://arxiv.org/abs/2602.04942",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Graph--Theoretic Analysis of Phase Optimization Complexity in Variational Wave Functions for Heisenberg Antiferromagnets",
    "summary": "arXiv:2602.04943v1 Announce Type: cross Abstract: Despite extensive study, the phase structure of the wavefunctions in frustrated Heisenberg antiferromagnets (HAF) is not yet systematically characterized. In this work, we represent the Hilbert space of an HAF as a weighted graph, which we term the Hilbert graph (HG), whose vertices are spin configu",
    "url": "https://arxiv.org/abs/2602.04943",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Smart Diagnosis and Early Intervention in PCOS: A Deep Learning Approach to Women's Reproductive Health",
    "summary": "arXiv:2602.04944v1 Announce Type: cross Abstract: Polycystic Ovary Syndrome (PCOS) is a widespread disorder in women of reproductive age, characterized by a hormonal imbalance, irregular periods, and multiple ovarian cysts. Infertility, metabolic syndrome, and cardiovascular risks are long-term complications that make early detection essential. In ",
    "url": "https://arxiv.org/abs/2602.04944",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Stochastic hierarchical data-driven optimization: application to plasma-surface kinetics",
    "summary": "arXiv:2602.04975v1 Announce Type: cross Abstract: This work introduces a stochastic hierarchical optimization framework inspired by Sloppy Model theory for the efficient calibration of physical models. Central to this method is the use of a reduced Hessian approximation, which identifies and targets the stiff parameter subspace using minimal simula",
    "url": "https://arxiv.org/abs/2602.04975",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "AI-Based Detection of In-Treatment Changes from Prostate MR-Linac Images",
    "summary": "arXiv:2602.04983v1 Announce Type: cross Abstract: Purpose: To investigate whether routinely acquired longitudinal MR-Linac images can be leveraged to characterize treatment-induced changes during radiotherapy, particularly subtle inter-fraction changes over short intervals (average of 2 days). Materials and Methods: This retrospective study include",
    "url": "https://arxiv.org/abs/2602.04983",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Near-Optimal Dynamic Matching via Coarsening with Application to Heart Transplantation",
    "summary": "arXiv:2602.04989v1 Announce Type: cross Abstract: Online matching has been a mainstay in domains such as Internet advertising and organ allocation, but practical algorithms often lack strong theoretical guarantees. We take an important step toward addressing this by developing new online matching algorithms based on a coarsening approach. Although ",
    "url": "https://arxiv.org/abs/2602.04989",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Learning Rate Matters: Vanilla LoRA May Suffice for LLM Fine-tuning",
    "summary": "arXiv:2602.04998v1 Announce Type: cross Abstract: Low-Rank Adaptation (LoRA) is the prevailing approach for efficient large language model (LLM) fine-tuning. Building on this paradigm, recent studies have proposed alternative initialization strategies and architectural modifications, reporting substantial improvements over vanilla LoRA. However, th",
    "url": "https://arxiv.org/abs/2602.04998",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "EntRGi: Entropy Aware Reward Guidance for Diffusion Language Models",
    "summary": "arXiv:2602.05000v1 Announce Type: cross Abstract: Reward guidance has been applied to great success in the test-time adaptation of continuous diffusion models; it updates each denoising step using the gradients from a downstream reward model. We study reward guidance for discrete diffusion language models, where one cannot differentiate through the",
    "url": "https://arxiv.org/abs/2602.05000",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "CoWork-X: Experience-Optimized Co-Evolution for Multi-Agent Collaboration System",
    "summary": "arXiv:2602.05004v1 Announce Type: cross Abstract: Large language models are enabling language-conditioned agents in interactive environments, but highly cooperative tasks often impose two simultaneous constraints: sub-second real-time coordination and sustained multi-episode adaptation under a strict online token budget. Existing approaches either ",
    "url": "https://arxiv.org/abs/2602.05004",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Enhanced QKNorm normalization for neural transformers with the Lp norm",
    "summary": "arXiv:2602.05006v1 Announce Type: cross Abstract: The normalization of query and key vectors is an essential part of the Transformer architecture. It ensures that learning is stable regardless of the scale of these vectors. Some normalization approaches are available. In this preliminary work, a generalization of the QKNorm normalization scheme is ",
    "url": "https://arxiv.org/abs/2602.05006",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "From Fragmentation to Integration: Exploring the Design Space of AI Agents for Human-as-the-Unit Privacy Management",
    "summary": "arXiv:2602.05016v1 Announce Type: cross Abstract: Managing one's digital footprint is overwhelming, as it spans multiple platforms and involves countless context-dependent decisions. Recent advances in agentic AI offer ways forward by enabling holistic, contextual privacy-enhancing solutions. Building on this potential, we adopted a ''human-as-the-",
    "url": "https://arxiv.org/abs/2602.05016",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Do Vision-Language Models Respect Contextual Integrity in Location Disclosure?",
    "summary": "arXiv:2602.05023v1 Announce Type: cross Abstract: Vision-language models (VLMs) have demonstrated strong performance in image geolocation, a capability further sharpened by frontier multimodal large reasoning models (MLRMs). This poses a significant privacy risk, as these widely accessible models can be exploited to infer sensitive locations from c",
    "url": "https://arxiv.org/abs/2602.05023",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Laws of Learning Dynamics and the Core of Learners",
    "summary": "arXiv:2602.05026v1 Announce Type: cross Abstract: We formulate the fundamental laws governing learning dynamics, namely the conservation law and the decrease of total entropy. Within this framework, we introduce an entropy-based lifelong ensemble learning method. We evaluate its effectiveness by constructing an immunization mechanism to defend agai",
    "url": "https://arxiv.org/abs/2602.05026",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "AudioSAE: Towards Understanding of Audio-Processing Models with Sparse AutoEncoders",
    "summary": "arXiv:2602.05027v1 Announce Type: cross Abstract: Sparse Autoencoders (SAEs) are powerful tools for interpreting neural representations, yet their use in audio remains underexplored. We train SAEs across all encoder layers of Whisper and HuBERT, provide an extensive evaluation of their stability, interpretability, and show their practical utility. ",
    "url": "https://arxiv.org/abs/2602.05027",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Differentiable Inverse Graphics for Zero-shot Scene Reconstruction and Robot Grasping",
    "summary": "arXiv:2602.05029v1 Announce Type: cross Abstract: Operating effectively in novel real-world environments requires robotic systems to estimate and interact with previously unseen objects. Current state-of-the-art models address this challenge by using large amounts of training data and test-time samples to build black-box scene representations. In t",
    "url": "https://arxiv.org/abs/2602.05029",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Quality Model for Machine Learning Components",
    "summary": "arXiv:2602.05043v1 Announce Type: cross Abstract: Despite increased adoption and advances in machine learning (ML), there are studies showing that many ML prototypes do not reach the production stage and that testing is still largely limited to testing model properties, such as model performance, without considering requirements derived from the sy",
    "url": "https://arxiv.org/abs/2602.05043",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "VISTA: Enhancing Visual Conditioning via Track-Following Preference Optimization in Vision-Language-Action Models",
    "summary": "arXiv:2602.05049v1 Announce Type: cross Abstract: Vision-Language-Action (VLA) models have demonstrated strong performance across a wide range of robotic manipulation tasks. Despite the success, extending large pretrained Vision-Language Models (VLMs) to the action space can induce vision-action misalignment, where action predictions exhibit weak d",
    "url": "https://arxiv.org/abs/2602.05049",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "ReFORM: Reflected Flows for On-support Offline RL via Noise Manipulation",
    "summary": "arXiv:2602.05051v1 Announce Type: cross Abstract: Offline reinforcement learning (RL) aims to learn the optimal policy from a fixed dataset generated by behavior policies without additional environment interactions. One common challenge that arises in this setting is the out-of-distribution (OOD) error, which occurs when the policy leaves the train",
    "url": "https://arxiv.org/abs/2602.05051",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Bypassing AI Control Protocols via Agent-as-a-Proxy Attacks",
    "summary": "arXiv:2602.05066v1 Announce Type: cross Abstract: As AI agents automate critical workloads, they remain vulnerable to indirect prompt injection (IPI) attacks. Current defenses rely on monitoring protocols that jointly evaluate an agent's Chain-of-Thought (CoT) and tool-use actions to ensure alignment with user intent. We demonstrate that these moni",
    "url": "https://arxiv.org/abs/2602.05066",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "E-Globe: Scalable $\\epsilon$-Global Verification of Neural Networks via Tight Upper Bounds and Pattern-Aware Branching",
    "summary": "arXiv:2602.05068v1 Announce Type: cross Abstract: Neural networks achieve strong empirical performance, but robustness concerns still hinder deployment in safety-critical applications. Formal verification provides robustness guarantees, but current methods face a scalability-completeness trade-off. We propose a hybrid verifier in a branch-and-bound",
    "url": "https://arxiv.org/abs/2602.05068",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Food Portion Estimation: From Pixels to Calories",
    "summary": "arXiv:2602.05078v1 Announce Type: cross Abstract: Reliance on images for dietary assessment is an important strategy to accurately and conveniently monitor an individual's health, making it a vital mechanism in the prevention and care of chronic diseases and obesity. However, image-based dietary assessment suffers from estimating the three dimensio",
    "url": "https://arxiv.org/abs/2602.05078",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Reliable Explanations or Random Noise? A Reliability Metric for XAI",
    "summary": "arXiv:2602.05082v1 Announce Type: cross Abstract: In recent years, explaining decisions made by complex machine learning models has become essential in high-stakes domains such as energy systems, healthcare, finance, and autonomous systems. However, the reliability of these explanations, namely, whether they remain stable and consistent under reali",
    "url": "https://arxiv.org/abs/2602.05082",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Large-Ensemble Simulations Reveal Links Between Atmospheric Blocking Frequency and Sea Surface Temperature Variability",
    "summary": "arXiv:2602.05083v1 Announce Type: cross Abstract: Atmospheric blocking events drive persistent weather extremes in midlatitudes, but isolating the influence of sea surface temperature (SST) from chaotic internal atmospheric variability on these events remains a challenge. We address this challenge using century-long (1900-2010), large-ensemble simu",
    "url": "https://arxiv.org/abs/2602.05083",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Individual Fairness In Strategic Classification",
    "summary": "arXiv:2602.05084v1 Announce Type: cross Abstract: Strategic classification, where individuals modify their features to influence machine learning (ML) decisions, presents critical fairness challenges. While group fairness in this setting has been widely studied, individual fairness remains underexplored. We analyze threshold-based classifiers and p",
    "url": "https://arxiv.org/abs/2602.05084",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Autodiscover: A reinforcement learning recommendation system for the cold-start imbalance challenge in active learning, powered by graph-aware thompson sampling",
    "summary": "arXiv:2602.05087v1 Announce Type: cross Abstract: Systematic literature reviews (SLRs) are fundamental to evidence-based research, but manual screening is an increasing bottleneck as scientific output grows. Screening features low prevalence of relevant studies and scarce, costly expert decisions. Traditional active learning (AL) systems help, yet ",
    "url": "https://arxiv.org/abs/2602.05087",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Rethinking Rubric Generation for Improving LLM Judge and Reward Modeling for Open-ended Tasks",
    "summary": "arXiv:2602.05125v1 Announce Type: cross Abstract: Recently, rubrics have been used to guide LLM judges in capturing subjective, nuanced, multi-dimensional human preferences, and have been extended from evaluation to reward signals for reinforcement fine-tuning (RFT). However, rubric generation remains hard to control: rubrics often lack coverage, c",
    "url": "https://arxiv.org/abs/2602.05125",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "TIDE: Temporal Incremental Draft Engine for Self-Improving LLM Inference",
    "summary": "arXiv:2602.05145v1 Announce Type: cross Abstract: Speculative decoding can substantially accelerate LLM inference, but realizing its benefits in practice is challenging due to evolving workloads and system-level constraints. We present TIDE (Temporal Incremental Draft Engine), a serving-engine-native framework that integrates online draft adaptatio",
    "url": "https://arxiv.org/abs/2602.05145",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Cross-talk based multi-task learning for fault classification of physically coupled machine system",
    "summary": "arXiv:2602.05146v1 Announce Type: cross Abstract: Machine systems inherently generate signals in which fault conditions and various physical variables are physically coupled. Although many existing fault classification studies rely solely on direct fault labels, the aforementioned signals naturally embed additional information shaped by other physi",
    "url": "https://arxiv.org/abs/2602.05146",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "CoSA: Compressed Sensing-Based Adaptation of Large Language Models",
    "summary": "arXiv:2602.05148v1 Announce Type: cross Abstract: Parameter-Efficient Fine-Tuning (PEFT) has emerged as a practical paradigm for adapting large language models (LLMs) without updating all parameters. Most existing approaches, such as LoRA and PiSSA, rely on low-rank decompositions of weight updates. However, the low-rank assumption may restrict exp",
    "url": "https://arxiv.org/abs/2602.05148",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Position: Capability Control Should be a Separate Goal From Alignment",
    "summary": "arXiv:2602.05164v1 Announce Type: cross Abstract: Foundation models are trained on broad data distributions, yielding generalist capabilities that enable many downstream applications but also expand the space of potential misuse and failures. This position paper argues that capability control -- imposing restrictions on permissible model behavior -",
    "url": "https://arxiv.org/abs/2602.05164",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "EBPO: Empirical Bayes Shrinkage for Stabilizing Group-Relative Policy Optimization",
    "summary": "arXiv:2602.05165v1 Announce Type: cross Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective for enhancing the reasoning capabilities of Large Language Models (LLMs). However, dominant approaches like Group Relative Policy Optimization (GRPO) face critical stability challenges: they suffer from high estimator varianc",
    "url": "https://arxiv.org/abs/2602.05165",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Total Variation Rates for Riemannian Flow Matching",
    "summary": "arXiv:2602.05174v1 Announce Type: cross Abstract: Riemannian flow matching (RFM) extends flow-based generative modeling to data supported on manifolds by learning a time-dependent tangent vector field whose flow-ODE transports a simple base distribution to the data law. We develop a nonasymptotic Total Variation (TV) convergence analysis for RFM sa",
    "url": "https://arxiv.org/abs/2602.05174",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Benchmarking Artificial Intelligence Models for Daily Coastal Hypoxia Forecasting",
    "summary": "arXiv:2602.05178v1 Announce Type: cross Abstract: Coastal hypoxia, especially in the northern part of Gulf of Mexico, presents a persistent ecological and economic concern. Seasonal models offer coarse forecasts that miss the fine-scale variability needed for daily, responsive ecosystem management. We present study that compares four deep learning ",
    "url": "https://arxiv.org/abs/2602.05178",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Data-Centric Interpretability for LLM-based Multi-Agent Reinforcement Learning",
    "summary": "arXiv:2602.05183v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly trained in complex Reinforcement Learning, multi-agent environments, making it difficult to understand how behavior changes over training. Sparse Autoencoders (SAEs) have recently shown to be useful for data-centric interpretability. In this work, we ana",
    "url": "https://arxiv.org/abs/2602.05183",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Towards Worst-Case Guarantees with Scale-Aware Interpretability",
    "summary": "arXiv:2602.05184v1 Announce Type: cross Abstract: Neural networks organize information according to the hierarchical, multi-scale structure of natural data. Methods to interpret model internals should be similarly scale-aware, explicitly tracking how features compose across resolutions and guaranteeing bounds on the influence of fine-grained struct",
    "url": "https://arxiv.org/abs/2602.05184",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Double-P: Hierarchical Top-P Sparse Attention for Long-Context LLMs",
    "summary": "arXiv:2602.05191v1 Announce Type: cross Abstract: As long-context inference becomes central to large language models (LLMs), attention over growing key-value caches emerges as a dominant decoding bottleneck, motivating sparse attention for scalable inference. Fixed-budget top-k sparse attention cannot adapt to heterogeneous attention distributions ",
    "url": "https://arxiv.org/abs/2602.05191",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Aligning Large Language Model Behavior with Human Citation Preferences",
    "summary": "arXiv:2602.05205v1 Announce Type: cross Abstract: Most services built on powerful large-scale language models (LLMs) add citations to their output to enhance credibility. Recent research has paid increasing attention to the question of what reference documents to link to outputs. However, how LLMs recognize cite-worthiness and how this process shou",
    "url": "https://arxiv.org/abs/2602.05205",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "ARCHI-TTS: A flow-matching-based Text-to-Speech Model with Self-supervised Semantic Aligner and Accelerated Inference",
    "summary": "arXiv:2602.05207v1 Announce Type: cross Abstract: Although diffusion-based, non-autoregressive text-to-speech (TTS) systems have demonstrated impressive zero-shot synthesis capabilities, their efficacy is still hindered by two key challenges: the difficulty of text-speech alignment modeling and the high computational overhead of the iterative denoi",
    "url": "https://arxiv.org/abs/2602.05207",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Semantic Search over 9 Million Mathematical Theorems",
    "summary": "arXiv:2602.05216v1 Announce Type: cross Abstract: Searching for mathematical results remains difficult: most existing tools retrieve entire papers, while mathematicians and theorem-proving agents often seek a specific theorem, lemma, or proposition that answers a query. While semantic search has seen rapid progress, its behavior on large, highly te",
    "url": "https://arxiv.org/abs/2602.05216",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "ZeroS: Zero-Sum Linear Attention for Efficient Transformers",
    "summary": "arXiv:2602.05230v1 Announce Type: cross Abstract: Linear attention methods offer Transformers $O(N)$ complexity but typically underperform standard softmax attention. We identify two fundamental limitations affecting these approaches: the restriction to convex combinations that only permits additive information blending, and uniform accumulated wei",
    "url": "https://arxiv.org/abs/2602.05230",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Balanced Anomaly-guided Ego-graph Diffusion Model for Inductive Graph Anomaly Detection",
    "summary": "arXiv:2602.05232v1 Announce Type: cross Abstract: Graph anomaly detection (GAD) is crucial in applications like fraud detection and cybersecurity. Despite recent advancements using graph neural networks (GNNs), two major challenges persist. At the model level, most methods adopt a transductive learning paradigm, which assumes static graph structure",
    "url": "https://arxiv.org/abs/2602.05232",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "EGSS: Entropy-guided Stepwise Scaling for Reliable Software Engineering",
    "summary": "arXiv:2602.05242v1 Announce Type: cross Abstract: Agentic Test-Time Scaling (TTS) has delivered state-of-the-art (SOTA) performance on complex software engineering tasks such as code generation and bug fixing. However, its practical adoption remains limited due to significant computational overhead, primarily driven by two key challenges: (1) the h",
    "url": "https://arxiv.org/abs/2602.05242",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "CoPE: Clipped RoPE as A Scalable Free Lunch for Long Context LLMs",
    "summary": "arXiv:2602.05258v1 Announce Type: cross Abstract: Rotary Positional Embedding (RoPE) is a key component of context scaling in Large Language Models (LLMs). While various methods have been proposed to adapt RoPE to longer contexts, their guiding principles generally fall into two categories: (1) out-of-distribution (OOD) mitigation, which scales RoP",
    "url": "https://arxiv.org/abs/2602.05258",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Hybrid Gated Flow (HGF): Stabilizing 1.58-bit LLMs via Selective Low-Rank Correction",
    "summary": "arXiv:2602.05269v1 Announce Type: cross Abstract: The deployment of Large Language Models (LLMs) on edge devices is fundamentally constrained by the \"Memory Wall\" -- a hardware limitation where memory bandwidth, not compute, becomes the bottleneck. Recent 1.58-bit quantization techniques (e.g., BitNet b1.58) dramatically reduce memory footprint but",
    "url": "https://arxiv.org/abs/2602.05269",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "HealthMamba: An Uncertainty-aware Spatiotemporal Graph State Space Model for Effective and Reliable Healthcare Facility Visit Prediction",
    "summary": "arXiv:2602.05286v1 Announce Type: cross Abstract: Healthcare facility visit prediction is essential for optimizing healthcare resource allocation and informing public health policy. Despite advanced machine learning methods being employed for better prediction performance, existing works usually formulate this task as a time-series forecasting prob",
    "url": "https://arxiv.org/abs/2602.05286",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Towards a Science of Collective AI: LLM-based Multi-Agent Systems Need a Transition from Blind Trial-and-Error to Rigorous Science",
    "summary": "arXiv:2602.05289v1 Announce Type: cross Abstract: Recent advancements in Large Language Models (LLMs) have greatly extended the capabilities of Multi-Agent Systems (MAS), demonstrating significant effectiveness across a wide range of complex and open-ended domains. However, despite this rapid progress, the field still relies heavily on empirical tr",
    "url": "https://arxiv.org/abs/2602.05289",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "FlashBlock: Attention Caching for Efficient Long-Context Block Diffusion",
    "summary": "arXiv:2602.05305v1 Announce Type: cross Abstract: Generating long-form content, such as minute-long videos and extended texts, is increasingly important for modern generative models. Block diffusion improves inference efficiency via KV caching and block-wise causal inference and has been widely adopted in diffusion language models and video generat",
    "url": "https://arxiv.org/abs/2602.05305",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Formal Synthesis of Certifiably Robust Neural Lyapunov-Barrier Certificates",
    "summary": "arXiv:2602.05311v1 Announce Type: cross Abstract: Neural Lyapunov and barrier certificates have recently been used as powerful tools for verifying the safety and stability properties of deep reinforcement learning (RL) controllers. However, existing methods offer guarantees only under fixed ideal unperturbed dynamics, limiting their reliability in ",
    "url": "https://arxiv.org/abs/2602.05311",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "GAS: Enhancing Reward-Cost Balance of Generative Model-assisted Offline Safe RL",
    "summary": "arXiv:2602.05323v1 Announce Type: cross Abstract: Offline Safe Reinforcement Learning (OSRL) aims to learn a policy to achieve high performance in sequential decision-making while satisfying constraints, using only pre-collected datasets. Recent works, inspired by the strong capabilities of Generative Models (GMs), reformulate decision-making in OS",
    "url": "https://arxiv.org/abs/2602.05323",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Spider-Sense: Intrinsic Risk Sensing for Efficient Agent Defense with Hierarchical Adaptive Screening",
    "summary": "arXiv:2602.05386v1 Announce Type: cross Abstract: As large language models (LLMs) evolve into autonomous agents, their real-world applicability has expanded significantly, accompanied by new security challenges. Most existing agent defense mechanisms adopt a mandatory checking paradigm, in which security validation is forcibly triggered at predefin",
    "url": "https://arxiv.org/abs/2602.05386",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Assessing Electricity Demand Forecasting with Exogenous Data in Time Series Foundation Models",
    "summary": "arXiv:2602.05390v1 Announce Type: cross Abstract: Time-series foundation models have emerged as a new paradigm for forecasting, yet their ability to effectively leverage exogenous features -- critical for electricity demand forecasting -- remains unclear. This paper empirically evaluates foundation models capable of modeling cross-channel correlati",
    "url": "https://arxiv.org/abs/2602.05390",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Beyond Length: Context-Aware Expansion and Independence as Developmentally Sensitive Evaluation in Child Utterances",
    "summary": "arXiv:2602.05392v1 Announce Type: cross Abstract: Evaluating the quality of children's utterances in adult-child dialogue remains challenging due to insufficient context-sensitive metrics. Common proxies such as Mean Length of Utterance (MLU), lexical diversity (vocd-D), and readability indices (Flesch-Kincaid Grade Level, Gunning Fog Index) are do",
    "url": "https://arxiv.org/abs/2602.05392",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Optimal Bayesian Stopping for Efficient Inference of Consistent LLM Answers",
    "summary": "arXiv:2602.05395v1 Announce Type: cross Abstract: A simple strategy for improving LLM accuracy, especially in math and reasoning problems, is to sample multiple responses and submit the answer most consistently reached. In this paper we leverage Bayesian prior information to save on sampling costs, stopping once sufficient consistency is reached. A",
    "url": "https://arxiv.org/abs/2602.05395",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Enabling Automatic Disordered Speech Recognition: An Impaired Speech Dataset in the Akan Language",
    "summary": "arXiv:2602.05406v1 Announce Type: cross Abstract: The lack of impaired speech data hinders advancements in the development of inclusive speech technologies, particularly in low-resource languages such as Akan. To address this gap, this study presents a curated corpus of speech samples from native Akan speakers with speech impairment. The dataset co",
    "url": "https://arxiv.org/abs/2602.05406",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Reduced-Order Surrogates for Forced Flexible Mesh Coastal-Ocean Models",
    "summary": "arXiv:2602.05416v1 Announce Type: cross Abstract: While POD-based surrogates are widely explored for hydrodynamic applications, the use of Koopman Autoencoders for real-world coastal-ocean modelling remains relatively limited. This paper introduces a flexible Koopman autoencoder formulation that incorporates meteorological forcings and boundary con",
    "url": "https://arxiv.org/abs/2602.05416",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Disco: Densely-overlapping Cell Instance Segmentation via Adjacency-aware Collaborative Coloring",
    "summary": "arXiv:2602.05420v1 Announce Type: cross Abstract: Accurate cell instance segmentation is foundational for digital pathology analysis. Existing methods based on contour detection and distance mapping still face significant challenges in processing complex and dense cellular regions. Graph coloring-based methods provide a new paradigm for this task, ",
    "url": "https://arxiv.org/abs/2602.05420",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Benchmarking Affordance Generalization with BusyBox",
    "summary": "arXiv:2602.05441v1 Announce Type: cross Abstract: Vision-Language-Action (VLA) models have been attracting the attention of researchers and practitioners thanks to their promise of generalization. Although single-task policies still offer competitive performance, VLAs are increasingly able to handle commands and environments unseen in their trainin",
    "url": "https://arxiv.org/abs/2602.05441",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Structured Context Engineering for File-Native Agentic Systems: Evaluating Schema Accuracy, Format Effectiveness, and Multi-File Navigation at Scale",
    "summary": "arXiv:2602.05447v1 Announce Type: cross Abstract: Large Language Model agents increasingly operate external systems through programmatic interfaces, yet practitioners lack empirical guidance on how to structure the context these agents consume. Using SQL generation as a proxy for programmatic agent operations, we present a systematic study of conte",
    "url": "https://arxiv.org/abs/2602.05447",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "DisCa: Accelerating Video Diffusion Transformers with Distillation-Compatible Learnable Feature Caching",
    "summary": "arXiv:2602.05449v1 Announce Type: cross Abstract: While diffusion models have achieved great success in the field of video generation, this progress is accompanied by a rapidly escalating computational burden. Among the existing acceleration methods, Feature Caching is popular due to its training-free property and considerable speedup performance, ",
    "url": "https://arxiv.org/abs/2602.05449",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Towards Segmenting the Invisible: An End-to-End Registration and Segmentation Framework for Weakly Supervised Tumour Analysis",
    "summary": "arXiv:2602.05453v1 Announce Type: cross Abstract: Liver tumour ablation presents a significant clinical challenge: whilst tumours are clearly visible on pre-operative MRI, they are often effectively invisible on intra-operative CT due to minimal contrast between pathological and healthy tissue. This work investigates the feasibility of cross-modali",
    "url": "https://arxiv.org/abs/2602.05453",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Attention Retention for Continual Learning with Vision Transformers",
    "summary": "arXiv:2602.05454v1 Announce Type: cross Abstract: Continual learning (CL) empowers AI systems to progressively acquire knowledge from non-stationary data streams. However, catastrophic forgetting remains a critical challenge. In this work, we identify attention drift in Vision Transformers as a primary source of catastrophic forgetting, where the a",
    "url": "https://arxiv.org/abs/2602.05454",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Ontology-Driven Robotic Specification Synthesis",
    "summary": "arXiv:2602.05456v1 Announce Type: cross Abstract: This paper addresses robotic system engineering for safety- and mission-critical applications by bridging the gap between high-level objectives and formal, executable specifications. The proposed method, Robotic System Task to Model Transformation Methodology (RSTM2) is an ontology-driven, hierarchi",
    "url": "https://arxiv.org/abs/2602.05456",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Thermodynamic Limits of Physical Intelligence",
    "summary": "arXiv:2602.05463v1 Announce Type: cross Abstract: Modern AI systems achieve remarkable capabilities at the cost of substantial energy consumption. To connect intelligence to physical efficiency, we propose two complementary bits-per-joule metrics under explicit accounting conventions: (1) Thermodynamic Epiplexity per Joule -- bits of structural inf",
    "url": "https://arxiv.org/abs/2602.05463",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "LMMRec: LLM-driven Motivation-aware Multimodal Recommendation",
    "summary": "arXiv:2602.05474v1 Announce Type: cross Abstract: Motivation-based recommendation systems uncover user behavior drivers. Motivation modeling, crucial for decision-making and content preference, explains recommendation generation. Existing methods often treat motivation as latent variables from interaction data, neglecting heterogeneous information ",
    "url": "https://arxiv.org/abs/2602.05474",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Sovereign-by-Design A Reference Architecture for AI and Blockchain Enabled Systems",
    "summary": "arXiv:2602.05486v1 Announce Type: cross Abstract: Digital sovereignty has emerged as a central concern for modern software-intensive systems, driven by the dominance of non-sovereign cloud infrastructures, the rapid adoption of Generative AI, and increasingly stringent regulatory requirements. While existing initiatives address governance, complian",
    "url": "https://arxiv.org/abs/2602.05486",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "LinguistAgent: A Reflective Multi-Model Platform for Automated Linguistic Annotation",
    "summary": "arXiv:2602.05493v1 Announce Type: cross Abstract: Data annotation remains a significant bottleneck in the Humanities and Social Sciences, particularly for complex semantic tasks such as metaphor identification. While Large Language Models (LLMs) show promise, a significant gap remains between the theoretical capability of LLMs and their practical u",
    "url": "https://arxiv.org/abs/2602.05493",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "A Unified Framework for Rethinking Policy Divergence Measures in GRPO",
    "summary": "arXiv:2602.05494v1 Announce Type: cross Abstract: Reinforcement Learning with Verified Reward (RLVR) has emerged as a critical paradigm for advancing the reasoning capabilities of Large Language Models (LLMs). Most existing RLVR methods, such as GRPO and its variants, ensure stable updates by constraining policy divergence through clipping likeliho",
    "url": "https://arxiv.org/abs/2602.05494",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Transport and Merge: Cross-Architecture Merging for Large Language Models",
    "summary": "arXiv:2602.05495v1 Announce Type: cross Abstract: Large language models (LLMs) achieve strong capabilities by scaling model capacity and training data, yet many real-world deployments rely on smaller models trained or adapted from low-resource data. This gap motivates the need for mechanisms to transfer knowledge from large, high-resource models to",
    "url": "https://arxiv.org/abs/2602.05495",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "XEmoGPT: An Explainable Multimodal Emotion Recognition Framework with Cue-Level Perception and Reasoning",
    "summary": "arXiv:2602.05496v1 Announce Type: cross Abstract: Explainable Multimodal Emotion Recognition plays a crucial role in applications such as human-computer interaction and social media analytics. However, current approaches struggle with cue-level perception and reasoning due to two main challenges: 1) general-purpose modality encoders are pretrained ",
    "url": "https://arxiv.org/abs/2602.05496",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "DECO: Decoupled Multimodal Diffusion Transformer for Bimanual Dexterous Manipulation with a Plugin Tactile Adapter",
    "summary": "arXiv:2602.05513v1 Announce Type: cross Abstract: Overview of the Proposed DECO Framework.} DECO is a DiT-based policy that decouples multimodal conditioning. Image and action tokens interact via joint self attention, while proprioceptive states and optional conditions are injected through adaptive layer normalization. Tactile signals are injected ",
    "url": "https://arxiv.org/abs/2602.05513",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Capture the Flags: Family-Based Evaluation of Agentic LLMs via Semantics-Preserving Transformations",
    "summary": "arXiv:2602.05523v1 Announce Type: cross Abstract: Agentic large language models (LLMs) are increasingly evaluated on cybersecurity tasks using capture-the-flag (CTF) benchmarks. However, existing pointwise benchmarks have limited ability to shed light on the robustness and generalisation abilities of agents across alternative versions of the source",
    "url": "https://arxiv.org/abs/2602.05523",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "AI Agent Systems for Supply Chains: Structured Decision Prompts and Memory Retrieval",
    "summary": "arXiv:2602.05524v1 Announce Type: cross Abstract: This study investigates large language model (LLM) -based multi-agent systems (MASs) as a promising approach to inventory management, which is a key component of supply chain management. Although these systems have gained considerable attention for their potential to address the challenges associate",
    "url": "https://arxiv.org/abs/2602.05524",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "When Shared Knowledge Hurts: Spectral Over-Accumulation in Model Merging",
    "summary": "arXiv:2602.05536v1 Announce Type: cross Abstract: Model merging combines multiple fine-tuned models into a single model by adding their weight updates, providing a lightweight alternative to retraining. Existing methods primarily target resolving conflicts between task updates, leaving the failure mode of over-counting shared knowledge unaddressed.",
    "url": "https://arxiv.org/abs/2602.05536",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Steering Large Reasoning Models towards Concise Reasoning via Flow Matching",
    "summary": "arXiv:2602.05539v1 Announce Type: cross Abstract: Large Reasoning Models (LRMs) excel at complex reasoning tasks, but their efficiency is often hampered by overly verbose outputs. Prior steering methods attempt to address this issue by applying a single, global vector to hidden representations -- an approach grounded in the restrictive linear repre",
    "url": "https://arxiv.org/abs/2602.05539",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Multi-Task GRPO: Reliable LLM Reasoning Across Tasks",
    "summary": "arXiv:2602.05547v1 Announce Type: cross Abstract: RL-based post-training with GRPO is widely used to improve large language models on individual reasoning tasks. However, real-world deployment requires reliable performance across diverse tasks. A straightforward multi-task adaptation of GRPO often leads to imbalanced outcomes, with some tasks domin",
    "url": "https://arxiv.org/abs/2602.05547",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Unveiling Implicit Advantage Symmetry: Why GRPO Struggles with Exploration and Difficulty Adaptation",
    "summary": "arXiv:2602.05548v1 Announce Type: cross Abstract: Reinforcement Learning with Verifiable Rewards (RLVR), particularly GRPO, has become the standard for eliciting LLM reasoning. However, its efficiency in exploration and difficulty adaptation remains an open challenge. In this work, we argue that these bottlenecks stem from an implicit advantage sym",
    "url": "https://arxiv.org/abs/2602.05548",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "CAViT -- Channel-Aware Vision Transformer for Dynamic Feature Fusion",
    "summary": "arXiv:2602.05598v1 Announce Type: cross Abstract: Vision Transformers (ViTs) have demonstrated strong performance across a range of computer vision tasks by modeling long-range spatial interactions via self-attention. However, channel-wise mixing in ViTs remains static, relying on fixed multilayer perceptrons (MLPs) that lack adaptability to input ",
    "url": "https://arxiv.org/abs/2602.05598",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Shiva-DiT: Residual-Based Differentiable Top-$k$ Selection for Efficient Diffusion Transformers",
    "summary": "arXiv:2602.05605v1 Announce Type: cross Abstract: Diffusion Transformers (DiTs) incur prohibitive computational costs due to the quadratic scaling of self-attention. Existing pruning methods fail to simultaneously satisfy differentiability, efficiency, and the strict static budgets required for hardware overhead. To address this, we propose Shiva-D",
    "url": "https://arxiv.org/abs/2602.05605",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Path-Guided Flow Matching for Dataset Distillation",
    "summary": "arXiv:2602.05616v1 Announce Type: cross Abstract: Dataset distillation compresses large datasets into compact synthetic sets with comparable performance in training models. Despite recent progress on diffusion-based distillation, this type of method typically depends on heuristic guidance or prototype assignment, which comes with time-consuming sam",
    "url": "https://arxiv.org/abs/2602.05616",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Mode-Dependent Rectification for Stable PPO Training",
    "summary": "arXiv:2602.05619v1 Announce Type: cross Abstract: Mode-dependent architectural components (layers that behave differently during training and evaluation, such as Batch Normalization or dropout) are commonly used in visual reinforcement learning but can destabilize on-policy optimization. We show that in Proximal Policy Optimization (PPO), discrepan",
    "url": "https://arxiv.org/abs/2602.05619",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "AI chatbots versus human healthcare professionals: a systematic review and meta-analysis of empathy in patient care",
    "summary": "arXiv:2602.05628v1 Announce Type: cross Abstract: Background: Empathy is widely recognized for improving patient outcomes, including reduced pain and anxiety and improved satisfaction, and its absence can cause harm. Meanwhile, use of artificial intelligence (AI)-based chatbots in healthcare is rapidly expanding, with one in five general practition",
    "url": "https://arxiv.org/abs/2602.05628",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Enhancing Personality Recognition by Comparing the Predictive Power of Traits, Facets, and Nuances",
    "summary": "arXiv:2602.05650v1 Announce Type: cross Abstract: Personality is a complex, hierarchical construct typically assessed through item-level questionnaires aggregated into broad trait scores. Personality recognition models aim to infer personality traits from different sources of behavioral data. However, reliance on broad trait scores as ground truth,",
    "url": "https://arxiv.org/abs/2602.05650",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Alignment Verifiability in Large Language Models: Normative Indistinguishability under Behavioral Evaluation",
    "summary": "arXiv:2602.05656v1 Announce Type: cross Abstract: Behavioral evaluation is the dominant paradigm for assessing alignment in large language models (LLMs). In practice, alignment is inferred from performance under finite evaluation protocols - benchmarks, red-teaming suites, or automated pipelines - and observed compliance is often treated as evidenc",
    "url": "https://arxiv.org/abs/2602.05656",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Probabilistic Multi-Regional Solar Power Forecasting with Any-Quantile Recurrent Neural Networks",
    "summary": "arXiv:2602.05660v1 Announce Type: cross Abstract: The increasing penetration of photovoltaic (PV) generation introduces significant uncertainty into power system operation, necessitating forecasting approaches that extend beyond deterministic point predictions. This paper proposes an any-quantile probabilistic forecasting framework for multi-region",
    "url": "https://arxiv.org/abs/2602.05660",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Stable but Wrong: When More Data Degrades Scientific Conclusions",
    "summary": "arXiv:2602.05668v1 Announce Type: cross Abstract: Modern science increasingly relies on ever-growing observational datasets and automated inference pipelines, under the implicit belief that accumulating more data makes scientific conclusions more reliable. Here we show that this belief can fail in a fundamental and irreversible way. We identify a s",
    "url": "https://arxiv.org/abs/2602.05668",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "HyperPotter: Spell the Charm of High-Order Interactions in Audio Deepfake Detection",
    "summary": "arXiv:2602.05670v1 Announce Type: cross Abstract: Advances in AIGC technologies have enabled the synthesis of highly realistic audio deepfakes capable of deceiving human auditory perception. Although numerous audio deepfake detection (ADD) methods have been developed, most rely on local temporal/spectral features or pairwise relations, overlooking ",
    "url": "https://arxiv.org/abs/2602.05670",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Exploring AI-Augmented Sensemaking of Patient-Generated Health Data: A Mixed-Method Study with Healthcare Professionals in Cardiac Risk Reduction",
    "summary": "arXiv:2602.05687v1 Announce Type: cross Abstract: Individuals are increasingly generating substantial personal health and lifestyle data, e.g. through wearables and smartphones. While such data could transform preventative care, its integration into clinical practice is hindered by its scale, heterogeneity and the time pressure and data literacy of",
    "url": "https://arxiv.org/abs/2602.05687",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Mining Generalizable Activation Functions",
    "summary": "arXiv:2602.05688v1 Announce Type: cross Abstract: The choice of activation function is an active area of research, with different proposals aimed at improving optimization, while maintaining expressivity. Additionally, the activation function can significantly alter the implicit inductive bias of the architecture, controlling its non-linear behavio",
    "url": "https://arxiv.org/abs/2602.05688",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Poster: Camera Tampering Detection for Outdoor IoT Systems",
    "summary": "arXiv:2602.05706v1 Announce Type: cross Abstract: Recently, the use of smart cameras in outdoor settings has grown to improve surveillance and security. Nonetheless, these systems are susceptible to tampering, whether from deliberate vandalism or harsh environmental conditions, which can undermine their monitoring effectiveness. In this context, de",
    "url": "https://arxiv.org/abs/2602.05706",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "OmniMoE: An Efficient MoE by Orchestrating Atomic Experts at Scale",
    "summary": "arXiv:2602.05711v1 Announce Type: cross Abstract: Mixture-of-Experts (MoE) architectures are evolving towards finer granularity to improve parameter efficiency. However, existing MoE designs face an inherent trade-off between the granularity of expert specialization and hardware execution efficiency. We propose OmniMoE, a system-algorithm co-design",
    "url": "https://arxiv.org/abs/2602.05711",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Towards Green AI: Decoding the Energy of LLM Inference in Software Development",
    "summary": "arXiv:2602.05712v1 Announce Type: cross Abstract: Context: AI-assisted tools are increasingly integrated into software development workflows, but their reliance on large language models (LLMs) introduces substantial computational and energy costs. Understanding and reducing the energy footprint of LLM inference is therefore essential for sustainabl",
    "url": "https://arxiv.org/abs/2602.05712",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "CompactRAG: Reducing LLM Calls and Token Overhead in Multi-Hop Question Answering",
    "summary": "arXiv:2602.05728v1 Announce Type: cross Abstract: Retrieval-augmented generation (RAG) has become a key paradigm for knowledge-intensive question answering. However, existing multi-hop RAG systems remain inefficient, as they alternate between retrieval and reasoning at each step, resulting in repeated LLM calls, high token consumption, and unstable",
    "url": "https://arxiv.org/abs/2602.05728",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Evaluating the impact of word embeddings on similarity scoring in practical information retrieval",
    "summary": "arXiv:2602.05734v1 Announce Type: cross Abstract: Search behaviour is characterised using synonymy and polysemy as users often want to search information based on meaning. Semantic representation strategies represent a move towards richer associative connections that can adequately capture this complex usage of language. Vector Space Modelling (VSM",
    "url": "https://arxiv.org/abs/2602.05734",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "CSRv2: Unlocking Ultra-Sparse Embeddings",
    "summary": "arXiv:2602.05735v1 Announce Type: cross Abstract: In the era of large foundation models, the quality of embeddings has become a central determinant of downstream task performance and overall system capability. Yet widely used dense embeddings are often extremely high-dimensional, incurring substantial costs in storage, memory, and inference latency",
    "url": "https://arxiv.org/abs/2602.05735",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Learning to Inject: Automated Prompt Injection via Reinforcement Learning",
    "summary": "arXiv:2602.05746v1 Announce Type: cross Abstract: Prompt injection is one of the most critical vulnerabilities in LLM agents; yet, effective automated attacks remain largely unexplored from an optimization perspective. Existing methods heavily depend on human red-teamers and hand-crafted prompts, limiting their scalability and adaptability. We prop",
    "url": "https://arxiv.org/abs/2602.05746",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "TimelyFreeze: Adaptive Parameter Freezing Mechanism for Pipeline Parallelism",
    "summary": "arXiv:2602.05754v1 Announce Type: cross Abstract: Pipeline parallelism enables training models that exceed single-device memory, but practical throughput remains limited by pipeline bubbles. Although parameter freezing can improve training throughput by adaptively skipping backward computation, existing methods often over-freeze parameters, resulti",
    "url": "https://arxiv.org/abs/2602.05754",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Variational Speculative Decoding: Rethinking Draft Training from Token Likelihood to Sequence Acceptance",
    "summary": "arXiv:2602.05774v1 Announce Type: cross Abstract: Speculative decoding accelerates inference for (M)LLMs, yet a training-decoding discrepancy persists: while existing methods optimize single greedy trajectories, decoding involves verifying and ranking multiple sampled draft paths. We propose Variational Speculative Decoding (VSD), formulating draft",
    "url": "https://arxiv.org/abs/2602.05774",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Automated Customization of LLMs for Enterprise Code Repositories Using Semantic Scopes",
    "summary": "arXiv:2602.05780v1 Announce Type: cross Abstract: Code completion (CC) is a task frequently used by developers when working in collaboration with LLM-based programming assistants. Despite the increased performance of LLMs on public benchmarks, out of the box LLMs still have a hard time generating code that aligns with a private code repository not ",
    "url": "https://arxiv.org/abs/2602.05780",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "ReText: Text Boosts Generalization in Image-Based Person Re-identification",
    "summary": "arXiv:2602.05785v1 Announce Type: cross Abstract: Generalizable image-based person re-identification (Re-ID) aims to recognize individuals across cameras in unseen domains without retraining. While multiple existing approaches address the domain gap through complex architectures, recent findings indicate that better generalization can be achieved b",
    "url": "https://arxiv.org/abs/2602.05785",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Bagging-Based Model Merging for Robust General Text Embeddings",
    "summary": "arXiv:2602.05787v1 Announce Type: cross Abstract: General-purpose text embedding models underpin a wide range of NLP and information retrieval applications, and are typically trained on large-scale multi-task corpora to encourage broad generalization. However, it remains unclear how different multi-task training strategies compare in practice, and ",
    "url": "https://arxiv.org/abs/2602.05787",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Allocentric Perceiver: Disentangling Allocentric Reasoning from Egocentric Visual Priors via Frame Instantiation",
    "summary": "arXiv:2602.05789v1 Announce Type: cross Abstract: With the rising need for spatially grounded tasks such as Vision-Language Navigation/Action, allocentric perception capabilities in Vision-Language Models (VLMs) are receiving growing focus. However, VLMs remain brittle on allocentric spatial queries that require explicit perspective shifts, where t",
    "url": "https://arxiv.org/abs/2602.05789",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "FHAIM: Fully Homomorphic AIM For Private Synthetic Data Generation",
    "summary": "arXiv:2602.05838v1 Announce Type: cross Abstract: Data is the lifeblood of AI, yet much of the most valuable data remains locked in silos due to privacy and regulations. As a result, AI remains heavily underutilized in many of the most important domains, including healthcare, education, and finance. Synthetic data generation (SDG), i.e. the generat",
    "url": "https://arxiv.org/abs/2602.05838",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "DARWIN: Dynamic Agentically Rewriting Self-Improving Network",
    "summary": "arXiv:2602.05848v1 Announce Type: cross Abstract: DARWIN is an evolutionary GPT model, utilizing a genetic-algorithm like optimization structure with several independent GPT agents being trained individually using unique training code. Each iteration, the GPT models are prompted to modify the training code of one another in an attempt to improve th",
    "url": "https://arxiv.org/abs/2602.05848",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "DLM-Scope: Mechanistic Interpretability of Diffusion Language Models via Sparse Autoencoders",
    "summary": "arXiv:2602.05859v1 Announce Type: cross Abstract: Sparse autoencoders (SAEs) have become a standard tool for mechanistic interpretability in autoregressive large language models (LLMs), enabling researchers to extract sparse, human-interpretable features and intervene on model behavior. Recently, as diffusion language models (DLMs) have become an i",
    "url": "https://arxiv.org/abs/2602.05859",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "xList-Hate: A Checklist-Based Framework for Interpretable and Generalizable Hate Speech Detection",
    "summary": "arXiv:2602.05874v1 Announce Type: cross Abstract: Hate speech detection is commonly framed as a direct binary classification problem despite being a composite concept defined through multiple interacting factors that vary across legal frameworks, platform policies, and annotation guidelines. As a result, supervised models often overfit dataset-spec",
    "url": "https://arxiv.org/abs/2602.05874",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "EuroLLM-22B: Technical Report",
    "summary": "arXiv:2602.05879v1 Announce Type: cross Abstract: This report presents EuroLLM-22B, a large language model trained from scratch to support the needs of European citizens by covering all 24 official European Union languages and 11 additional languages. EuroLLM addresses the issue of European languages being underrepresented and underserved in existi",
    "url": "https://arxiv.org/abs/2602.05879",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Neural Implicit 3D Cardiac Shape Reconstruction from Sparse CT Angiography Slices Mimicking 2D Transthoracic Echocardiography Views",
    "summary": "arXiv:2602.05884v1 Announce Type: cross Abstract: Accurate 3D representations of cardiac structures allow quantitative analysis of anatomy and function. In this work, we propose a method for reconstructing complete 3D cardiac shapes from segmentations of sparse planes in CT angiography (CTA) for application in 2D transthoracic echocardiography (TTE",
    "url": "https://arxiv.org/abs/2602.05884",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Dr. Kernel: Reinforcement Learning Done Right for Triton Kernel Generations",
    "summary": "arXiv:2602.05885v1 Announce Type: cross Abstract: High-quality kernel is critical for scalable AI systems, and enabling LLMs to generate such code would advance AI development. However, training LLMs for this task requires sufficient data, a robust environment, and the process is often vulnerable to reward hacking and lazy optimization. In these ca",
    "url": "https://arxiv.org/abs/2602.05885",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Metric Hedonic Games on the Line",
    "summary": "arXiv:2602.05888v1 Announce Type: cross Abstract: Hedonic games are fundamental models for investigating the formation of coalitions among a set of strategic agents, where every agent has a certain utility for every possible coalition of agents it can be part of. To avoid the intractability of defining exponentially many utilities for all possible ",
    "url": "https://arxiv.org/abs/2602.05888",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Parity, Sensitivity, and Transformers",
    "summary": "arXiv:2602.05896v1 Announce Type: cross Abstract: The transformer architecture is almost a decade old. Despite that, we still have a limited understanding of what this architecture can or cannot compute. For instance, can a 1-layer transformer solve PARITY -- or more generally -- which kinds of transformers can do it? Known constructions for PARITY",
    "url": "https://arxiv.org/abs/2602.05896",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Regularized Calibration with Successive Rounding for Post-Training Quantization",
    "summary": "arXiv:2602.05902v1 Announce Type: cross Abstract: Large language models (LLMs) deliver robust performance across diverse applications, yet their deployment often faces challenges due to the memory and latency costs of storing and accessing billions of parameters. Post-training quantization (PTQ) enables efficient inference by mapping pretrained wei",
    "url": "https://arxiv.org/abs/2602.05902",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Verification of the Implicit World Model in a Generative Model via Adversarial Sequences",
    "summary": "arXiv:2602.05903v1 Announce Type: cross Abstract: Generative sequence models are typically trained on sample sequences from natural or formal languages. It is a crucial question whether -- or to what extent -- sample-based training is able to capture the true structure of these languages, often referred to as the ``world model''. Theoretical result",
    "url": "https://arxiv.org/abs/2602.05903",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Compound Deception in Elite Peer Review: A Failure Mode Taxonomy of 100 Fabricated Citations at NeurIPS 2025",
    "summary": "arXiv:2602.05930v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly used in academic writing workflows, yet they frequently hallucinate by generating citations to sources that do not exist. This study analyzes 100 AI-generated hallucinated citations that appeared in papers accepted by the 2025 Conference on Neural Inform",
    "url": "https://arxiv.org/abs/2602.05930",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Better Source, Better Flow: Learning Condition-Dependent Source Distribution for Flow Matching",
    "summary": "arXiv:2602.05951v1 Announce Type: cross Abstract: Flow matching has recently emerged as a promising alternative to diffusion-based generative models, particularly for text-to-image generation. Despite its flexibility in allowing arbitrary source distributions, most existing approaches rely on a standard Gaussian distribution, a choice inherited fro",
    "url": "https://arxiv.org/abs/2602.05951",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Learning to Share: Selective Memory for Efficient Parallel Agentic Systems",
    "summary": "arXiv:2602.05965v1 Announce Type: cross Abstract: Agentic systems solve complex tasks by coordinating multiple agents that iteratively reason, invoke tools, and exchange intermediate results. To improve robustness and solution quality, recent approaches deploy multiple agent teams running in parallel to explore diverse reasoning trajectories. Howev",
    "url": "https://arxiv.org/abs/2602.05965",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "LSA: Localized Semantic Alignment for Enhancing Temporal Consistency in Traffic Video Generation",
    "summary": "arXiv:2602.05966v1 Announce Type: cross Abstract: Controllable video generation has emerged as a versatile tool for autonomous driving, enabling realistic synthesis of traffic scenarios. However, existing methods depend on control signals at inference time to guide the generative model towards temporally consistent generation of dynamic objects, li",
    "url": "https://arxiv.org/abs/2602.05966",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Inverse Depth Scaling From Most Layers Being Similar",
    "summary": "arXiv:2602.05970v1 Announce Type: cross Abstract: Neural scaling laws relate loss to model size in large language models (LLMs), yet depth and width may contribute to performance differently, requiring more detailed studies. Here, we quantify how depth affects loss via analysis of LLMs and toy residual networks. We find loss scales inversely propor",
    "url": "https://arxiv.org/abs/2602.05970",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Clifford Kolmogorov-Arnold Networks",
    "summary": "arXiv:2602.05977v1 Announce Type: cross Abstract: We introduce Clifford Kolmogorov-Arnold Network (ClKAN), a flexible and efficient architecture for function approximation in arbitrary Clifford algebra spaces. We propose the use of Randomized Quasi Monte Carlo grid generation as a solution to the exponential scaling associated with higher dimension",
    "url": "https://arxiv.org/abs/2602.05977",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "RISE-Video: Can Video Generators Decode Implicit World Rules?",
    "summary": "arXiv:2602.05986v1 Announce Type: cross Abstract: While generative video models have achieved remarkable visual fidelity, their capacity to internalize and reason over implicit world rules remains a critical yet under-explored frontier. To bridge this gap, we present RISE-Video, a pioneering reasoning-oriented benchmark for Text-Image-to-Video (TI2",
    "url": "https://arxiv.org/abs/2602.05986",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Diamond Maps: Efficient Reward Alignment via Stochastic Flow Maps",
    "summary": "arXiv:2602.05993v1 Announce Type: cross Abstract: Flow and diffusion models produce high-quality samples, but adapting them to user preferences or constraints post-training remains costly and brittle, a challenge commonly called reward alignment. We argue that efficient reward alignment should be a property of the generative model itself, not an af",
    "url": "https://arxiv.org/abs/2602.05993",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "GenArena: How Can We Achieve Human-Aligned Evaluation for Visual Generation Tasks?",
    "summary": "arXiv:2602.06013v1 Announce Type: cross Abstract: The rapid advancement of visual generation models has outpaced traditional evaluation approaches, necessitating the adoption of Vision-Language Models as surrogate judges. In this work, we systematically investigate the reliability of the prevailing absolute pointwise scoring standard, across a wide",
    "url": "https://arxiv.org/abs/2602.06013",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Optimism Stabilizes Thompson Sampling for Adaptive Inference",
    "summary": "arXiv:2602.06014v1 Announce Type: cross Abstract: Thompson sampling (TS) is widely used for stochastic multi-armed bandits, yet its inferential properties under adaptive data collection are subtle. Classical asymptotic theory for sample means can fail because arm-specific sample sizes are random and coupled with the rewards through the action-selec",
    "url": "https://arxiv.org/abs/2602.06014",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Correctness-Optimized Residual Activation Lens (CORAL): Transferrable and Calibration-Aware Inference-Time Steering",
    "summary": "arXiv:2602.06022v1 Announce Type: cross Abstract: Large language models (LLMs) exhibit persistent miscalibration, especially after instruction tuning and preference alignment. Modified training objectives can improve calibration, but retraining is expensive. Inference-time steering offers a lightweight alternative, yet most existing methods optimiz",
    "url": "https://arxiv.org/abs/2602.06022",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory",
    "summary": "arXiv:2602.06025v1 Announce Type: cross Abstract: Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a nat",
    "url": "https://arxiv.org/abs/2602.06025",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction",
    "summary": "arXiv:2602.06038v1 Announce Type: cross Abstract: To complete assignments provided by humans in natural language, robots must interpret commands, generate and answer relevant questions for scene understanding, and manipulate target objects. Real-world deployments often require multiple heterogeneous robots with different manipulation capabilities t",
    "url": "https://arxiv.org/abs/2602.06038",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Shared LoRA Subspaces for almost Strict Continual Learning",
    "summary": "arXiv:2602.06043v1 Announce Type: cross Abstract: Adapting large pretrained models to new tasks efficiently and continually is crucial for real-world deployment but remains challenging due to catastrophic forgetting and the high cost of retraining. While parameter-efficient tuning methods like low rank adaptation (LoRA) reduce computational demands",
    "url": "https://arxiv.org/abs/2602.06043",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Can MLLMs generate human-like feedback in grading multimodal short answers?",
    "summary": "arXiv:2412.19755v4 Announce Type: replace Abstract: In education, the traditional Automatic Short Answer Grading (ASAG) with feedback problem has focused primarily on evaluating text-only responses. However, real-world assessments often include multimodal responses containing both diagrams and text. To address this limitation, we introduce the Mult",
    "url": "https://arxiv.org/abs/2412.19755",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Are foundation models useful feature extractors for electroencephalography analysis?",
    "summary": "arXiv:2502.21086v2 Announce Type: replace Abstract: The success of foundation models in natural language processing and computer vision has motivated similar approaches in time series analysis. While foundational time series models have proven beneficial on a variety of tasks, their effectiveness in medical applications with limited data remains un",
    "url": "https://arxiv.org/abs/2502.21086",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "SPhyR: Spatial-Physical Reasoning Benchmark on Material Distribution",
    "summary": "arXiv:2505.16048v4 Announce Type: replace Abstract: We introduce a novel dataset designed to benchmark the physical and spatial reasoning capabilities of Large Language Models (LLM) based on topology optimization, a method for computing optimal material distributions within a design space under prescribed loads and supports. In this dataset, LLMs a",
    "url": "https://arxiv.org/abs/2505.16048",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Robust Answers, Fragile Logic: Probing the Decoupling Hypothesis in LLM Reasoning",
    "summary": "arXiv:2505.17406v2 Announce Type: replace Abstract: While Chain-of-Thought (CoT) prompting has become a cornerstone for complex reasoning in Large Language Models (LLMs), the faithfulness of the generated reasoning remains an open question. We investigate the Decoupling Hypothesis: that correct answers often mask fragile, post-hoc rationalizations ",
    "url": "https://arxiv.org/abs/2505.17406",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Interpretability by Design for Efficient Multi-Objective Reinforcement Learning",
    "summary": "arXiv:2506.04022v2 Announce Type: replace Abstract: Multi-objective reinforcement learning (MORL) aims at optimising several, often conflicting goals to improve the flexibility and reliability of RL in practical tasks. This is typically achieved by finding a set of diverse, non-dominated policies that form a Pareto front in the performance space. W",
    "url": "https://arxiv.org/abs/2506.04022",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Verifying the Verifiers: Unveiling Pitfalls and Potentials in Fact Verifiers",
    "summary": "arXiv:2506.13342v2 Announce Type: replace Abstract: Fact verification is essential for ensuring the reliability of LLM applications. In this study, we evaluate 12 pre-trained LLMs and one specialized fact-verifier, including frontier LLMs and open-weight reasoning LLMs, using a collection of examples from 14 fact-checking benchmarks. We share three",
    "url": "https://arxiv.org/abs/2506.13342",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "AlphaBeta is not as good as you think: a simple class of synthetic games for a better analysis of deterministic game-solving algorithms",
    "summary": "arXiv:2506.21996v3 Announce Type: replace Abstract: Deterministic game-solving algorithms are conventionally analyzed in the light of their average-case complexity against a distribution of random game-trees, where leaf values are independently sampled from a fixed distribution. This simplified model enables uncluttered mathematical analysis, revea",
    "url": "https://arxiv.org/abs/2506.21996",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Explanations are a Means to an End: Decision Theoretic Explanation Evaluation",
    "summary": "arXiv:2506.22740v2 Announce Type: replace Abstract: Explanations of model behavior are commonly evaluated via proxy properties weakly tied to the purposes explanations serve in practice. We contribute a decision theoretic framework that treats explanations as information signals valued by the expected improvement they enable on a specified decision",
    "url": "https://arxiv.org/abs/2506.22740",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Dynamic Context Adaptation for Consistent Role-Playing Agents with Retrieval-Augmented Generations",
    "summary": "arXiv:2508.02016v4 Announce Type: replace Abstract: Building role-playing agents (RPAs) that faithfully emulate specific characters remains challenging because collecting character-specific utterances and continually updating model parameters are resource-intensive, making retrieval-augmented generation (RAG) a practical necessity. However, despite",
    "url": "https://arxiv.org/abs/2508.02016",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics",
    "summary": "arXiv:2508.12840v3 Announce Type: replace Abstract: Multi-agent Epistemic Planning (MEP) is an autonomous planning framework for reasoning about both the physical world and the beliefs of agents, with applications in domains where information flow and awareness among agents are critical. The richness of MEP requires states to be represented as Krip",
    "url": "https://arxiv.org/abs/2508.12840",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Controlling the Risk of Corrupted Contexts for Language Models via Early-Exiting",
    "summary": "arXiv:2510.02480v2 Announce Type: replace Abstract: Large language models (LLMs) can be influenced by harmful or irrelevant context, which can significantly harm model performance on downstream tasks. This motivates principled designs in which LLM systems include built-in mechanisms to guard against such ``garbage in, garbage out'' scenarios. We pr",
    "url": "https://arxiv.org/abs/2510.02480",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "How Catastrophic is Your LLM? Certifying Risk in Conversation",
    "summary": "arXiv:2510.03969v3 Announce Type: replace Abstract: Large Language Models (LLMs) can produce catastrophic responses in conversational settings that pose serious risks to public safety and security. Existing evaluations often fail to fully reveal these vulnerabilities because they rely on fixed attack prompt sequences, lack statistical guarantees, a",
    "url": "https://arxiv.org/abs/2510.03969",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "DeepAgent: A General Reasoning Agent with Scalable Toolsets",
    "summary": "arXiv:2510.21618v3 Announce Type: replace Abstract: Large reasoning models have demonstrated strong problem-solving abilities, yet real-world tasks often require external tools and long-horizon interactions. Existing agent frameworks typically follow predefined workflows, which limit autonomous and global task completion. In this paper, we introduc",
    "url": "https://arxiv.org/abs/2510.21618",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Resisting Manipulative Bots in Meme Coin Copy Trading: A Multi-Agent Approach with Chain-of-Thought Reasoning",
    "summary": "arXiv:2601.08641v3 Announce Type: replace Abstract: Copy trading has become the dominant entry strategy in meme coin markets. However, due to the market's extremely illiquid and volatile nature, the strategy exposes an exploitable attack surface: adversaries deploy manipulative bots to front-run trades, conceal positions, and fabricate sentiment, s",
    "url": "https://arxiv.org/abs/2601.08641",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "The Why Behind the Action: Unveiling Internal Drivers via Agentic Attribution",
    "summary": "arXiv:2601.15075v2 Announce Type: replace Abstract: Large Language Model (LLM)-based agents are widely used in real-world applications such as customer service, web navigation, and software engineering. As these systems become more autonomous and are deployed at scale, understanding why an agent takes a particular action becomes increasingly import",
    "url": "https://arxiv.org/abs/2601.15075",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Beyond Prompting: Efficient and Robust Contextual Biasing for Speech LLMs via Logit-Space Integration (LOGIC)",
    "summary": "arXiv:2601.15397v2 Announce Type: replace Abstract: The rapid emergence of new entities -- driven by cultural shifts, evolving trends, and personalized user data -- poses a significant challenge for existing Speech Large Language Models (Speech LLMs). While these models excel at general conversational tasks, their static training knowledge limits t",
    "url": "https://arxiv.org/abs/2601.15397",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Semi-Autonomous Mathematics Discovery with Gemini: A Case Study on the Erd\\H{o}s Problems",
    "summary": "arXiv:2601.22401v3 Announce Type: replace Abstract: We present a case study in semi-autonomous mathematics discovery, using Gemini to systematically evaluate 700 conjectures labeled 'Open' in Bloom's Erd\\H{o}s Problems database. We employ a hybrid methodology: AI-driven natural language verification to narrow the search space, followed by human exp",
    "url": "https://arxiv.org/abs/2601.22401",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "A Study of Adaptive Modeling Towards Robust Generalization",
    "summary": "arXiv:2602.02780v2 Announce Type: replace Abstract: Large language models (LLMs) increasingly support reasoning over biomolecular structures, but most existing approaches remain modality-specific and rely on either sequence-style encodings or fixed-length connector tokens for structural inputs. These designs can under-expose explicit geometric cues",
    "url": "https://arxiv.org/abs/2602.02780",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "KANFIS: A Neuro-Symbolic Framework for Interpretable and Uncertainty-Aware Learning",
    "summary": "arXiv:2602.03034v2 Announce Type: replace Abstract: Adaptive Neuro-Fuzzy Inference System (ANFIS) was designed to combine the learning capabilities of neural network with the reasoning transparency of fuzzy logic. However, conventional ANFIS architectures suffer from structural complexity, where the product-based inference mechanism causes an expon",
    "url": "https://arxiv.org/abs/2602.03034",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Mitigating Conversational Inertia in Multi-Turn Agents",
    "summary": "arXiv:2602.03664v2 Announce Type: replace Abstract: Large language models excel as few-shot learners when provided with appropriate demonstrations, yet this strength becomes problematic in multiturn agent scenarios, where LLMs erroneously mimic their own previous responses as few-shot examples. Through attention analysis, we identify conversational",
    "url": "https://arxiv.org/abs/2602.03664",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration",
    "summary": "arXiv:2602.04575v2 Announce Type: replace Abstract: For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' manifested as the Intent-Execution Gap (i.e., th",
    "url": "https://arxiv.org/abs/2602.04575",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "CATS: Enhancing Multivariate Time Series Forecasting by Constructing Auxiliary Time Series as Exogenous Variables",
    "summary": "arXiv:2403.01673v2 Announce Type: replace-cross Abstract: For Multivariate Time Series Forecasting (MTSF), recent deep learning applications show that univariate models frequently outperform multivariate ones. To address the difficiency in multivariate models, we introduce a method to Construct Auxiliary Time Series (CATS) that functions like a 2D ",
    "url": "https://arxiv.org/abs/2403.01673",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "A Differential and Pointwise Control Approach to Reinforcement Learning",
    "summary": "arXiv:2404.15617v4 Announce Type: replace-cross Abstract: Reinforcement learning (RL) in continuous state-action spaces remains challenging in scientific computing due to poor sample efficiency and lack of pathwise physical consistency. We introduce Differential Reinforcement Learning (Differential RL), a novel framework that reformulates RL from a",
    "url": "https://arxiv.org/abs/2404.15617",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "In-context Time Series Predictor",
    "summary": "arXiv:2405.14982v2 Announce Type: replace-cross Abstract: Recent Transformer-based large language models (LLMs) demonstrate in-context learning ability to perform various functions based solely on the provided context, without updating model parameters. To fully utilize the in-context capabilities in time series forecasting (TSF) problems, unlike p",
    "url": "https://arxiv.org/abs/2405.14982",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "The Use of AI-Robotic Systems for Scientific Discovery",
    "summary": "arXiv:2406.17835v2 Announce Type: replace-cross Abstract: The process of developing theories and models and testing them with experiments is fundamental to the scientific method. Automating the entire scientific method then requires not only automation of the induction of theories from data, but also experimentation from design to implementation. T",
    "url": "https://arxiv.org/abs/2406.17835",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "CGRA4ML: A Hardware/Software Framework to Implement Neural Networks for Scientific Edge Computing",
    "summary": "arXiv:2408.15561v3 Announce Type: replace-cross Abstract: The scientific community increasingly relies on machine learning (ML) for near-sensor processing, leveraging its strengths in tasks such as pattern recognition, anomaly detection, and real-time decision-making. These deployments demand accelerators that combine extremely high performance wit",
    "url": "https://arxiv.org/abs/2408.15561",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "WAVE: Weighted Autoregressive Varying Gate for Time Series Forecasting",
    "summary": "arXiv:2410.03159v4 Announce Type: replace-cross Abstract: We propose a Weighted Autoregressive Varying gatE (WAVE) attention mechanism equipped with both Autoregressive (AR) and Moving-average (MA) components. It can adapt to various attention mechanisms, enhancing and decoupling their ability to capture long-range and local temporal patterns in ti",
    "url": "https://arxiv.org/abs/2410.03159",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Solving Prior Distribution Mismatch in Diffusion Models via Optimal Transport",
    "summary": "arXiv:2410.13431v2 Announce Type: replace-cross Abstract: Diffusion Models (DMs) have achieved remarkable progress in generative modeling. However, the mismatch between the forward terminal distribution and reverse initial distribution introduces prior error, leading to deviations of sampling trajectories from the true distribution and severely lim",
    "url": "https://arxiv.org/abs/2410.13431",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "LIBMoE: A Library for comprehensive benchmarking Mixture of Experts in Large Language Models",
    "summary": "arXiv:2411.00918v3 Announce Type: replace-cross Abstract: Mixture of experts (MoE) architectures have become a cornerstone for scaling up and are a key component in most large language models such as GPT-OSS, DeepSeek-V3, Llama-4, and Gemini-2.5. However, systematic research on MoE remains severely constrained by the prohibitive computational costs",
    "url": "https://arxiv.org/abs/2411.00918",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Multiple Invertible and Partial-Equivariant Function for Latent Vector Transformation to Enhance Disentanglement in VAEs",
    "summary": "arXiv:2502.03740v3 Announce Type: replace-cross Abstract: Disentanglement learning is central to understanding and reusing learned representations in variational autoencoders (VAEs). Although equivariance has been explored in this context, effectively exploiting it for disentanglement remains challenging. In this paper, we propose a novel method, c",
    "url": "https://arxiv.org/abs/2502.03740",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "EigenLoRAx: Recycling Adapters to Find Principal Subspaces for Resource-Efficient Adaptation and Inference",
    "summary": "arXiv:2502.04700v5 Announce Type: replace-cross Abstract: The rapid growth of large models has raised concerns about their environmental impact and equity in accessibility due to significant computational costs. Low-Rank Adapters (LoRA) offer a lightweight solution for finetuning large models, resulting in an abundance of publicly available adapter",
    "url": "https://arxiv.org/abs/2502.04700",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Linear Transformers as VAR Models: Aligning Autoregressive Attention Mechanisms with Autoregressive Forecasting",
    "summary": "arXiv:2502.07244v2 Announce Type: replace-cross Abstract: Autoregressive attention-based time series forecasting (TSF) has drawn increasing interest, with mechanisms like linear attention sometimes outperforming vanilla attention. However, deeper Transformer architectures frequently misalign with autoregressive objectives, obscuring the underlying ",
    "url": "https://arxiv.org/abs/2502.07244",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Video Soundtrack Generation by Aligning Emotions and Temporal Boundaries",
    "summary": "arXiv:2502.10154v3 Announce Type: replace-cross Abstract: Providing soundtracks for videos remains a costly and time-consuming challenge for multimedia content creators. We introduce EMSYNC, an automatic video-based symbolic music generator that creates music aligned with a video's emotional content and temporal boundaries. It follows a two-stage f",
    "url": "https://arxiv.org/abs/2502.10154",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "ExplainReduce: Generating global explanations from many local explanations",
    "summary": "arXiv:2502.10311v2 Announce Type: replace-cross Abstract: Most commonly used non-linear machine learning methods are closed-box models, uninterpretable to humans. The field of explainable artificial intelligence (XAI) aims to develop tools to examine the inner workings of these closed boxes. An often-used model-agnostic approach to XAI involves usi",
    "url": "https://arxiv.org/abs/2502.10311",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "MaxSup: Overcoming Representation Collapse in Label Smoothing",
    "summary": "arXiv:2502.15798v4 Announce Type: replace-cross Abstract: Label Smoothing (LS) is widely adopted to reduce overconfidence in neural network predictions and improve generalization. Despite these benefits, recent studies reveal two critical issues with LS. First, LS induces overconfidence in misclassified samples. Second, it compacts feature represen",
    "url": "https://arxiv.org/abs/2502.15798",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Vision-R1: Incentivizing Reasoning Capability in Multimodal Large Language Models",
    "summary": "arXiv:2503.06749v3 Announce Type: replace-cross Abstract: DeepSeek-R1-Zero has successfully demonstrated the emergence of reasoning capabilities in LLMs purely through Reinforcement Learning (RL). Inspired by this breakthrough, we explore how RL can be utilized to enhance the reasoning capability of MLLMs. However, direct training with RL struggles",
    "url": "https://arxiv.org/abs/2503.06749",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Collaborating with AI Agents: Field Experiments on Teamwork, Productivity, and Performance",
    "summary": "arXiv:2503.18238v3 Announce Type: replace-cross Abstract: We examined the mechanisms underlying productivity and performance gains from AI agents using a large-scale experiment on Pairit, a platform we developed to study human-AI collaboration. We randomly assigned 2,234 participants to human-human and human-AI teams that produced 11,024 ads for a ",
    "url": "https://arxiv.org/abs/2503.18238",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "CMD-HAR: Cross-Modal Disentanglement for Wearable Human Activity Recognition",
    "summary": "arXiv:2503.21843v4 Announce Type: replace-cross Abstract: Human Activity Recognition (HAR) is a fundamental technology for numerous human - centered intelligent applications. Although deep learning methods have been utilized to accelerate feature extraction, issues such as multimodal data mixing, activity heterogeneity, and complex model deployment",
    "url": "https://arxiv.org/abs/2503.21843",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "ScholarMate: A Mixed-Initiative Tool for Qualitative Knowledge Work and Information Sensemaking",
    "summary": "arXiv:2504.14406v3 Announce Type: replace-cross Abstract: Synthesizing knowledge from large document collections is a critical yet increasingly complex aspect of qualitative research and knowledge work. While AI offers automation potential, effectively integrating it into human-centric sensemaking workflows remains challenging. We present ScholarMa",
    "url": "https://arxiv.org/abs/2504.14406",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Bringing Diversity from Diffusion Models to Semantic-Guided Face Asset Generation",
    "summary": "arXiv:2504.15259v2 Announce Type: replace-cross Abstract: Digital modeling and reconstruction of human faces serve various applications. However, its availability is often hindered by the requirements of data capturing devices, manual labor, and suitable actors. This situation restricts the diversity, expressiveness, and control over the resulting ",
    "url": "https://arxiv.org/abs/2504.15259",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Relational Graph Transformer",
    "summary": "arXiv:2505.10960v2 Announce Type: replace-cross Abstract: Relational Deep Learning (RDL) is a promising approach for building state-of-the-art predictive models on multi-table relational data by representing it as a heterogeneous temporal graph. However, commonly used Graph Neural Network models suffer from fundamental limitations in capturing comp",
    "url": "https://arxiv.org/abs/2505.10960",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Guided Diffusion Sampling on Function Spaces with Applications to PDEs",
    "summary": "arXiv:2505.17004v3 Announce Type: replace-cross Abstract: We propose a general framework for conditional sampling in PDE-based inverse problems, targeting the recovery of whole solutions from extremely sparse or noisy measurements. This is accomplished by a function-space diffusion model and plug-and-play guidance for conditioning. Our method first",
    "url": "https://arxiv.org/abs/2505.17004",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "SelfReflect: Can LLMs Communicate Their Internal Answer Distribution?",
    "summary": "arXiv:2505.20295v4 Announce Type: replace-cross Abstract: The common approach to communicate a large language model's (LLM) uncertainty is to add a percentage number or a hedging word to its response. But is this all we can do? Instead of generating a single answer and then hedging it, an LLM that is fully transparent to the user needs to be able t",
    "url": "https://arxiv.org/abs/2505.20295",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Generalizable Trajectory Prediction via Inverse Reinforcement Learning with Mamba-Graph Architecture",
    "summary": "arXiv:2506.12474v2 Announce Type: replace-cross Abstract: Accurate driving behavior modeling is fundamental to safe and efficient trajectory prediction, yet remains challenging in complex traffic scenarios. This paper presents a novel Inverse Reinforcement Learning (IRL) framework that captures human-like decision-making by inferring diverse reward",
    "url": "https://arxiv.org/abs/2506.12474",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "LittleBit: Ultra Low-Bit Quantization via Latent Factorization",
    "summary": "arXiv:2506.13771v5 Announce Type: replace-cross Abstract: The deployment of large language models (LLMs) is frequently hindered by prohibitive memory and computational requirements. While quantization mitigates these bottlenecks, maintaining model fidelity in the sub-1-bit regime remains a persistent challenge. In this paper, we introduce LittleBit",
    "url": "https://arxiv.org/abs/2506.13771",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Accurate and scalable exchange-correlation with deep learning",
    "summary": "arXiv:2506.14665v5 Announce Type: replace-cross Abstract: Density Functional Theory (DFT) is the most widely used electronic structure method for predicting the properties of molecules and materials. Although DFT is, in principle, an exact reformulation of the Schr\\\"odinger equation, practical applications rely on approximations to the unknown exch",
    "url": "https://arxiv.org/abs/2506.14665",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Dissecting the SWE-Bench Leaderboards: Profiling Submitters and Architectures of LLM- and Agent-Based Repair Systems",
    "summary": "arXiv:2506.17208v3 Announce Type: replace-cross Abstract: The rapid progress in Automated Program Repair (APR) has been driven by advances in AI, particularly large language models (LLMs) and agent-based systems. SWE-Bench is a recent benchmark designed to evaluate LLM-based repair systems using real issues and pull requests mined from 12 popular o",
    "url": "https://arxiv.org/abs/2506.17208",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "STACK: Adversarial Attacks on LLM Safeguard Pipelines",
    "summary": "arXiv:2506.24068v3 Announce Type: replace-cross Abstract: Frontier AI developers are relying on layers of safeguards to protect against catastrophic misuse of AI systems. Anthropic and OpenAI guard their latest Opus 4 model and GPT-5 models using such defense pipelines, and other frontier developers including Google DeepMind pledge to soon deploy s",
    "url": "https://arxiv.org/abs/2506.24068",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Dual Perspectives on Non-Contrastive Self-Supervised Learning",
    "summary": "arXiv:2507.01028v3 Announce Type: replace-cross Abstract: The {\\em stop gradient} and {\\em exponential moving average} iterative procedures are commonly used in non-contrastive approaches to self-supervised learning to avoid representation collapse, with excellent performance in downstream applications in practice. This presentation investigates th",
    "url": "https://arxiv.org/abs/2507.01028",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "CoSteer: Collaborative Decoding-Time Personalization via Local Delta Steering",
    "summary": "arXiv:2507.04756v3 Announce Type: replace-cross Abstract: Personalization has become crucial for adapting models to the diverse and evolving needs of users across cultural, temporal, and contextual dimensions. While existing methods often rely on centralized fine-tuning or static preference alignment within a single model, they struggle to achieve ",
    "url": "https://arxiv.org/abs/2507.04756",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Learning to summarize user information for personalized reinforcement learning from human feedback",
    "summary": "arXiv:2507.13579v3 Announce Type: replace-cross Abstract: As everyday use cases of large language model (LLM) AI assistants have expanded, it is becoming increasingly important to personalize responses to align to different users' preferences and goals. While reinforcement learning from human feedback (RLHF) is effective at improving LLMs to be gen",
    "url": "https://arxiv.org/abs/2507.13579",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Segmentation-free Goodness of Pronunciation",
    "summary": "arXiv:2507.16838v3 Announce Type: replace-cross Abstract: Mispronunciation detection and diagnosis (MDD) is a significant part in modern computer-aided language learning (CALL) systems. Most systems implementing phoneme-level MDD through goodness of pronunciation (GOP), however, rely on pre-segmentation of speech into phonetic units. This limits th",
    "url": "https://arxiv.org/abs/2507.16838",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Personalized Safety Alignment for Text-to-Image Diffusion Models",
    "summary": "arXiv:2508.01151v3 Announce Type: replace-cross Abstract: Text-to-image diffusion models have revolutionized visual content generation, yet their deployment is hindered by a fundamental limitation: safety mechanisms enforce rigid, uniform standards that fail to reflect diverse user preferences shaped by age, culture, or personal beliefs. To address",
    "url": "https://arxiv.org/abs/2508.01151",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "CellForge: Agentic Design of Virtual Cell Models",
    "summary": "arXiv:2508.02276v2 Announce Type: replace-cross Abstract: Virtual cell modeling aims to predict cellular responses to diverse perturbations but faces challenges from biological complexity, multimodal data heterogeneity, and the need for interdisciplinary expertise. We introduce CellForge, a multi-agent framework that autonomously designs and synthe",
    "url": "https://arxiv.org/abs/2508.02276",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Generative AI for Intent-Driven Network Management in 6G RAN: A Case Study on the Mamba Model",
    "summary": "arXiv:2508.06616v2 Announce Type: replace-cross Abstract: With the emergence of 6G, mobile networks are becoming increasingly heterogeneous and dynamic, necessitating advanced automation for efficient management. Intent-Driven Networks (IDNs) address this by translating high-level intents into optimization policies. Large Language Models (LLMs) can",
    "url": "https://arxiv.org/abs/2508.06616",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Amortized Sampling with Transferable Normalizing Flows",
    "summary": "arXiv:2508.18175v4 Announce Type: replace-cross Abstract: Efficient equilibrium sampling of molecular conformations remains a core challenge in computational chemistry and statistical inference. Classical approaches such as molecular dynamics or Markov chain Monte Carlo inherently lack amortization; the computational cost of sampling must be paid i",
    "url": "https://arxiv.org/abs/2508.18175",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Language Models and Logic Programs for Trustworthy Tax Reasoning",
    "summary": "arXiv:2508.21051v3 Announce Type: replace-cross Abstract: According to the United States Internal Revenue Service, ``the average American spends $\\$270$ and 13 hours filing their taxes''. Even beyond the U.S., tax filing requires complex reasoning, combining application of overlapping rules with numerical calculations. Because errors can incur cost",
    "url": "https://arxiv.org/abs/2508.21051",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Calibration and Transformation-Free Weight-Only LLMs Quantization via Dynamic Grouping",
    "summary": "arXiv:2509.03054v3 Announce Type: replace-cross Abstract: Large Language Models (LLMs) deliver strong performance but are difficult to deploy under tight memory and compute constraints. Low-bit post-training quantization (PTQ) is a promising direction; however, it typically relies on calibration data, auxiliary transformations, and GPU tools. To ad",
    "url": "https://arxiv.org/abs/2509.03054",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "YOLO-based Bearing Fault Diagnosis With Continuous Wavelet Transform",
    "summary": "arXiv:2509.03070v3 Announce Type: replace-cross Abstract: This letter presents a locality-aware bearing fault diagnosis framework that operates on time-frequency representations and enables spatially interpretable decision-making. One-dimensional vibration signals are first mapped to two-dimensional time-frequency spectrograms using the continuous ",
    "url": "https://arxiv.org/abs/2509.03070",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "On Entropy Control in LLM-RL Algorithms",
    "summary": "arXiv:2509.03493v3 Announce Type: replace-cross Abstract: For RL algorithms, appropriate entropy control is crucial to their effectiveness. To control the policy entropy, a commonly used method is entropy regularization, which is adopted in various popular RL algorithms including PPO, SAC and A3C. Although entropy regularization proves effective in",
    "url": "https://arxiv.org/abs/2509.03493",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Real-Time Detection of Hallucinated Entities in Long-Form Generation",
    "summary": "arXiv:2509.03531v2 Announce Type: replace-cross Abstract: Large language models are now routinely used in high-stakes applications where hallucinations can cause serious harm, such as medical consultations or legal advice. Existing hallucination detection methods, however, are impractical for real-world use, as they are either limited to short fact",
    "url": "https://arxiv.org/abs/2509.03531",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "BioLite U-Net: Edge-Deployable Semantic Segmentation for In Situ Bioprinting Monitoring",
    "summary": "arXiv:2509.06690v2 Announce Type: replace-cross Abstract: Bioprinting is a rapidly advancing field that offers a transformative approach to fabricating tissue and organ models through the precise deposition of cell-laden bioinks. Ensuring the fidelity and consistency of printed structures in real-time remains a core challenge, particularly under co",
    "url": "https://arxiv.org/abs/2509.06690",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "When Are Two RLHF Objectives the Same?",
    "summary": "arXiv:2509.11298v2 Announce Type: replace-cross Abstract: The preference optimization literature contains many proposed objectives, often presented as distinct improvements. We introduce Opal, a canonicalization algorithm that determines whether two preference objectives are algebraically equivalent by producing either a canonical form or a concret",
    "url": "https://arxiv.org/abs/2509.11298",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Patterns in the Transition From Founder-Leadership to Community Governance of Open Source",
    "summary": "arXiv:2509.16295v4 Announce Type: replace-cross Abstract: Open digital public infrastructure needs community management to ensure accountability, sustainability, and robustness. Yet open-source projects often rely on centralized decision-making, and the determinants of successful community management remain unclear. We analyze 637 GitHub repositori",
    "url": "https://arxiv.org/abs/2509.16295",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Unveiling m-Sharpness Through the Structure of Stochastic Gradient Noise",
    "summary": "arXiv:2509.18001v4 Announce Type: replace-cross Abstract: Sharpness-aware minimization (SAM) has emerged as a highly effective technique to improve model generalization, but its underlying principles are not fully understood. We investigate m-sharpness, where SAM performance improves monotonically as the micro-batch size for computing perturbations",
    "url": "https://arxiv.org/abs/2509.18001",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "TensLoRA: Tensor Alternatives for Low-Rank Adaptation",
    "summary": "arXiv:2509.19391v3 Announce Type: replace-cross Abstract: Low-Rank Adaptation (LoRA) is widely used to efficiently adapt Transformers by adding trainable low-rank matrices to attention projections. While effective, these matrices are considered independent for each attention projection (Query, Key, and Value) and each layer. Recent extensions have ",
    "url": "https://arxiv.org/abs/2509.19391",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "SurvDiff: A Diffusion Model for Generating Synthetic Data in Survival Analysis",
    "summary": "arXiv:2509.22352v2 Announce Type: replace-cross Abstract: Survival analysis is a cornerstone of clinical research by modeling time-to-event outcomes such as metastasis, disease relapse, or patient death. Unlike standard tabular data, survival data often come with incomplete event information due to dropout, or loss to follow-up. This poses unique c",
    "url": "https://arxiv.org/abs/2509.22352",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "VibeCodeHPC: An Agent-Based Iterative Prompting Auto-Tuner for HPC Code Generation Using LLMs",
    "summary": "arXiv:2510.00031v2 Announce Type: replace-cross Abstract: We propose VibeCodeHPC, an automatic tuning system for HPC programs based on multi-agent LLMs for code generation. VibeCodeHPC tunes programs through multi-agent role allocation and iterative prompt refinement. We describe the system configuration with four roles: Project Manager (PM), Syste",
    "url": "https://arxiv.org/abs/2510.00031",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "UniverSR: Unified and Versatile Audio Super-Resolution via Vocoder-Free Flow Matching",
    "summary": "arXiv:2510.00771v2 Announce Type: replace-cross Abstract: In this paper, we present a vocoder-free framework for audio super-resolution that employs a flow matching generative model to capture the conditional distribution of complex-valued spectral coefficients. Unlike conventional two-stage diffusion-based approaches that predict a mel-spectrogram",
    "url": "https://arxiv.org/abs/2510.00771",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Breaking the MoE LLM Trilemma: Dynamic Expert Clustering with Structured Compression",
    "summary": "arXiv:2510.02345v3 Announce Type: replace-cross Abstract: Mixture-of-Experts (MoE) Large Language Models (LLMs) face a trilemma of load imbalance, parameter redundancy, and communication overhead. We introduce a unified framework based on dynamic expert clustering and structured compression to address these issues cohesively. Our method employs an ",
    "url": "https://arxiv.org/abs/2510.02345",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "VAO: Validation-Aligned Optimization for Cross-Task Generative Auto-Bidding",
    "summary": "arXiv:2510.07760v2 Announce Type: replace-cross Abstract: Generative auto-bidding has demonstrated strong performance in online advertising, yet it often suffers from data scarcity in small-scale settings with limited advertiser participation. While cross-task data sharing is a natural remedy to mitigate this issue, naive approaches often introduce",
    "url": "https://arxiv.org/abs/2510.07760",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Leveraging Whisper Embeddings for Audio-based Lyrics Matching",
    "summary": "arXiv:2510.08176v2 Announce Type: replace-cross Abstract: Audio-based lyrics matching can be an appealing alternative to other content-based retrieval approaches, but existing methods often suffer from limited reproducibility and inconsistent baselines. In this work, we introduce WEALY, a fully reproducible pipeline that leverages Whisper decoder e",
    "url": "https://arxiv.org/abs/2510.08176",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "RAG4Tickets: AI-Powered Ticket Resolution via Retrieval-Augmented Generation on JIRA and GitHub Data",
    "summary": "arXiv:2510.08667v2 Announce Type: replace-cross Abstract: Modern software teams frequently encounter delays in resolving recurring or related issues due to fragmented knowledge scattered across JIRA tickets, developer discussions, and GitHub pull requests (PRs). To address this challenge, we propose a Retrieval-Augmented Generation (RAG) framework ",
    "url": "https://arxiv.org/abs/2510.08667",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Pattern Enhanced Multi-Turn Jailbreaking: Exploiting Structural Vulnerabilities in Large Language Models",
    "summary": "arXiv:2510.08859v2 Announce Type: replace-cross Abstract: Large language models (LLMs) remain vulnerable to multi-turn jailbreaking attacks that exploit conversational context to bypass safety constraints gradually. These attacks target different harm categories through distinct conversational approaches. Existing multi-turn methods often rely on h",
    "url": "https://arxiv.org/abs/2510.08859",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Bandits with Single-Peaked Preferences and Limited Resources",
    "summary": "arXiv:2510.09425v2 Announce Type: replace-cross Abstract: We study an online stochastic matching problem in which an algorithm sequentially matches $U$ users to $K$ arms, aiming to maximize cumulative reward over $T$ rounds under budget constraints. Without structural assumptions, computing the optimal matching is NP-hard, making online learning co",
    "url": "https://arxiv.org/abs/2510.09425",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Group-Adaptive Adversarial Learning for Robust Fake News Detection Against Malicious Comments",
    "summary": "arXiv:2510.09712v3 Announce Type: replace-cross Abstract: Online fake news profoundly distorts public judgment and erodes trust in social platforms. While existing detectors achieve competitive performance on benchmark datasets, they remain notably vulnerable to malicious comments designed specifically to induce misclassification. This evolving thr",
    "url": "https://arxiv.org/abs/2510.09712",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Beyond touch-based human-machine interface: Control your machines in natural language by utilizing large language models and OPC UA",
    "summary": "arXiv:2510.11300v2 Announce Type: replace-cross Abstract: This paper proposes an agent-based approach toward a more natural interface between humans and machines. Large language models equipped with tools and the communication standard OPC UA are utilized to control machines in natural language. Instead of touch interaction, which is currently the ",
    "url": "https://arxiv.org/abs/2510.11300",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Understanding and Improving Length Generalization in Hierarchical Sparse Attention Models",
    "summary": "arXiv:2510.17196v2 Announce Type: replace-cross Abstract: Effectively processing long contexts is a critical challenge for language models. While standard Transformers are limited by quadratic complexity and poor length extrapolation, alternative architectures like sliding window attention and state space models sacrifice the ability to effectively",
    "url": "https://arxiv.org/abs/2510.17196",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Auto-Rubric: Learning From Implicit Weights to Explicit Rubrics for Reward Modeling",
    "summary": "arXiv:2510.17314v2 Announce Type: replace-cross Abstract: Conventional reward modeling relies on gradient descent over neural weights, creating opaque, data-hungry \"black boxes.\" We propose a paradigm shift from implicit to explicit reward parameterization, recasting optimization from continuous weight spaces to the discrete space of natural langua",
    "url": "https://arxiv.org/abs/2510.17314",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Preference-based Reinforcement Learning beyond Pairwise Comparisons: Benefits of Multiple Options",
    "summary": "arXiv:2510.18713v3 Announce Type: replace-cross Abstract: We study online preference-based reinforcement learning (PbRL) with the goal of improving sample efficiency. While a growing body of theoretical work has emerged-motivated by PbRL's recent empirical success, particularly in aligning large language models (LLMs)-most existing studies focus on",
    "url": "https://arxiv.org/abs/2510.18713",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Differentiable Constraint-Based Causal Discovery",
    "summary": "arXiv:2510.22031v2 Announce Type: replace-cross Abstract: Causal discovery from observational data is a fundamental task in artificial intelligence, with far-reaching implications for decision-making, predictions, and interventions. Despite significant advances, existing methods can be broadly categorized as constraint-based or score-based approach",
    "url": "https://arxiv.org/abs/2510.22031",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "TempoPFN: Synthetic Pre-training of Linear RNNs for Zero-shot Time Series Forecasting",
    "summary": "arXiv:2510.25502v4 Announce Type: replace-cross Abstract: Foundation models for zero-shot time series forecasting face challenges in efficient long-horizon prediction and reproducibility, with existing synthetic-only approaches underperforming on challenging benchmarks. This paper presents TempoPFN, a univariate time series foundation model based o",
    "url": "https://arxiv.org/abs/2510.25502",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot Skills",
    "summary": "arXiv:2510.25634v2 Announce Type: replace-cross Abstract: Long-horizon contact-rich bimanual manipulation presents a significant challenge, requiring complex coordination involving a mixture of parallel execution and sequential collaboration between arms. In this paper, we introduce a hierarchical framework that frames this challenge as an integrat",
    "url": "https://arxiv.org/abs/2510.25634",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "VisMem: Latent Vision Memory Unlocks Potential of Vision-Language Models",
    "summary": "arXiv:2511.11007v2 Announce Type: replace-cross Abstract: Despite the remarkable success of Vision-Language Models (VLMs), their performance on a range of complex visual tasks is often hindered by a \"visual processing bottleneck\": a propensity to lose grounding in visual evidence and exhibit a deficit in contextualized visual experience during prol",
    "url": "https://arxiv.org/abs/2511.11007",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Neural Networks Learn Generic Multi-Index Models Near Information-Theoretic Limit",
    "summary": "arXiv:2511.15120v2 Announce Type: replace-cross Abstract: In deep learning, a central issue is to understand how neural networks efficiently learn high-dimensional features. To this end, we explore the gradient descent learning of a general Gaussian Multi-index model $f(\\boldsymbol{x})=g(\\boldsymbol{U}\\boldsymbol{x})$ with hidden subspace $\\boldsym",
    "url": "https://arxiv.org/abs/2511.15120",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Your Latent Reasoning is Secretly Policy Improvement Operator",
    "summary": "arXiv:2511.16886v4 Announce Type: replace-cross Abstract: Recently, small models with latent recursion have obtained promising results on complex reasoning tasks. These results are typically explained by the theory that such recursion increases a networks depth, allowing it to compactly emulate the capacity of larger models. However, the performanc",
    "url": "https://arxiv.org/abs/2511.16886",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "CARL: Focusing Agentic Reinforcement Learning on Critical Actions",
    "summary": "arXiv:2512.04949v2 Announce Type: replace-cross Abstract: Agents capable of accomplishing complex tasks through multiple interactions with the environment have emerged as a popular research direction. However, in such multi-step settings, the conventional group-level policy optimization algorithm becomes suboptimal because of its underlying assumpt",
    "url": "https://arxiv.org/abs/2512.04949",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Sparse Attention Post-Training for Mechanistic Interpretability",
    "summary": "arXiv:2512.05865v2 Announce Type: replace-cross Abstract: We introduce a simple post-training method that makes transformer attention sparse without sacrificing performance. Applying a flexible sparsity regularisation under a constrained-loss objective, we show on models up to 7B parameters that it is possible to retain the original pretraining los",
    "url": "https://arxiv.org/abs/2512.05865",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "WebSTAR: Scalable Data Synthesis for Computer Use Agents with Step-Level Filtering",
    "summary": "arXiv:2512.10962v3 Announce Type: replace-cross Abstract: Computer use agents (CUAs) can operate real-world digital interfaces but remain difficult to train due to the high cost of graphical user interface (GUI) interaction and the scarcity of high-quality trajectory data. Existing datasets rely on human demonstrations, limiting scalability. A natu",
    "url": "https://arxiv.org/abs/2512.10962",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "SIRR-LMM: Single-image Reflection Removal via Large Multimodal Model",
    "summary": "arXiv:2601.07209v2 Announce Type: replace-cross Abstract: Glass surfaces create complex interactions of reflected and transmitted light, making single-image reflection removal (SIRR) challenging. Existing datasets suffer from limited physical realism in synthetic data or insufficient scale in real captures. We introduce a synthetic dataset generati",
    "url": "https://arxiv.org/abs/2601.07209",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "An Example for Domain Adaptation Using CycleGAN",
    "summary": "arXiv:2601.08776v2 Announce Type: replace-cross Abstract: Cycle-Consistent Adversarial Network (CycleGAN) is very promising in domain adaptation. In this report, an example in medical domain will be explained. We present struecture of a CycleGAN model for unpaired image-to-image translation from microscopy to pseudo H\\&amp;E stained histopathology ",
    "url": "https://arxiv.org/abs/2601.08776",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "GeoRA: Geometry-Aware Low-Rank Adaptation for RLVR",
    "summary": "arXiv:2601.09361v2 Announce Type: replace-cross Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is crucial for advancing large-scale reasoning models. However, existing parameter-efficient methods, such as PiSSA and MiLoRA, are designed for Supervised Fine-Tuning (SFT) and do not account for the distinct optimization dynamics and ge",
    "url": "https://arxiv.org/abs/2601.09361",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Improving Low-Resource Machine Translation via Round-Trip Reinforcement Learning",
    "summary": "arXiv:2601.12535v2 Announce Type: replace-cross Abstract: Low-resource machine translation (MT) has gained increasing attention as parallel data from low-resource language communities is collected, but many potential methods for improving low-resource MT remain unexplored. We investigate a self-supervised reinforcement-learning-based fine-tuning fo",
    "url": "https://arxiv.org/abs/2601.12535",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Stream-Voice-Anon: Enhancing Utility of Real-Time Speaker Anonymization via Neural Audio Codec and Language Models",
    "summary": "arXiv:2601.13948v3 Announce Type: replace-cross Abstract: Protecting speaker identity is crucial for online voice applications, yet streaming speaker anonymization (SA) remains underexplored. Recent research has demonstrated that neural audio codec (NAC) provides superior speaker feature disentanglement and linguistic fidelity. NAC can also be used",
    "url": "https://arxiv.org/abs/2601.13948",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Reflexis: Supporting Reflexivity and Rigor in Collaborative Qualitative Analysis through Design for Deliberation",
    "summary": "arXiv:2601.15445v2 Announce Type: replace-cross Abstract: Reflexive Thematic Analysis (RTA) is a critical method for generating deep interpretive insights. Yet its core tenets, including researcher reflexivity, tangible analytical evolution, and productive disagreement, are often poorly supported by software tools that prioritize speed and consensu",
    "url": "https://arxiv.org/abs/2601.15445",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Connect the Dots: Knowledge Graph-Guided Crawler Attack on Retrieval-Augmented Generation Systems",
    "summary": "arXiv:2601.15678v2 Announce Type: replace-cross Abstract: Stealing attacks pose a persistent threat to the intellectual property of deployed machine-learning systems. Retrieval-augmented generation (RAG) intensifies this risk by extending the attack surface beyond model weights to knowledge base that often contains IP-bearing assets such as proprie",
    "url": "https://arxiv.org/abs/2601.15678",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Learning to Discover at Test Time",
    "summary": "arXiv:2601.16175v2 Announce Type: replace-cross Abstract: How can we use AI to discover a new state of the art for a scientific problem? Prior work in test-time scaling, such as AlphaEvolve, performs search by prompting a frozen LLM. We perform reinforcement learning at test time, so the LLM can continue to train, but now with experience specific t",
    "url": "https://arxiv.org/abs/2601.16175",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Adaptive Attribute-Decoupled Encryption for Trusted Respiratory Monitoring in Resource-Limited Consumer Healthcare",
    "summary": "arXiv:2601.16241v2 Announce Type: replace-cross Abstract: Respiratory monitoring is an extremely important task in modern medical services. Due to its significant advantages, e.g., non-contact, radar-based respiratory monitoring has attracted widespread attention from both academia and industry. Unfortunately, though it can achieve high monitoring ",
    "url": "https://arxiv.org/abs/2601.16241",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "When Iterative RAG Beats Ideal Evidence: A Diagnostic Study in Scientific Multi-hop Question Answering",
    "summary": "arXiv:2601.19827v2 Announce Type: replace-cross Abstract: Retrieval-Augmented Generation (RAG) extends large language models (LLMs) beyond parametric knowledge, yet it is unclear when iterative retrieval-reasoning loops meaningfully outperform static RAG, particularly in scientific domains with multi-hop reasoning, sparse domain knowledge, and hete",
    "url": "https://arxiv.org/abs/2601.19827",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "STELLAR: Structure-guided LLM Assertion Retrieval and Generation for Formal Verification",
    "summary": "arXiv:2601.19903v2 Announce Type: replace-cross Abstract: Formal Verification (FV) relies on high-quality SystemVerilog Assertions (SVAs), but the manual writing process is slow and error-prone. Existing LLM-based approaches either generate assertions from scratch or ignore structural patterns in hardware designs and expert-crafted assertions. This",
    "url": "https://arxiv.org/abs/2601.19903",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Log2Motion: Biomechanical Motion Synthesis from Touch Logs",
    "summary": "arXiv:2601.21043v2 Announce Type: replace-cross Abstract: Touch data from mobile devices are collected at scale but reveal little about the interactions that produce them. While biomechanical simulations can illuminate motor control processes, they have not yet been developed for touch interactions. To close this gap, we propose a novel computation",
    "url": "https://arxiv.org/abs/2601.21043",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Zenith: Scaling up Ranking Models for Billion-scale Livestreaming Recommendation",
    "summary": "arXiv:2601.21285v3 Announce Type: replace-cross Abstract: Accurately capturing feature interactions is essential in recommender systems, and recent trends show that scaling up model capacity could be a key driver for next-level predictive performance. While prior work has explored various model architectures to capture multi-granularity feature int",
    "url": "https://arxiv.org/abs/2601.21285",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "SWE-Replay: Efficient Test-Time Scaling for Software Engineering Agents",
    "summary": "arXiv:2601.22129v2 Announce Type: replace-cross Abstract: Test-time scaling has been widely adopted to enhance the capabilities of Large Language Model (LLM) agents in software engineering (SWE) tasks. However, the standard approach of repeatedly sampling trajectories from scratch is computationally expensive. While recent methods have attempted to",
    "url": "https://arxiv.org/abs/2601.22129",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "PEAR: Pixel-aligned Expressive humAn mesh Recovery",
    "summary": "arXiv:2601.22693v2 Announce Type: replace-cross Abstract: Reconstructing detailed 3D human meshes from a single in-the-wild image remains a fundamental challenge in computer vision. Existing SMPLX-based methods often suffer from slow inference, produce only coarse body poses, and exhibit misalignments or unnatural artifacts in fine-grained regions ",
    "url": "https://arxiv.org/abs/2601.22693",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Avoiding Premature Collapse: Adaptive Annealing for Entropy-Regularized Structural Inference",
    "summary": "arXiv:2601.23039v3 Announce Type: replace-cross Abstract: Differentiable matching layers and residual connection paradigms, often implemented via entropy-regularized Optimal Transport (OT), serve as critical mechanisms in structural prediction and architectural scaling. However, recovering discrete permutations or maintaining identity mappings via ",
    "url": "https://arxiv.org/abs/2601.23039",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Impact of LLMs news Sentiment Analysis on Stock Price Movement Prediction",
    "summary": "arXiv:2602.00086v2 Announce Type: replace-cross Abstract: This paper addresses stock price movement prediction by leveraging LLM-based news sentiment analysis. Earlier works have largely focused on proposing and assessing sentiment analysis models and stock movement prediction methods, however, separately. Although promising results have been achie",
    "url": "https://arxiv.org/abs/2602.00086",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Investigating the Impact of Histopathological Foundation Models on Regressive Prediction of Homologous Recombination Deficiency",
    "summary": "arXiv:2602.00151v2 Announce Type: replace-cross Abstract: Foundation models pretrained on large-scale histopathology data have found great success in various fields of computational pathology, but their impact on regressive biomarker prediction remains underexplored. In this work, we systematically evaluate histopathological foundation models for r",
    "url": "https://arxiv.org/abs/2602.00151",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Joint Continual Learning of Local Language Models and Cloud Offloading Decisions with Budget Constraints",
    "summary": "arXiv:2602.00166v2 Announce Type: replace-cross Abstract: Locally deployed Small Language Models (SLMs) must continually support diverse tasks under strict memory and computation constraints, making selective reliance on cloud Large Language Models (LLMs) unavoidable. Regulating cloud assistance during continual learning is challenging, as naive re",
    "url": "https://arxiv.org/abs/2602.00166",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Hallucination is a Consequence of Space-Optimality: A Rate-Distortion Theorem for Membership Testing",
    "summary": "arXiv:2602.00906v4 Announce Type: replace-cross Abstract: Large language models often hallucinate with high confidence on \"random facts\" that lack inferable patterns. We formalize the memorization of such facts as a membership testing problem, unifying the discrete error metrics of Bloom filters with the continuous log-loss of LLMs. By analyzing th",
    "url": "https://arxiv.org/abs/2602.00906",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Unifying Ranking and Generation in Query Auto-Completion via Retrieval-Augmented Generation and Multi-Objective Alignment",
    "summary": "arXiv:2602.01023v3 Announce Type: replace-cross Abstract: Query Auto-Completion (QAC) suggests query completions as users type, helping them articulate intent and reach results more efficiently. Existing approaches face fundamental challenges: traditional retrieve-and-rank pipelines have limited long-tail coverage and require extensive feature engi",
    "url": "https://arxiv.org/abs/2602.01023",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "TxRay: Agentic Postmortem of Live Blockchain Attacks",
    "summary": "arXiv:2602.01317v3 Announce Type: replace-cross Abstract: Decentralized Finance (DeFi) has turned blockchains into financial infrastructure, allowing anyone to trade, lend, and build protocols without intermediaries, but this openness exposes pools of value controlled by code. Within five years, the DeFi ecosystem has lost over 15.75B USD to report",
    "url": "https://arxiv.org/abs/2602.01317",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "The Gradient-Causal Gap: Why Gradient Importance Fails on Complex Tasks",
    "summary": "arXiv:2602.01442v2 Announce Type: replace-cross Abstract: Removing ''important'' high-gradient components from a neural network can improve generalization, while removing unimportant'' low-gradient components can destroy it. We demonstrate this paradox by formalizing the \\textit{Gradient-Causal Gap} in Transformers trained on algorithmic tasks. Whi",
    "url": "https://arxiv.org/abs/2602.01442",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Governance at the Edge of Architecture: Regulating NeuroAI and Neuromorphic Systems",
    "summary": "arXiv:2602.01503v2 Announce Type: replace-cross Abstract: Current AI governance frameworks, including regulatory benchmarks for accuracy, latency, and energy efficiency, are built for static, centrally trained artificial neural networks on von Neumann hardware. NeuroAI systems, embodied in neuromorphic hardware and implemented via spiking neural ne",
    "url": "https://arxiv.org/abs/2602.01503",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "ProphetKV: User-Query-Driven Selective Recomputation for Efficient KV Cache Reuse in Retrieval-Augmented Generation",
    "summary": "arXiv:2602.02579v3 Announce Type: replace-cross Abstract: The prefill stage of long-context Retrieval-Augmented Generation (RAG) is severely bottlenecked by computational overhead. To mitigate this, recent methods assemble pre-calculated KV caches of retrieved RAG documents (by a user query) and reprocess selected tokens to recover cross-attention ",
    "url": "https://arxiv.org/abs/2602.02579",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Exploring Silicon-Based Societies: An Early Study of the Moltbook Agent Community",
    "summary": "arXiv:2602.02613v2 Announce Type: replace-cross Abstract: The rapid emergence of autonomous large language model agents has given rise to persistent, large-scale agent ecosystems whose collective behavior cannot be adequately understood through anecdotal observation or small-scale simulation. This paper introduces data-driven silicon sociology as a",
    "url": "https://arxiv.org/abs/2602.02613",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Prompt Augmentation Scales up GRPO Training on Mathematical Reasoning",
    "summary": "arXiv:2602.03190v2 Announce Type: replace-cross Abstract: Reinforcement learning algorithms such as group-relative policy optimization (GRPO) have demonstrated strong potential for improving the mathematical reasoning capabilities of large language models. However, prior work has consistently observed an entropy collapse phenomenon during reinforce",
    "url": "https://arxiv.org/abs/2602.03190",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "PaperX: A Unified Framework for Multimodal Academic Presentation Generation with Scholar DAG",
    "summary": "arXiv:2602.03866v2 Announce Type: replace-cross Abstract: Transforming scientific papers into multimodal presentation content is essential for research dissemination but remains labor intensive. Existing automated solutions typically treat each format as an isolated downstream task, leading to redundant processing and semantic inconsistency. We int",
    "url": "https://arxiv.org/abs/2602.03866",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Reversible Deep Learning for 13C NMR in Chemoinformatics: On Structures and Spectra",
    "summary": "arXiv:2602.03875v2 Announce Type: replace-cross Abstract: We introduce a reversible deep learning model for 13C NMR that uses a single conditional invertible neural network for both directions between molecular structures and spectra. The network is built from i-RevNet style bijective blocks, so the forward map and its inverse are available by cons",
    "url": "https://arxiv.org/abs/2602.03875",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Sounding Highlights: Dual-Pathway Audio Encoders for Audio-Visual Video Highlight Detection",
    "summary": "arXiv:2602.03891v2 Announce Type: replace-cross Abstract: Audio-visual video highlight detection aims to automatically identify the most salient moments in videos by leveraging both visual and auditory cues. However, existing models often underutilize the audio modality, focusing on high-level semantic features while failing to fully leverage the r",
    "url": "https://arxiv.org/abs/2602.03891",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "JSynFlow: Japanese Synthesised Flowchart Visual Question Answering Dataset built with Large Language Models",
    "summary": "arXiv:2602.04142v2 Announce Type: replace-cross Abstract: Vision and language models (VLMs) are expected to analyse complex documents, such as those containing flowcharts, through a question-answering (QA) interface. The ability to recognise and interpret these flowcharts is in high demand, as they provide valuable insights unavailable in text-only",
    "url": "https://arxiv.org/abs/2602.04142",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  },
  {
    "title": "Addressing Corpus Knowledge Poisoning Attacks on RAG Using Sparse Attention",
    "summary": "arXiv:2602.04711v2 Announce Type: replace-cross Abstract: Retrieval Augmented Generation (RAG) is a highly effective paradigm for keeping LLM-based responses up-to-date and reducing the likelihood of hallucinations. Yet, RAG was recently shown to be quite vulnerable to corpus knowledge poisoning: an attacker injects misleading documents to the corp",
    "url": "https://arxiv.org/abs/2602.04711",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00"
  }
]