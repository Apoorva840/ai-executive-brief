[
  {
    "title": "Google’s AI Overviews Can Scam You. Here’s How to Stay Safe",
    "url": "https://www.wired.com/story/googles-ai-overviews-can-scam-you-heres-how-to-stay-safe/",
    "source": "Wired AI",
    "score": 5,
    "what_happened": "Beyond mistakes or nonsense, deliberately bad information being injected into AI search summaries is leading people down potentially harmful paths.",
    "technical_takeaway": null,
    "primary_risk": null,
    "primary_opportunity": null,
    "who_should_care": null
  },
  {
    "title": "MiniCPM-SALA: Hybridizing Sparse and Linear Attention for Efficient Long-Context Modeling",
    "url": "https://arxiv.org/abs/2602.11761",
    "source": "Arxiv AI",
    "score": 8,
    "what_happened": "arXiv:2602.11761v1 Announce Type: cross Abstract: The evolution of large language models (LLMs) towards applications with ultra-long contexts faces challenges posed by the high computational and memory costs of the Transformer architecture. While existing sparse and linear attention mechanisms attempt to mitigate these issues, they typically involv",
    "technical_takeaway": null,
    "primary_risk": null,
    "primary_opportunity": null,
    "who_should_care": null
  },
  {
    "title": "Bi-Level Prompt Optimization for Multimodal LLM-as-a-Judge",
    "url": "https://arxiv.org/abs/2602.11340",
    "source": "Arxiv AI",
    "score": 7,
    "what_happened": "arXiv:2602.11340v1 Announce Type: new Abstract: Large language models (LLMs) have become widely adopted as automated judges for evaluating AI-generated content. Despite their success, aligning LLM-based evaluations with human judgments remains challenging. While supervised fine-tuning on human-labeled data can improve alignment, it is costly and in",
    "technical_takeaway": null,
    "primary_risk": null,
    "primary_opportunity": null,
    "who_should_care": null
  },
  {
    "title": "Credit Where It is Due: Cross-Modality Connectivity Drives Precise Reinforcement Learning for MLLM Reasoning",
    "url": "https://arxiv.org/abs/2602.11455",
    "source": "Arxiv AI",
    "score": 7,
    "what_happened": "arXiv:2602.11455v1 Announce Type: new Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has significantly advanced the reasoning capabilities of Multimodal Large Language Models (MLLMs), yet how visual evidence is integrated during reasoning remains poorly understood. We explore multimodal RLVR through the lens of cross-modal attentio",
    "technical_takeaway": null,
    "primary_risk": null,
    "primary_opportunity": null,
    "who_should_care": null
  },
  {
    "title": "scPilot: Large Language Model Reasoning Toward Automated Single-Cell Analysis and Discovery",
    "url": "https://arxiv.org/abs/2602.11609",
    "source": "Arxiv AI",
    "score": 7,
    "what_happened": "arXiv:2602.11609v1 Announce Type: new Abstract: We present scPilot, the first systematic framework to practice omics-native reasoning: a large language model (LLM) converses in natural language while directly inspecting single-cell RNA-seq data and on-demand bioinformatics tools. scPilot converts core single-cell analyses, i.e., cell-type annotatio",
    "technical_takeaway": null,
    "primary_risk": null,
    "primary_opportunity": null,
    "who_should_care": null
  }
]