[
  {
    "title": "RooflineBench: A Benchmarking Framework for On-Device LLMs via Roofline Analysis",
    "url": "https://arxiv.org/abs/2602.11506",
    "source": "Arxiv AI",
    "score": 8,
    "what_happened": "arXiv:2602.11506v1 Announce Type: cross Abstract: The transition toward localized intelligence through Small Language Models (SLMs) has intensified the need for rigorous performance characterization on resource-constrained edge hardware. However, objectively measuring the theoretical performance ceilings of diverse architectures across heterogeneou",
    "technical_takeaway": null,
    "primary_risk": null,
    "primary_opportunity": null,
    "who_should_care": null
  },
  {
    "title": "OpenAI Is Nuking Its 4o Model. China’s ChatGPT Fans Aren’t OK",
    "url": "https://www.wired.com/story/openai-nuking-4o-model-china-chatgpt-fans-arent-ok/",
    "source": "Wired AI",
    "score": 6,
    "what_happened": "As OpenAI removed access to GPT-4o in its app on Friday, people who have come to rely on the chatbot for companionship are mourning the loss all over the world.",
    "technical_takeaway": null,
    "primary_risk": null,
    "primary_opportunity": null,
    "who_should_care": null
  },
  {
    "title": "Zillow Has Gone Wild—for AI",
    "url": "https://www.wired.com/story/backchannel-how-artificial-intelligence-changed-zillow/",
    "source": "Wired AI",
    "score": 5,
    "what_happened": "As the housing market stalls, Zillow’s CEO sees AI as “an ingredient rather than a threat” that can both help the company protect its turf and reinvent how people search for homes.",
    "technical_takeaway": null,
    "primary_risk": null,
    "primary_opportunity": null,
    "who_should_care": null
  },
  {
    "title": "Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle",
    "url": "https://arxiv.org/abs/2508.05612",
    "source": "Arxiv AI",
    "score": 8,
    "what_happened": "arXiv:2508.05612v4 Announce Type: replace-cross Abstract: Reinforcement learning (RL) has emerged as an effective post-training paradigm for enhancing the reasoning capabilities of multimodal large language model (MLLM). However, current RL pipelines often suffer from training inefficiencies caused by two underexplored issues: Advantage Collapsing,",
    "technical_takeaway": null,
    "primary_risk": null,
    "primary_opportunity": null,
    "who_should_care": null
  },
  {
    "title": "Discovering Differences in Strategic Behavior Between Humans and LLMs",
    "url": "https://arxiv.org/abs/2602.10324",
    "source": "Arxiv AI",
    "score": 7,
    "what_happened": "arXiv:2602.10324v1 Announce Type: new Abstract: As Large Language Models (LLMs) are increasingly deployed in social and strategic scenarios, it becomes critical to understand where and why their behavior diverges from that of humans. While behavioral game theory (BGT) provides a framework for analyzing behavior, existing models do not fully capture",
    "technical_takeaway": null,
    "primary_risk": null,
    "primary_opportunity": null,
    "who_should_care": null
  }
]