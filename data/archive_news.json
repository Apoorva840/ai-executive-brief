[
  {
    "title": "Interfaze: The Future of AI is built on Task-Specific Small Models",
    "summary": "arXiv:2602.04101v1 Announce Type: new Abstract: We present Interfaze, a system that treats modern LLM applications as a problem of building and acting over context, not just picking the right monolithic model. Instead of a single transformer, we combine (i) a stack of heterogeneous DNNs paired with small language models as perception modules for OC",
    "url": "https://arxiv.org/abs/2602.04101",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-07T03:10:55.111214+00:00"
  },
  {
    "title": "OMG-Agent: Toward Robust Missing Modality Generation with Decoupled Coarse-to-Fine Agentic Workflows",
    "summary": "arXiv:2602.04144v1 Announce Type: new Abstract: Data incompleteness severely impedes the reliability of multimodal systems. Existing reconstruction methods face distinct bottlenecks: conventional parametric/generative models are prone to hallucinations due to over-reliance on internal memory, while retrieval-augmented frameworks struggle with retri",
    "url": "https://arxiv.org/abs/2602.04144",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-07T03:10:55.111214+00:00"
  },
  {
    "title": "ProxyWar: Dynamic Assessment of LLM Code Generation in Game Arenas",
    "summary": "arXiv:2602.04296v1 Announce Type: cross Abstract: Large language models (LLMs) have revolutionized automated code generation, yet the evaluation of their real-world effectiveness remains limited by static benchmarks and simplistic metrics. We present ProxyWar, a novel framework that systematically assesses code generation quality by embedding LLM-g",
    "url": "https://arxiv.org/abs/2602.04296",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-07T03:10:55.111214+00:00"
  },
  {
    "title": "History-Guided Iterative Visual Reasoning with Self-Correction",
    "summary": "arXiv:2602.04413v1 Announce Type: cross Abstract: Self-consistency methods are the core technique for improving the reasoning reliability of multimodal large language models (MLLMs). By generating multiple reasoning results through repeated sampling and selecting the best answer via voting, they play an important role in cross-modal tasks. However,",
    "url": "https://arxiv.org/abs/2602.04413",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-07T03:10:55.111214+00:00"
  },
  {
    "title": "Alignment Drift in Multimodal LLMs: A Two-Phase, Longitudinal Evaluation of Harm Across Eight Model Releases",
    "summary": "arXiv:2602.04739v1 Announce Type: cross Abstract: Multimodal large language models (MLLMs) are increasingly deployed in real-world systems, yet their safety under adversarial prompting remains underexplored. We present a two-phase evaluation of MLLM harmlessness using a fixed benchmark of 726 adversarial prompts authored by 26 professional red team",
    "url": "https://arxiv.org/abs/2602.04739",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-07T03:10:55.111214+00:00"
  },
  {
    "title": "Improving Multimodal Brain Encoding Model with Dynamic Subject-awareness Routing",
    "summary": "arXiv:2510.04670v3 Announce Type: replace Abstract: Naturalistic fMRI encoding must handle multimodal inputs, shifting fusion styles, and pronounced inter-subject variability. We introduce AFIRE (Agnostic Framework for Multimodal fMRI Response Encoding), an agnostic interface that standardizes time-aligned post-fusion tokens from varied encoders, a",
    "url": "https://arxiv.org/abs/2510.04670",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-07T03:10:55.111214+00:00"
  },
  {
    "title": "M^3-Bench: Multi-Modal, Multi-Hop, Multi-Threaded Tool-Using MLLM Agent Benchmark",
    "summary": "arXiv:2511.17729v4 Announce Type: replace Abstract: We present M^3-Bench, the first benchmark for evaluating multimodal tool use under the Model Context Protocol. The benchmark targets realistic, multi-hop and multi-threaded workflows that require visual grounding and textual reasoning, cross-tool dependencies, and persistence of intermediate resou",
    "url": "https://arxiv.org/abs/2511.17729",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-07T03:10:55.111214+00:00"
  },
  {
    "title": "Concise Geometric Description as a Bridge: Unleashing the Potential of LLM for Plane Geometry Problem Solving",
    "summary": "arXiv:2601.21164v2 Announce Type: replace Abstract: Plane Geometry Problem Solving (PGPS) is a multimodal reasoning task that aims to solve a plane geometric problem based on a geometric diagram and problem textual descriptions. Although Large Language Models (LLMs) possess strong reasoning skills, their direct application to PGPS is hindered by th",
    "url": "https://arxiv.org/abs/2601.21164",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-07T03:10:55.111214+00:00"
  },
  {
    "title": "Building Interpretable Models for Moral Decision-Making",
    "summary": "arXiv:2602.03351v2 Announce Type: replace Abstract: We build a custom transformer model to study how neural networks make moral decisions on trolley-style dilemmas. The model processes structured scenarios using embeddings that encode who is affected, how many people, and which outcome they belong to. Our 2-layer architecture achieves 77% accuracy ",
    "url": "https://arxiv.org/abs/2602.03351",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-07T03:10:55.111214+00:00"
  },
  {
    "title": "Investigating Redundancy in Multimodal Large Language Models with Multiple Vision Encoders",
    "summary": "arXiv:2507.03262v3 Announce Type: replace-cross Abstract: Recent multimodal large language models (MLLMs) increasingly integrate multiple vision encoders to improve performance on various benchmarks, assuming that diverse pretraining objectives yield complementary visual signals. However, we show this assumption often fails in practice. Through sys",
    "url": "https://arxiv.org/abs/2507.03262",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-07T03:10:55.111214+00:00"
  },
  {
    "title": "Vid-LLM: A Compact Video-based 3D Multimodal LLM with Reconstruction-Reasoning Synergy",
    "summary": "arXiv:2509.24385v2 Announce Type: replace-cross Abstract: Recent developments in Multimodal Large Language Models (MLLMs) have significantly improved Vision-Language (VL) reasoning in 2D domains. However, extending these capabilities to 3D scene understanding remains a major challenge. Existing 3D Multimodal Large Language Models (3D-MLLMs) often d",
    "url": "https://arxiv.org/abs/2509.24385",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-07T03:10:55.111214+00:00"
  },
  {
    "title": "Breaking the MoE LLM Trilemma: Dynamic Expert Clustering with Structured Compression",
    "summary": "arXiv:2510.02345v3 Announce Type: replace-cross Abstract: Mixture-of-Experts (MoE) Large Language Models (LLMs) face a trilemma of load imbalance, parameter redundancy, and communication overhead. We introduce a unified framework based on dynamic expert clustering and structured compression to address these issues cohesively. Our method employs an ",
    "url": "https://arxiv.org/abs/2510.02345",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-07T03:10:55.111214+00:00"
  },
  {
    "title": "Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks",
    "summary": "arXiv:2510.02712v4 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have revolutionized conversational AI, yet their robustness in extended multi-turn dialogues remains poorly understood. Existing evaluation frameworks focus on static benchmarks and single-turn assessments, failing to capture the temporal dynamics of conversation",
    "url": "https://arxiv.org/abs/2510.02712",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-07T03:10:55.111214+00:00"
  },
  {
    "title": "UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing",
    "summary": "arXiv:2602.02437v2 Announce Type: replace-cross Abstract: Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework tha",
    "url": "https://arxiv.org/abs/2602.02437",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-07T03:10:55.111214+00:00"
  },
  {
    "title": "Knowledge Model Prompting Increases LLM Performance on Planning Tasks",
    "summary": "arXiv:2602.03900v1 Announce Type: new Abstract: Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have come under scrutiny as LLMs' ability to reason at all has come into quest",
    "url": "https://arxiv.org/abs/2602.03900",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 6,
    "archived_at": "2026-02-07T03:10:55.111214+00:00"
  },
  {
    "title": "Interfaze: The Future of AI is built on Task-Specific Small Models",
    "summary": "arXiv:2602.04101v1 Announce Type: new Abstract: We present Interfaze, a system that treats modern LLM applications as a problem of building and acting over context, not just picking the right monolithic model. Instead of a single transformer, we combine (i) a stack of heterogeneous DNNs paired with small language models as perception modules for OC",
    "url": "https://arxiv.org/abs/2602.04101",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:43:59.740086+00:00"
  },
  {
    "title": "OMG-Agent: Toward Robust Missing Modality Generation with Decoupled Coarse-to-Fine Agentic Workflows",
    "summary": "arXiv:2602.04144v1 Announce Type: new Abstract: Data incompleteness severely impedes the reliability of multimodal systems. Existing reconstruction methods face distinct bottlenecks: conventional parametric/generative models are prone to hallucinations due to over-reliance on internal memory, while retrieval-augmented frameworks struggle with retri",
    "url": "https://arxiv.org/abs/2602.04144",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:43:59.740086+00:00"
  },
  {
    "title": "ProxyWar: Dynamic Assessment of LLM Code Generation in Game Arenas",
    "summary": "arXiv:2602.04296v1 Announce Type: cross Abstract: Large language models (LLMs) have revolutionized automated code generation, yet the evaluation of their real-world effectiveness remains limited by static benchmarks and simplistic metrics. We present ProxyWar, a novel framework that systematically assesses code generation quality by embedding LLM-g",
    "url": "https://arxiv.org/abs/2602.04296",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:43:59.740086+00:00"
  },
  {
    "title": "History-Guided Iterative Visual Reasoning with Self-Correction",
    "summary": "arXiv:2602.04413v1 Announce Type: cross Abstract: Self-consistency methods are the core technique for improving the reasoning reliability of multimodal large language models (MLLMs). By generating multiple reasoning results through repeated sampling and selecting the best answer via voting, they play an important role in cross-modal tasks. However,",
    "url": "https://arxiv.org/abs/2602.04413",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:43:59.740086+00:00"
  },
  {
    "title": "Alignment Drift in Multimodal LLMs: A Two-Phase, Longitudinal Evaluation of Harm Across Eight Model Releases",
    "summary": "arXiv:2602.04739v1 Announce Type: cross Abstract: Multimodal large language models (MLLMs) are increasingly deployed in real-world systems, yet their safety under adversarial prompting remains underexplored. We present a two-phase evaluation of MLLM harmlessness using a fixed benchmark of 726 adversarial prompts authored by 26 professional red team",
    "url": "https://arxiv.org/abs/2602.04739",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:43:59.740086+00:00"
  },
  {
    "title": "Improving Multimodal Brain Encoding Model with Dynamic Subject-awareness Routing",
    "summary": "arXiv:2510.04670v3 Announce Type: replace Abstract: Naturalistic fMRI encoding must handle multimodal inputs, shifting fusion styles, and pronounced inter-subject variability. We introduce AFIRE (Agnostic Framework for Multimodal fMRI Response Encoding), an agnostic interface that standardizes time-aligned post-fusion tokens from varied encoders, a",
    "url": "https://arxiv.org/abs/2510.04670",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:43:59.740086+00:00"
  },
  {
    "title": "M^3-Bench: Multi-Modal, Multi-Hop, Multi-Threaded Tool-Using MLLM Agent Benchmark",
    "summary": "arXiv:2511.17729v4 Announce Type: replace Abstract: We present M^3-Bench, the first benchmark for evaluating multimodal tool use under the Model Context Protocol. The benchmark targets realistic, multi-hop and multi-threaded workflows that require visual grounding and textual reasoning, cross-tool dependencies, and persistence of intermediate resou",
    "url": "https://arxiv.org/abs/2511.17729",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:43:59.740086+00:00"
  },
  {
    "title": "Concise Geometric Description as a Bridge: Unleashing the Potential of LLM for Plane Geometry Problem Solving",
    "summary": "arXiv:2601.21164v2 Announce Type: replace Abstract: Plane Geometry Problem Solving (PGPS) is a multimodal reasoning task that aims to solve a plane geometric problem based on a geometric diagram and problem textual descriptions. Although Large Language Models (LLMs) possess strong reasoning skills, their direct application to PGPS is hindered by th",
    "url": "https://arxiv.org/abs/2601.21164",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:43:59.740086+00:00"
  },
  {
    "title": "Building Interpretable Models for Moral Decision-Making",
    "summary": "arXiv:2602.03351v2 Announce Type: replace Abstract: We build a custom transformer model to study how neural networks make moral decisions on trolley-style dilemmas. The model processes structured scenarios using embeddings that encode who is affected, how many people, and which outcome they belong to. Our 2-layer architecture achieves 77% accuracy ",
    "url": "https://arxiv.org/abs/2602.03351",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:43:59.740086+00:00"
  },
  {
    "title": "Investigating Redundancy in Multimodal Large Language Models with Multiple Vision Encoders",
    "summary": "arXiv:2507.03262v3 Announce Type: replace-cross Abstract: Recent multimodal large language models (MLLMs) increasingly integrate multiple vision encoders to improve performance on various benchmarks, assuming that diverse pretraining objectives yield complementary visual signals. However, we show this assumption often fails in practice. Through sys",
    "url": "https://arxiv.org/abs/2507.03262",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:43:59.740086+00:00"
  },
  {
    "title": "Vid-LLM: A Compact Video-based 3D Multimodal LLM with Reconstruction-Reasoning Synergy",
    "summary": "arXiv:2509.24385v2 Announce Type: replace-cross Abstract: Recent developments in Multimodal Large Language Models (MLLMs) have significantly improved Vision-Language (VL) reasoning in 2D domains. However, extending these capabilities to 3D scene understanding remains a major challenge. Existing 3D Multimodal Large Language Models (3D-MLLMs) often d",
    "url": "https://arxiv.org/abs/2509.24385",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:43:59.740086+00:00"
  },
  {
    "title": "Breaking the MoE LLM Trilemma: Dynamic Expert Clustering with Structured Compression",
    "summary": "arXiv:2510.02345v3 Announce Type: replace-cross Abstract: Mixture-of-Experts (MoE) Large Language Models (LLMs) face a trilemma of load imbalance, parameter redundancy, and communication overhead. We introduce a unified framework based on dynamic expert clustering and structured compression to address these issues cohesively. Our method employs an ",
    "url": "https://arxiv.org/abs/2510.02345",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:43:59.740086+00:00"
  },
  {
    "title": "Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks",
    "summary": "arXiv:2510.02712v4 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have revolutionized conversational AI, yet their robustness in extended multi-turn dialogues remains poorly understood. Existing evaluation frameworks focus on static benchmarks and single-turn assessments, failing to capture the temporal dynamics of conversation",
    "url": "https://arxiv.org/abs/2510.02712",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:43:59.740086+00:00"
  },
  {
    "title": "UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing",
    "summary": "arXiv:2602.02437v2 Announce Type: replace-cross Abstract: Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework tha",
    "url": "https://arxiv.org/abs/2602.02437",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:43:59.740086+00:00"
  },
  {
    "title": "Knowledge Model Prompting Increases LLM Performance on Planning Tasks",
    "summary": "arXiv:2602.03900v1 Announce Type: new Abstract: Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have come under scrutiny as LLMs' ability to reason at all has come into quest",
    "url": "https://arxiv.org/abs/2602.03900",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 6,
    "archived_at": "2026-02-06T12:43:59.740086+00:00"
  },
  {
    "title": "Interfaze: The Future of AI is built on Task-Specific Small Models",
    "summary": "arXiv:2602.04101v1 Announce Type: new Abstract: We present Interfaze, a system that treats modern LLM applications as a problem of building and acting over context, not just picking the right monolithic model. Instead of a single transformer, we combine (i) a stack of heterogeneous DNNs paired with small language models as perception modules for OC",
    "url": "https://arxiv.org/abs/2602.04101",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:38:59.092933+00:00"
  },
  {
    "title": "OMG-Agent: Toward Robust Missing Modality Generation with Decoupled Coarse-to-Fine Agentic Workflows",
    "summary": "arXiv:2602.04144v1 Announce Type: new Abstract: Data incompleteness severely impedes the reliability of multimodal systems. Existing reconstruction methods face distinct bottlenecks: conventional parametric/generative models are prone to hallucinations due to over-reliance on internal memory, while retrieval-augmented frameworks struggle with retri",
    "url": "https://arxiv.org/abs/2602.04144",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:38:59.092933+00:00"
  },
  {
    "title": "ProxyWar: Dynamic Assessment of LLM Code Generation in Game Arenas",
    "summary": "arXiv:2602.04296v1 Announce Type: cross Abstract: Large language models (LLMs) have revolutionized automated code generation, yet the evaluation of their real-world effectiveness remains limited by static benchmarks and simplistic metrics. We present ProxyWar, a novel framework that systematically assesses code generation quality by embedding LLM-g",
    "url": "https://arxiv.org/abs/2602.04296",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:38:59.092933+00:00"
  },
  {
    "title": "History-Guided Iterative Visual Reasoning with Self-Correction",
    "summary": "arXiv:2602.04413v1 Announce Type: cross Abstract: Self-consistency methods are the core technique for improving the reasoning reliability of multimodal large language models (MLLMs). By generating multiple reasoning results through repeated sampling and selecting the best answer via voting, they play an important role in cross-modal tasks. However,",
    "url": "https://arxiv.org/abs/2602.04413",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:38:59.092933+00:00"
  },
  {
    "title": "Alignment Drift in Multimodal LLMs: A Two-Phase, Longitudinal Evaluation of Harm Across Eight Model Releases",
    "summary": "arXiv:2602.04739v1 Announce Type: cross Abstract: Multimodal large language models (MLLMs) are increasingly deployed in real-world systems, yet their safety under adversarial prompting remains underexplored. We present a two-phase evaluation of MLLM harmlessness using a fixed benchmark of 726 adversarial prompts authored by 26 professional red team",
    "url": "https://arxiv.org/abs/2602.04739",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:38:59.092933+00:00"
  },
  {
    "title": "Improving Multimodal Brain Encoding Model with Dynamic Subject-awareness Routing",
    "summary": "arXiv:2510.04670v3 Announce Type: replace Abstract: Naturalistic fMRI encoding must handle multimodal inputs, shifting fusion styles, and pronounced inter-subject variability. We introduce AFIRE (Agnostic Framework for Multimodal fMRI Response Encoding), an agnostic interface that standardizes time-aligned post-fusion tokens from varied encoders, a",
    "url": "https://arxiv.org/abs/2510.04670",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:38:59.092933+00:00"
  },
  {
    "title": "M^3-Bench: Multi-Modal, Multi-Hop, Multi-Threaded Tool-Using MLLM Agent Benchmark",
    "summary": "arXiv:2511.17729v4 Announce Type: replace Abstract: We present M^3-Bench, the first benchmark for evaluating multimodal tool use under the Model Context Protocol. The benchmark targets realistic, multi-hop and multi-threaded workflows that require visual grounding and textual reasoning, cross-tool dependencies, and persistence of intermediate resou",
    "url": "https://arxiv.org/abs/2511.17729",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:38:59.092933+00:00"
  },
  {
    "title": "Concise Geometric Description as a Bridge: Unleashing the Potential of LLM for Plane Geometry Problem Solving",
    "summary": "arXiv:2601.21164v2 Announce Type: replace Abstract: Plane Geometry Problem Solving (PGPS) is a multimodal reasoning task that aims to solve a plane geometric problem based on a geometric diagram and problem textual descriptions. Although Large Language Models (LLMs) possess strong reasoning skills, their direct application to PGPS is hindered by th",
    "url": "https://arxiv.org/abs/2601.21164",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:38:59.092933+00:00"
  },
  {
    "title": "Building Interpretable Models for Moral Decision-Making",
    "summary": "arXiv:2602.03351v2 Announce Type: replace Abstract: We build a custom transformer model to study how neural networks make moral decisions on trolley-style dilemmas. The model processes structured scenarios using embeddings that encode who is affected, how many people, and which outcome they belong to. Our 2-layer architecture achieves 77% accuracy ",
    "url": "https://arxiv.org/abs/2602.03351",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:38:59.092933+00:00"
  },
  {
    "title": "Investigating Redundancy in Multimodal Large Language Models with Multiple Vision Encoders",
    "summary": "arXiv:2507.03262v3 Announce Type: replace-cross Abstract: Recent multimodal large language models (MLLMs) increasingly integrate multiple vision encoders to improve performance on various benchmarks, assuming that diverse pretraining objectives yield complementary visual signals. However, we show this assumption often fails in practice. Through sys",
    "url": "https://arxiv.org/abs/2507.03262",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:38:59.092933+00:00"
  },
  {
    "title": "Vid-LLM: A Compact Video-based 3D Multimodal LLM with Reconstruction-Reasoning Synergy",
    "summary": "arXiv:2509.24385v2 Announce Type: replace-cross Abstract: Recent developments in Multimodal Large Language Models (MLLMs) have significantly improved Vision-Language (VL) reasoning in 2D domains. However, extending these capabilities to 3D scene understanding remains a major challenge. Existing 3D Multimodal Large Language Models (3D-MLLMs) often d",
    "url": "https://arxiv.org/abs/2509.24385",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:38:59.092933+00:00"
  },
  {
    "title": "Breaking the MoE LLM Trilemma: Dynamic Expert Clustering with Structured Compression",
    "summary": "arXiv:2510.02345v3 Announce Type: replace-cross Abstract: Mixture-of-Experts (MoE) Large Language Models (LLMs) face a trilemma of load imbalance, parameter redundancy, and communication overhead. We introduce a unified framework based on dynamic expert clustering and structured compression to address these issues cohesively. Our method employs an ",
    "url": "https://arxiv.org/abs/2510.02345",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:38:59.092933+00:00"
  },
  {
    "title": "Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks",
    "summary": "arXiv:2510.02712v4 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have revolutionized conversational AI, yet their robustness in extended multi-turn dialogues remains poorly understood. Existing evaluation frameworks focus on static benchmarks and single-turn assessments, failing to capture the temporal dynamics of conversation",
    "url": "https://arxiv.org/abs/2510.02712",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:38:59.092933+00:00"
  },
  {
    "title": "UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing",
    "summary": "arXiv:2602.02437v2 Announce Type: replace-cross Abstract: Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework tha",
    "url": "https://arxiv.org/abs/2602.02437",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:38:59.092933+00:00"
  },
  {
    "title": "Knowledge Model Prompting Increases LLM Performance on Planning Tasks",
    "summary": "arXiv:2602.03900v1 Announce Type: new Abstract: Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have come under scrutiny as LLMs' ability to reason at all has come into quest",
    "url": "https://arxiv.org/abs/2602.03900",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 6,
    "archived_at": "2026-02-06T12:38:59.092933+00:00"
  },
  {
    "title": "Interfaze: The Future of AI is built on Task-Specific Small Models",
    "summary": "arXiv:2602.04101v1 Announce Type: new Abstract: We present Interfaze, a system that treats modern LLM applications as a problem of building and acting over context, not just picking the right monolithic model. Instead of a single transformer, we combine (i) a stack of heterogeneous DNNs paired with small language models as perception modules for OC",
    "url": "https://arxiv.org/abs/2602.04101",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:20:47.126404+00:00"
  },
  {
    "title": "OMG-Agent: Toward Robust Missing Modality Generation with Decoupled Coarse-to-Fine Agentic Workflows",
    "summary": "arXiv:2602.04144v1 Announce Type: new Abstract: Data incompleteness severely impedes the reliability of multimodal systems. Existing reconstruction methods face distinct bottlenecks: conventional parametric/generative models are prone to hallucinations due to over-reliance on internal memory, while retrieval-augmented frameworks struggle with retri",
    "url": "https://arxiv.org/abs/2602.04144",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:20:47.126404+00:00"
  },
  {
    "title": "ProxyWar: Dynamic Assessment of LLM Code Generation in Game Arenas",
    "summary": "arXiv:2602.04296v1 Announce Type: cross Abstract: Large language models (LLMs) have revolutionized automated code generation, yet the evaluation of their real-world effectiveness remains limited by static benchmarks and simplistic metrics. We present ProxyWar, a novel framework that systematically assesses code generation quality by embedding LLM-g",
    "url": "https://arxiv.org/abs/2602.04296",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:20:47.126404+00:00"
  },
  {
    "title": "History-Guided Iterative Visual Reasoning with Self-Correction",
    "summary": "arXiv:2602.04413v1 Announce Type: cross Abstract: Self-consistency methods are the core technique for improving the reasoning reliability of multimodal large language models (MLLMs). By generating multiple reasoning results through repeated sampling and selecting the best answer via voting, they play an important role in cross-modal tasks. However,",
    "url": "https://arxiv.org/abs/2602.04413",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:20:47.126404+00:00"
  },
  {
    "title": "Alignment Drift in Multimodal LLMs: A Two-Phase, Longitudinal Evaluation of Harm Across Eight Model Releases",
    "summary": "arXiv:2602.04739v1 Announce Type: cross Abstract: Multimodal large language models (MLLMs) are increasingly deployed in real-world systems, yet their safety under adversarial prompting remains underexplored. We present a two-phase evaluation of MLLM harmlessness using a fixed benchmark of 726 adversarial prompts authored by 26 professional red team",
    "url": "https://arxiv.org/abs/2602.04739",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:20:47.126404+00:00"
  },
  {
    "title": "Improving Multimodal Brain Encoding Model with Dynamic Subject-awareness Routing",
    "summary": "arXiv:2510.04670v3 Announce Type: replace Abstract: Naturalistic fMRI encoding must handle multimodal inputs, shifting fusion styles, and pronounced inter-subject variability. We introduce AFIRE (Agnostic Framework for Multimodal fMRI Response Encoding), an agnostic interface that standardizes time-aligned post-fusion tokens from varied encoders, a",
    "url": "https://arxiv.org/abs/2510.04670",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:20:47.126404+00:00"
  },
  {
    "title": "M^3-Bench: Multi-Modal, Multi-Hop, Multi-Threaded Tool-Using MLLM Agent Benchmark",
    "summary": "arXiv:2511.17729v4 Announce Type: replace Abstract: We present M^3-Bench, the first benchmark for evaluating multimodal tool use under the Model Context Protocol. The benchmark targets realistic, multi-hop and multi-threaded workflows that require visual grounding and textual reasoning, cross-tool dependencies, and persistence of intermediate resou",
    "url": "https://arxiv.org/abs/2511.17729",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:20:47.126404+00:00"
  },
  {
    "title": "Concise Geometric Description as a Bridge: Unleashing the Potential of LLM for Plane Geometry Problem Solving",
    "summary": "arXiv:2601.21164v2 Announce Type: replace Abstract: Plane Geometry Problem Solving (PGPS) is a multimodal reasoning task that aims to solve a plane geometric problem based on a geometric diagram and problem textual descriptions. Although Large Language Models (LLMs) possess strong reasoning skills, their direct application to PGPS is hindered by th",
    "url": "https://arxiv.org/abs/2601.21164",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:20:47.126404+00:00"
  },
  {
    "title": "Building Interpretable Models for Moral Decision-Making",
    "summary": "arXiv:2602.03351v2 Announce Type: replace Abstract: We build a custom transformer model to study how neural networks make moral decisions on trolley-style dilemmas. The model processes structured scenarios using embeddings that encode who is affected, how many people, and which outcome they belong to. Our 2-layer architecture achieves 77% accuracy ",
    "url": "https://arxiv.org/abs/2602.03351",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:20:47.126404+00:00"
  },
  {
    "title": "Investigating Redundancy in Multimodal Large Language Models with Multiple Vision Encoders",
    "summary": "arXiv:2507.03262v3 Announce Type: replace-cross Abstract: Recent multimodal large language models (MLLMs) increasingly integrate multiple vision encoders to improve performance on various benchmarks, assuming that diverse pretraining objectives yield complementary visual signals. However, we show this assumption often fails in practice. Through sys",
    "url": "https://arxiv.org/abs/2507.03262",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:20:47.126404+00:00"
  },
  {
    "title": "Vid-LLM: A Compact Video-based 3D Multimodal LLM with Reconstruction-Reasoning Synergy",
    "summary": "arXiv:2509.24385v2 Announce Type: replace-cross Abstract: Recent developments in Multimodal Large Language Models (MLLMs) have significantly improved Vision-Language (VL) reasoning in 2D domains. However, extending these capabilities to 3D scene understanding remains a major challenge. Existing 3D Multimodal Large Language Models (3D-MLLMs) often d",
    "url": "https://arxiv.org/abs/2509.24385",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:20:47.126404+00:00"
  },
  {
    "title": "Breaking the MoE LLM Trilemma: Dynamic Expert Clustering with Structured Compression",
    "summary": "arXiv:2510.02345v3 Announce Type: replace-cross Abstract: Mixture-of-Experts (MoE) Large Language Models (LLMs) face a trilemma of load imbalance, parameter redundancy, and communication overhead. We introduce a unified framework based on dynamic expert clustering and structured compression to address these issues cohesively. Our method employs an ",
    "url": "https://arxiv.org/abs/2510.02345",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:20:47.126404+00:00"
  },
  {
    "title": "Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks",
    "summary": "arXiv:2510.02712v4 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have revolutionized conversational AI, yet their robustness in extended multi-turn dialogues remains poorly understood. Existing evaluation frameworks focus on static benchmarks and single-turn assessments, failing to capture the temporal dynamics of conversation",
    "url": "https://arxiv.org/abs/2510.02712",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:20:47.126404+00:00"
  },
  {
    "title": "UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing",
    "summary": "arXiv:2602.02437v2 Announce Type: replace-cross Abstract: Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework tha",
    "url": "https://arxiv.org/abs/2602.02437",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T12:20:47.126404+00:00"
  },
  {
    "title": "Knowledge Model Prompting Increases LLM Performance on Planning Tasks",
    "summary": "arXiv:2602.03900v1 Announce Type: new Abstract: Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have come under scrutiny as LLMs' ability to reason at all has come into quest",
    "url": "https://arxiv.org/abs/2602.03900",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 6,
    "archived_at": "2026-02-06T12:20:47.126404+00:00"
  },
  {
    "title": "Interfaze: The Future of AI is built on Task-Specific Small Models",
    "summary": "arXiv:2602.04101v1 Announce Type: new Abstract: We present Interfaze, a system that treats modern LLM applications as a problem of building and acting over context, not just picking the right monolithic model. Instead of a single transformer, we combine (i) a stack of heterogeneous DNNs paired with small language models as perception modules for OC",
    "url": "https://arxiv.org/abs/2602.04101",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T11:49:35.333557+00:00"
  },
  {
    "title": "OMG-Agent: Toward Robust Missing Modality Generation with Decoupled Coarse-to-Fine Agentic Workflows",
    "summary": "arXiv:2602.04144v1 Announce Type: new Abstract: Data incompleteness severely impedes the reliability of multimodal systems. Existing reconstruction methods face distinct bottlenecks: conventional parametric/generative models are prone to hallucinations due to over-reliance on internal memory, while retrieval-augmented frameworks struggle with retri",
    "url": "https://arxiv.org/abs/2602.04144",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T11:49:35.333557+00:00"
  },
  {
    "title": "ProxyWar: Dynamic Assessment of LLM Code Generation in Game Arenas",
    "summary": "arXiv:2602.04296v1 Announce Type: cross Abstract: Large language models (LLMs) have revolutionized automated code generation, yet the evaluation of their real-world effectiveness remains limited by static benchmarks and simplistic metrics. We present ProxyWar, a novel framework that systematically assesses code generation quality by embedding LLM-g",
    "url": "https://arxiv.org/abs/2602.04296",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T11:49:35.333557+00:00"
  },
  {
    "title": "History-Guided Iterative Visual Reasoning with Self-Correction",
    "summary": "arXiv:2602.04413v1 Announce Type: cross Abstract: Self-consistency methods are the core technique for improving the reasoning reliability of multimodal large language models (MLLMs). By generating multiple reasoning results through repeated sampling and selecting the best answer via voting, they play an important role in cross-modal tasks. However,",
    "url": "https://arxiv.org/abs/2602.04413",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T11:49:35.333557+00:00"
  },
  {
    "title": "Alignment Drift in Multimodal LLMs: A Two-Phase, Longitudinal Evaluation of Harm Across Eight Model Releases",
    "summary": "arXiv:2602.04739v1 Announce Type: cross Abstract: Multimodal large language models (MLLMs) are increasingly deployed in real-world systems, yet their safety under adversarial prompting remains underexplored. We present a two-phase evaluation of MLLM harmlessness using a fixed benchmark of 726 adversarial prompts authored by 26 professional red team",
    "url": "https://arxiv.org/abs/2602.04739",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T11:49:35.333557+00:00"
  },
  {
    "title": "Improving Multimodal Brain Encoding Model with Dynamic Subject-awareness Routing",
    "summary": "arXiv:2510.04670v3 Announce Type: replace Abstract: Naturalistic fMRI encoding must handle multimodal inputs, shifting fusion styles, and pronounced inter-subject variability. We introduce AFIRE (Agnostic Framework for Multimodal fMRI Response Encoding), an agnostic interface that standardizes time-aligned post-fusion tokens from varied encoders, a",
    "url": "https://arxiv.org/abs/2510.04670",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T11:49:35.333557+00:00"
  },
  {
    "title": "M^3-Bench: Multi-Modal, Multi-Hop, Multi-Threaded Tool-Using MLLM Agent Benchmark",
    "summary": "arXiv:2511.17729v4 Announce Type: replace Abstract: We present M^3-Bench, the first benchmark for evaluating multimodal tool use under the Model Context Protocol. The benchmark targets realistic, multi-hop and multi-threaded workflows that require visual grounding and textual reasoning, cross-tool dependencies, and persistence of intermediate resou",
    "url": "https://arxiv.org/abs/2511.17729",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T11:49:35.333557+00:00"
  },
  {
    "title": "Concise Geometric Description as a Bridge: Unleashing the Potential of LLM for Plane Geometry Problem Solving",
    "summary": "arXiv:2601.21164v2 Announce Type: replace Abstract: Plane Geometry Problem Solving (PGPS) is a multimodal reasoning task that aims to solve a plane geometric problem based on a geometric diagram and problem textual descriptions. Although Large Language Models (LLMs) possess strong reasoning skills, their direct application to PGPS is hindered by th",
    "url": "https://arxiv.org/abs/2601.21164",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T11:49:35.333557+00:00"
  },
  {
    "title": "Building Interpretable Models for Moral Decision-Making",
    "summary": "arXiv:2602.03351v2 Announce Type: replace Abstract: We build a custom transformer model to study how neural networks make moral decisions on trolley-style dilemmas. The model processes structured scenarios using embeddings that encode who is affected, how many people, and which outcome they belong to. Our 2-layer architecture achieves 77% accuracy ",
    "url": "https://arxiv.org/abs/2602.03351",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T11:49:35.333557+00:00"
  },
  {
    "title": "Investigating Redundancy in Multimodal Large Language Models with Multiple Vision Encoders",
    "summary": "arXiv:2507.03262v3 Announce Type: replace-cross Abstract: Recent multimodal large language models (MLLMs) increasingly integrate multiple vision encoders to improve performance on various benchmarks, assuming that diverse pretraining objectives yield complementary visual signals. However, we show this assumption often fails in practice. Through sys",
    "url": "https://arxiv.org/abs/2507.03262",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T11:49:35.333557+00:00"
  },
  {
    "title": "Vid-LLM: A Compact Video-based 3D Multimodal LLM with Reconstruction-Reasoning Synergy",
    "summary": "arXiv:2509.24385v2 Announce Type: replace-cross Abstract: Recent developments in Multimodal Large Language Models (MLLMs) have significantly improved Vision-Language (VL) reasoning in 2D domains. However, extending these capabilities to 3D scene understanding remains a major challenge. Existing 3D Multimodal Large Language Models (3D-MLLMs) often d",
    "url": "https://arxiv.org/abs/2509.24385",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T11:49:35.333557+00:00"
  },
  {
    "title": "Breaking the MoE LLM Trilemma: Dynamic Expert Clustering with Structured Compression",
    "summary": "arXiv:2510.02345v3 Announce Type: replace-cross Abstract: Mixture-of-Experts (MoE) Large Language Models (LLMs) face a trilemma of load imbalance, parameter redundancy, and communication overhead. We introduce a unified framework based on dynamic expert clustering and structured compression to address these issues cohesively. Our method employs an ",
    "url": "https://arxiv.org/abs/2510.02345",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T11:49:35.333557+00:00"
  },
  {
    "title": "Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks",
    "summary": "arXiv:2510.02712v4 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have revolutionized conversational AI, yet their robustness in extended multi-turn dialogues remains poorly understood. Existing evaluation frameworks focus on static benchmarks and single-turn assessments, failing to capture the temporal dynamics of conversation",
    "url": "https://arxiv.org/abs/2510.02712",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T11:49:35.333557+00:00"
  },
  {
    "title": "UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing",
    "summary": "arXiv:2602.02437v2 Announce Type: replace-cross Abstract: Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework tha",
    "url": "https://arxiv.org/abs/2602.02437",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-06T11:49:35.333557+00:00"
  },
  {
    "title": "Knowledge Model Prompting Increases LLM Performance on Planning Tasks",
    "summary": "arXiv:2602.03900v1 Announce Type: new Abstract: Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have come under scrutiny as LLMs' ability to reason at all has come into quest",
    "url": "https://arxiv.org/abs/2602.03900",
    "source": "Arxiv AI",
    "published_at": "2026-02-06T05:00:00+00:00",
    "score": 6,
    "archived_at": "2026-02-06T11:49:35.333557+00:00"
  }
]