[
  {
    "title": "The Small English Town Swept Up in the Global AI Arms Race",
    "summary": "The residents of Potters Bar are working to protect the \u201cgreen belt\u201d of farms, forests, and meadows that surround London from the endless demand for AI infrastructure.",
    "url": "https://www.wired.com/story/the-small-english-town-swept-up-in-the-global-ai-arms-race/",
    "source": "Wired AI",
    "published_at": "2026-02-17T07:00:00+00:00"
  },
  {
    "title": "Agentic AI for Commercial Insurance Underwriting with Adversarial Self-Critique",
    "summary": "arXiv:2602.13213v1 Announce Type: new Abstract: Commercial insurance underwriting is a labor-intensive process that requires manual review of extensive documentation to assess risk and determine policy pricing. While AI offers substantial efficiency improvements, existing solutions lack comprehensive reasoning capabilities and internal mechanisms t",
    "url": "https://arxiv.org/abs/2602.13213",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "BotzoneBench: Scalable LLM Evaluation via Graded AI Anchors",
    "summary": "arXiv:2602.13214v1 Announce Type: new Abstract: Large Language Models (LLMs) are increasingly deployed in interactive environments requiring strategic decision-making, yet systematic evaluation of these capabilities remains challenging. Existing benchmarks for LLMs primarily assess static reasoning through isolated tasks and fail to capture dynamic",
    "url": "https://arxiv.org/abs/2602.13214",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "When to Think Fast and Slow? AMOR: Entropy-Based Metacognitive Gate for Dynamic SSM-Attention Switching",
    "summary": "arXiv:2602.13215v1 Announce Type: new Abstract: Transformers allocate uniform computation to every position, regardless of difficulty. State Space Models (SSMs) offer efficient alternatives but struggle with precise information retrieval over a long horizon. Inspired by dual-process theories of cognition (Kahneman, 2011), we propose AMOR (Adaptive ",
    "url": "https://arxiv.org/abs/2602.13215",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "VeRA: Verified Reasoning Data Augmentation at Scale",
    "summary": "arXiv:2602.13217v1 Announce Type: new Abstract: The main issue with most evaluation schemes today is their \"static\" nature: the same problems are reused repeatedly, allowing for memorization, format exploitation, and eventual saturation. To measure genuine AI progress, we need evaluation that is robust by construction, not by post-hoc detection. In",
    "url": "https://arxiv.org/abs/2602.13217",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Scaling the Scaling Logic: Agentic Meta-Synthesis of Logic Reasoning",
    "summary": "arXiv:2602.13218v1 Announce Type: new Abstract: Scaling verifiable training signals remains a key bottleneck for Reinforcement Learning from Verifiable Rewards (RLVR). Logical reasoning is a natural substrate: constraints are formal and answers are programmatically checkable. However, prior synthesis pipelines either depend on expert-written code o",
    "url": "https://arxiv.org/abs/2602.13218",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "A Geometric Taxonomy of Hallucinations in LLMs",
    "summary": "arXiv:2602.13224v1 Announce Type: new Abstract: The term \"hallucination\" in large language models conflates distinct phenomena with different geometric signatures in embedding space. We propose a taxonomy identifying three types: unfaithfulness (failure to engage with provided context), confabulation (invention of semantically foreign content), and",
    "url": "https://arxiv.org/abs/2602.13224",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Variation is the Key: A Variation-Based Framework for LLM-Generated Text Detection",
    "summary": "arXiv:2602.13226v1 Announce Type: new Abstract: Detecting text generated by large language models (LLMs) is crucial but challenging. Existing detectors depend on impractical assumptions, such as white-box settings, or solely rely on text-level features, leading to imprecise detection ability. In this paper, we propose a simple but effective and pra",
    "url": "https://arxiv.org/abs/2602.13226",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Intelligence as Trajectory-Dominant Pareto Optimization",
    "summary": "arXiv:2602.13230v1 Announce Type: new Abstract: Despite recent advances in artificial intelligence, many systems exhibit stagnation in long-horizon adaptability despite continued performance optimization. This work argues that such limitations do not primarily arise from insufficient learning, data, or model capacity, but from a deeper structural p",
    "url": "https://arxiv.org/abs/2602.13230",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "PlotChain: Deterministic Checkpointed Evaluation of Multimodal LLMs on Engineering Plot Reading",
    "summary": "arXiv:2602.13232v1 Announce Type: new Abstract: We present PlotChain, a deterministic, generator-based benchmark for evaluating multimodal large language models (MLLMs) on engineering plot reading-recovering quantitative values from classic plots (e.g., Bode/FFT, step response, stress-strain, pump curves) rather than OCR-only extraction or free-for",
    "url": "https://arxiv.org/abs/2602.13232",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Stay in Character, Stay Safe: Dual-Cycle Adversarial Self-Evolution for Safety Role-Playing Agents",
    "summary": "arXiv:2602.13234v1 Announce Type: new Abstract: LLM-based role-playing has rapidly improved in fidelity, yet stronger adherence to persona constraints commonly increases vulnerability to jailbreak attacks, especially for risky or negative personas. Most prior work mitigates this issue with training-time solutions (e.g., data curation or alignment-o",
    "url": "https://arxiv.org/abs/2602.13234",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Lang2Act: Fine-Grained Visual Reasoning through Self-Emergent Linguistic Toolchains",
    "summary": "arXiv:2602.13235v1 Announce Type: new Abstract: Visual Retrieval-Augmented Generation (VRAG) enhances Vision-Language Models (VLMs) by incorporating external visual documents to address a given query. Existing VRAG frameworks usually depend on rigid, pre-defined external tools to extend the perceptual capabilities of VLMs, typically by explicitly s",
    "url": "https://arxiv.org/abs/2602.13235",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "NL2LOGIC: AST-Guided Translation of Natural Language into First-Order Logic with Large Language Models",
    "summary": "arXiv:2602.13237v1 Announce Type: new Abstract: Automated reasoning is critical in domains such as law and governance, where verifying claims against facts in documents requires both accuracy and interpretability. Recent work adopts structured reasoning pipelines that translate natural language into first-order logic and delegate inference to autom",
    "url": "https://arxiv.org/abs/2602.13237",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "AST-PAC: AST-guided Membership Inference for Code",
    "summary": "arXiv:2602.13240v1 Announce Type: new Abstract: Code Large Language Models are frequently trained on massive datasets containing restrictively licensed source code. This creates urgent data governance and copyright challenges. Membership Inference Attacks (MIAs) can serve as an auditing mechanism to detect unauthorized data usage in models. While a",
    "url": "https://arxiv.org/abs/2602.13240",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "X-Blocks: Linguistic Building Blocks of Natural Language Explanations for Automated Vehicles",
    "summary": "arXiv:2602.13248v1 Announce Type: new Abstract: Natural language explanations play a critical role in establishing trust and acceptance of automated vehicles (AVs), yet existing approaches lack systematic frameworks for analysing how humans linguistically construct driving rationales across diverse scenarios. This paper introduces X-Blocks (eXplana",
    "url": "https://arxiv.org/abs/2602.13248",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "DPBench: Large Language Models Struggle with Simultaneous Coordination",
    "summary": "arXiv:2602.13255v1 Announce Type: new Abstract: Large language models are increasingly deployed in multi-agent systems, yet we lack benchmarks that test whether they can coordinate under resource contention. We introduce DPBench, a benchmark based on the Dining Philosophers problem that evaluates LLM coordination across eight conditions that vary d",
    "url": "https://arxiv.org/abs/2602.13255",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "MAPLE: A Sub-Agent Architecture for Memory, Learning, and Personalization in Agentic AI Systems",
    "summary": "arXiv:2602.13258v1 Announce Type: new Abstract: Large language model (LLM) agents have emerged as powerful tools for complex tasks, yet their ability to adapt to individual users remains fundamentally limited. We argue this limitation stems from a critical architectural conflation: current systems treat memory, learning, and personalization as a un",
    "url": "https://arxiv.org/abs/2602.13258",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "General learned delegation by clones",
    "summary": "arXiv:2602.13262v1 Announce Type: new Abstract: Frontier language models improve with additional test-time computation, but serial reasoning or uncoordinated parallel sampling can be compute-inefficient under fixed inference budgets. We propose SELFCEST, which equips a base model with the ability to spawn same-weight clones in separate parallel con",
    "url": "https://arxiv.org/abs/2602.13262",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Human-Centered Explainable AI for Security Enhancement: A Deep Intrusion Detection Framework",
    "summary": "arXiv:2602.13271v1 Announce Type: new Abstract: The increasing complexity and frequency of cyber-threats demand intrusion detection systems (IDS) that are not only accurate but also interpretable. This paper presented a novel IDS framework that integrated Explainable Artificial Intelligence (XAI) to enhance transparency in deep learning models. The",
    "url": "https://arxiv.org/abs/2602.13271",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "TemporalBench: A Benchmark for Evaluating LLM-Based Agents on Contextual and Event-Informed Time Series Tasks",
    "summary": "arXiv:2602.13272v1 Announce Type: new Abstract: It is unclear whether strong forecasting performance reflects genuine temporal understanding or the ability to reason under contextual and event-driven conditions. We introduce TemporalBench, a multi-domain benchmark designed to evaluate temporal reasoning behavior under progressively richer informati",
    "url": "https://arxiv.org/abs/2602.13272",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ProMoral-Bench: Evaluating Prompting Strategies for Moral Reasoning and Safety in LLMs",
    "summary": "arXiv:2602.13274v1 Announce Type: new Abstract: Prompt design significantly impacts the moral competence and safety alignment of large language models (LLMs), yet empirical comparisons remain fragmented across datasets and models.We introduce ProMoral-Bench, a unified benchmark evaluating 11 prompting paradigms across four LLM families. Using ETHIC",
    "url": "https://arxiv.org/abs/2602.13274",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Artificial Organisations",
    "summary": "arXiv:2602.13275v1 Announce Type: new Abstract: Alignment research focuses on making individual AI systems reliable. Human institutions achieve reliable collective behaviour differently: they mitigate the risk posed by misaligned individuals through organisational structure. Multi-agent AI systems should follow this institutional model using compar",
    "url": "https://arxiv.org/abs/2602.13275",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "BEAGLE: Behavior-Enforced Agent for Grounded Learner Emulation",
    "summary": "arXiv:2602.13280v1 Announce Type: new Abstract: Simulating student learning behaviors in open-ended problem-solving environments holds potential for education research, from training adaptive tutoring systems to stress-testing pedagogical interventions. However, collecting authentic data is challenging due to privacy concerns and the high cost of l",
    "url": "https://arxiv.org/abs/2602.13280",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Accuracy Standards for AI at Work vs. Personal Life: Evidence from an Online Survey",
    "summary": "arXiv:2602.13283v1 Announce Type: new Abstract: We study how people trade off accuracy when using AI-powered tools in professional versus personal contexts for adoption purposes, the determinants of those trade-offs, and how users cope when AI/apps are unavailable. Because modern AI systems (especially generative models) can produce acceptable but ",
    "url": "https://arxiv.org/abs/2602.13283",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Mirror: A Multi-Agent System for AI-Assisted Ethics Review",
    "summary": "arXiv:2602.13292v1 Announce Type: new Abstract: Ethics review is a foundational mechanism of modern research governance, yet contemporary systems face increasing strain as ethical risks arise as structural consequences of large-scale, interdisciplinary scientific practice. The demand for consistent and defensible decisions under heterogeneous risk ",
    "url": "https://arxiv.org/abs/2602.13292",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "DECKBench: Benchmarking Multi-Agent Frameworks for Academic Slide Generation and Editing",
    "summary": "arXiv:2602.13318v1 Announce Type: new Abstract: Automatically generating and iteratively editing academic slide decks requires more than document summarization. It demands faithful content selection, coherent slide organization, layout-aware rendering, and robust multi-turn instruction following. However, existing benchmarks and evaluation protocol",
    "url": "https://arxiv.org/abs/2602.13318",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Situation Graph Prediction: Structured Perspective Inference for User Modeling",
    "summary": "arXiv:2602.13319v1 Announce Type: new Abstract: Perspective-Aware AI requires modeling evolving internal states--goals, emotions, contexts--not merely preferences. Progress is limited by a data bottleneck: digital footprints are privacy-sensitive and perspective states are rarely labeled. We propose Situation Graph Prediction (SGP), a task that fra",
    "url": "https://arxiv.org/abs/2602.13319",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Information Fidelity in Tool-Using LLM Agents: A Martingale Analysis of the Model Context Protocol",
    "summary": "arXiv:2602.13320v1 Announce Type: new Abstract: As AI agents powered by large language models (LLMs) increasingly use external tools for high-stakes decisions, a critical reliability question arises: how do errors propagate across sequential tool calls? We introduce the first theoretical framework for analyzing error accumulation in Model Context P",
    "url": "https://arxiv.org/abs/2602.13320",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Detecting Jailbreak Attempts in Clinical Training LLMs Through Automated Linguistic Feature Extraction",
    "summary": "arXiv:2602.13321v1 Announce Type: new Abstract: Detecting jailbreak attempts in clinical training large language models (LLMs) requires accurate modeling of linguistic deviations that signal unsafe or off-task user behavior. Prior work on the 2-Sigma clinical simulation platform showed that manually annotated linguistic features could support jailb",
    "url": "https://arxiv.org/abs/2602.13321",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Contrastive explanations of BDI agents",
    "summary": "arXiv:2602.13323v1 Announce Type: new Abstract: The ability of autonomous systems to provide explanations is important for supporting transparency and aiding the development of (appropriate) trust. Prior work has defined a mechanism for Belief-Desire-Intention (BDI) agents to be able to answer questions of the form ``why did you do action $X$?''. H",
    "url": "https://arxiv.org/abs/2602.13323",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Nanbeige4.1-3B: A Small General Model that Reasons, Aligns, and Acts",
    "summary": "arXiv:2602.13367v1 Announce Type: new Abstract: We present Nanbeige4.1-3B, a unified generalist language model that simultaneously achieves strong agentic behavior, code generation, and general reasoning with only 3B parameters. To the best of our knowledge, it is the first open-source small language model (SLM) to achieve such versatility in a sin",
    "url": "https://arxiv.org/abs/2602.13367",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "MoralityGym: A Benchmark for Evaluating Hierarchical Moral Alignment in Sequential Decision-Making Agents",
    "summary": "arXiv:2602.13372v1 Announce Type: new Abstract: Evaluating moral alignment in agents navigating conflicting, hierarchically structured human norms is a critical challenge at the intersection of AI safety, moral philosophy, and cognitive science. We introduce Morality Chains, a novel formalism for representing moral norms as ordered deontic constrai",
    "url": "https://arxiv.org/abs/2602.13372",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "On-Policy Supervised Fine-Tuning for Efficient Reasoning",
    "summary": "arXiv:2602.13407v1 Announce Type: new Abstract: Large reasoning models (LRMs) are commonly trained with reinforcement learning (RL) to explore long chain-of-thought reasoning, achieving strong performance at high computational cost. Recent methods add multi-reward objectives to jointly optimize correctness and brevity, but these complex extensions ",
    "url": "https://arxiv.org/abs/2602.13407",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "NeuroWeaver: An Autonomous Evolutionary Agent for Exploring the Programmatic Space of EEG Analysis Pipelines",
    "summary": "arXiv:2602.13473v1 Announce Type: new Abstract: Although foundation models have demonstrated remarkable success in general domains, the application of these models to electroencephalography (EEG) analysis is constrained by substantial data requirements and high parameterization. These factors incur prohibitive computational costs, thereby impeding ",
    "url": "https://arxiv.org/abs/2602.13473",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "OMNI-LEAK: Orchestrator Multi-Agent Network Induced Data Leakage",
    "summary": "arXiv:2602.13477v1 Announce Type: new Abstract: As Large Language Model (LLM) agents become more capable, their coordinated use in the form of multi-agent systems is anticipated to emerge as a practical paradigm. Prior work has examined the safety and misuse risks associated with agents. However, much of this has focused on the single-agent case an",
    "url": "https://arxiv.org/abs/2602.13477",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Translating Dietary Standards into Healthy Meals with Minimal Substitutions",
    "summary": "arXiv:2602.13502v1 Announce Type: new Abstract: An important goal for personalized diet systems is to improve nutritional quality without compromising convenience or affordability. We present an end-to-end framework that converts dietary standards into complete meals with minimal change. Using the What We Eat in America (WWEIA) intake data for 135,",
    "url": "https://arxiv.org/abs/2602.13502",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "SPILLage: Agentic Oversharing on the Web",
    "summary": "arXiv:2602.13516v1 Announce Type: new Abstract: LLM-powered agents are beginning to automate user's tasks across the open web, often with access to user resources such as emails and calendars. Unlike standard LLMs answering questions in a controlled ChatBot setting, web agents act \"in the wild\", interacting with third parties and leaving behind an ",
    "url": "https://arxiv.org/abs/2602.13516",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "REMem: Reasoning with Episodic Memory in Language Agent",
    "summary": "arXiv:2602.13530v1 Announce Type: new Abstract: Humans excel at remembering concrete experiences along spatiotemporal contexts and performing reasoning across those events, i.e., the capacity for episodic memory. In contrast, memory in language agents remains mainly semantic, and current agents are not yet capable of effectively recollecting and re",
    "url": "https://arxiv.org/abs/2602.13530",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "OpAgent: Operator Agent for Web Navigation",
    "summary": "arXiv:2602.13559v1 Announce Type: new Abstract: To fulfill user instructions, autonomous web agents must contend with the inherent complexity and volatile nature of real-world websites. Conventional paradigms predominantly rely on Supervised Fine-Tuning (SFT) or Offline Reinforcement Learning (RL) using static datasets. However, these methods suffe",
    "url": "https://arxiv.org/abs/2602.13559",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Who Do LLMs Trust? Human Experts Matter More Than Other LLMs",
    "summary": "arXiv:2602.13568v1 Announce Type: new Abstract: Large language models (LLMs) increasingly operate in environments where they encounter social information such as other agents' answers, tool outputs, or human recommendations. In humans, such inputs influence judgments in ways that depend on the source's credibility and the strength of consensus. Thi",
    "url": "https://arxiv.org/abs/2602.13568",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Differentiable Rule Induction from Raw Sequence Inputs",
    "summary": "arXiv:2602.13583v1 Announce Type: new Abstract: Rule learning-based models are widely used in highly interpretable scenarios due to their transparent structures. Inductive logic programming (ILP), a form of machine learning, induces rules from facts while maintaining interpretability. Differentiable ILP models enhance this process by leveraging neu",
    "url": "https://arxiv.org/abs/2602.13583",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "A First Proof Sprint",
    "summary": "arXiv:2602.13587v1 Announce Type: new Abstract: This monograph reports a multi-agent proof sprint on ten research-level problems, combining rapid draft generation with adversarial verification, targeted repair, and explicit provenance. The workflow uses wiring-diagram decompositions of claim dependencies to localize gaps and coordinate reviewer-dri",
    "url": "https://arxiv.org/abs/2602.13587",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Hippocampus: An Efficient and Scalable Memory Module for Agentic AI",
    "summary": "arXiv:2602.13594v1 Announce Type: new Abstract: Agentic AI require persistent memory to store user-specific histories beyond the limited context window of LLMs. Existing memory systems use dense vector databases or knowledge-graph traversal (or hybrid), incurring high retrieval latency and poor storage scalability. We introduce Hippocampus, an agen",
    "url": "https://arxiv.org/abs/2602.13594",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "The Quantization Trap: Breaking Linear Scaling Laws in Multi-Hop Reasoning",
    "summary": "arXiv:2602.13595v1 Announce Type: new Abstract: Neural scaling laws provide a predictable recipe for AI advancement: reducing numerical precision should linearly improve computational efficiency and energy profile (E proportional to bits). In this paper, we demonstrate that this scaling law breaks in the context of multi-hop reasoning. We reveal a ",
    "url": "https://arxiv.org/abs/2602.13595",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "DiffusionRollout: Uncertainty-Aware Rollout Planning in Long-Horizon PDE Solving",
    "summary": "arXiv:2602.13616v1 Announce Type: new Abstract: We propose DiffusionRollout, a novel selective rollout planning strategy for autoregressive diffusion models, aimed at mitigating error accumulation in long-horizon predictions of physical systems governed by partial differential equations (PDEs). Building on the recently validated probabilistic appro",
    "url": "https://arxiv.org/abs/2602.13616",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Guided Collaboration in Heterogeneous LLM-Based Multi-Agent Systems via Entropy-Based Understanding Assessment and Experience Retrieval",
    "summary": "arXiv:2602.13639v1 Announce Type: new Abstract: With recent breakthroughs in large language models (LLMs) for reasoning, planning, and complex task generation, artificial intelligence systems are transitioning from isolated single-agent architectures to multi-agent systems with collaborative intelligence. However, in heterogeneous multi-agent syste",
    "url": "https://arxiv.org/abs/2602.13639",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Building Autonomous GUI Navigation via Agentic-Q Estimation and Step-Wise Policy Optimization",
    "summary": "arXiv:2602.13653v1 Announce Type: new Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have substantially driven the progress of autonomous agents for Graphical User Interface (GUI). Nevertheless, in real-world applications, GUI agents are often faced with non-stationary environments, leading to high computational costs for dat",
    "url": "https://arxiv.org/abs/2602.13653",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "HyFunc: Accelerating LLM-based Function Calls for Agentic AI through Hybrid-Model Cascade and Dynamic Templating",
    "summary": "arXiv:2602.13665v1 Announce Type: new Abstract: While agentic AI systems rely on LLMs to translate user intent into structured function calls, this process is fraught with computational redundancy, leading to high inference latency that hinders real-time applications. This paper identifies and addresses three key redundancies: (1) the redundant pro",
    "url": "https://arxiv.org/abs/2602.13665",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "AllMem: A Memory-centric Recipe for Efficient Long-context Modeling",
    "summary": "arXiv:2602.13680v1 Announce Type: new Abstract: Large Language Models (LLMs) encounter significant performance bottlenecks in long-sequence tasks due to the computational complexity and memory overhead inherent in the self-attention mechanism. To address these challenges, we introduce \\textsc{AllMem}, a novel and efficient hybrid architecture that ",
    "url": "https://arxiv.org/abs/2602.13680",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "PhGPO: Pheromone-Guided Policy Optimization for Long-Horizon Tool Planning",
    "summary": "arXiv:2602.13691v1 Announce Type: new Abstract: Recent advancements in Large Language Model (LLM) agents have demonstrated strong capabilities in executing complex tasks through tool use. However, long-horizon multi-step tool planning is challenging, because the exploration space suffers from a combinatorial explosion. In this scenario, even when a",
    "url": "https://arxiv.org/abs/2602.13691",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Can a Lightweight Automated AI Pipeline Solve Research-Level Mathematical Problems?",
    "summary": "arXiv:2602.13695v1 Announce Type: new Abstract: Large language models (LLMs) have recently achieved remarkable success in generating rigorous mathematical proofs, with \"AI for Math\" emerging as a vibrant field of research. While these models have mastered competition-level benchmarks like the International Mathematical Olympiad and show promise in ",
    "url": "https://arxiv.org/abs/2602.13695",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "No Need to Train Your RDB Foundation Model",
    "summary": "arXiv:2602.13697v1 Announce Type: new Abstract: Relational databases (RDBs) contain vast amounts of heterogeneous tabular information that can be exploited for predictive modeling purposes. But since the space of potential targets is vast across enterprise settings, how can we \\textit{avoid retraining} a new model each time we wish to predict a new",
    "url": "https://arxiv.org/abs/2602.13697",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "OneLatent: Single-Token Compression for Visual Latent Reasoning",
    "summary": "arXiv:2602.13738v1 Announce Type: new Abstract: Chain-of-thought (CoT) prompting improves reasoning but often increases inference cost by one to two orders of magnitude. To address these challenges, we present \\textbf{OneLatent}, a framework that compresses intermediate reasoning into a single latent token via supervision from rendered CoT images a",
    "url": "https://arxiv.org/abs/2602.13738",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "OR-Agent: Bridging Evolutionary Search and Structured Research for Automated Algorithm Discovery",
    "summary": "arXiv:2602.13769v1 Announce Type: new Abstract: Automating scientific discovery in complex, experiment-driven domains requires more than iterative mutation of programs; it demands structured hypothesis management, environment interaction, and principled reflection. We present OR-Agent, a configurable multi-agent research framework designed for auto",
    "url": "https://arxiv.org/abs/2602.13769",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "StackingNet: Collective Inference Across Independent AI Foundation Models",
    "summary": "arXiv:2602.13792v1 Announce Type: new Abstract: Artificial intelligence built on large foundation models has transformed language understanding, vision and reasoning, yet these systems remain isolated and cannot readily share their capabilities. Integrating the complementary strengths of such independent foundation models is essential for building ",
    "url": "https://arxiv.org/abs/2602.13792",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Attention in Constant Time: Vashista Sparse Attention for Long-Context Decoding with Exponential Guarantees",
    "summary": "arXiv:2602.13804v1 Announce Type: new Abstract: Large language models spend most of their inference cost on attention over long contexts, yet empirical behavior suggests that only a small subset of tokens meaningfully contributes to each query. We formalize this phenomenon by modeling attention as a projection onto the convex hull of key vectors an",
    "url": "https://arxiv.org/abs/2602.13804",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "An end-to-end agentic pipeline for smart contract translation and quality evaluation",
    "summary": "arXiv:2602.13808v1 Announce Type: new Abstract: We present an end-to-end framework for systematic evaluation of LLM-generated smart contracts from natural-language specifications. The system parses contractual text into structured schemas, generates Solidity code, and performs automated quality assessment through compilation and security checks. Us",
    "url": "https://arxiv.org/abs/2602.13808",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Experimentation Accelerator: Interpretable Insights and Creative Recommendations for A/B Testing with Content-Aware ranking",
    "summary": "arXiv:2602.13852v1 Announce Type: new Abstract: Modern online experimentation faces two bottlenecks: scarce traffic forces tough choices on which variants to test, and post-hoc insight extraction is manual, inconsistent, and often content-agnostic. Meanwhile, organizations underuse historical A/B results and rich content embeddings that could guide",
    "url": "https://arxiv.org/abs/2602.13852",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "From Fluent to Verifiable: Claim-Level Auditability for Deep Research Agents",
    "summary": "arXiv:2602.13855v1 Announce Type: new Abstract: A deep research agent produces a fluent scientific report in minutes; a careful reader then tries to verify the main claims and discovers the real cost is not reading, but tracing: which sentence is supported by which passage, what was ignored, and where evidence conflicts. We argue that as research g",
    "url": "https://arxiv.org/abs/2602.13855",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Enabling Option Learning in Sparse Rewards with Hindsight Experience Replay",
    "summary": "arXiv:2602.13865v1 Announce Type: new Abstract: Hierarchical Reinforcement Learning (HRL) frameworks like Option-Critic (OC) and Multi-updates Option Critic (MOC) have introduced significant advancements in learning reusable options. However, these methods underperform in multi-goal environments with sparse rewards, where actions must be linked to ",
    "url": "https://arxiv.org/abs/2602.13865",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Ambient Physics: Training Neural PDE Solvers with Partial Observations",
    "summary": "arXiv:2602.13873v1 Announce Type: new Abstract: In many scientific settings, acquiring complete observations of PDE coefficients and solutions can be expensive, hazardous, or impossible. Recent diffusion-based methods can reconstruct fields given partial observations, but require complete observations for training. We introduce Ambient Physics, a f",
    "url": "https://arxiv.org/abs/2602.13873",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "VSAL: A Vision Solver with Adaptive Layouts for Graph Property Detection",
    "summary": "arXiv:2602.13880v1 Announce Type: new Abstract: Graph property detection aims to determine whether a graph exhibits certain structural properties, such as being Hamiltonian. Recently, learning-based approaches have shown great promise by leveraging data-driven models to detect graph properties efficiently. In particular, vision-based methods offer ",
    "url": "https://arxiv.org/abs/2602.13880",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Diagnosing Pathological Chain-of-Thought in Reasoning Models",
    "summary": "arXiv:2602.13904v1 Announce Type: new Abstract: Chain-of-thought (CoT) reasoning is fundamental to modern LLM architectures and represents a critical intervention point for AI safety. However, CoT reasoning may exhibit failure modes that we note as pathologies, which prevent it from being useful for monitoring. Prior work has identified three disti",
    "url": "https://arxiv.org/abs/2602.13904",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "From Pixels to Policies: Reinforcing Spatial Reasoning in Language Models for Content-Aware Layout Design",
    "summary": "arXiv:2602.13912v1 Announce Type: new Abstract: We introduce LaySPA, a reinforcement learning framework that equips large language models (LLMs) with explicit and interpretable spatial reasoning for content-aware graphic layout design. LaySPA addresses two key challenges: LLMs' limited spatial reasoning and the lack of opacity in design decision ma",
    "url": "https://arxiv.org/abs/2602.13912",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "HyMem: Hybrid Memory Architecture with Dynamic Retrieval Scheduling",
    "summary": "arXiv:2602.13933v1 Announce Type: new Abstract: Large language model (LLM) agents demonstrate strong performance in short-text contexts but often underperform in extended dialogues due to inefficient memory management. Existing approaches face a fundamental trade-off between efficiency and effectiveness: memory compression risks losing critical det",
    "url": "https://arxiv.org/abs/2602.13933",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Statistical Early Stopping for Reasoning Models",
    "summary": "arXiv:2602.13935v1 Announce Type: new Abstract: While LLMs have seen substantial improvement in reasoning capabilities, they also sometimes overthink, generating unnecessary reasoning steps, particularly under uncertainty, given ill-posed or ambiguous queries. We introduce statistically principled early stopping methods that monitor uncertainty sig",
    "url": "https://arxiv.org/abs/2602.13935",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "A Generalizable Physics-guided Causal Model for Trajectory Prediction in Autonomous Driving",
    "summary": "arXiv:2602.13936v1 Announce Type: new Abstract: Trajectory prediction for traffic agents is critical for safe autonomous driving. However, achieving effective zero-shot generalization in previously unseen domains remains a significant challenge. Motivated by the consistent nature of kinematics across diverse domains, we aim to incorporate domain-in",
    "url": "https://arxiv.org/abs/2602.13936",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Neuromem: A Granular Decomposition of the Streaming Lifecycle in External Memory for LLMs",
    "summary": "arXiv:2602.13967v1 Announce Type: new Abstract: Most evaluations of External Memory Module assume a static setting: memory is built offline and queried at a fixed state. In practice, memory is streaming: new facts arrive continuously, insertions interleave with retrievals, and the memory state evolves while the model is serving queries. In this reg",
    "url": "https://arxiv.org/abs/2602.13967",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Cognitive Chunking for Soft Prompts: Accelerating Compressor Learning via Block-wise Causal Masking",
    "summary": "arXiv:2602.13980v1 Announce Type: new Abstract: Providing extensive context via prompting is vital for leveraging the capabilities of Large Language Models (LLMs). However, lengthy contexts significantly increase inference latency, as the computational cost of self-attention grows quadratically with sequence length. To mitigate this issue, context ",
    "url": "https://arxiv.org/abs/2602.13980",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Bridging AI and Clinical Reasoning: Abductive Explanations for Alignment on Critical Symptoms",
    "summary": "arXiv:2602.13985v1 Announce Type: new Abstract: Artificial intelligence (AI) has demonstrated strong potential in clinical diagnostics, often achieving accuracy comparable to or exceeding that of human experts. A key challenge, however, is that AI reasoning frequently diverges from structured clinical frameworks, limiting trust, interpretability, a",
    "url": "https://arxiv.org/abs/2602.13985",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Prompt-Driven Low-Altitude Edge Intelligence: Modular Agents and Generative Reasoning",
    "summary": "arXiv:2602.14003v1 Announce Type: new Abstract: The large artificial intelligence models (LAMs) show strong capabilities in perception, reasoning, and multi-modal understanding, and can enable advanced capabilities in low-altitude edge intelligence. However, the deployment of LAMs at the edge remains constrained by some fundamental limitations. Fir",
    "url": "https://arxiv.org/abs/2602.14003",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "FloCA: Towards Faithful and Logically Consistent Flowchart Reasoning",
    "summary": "arXiv:2602.14035v1 Announce Type: new Abstract: Flowchart-oriented dialogue (FOD) systems aim to guide users through multi-turn decision-making or operational procedures by following a domain-specific flowchart to achieve a task goal. In this work, we formalize flowchart reasoning in FOD as grounding user input to flowchart nodes at each dialogue t",
    "url": "https://arxiv.org/abs/2602.14035",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Choosing How to Remember: Adaptive Memory Structures for LLM Agents",
    "summary": "arXiv:2602.14038v1 Announce Type: new Abstract: Memory is critical for enabling large language model (LLM) based agents to maintain coherent behavior over long-horizon interactions. However, existing agent memory systems suffer from two key gaps: they rely on a one-size-fits-all memory structure and do not model memory structure selection as a cont",
    "url": "https://arxiv.org/abs/2602.14038",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "REAL: Resolving Knowledge Conflicts in Knowledge-Intensive Visual Question Answering via Reasoning-Pivot Alignment",
    "summary": "arXiv:2602.14065v1 Announce Type: new Abstract: Knowledge-intensive Visual Question Answering (KI-VQA) frequently suffers from severe knowledge conflicts caused by the inherent limitations of open-domain retrieval. However, existing paradigms face critical limitations due to the lack of generalizable conflict detection and intra-model constraint me",
    "url": "https://arxiv.org/abs/2602.14065",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Plan-MCTS: Plan Exploration for Action Exploitation in Web Navigation",
    "summary": "arXiv:2602.14083v1 Announce Type: new Abstract: Large Language Models (LLMs) have empowered autonomous agents to handle complex web navigation tasks. While recent studies integrate tree search to enhance long-horizon reasoning, applying these algorithms in web navigation faces two critical challenges: sparse valid paths that lead to inefficient exp",
    "url": "https://arxiv.org/abs/2602.14083",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "GUI-GENESIS: Automated Synthesis of Efficient Environments with Verifiable Rewards for GUI Agent Post-Training",
    "summary": "arXiv:2602.14093v1 Announce Type: new Abstract: Post-training GUI agents in interactive environments is critical for developing generalization and long-horizon planning capabilities. However, training on real-world applications is hindered by high latency, poor reproducibility, and unverifiable rewards relying on noisy visual proxies. To address th",
    "url": "https://arxiv.org/abs/2602.14093",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "NEST: Nascent Encoded Steganographic Thoughts",
    "summary": "arXiv:2602.14095v1 Announce Type: new Abstract: Monitoring chain-of-thought (CoT) reasoning is a foundational safety technique for large language model (LLM) agents; however, this oversight is compromised if models learn to conceal their reasoning. We explore the potential for steganographic CoT -- where models hide secret reasoning within innocuou",
    "url": "https://arxiv.org/abs/2602.14095",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Algebraic Quantum Intelligence: A New Framework for Reproducible Machine Creativity",
    "summary": "arXiv:2602.14130v1 Announce Type: new Abstract: Large language models (LLMs) have achieved remarkable success in generating fluent and contextually appropriate text; however, their capacity to produce genuinely creative outputs remains limited. This paper posits that this limitation arises from a structural property of contemporary LLMs: when provi",
    "url": "https://arxiv.org/abs/2602.14130",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ForesightSafety Bench: A Frontier Risk Evaluation and Governance Framework towards Safe AI",
    "summary": "arXiv:2602.14135v1 Announce Type: new Abstract: Rapidly evolving AI exhibits increasingly strong autonomy and goal-directed capabilities, accompanied by derivative systemic risks that are more unpredictable, difficult to control, and potentially irreversible. However, current AI safety evaluation systems suffer from critical limitations such as res",
    "url": "https://arxiv.org/abs/2602.14135",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Process-Supervised Multi-Agent Reinforcement Learning for Reliable Clinical Reasoning",
    "summary": "arXiv:2602.14160v1 Announce Type: new Abstract: Clinical decision-making requires nuanced reasoning over heterogeneous evidence and traceable justifications. While recent LLM multi-agent systems (MAS) show promise, they largely optimise for outcome accuracy while overlooking process-grounded reasoning aligned with clinical standards. One critical r",
    "url": "https://arxiv.org/abs/2602.14160",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Text Before Vision: Staged Knowledge Injection Matters for Agentic RLVR in Ultra-High-Resolution Remote Sensing Understanding",
    "summary": "arXiv:2602.14225v1 Announce Type: new Abstract: Multimodal reasoning for ultra-high-resolution (UHR) remote sensing (RS) is usually bottlenecked by visual evidence acquisition: the model necessitates localizing tiny task-relevant regions in massive pixel spaces. While Agentic Reinforcement Learning with Verifiable Rewards (RLVR) using zoom-in tools",
    "url": "https://arxiv.org/abs/2602.14225",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "CORPGEN: Simulating Corporate Environments with Autonomous Digital Employees in Multi-Horizon Task Environments",
    "summary": "arXiv:2602.14229v1 Announce Type: new Abstract: Long-horizon reasoning is a key challenge for autonomous agents, yet existing benchmarks evaluate agents on single tasks in isolation. Real organizational work requires managing many concurrent long-horizon tasks with interleaving, dependencies, and reprioritization. We introduce Multi-Horizon Task En",
    "url": "https://arxiv.org/abs/2602.14229",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "REDSearcher: A Scalable and Cost-Efficient Framework for Long-Horizon Search Agents",
    "summary": "arXiv:2602.14234v1 Announce Type: new Abstract: Large language models are transitioning from generalpurpose knowledge engines to realworld problem solvers, yet optimizing them for deep search tasks remains challenging. The central bottleneck lies in the extreme sparsity of highquality search trajectories and reward signals, arising from the difficu",
    "url": "https://arxiv.org/abs/2602.14234",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "GRAIL: Goal Recognition Alignment through Imitation Learning",
    "summary": "arXiv:2602.14252v1 Announce Type: new Abstract: Understanding an agent's goals from its behavior is fundamental to aligning AI systems with human intentions. Existing goal recognition methods typically rely on an optimal goal-oriented policy representation, which may differ from the actor's true behavior and hinder the accurate recognition of their",
    "url": "https://arxiv.org/abs/2602.14252",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "AutoWebWorld: Synthesizing Infinite Verifiable Web Environments via Finite State Machines",
    "summary": "arXiv:2602.14296v1 Announce Type: new Abstract: The performance of autonomous Web GUI agents heavily relies on the quality and quantity of their training data. However, a fundamental bottleneck persists: collecting interaction trajectories from real-world websites is expensive and difficult to verify. The underlying state transitions are hidden, le",
    "url": "https://arxiv.org/abs/2602.14296",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Benchmarking at the Edge of Comprehension",
    "summary": "arXiv:2602.14307v1 Announce Type: new Abstract: As frontier Large Language Models (LLMs) increasingly saturate new benchmarks shortly after they are published, benchmarking itself is at a juncture: if frontier models keep improving, it will become increasingly hard for humans to generate discriminative tasks, provide accurate ground-truth answers, ",
    "url": "https://arxiv.org/abs/2602.14307",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Competition for attention predicts good-to-bad tipping in AI",
    "summary": "arXiv:2602.14370v1 Announce Type: new Abstract: More than half the global population now carries devices that can run ChatGPT-like language models with no Internet connection and minimal safety oversight -- and hence the potential to promote self-harm, financial losses and extremism among other dangers. Existing safety tools either require cloud co",
    "url": "https://arxiv.org/abs/2602.14370",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Boule or Baguette? A Study on Task Topology, Length Generalization, and the Benefit of Reasoning Traces",
    "summary": "arXiv:2602.14404v1 Announce Type: new Abstract: Recent years have witnessed meteoric progress in reasoning models: neural networks that generate intermediate reasoning traces (RTs) before producing a final output. Despite the rapid advancement, our understanding of how RTs support reasoning, and the limits of this paradigm, remain incomplete. To pr",
    "url": "https://arxiv.org/abs/2602.14404",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Precedent-Informed Reasoning: Mitigating Overthinking in Large Reasoning Models via Test-Time Precedent Learning",
    "summary": "arXiv:2602.14451v1 Announce Type: new Abstract: Reasoning in Large Language Models (LLMs) often suffers from inefficient long chain-of-thought traces with redundant self-exploration and validation, which inflate computational costs and even degrade performance. Inspired by human reasoning patterns where people solve new problems by leveraging past ",
    "url": "https://arxiv.org/abs/2602.14451",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report v1.5",
    "summary": "arXiv:2602.14457v1 Announce Type: new Abstract: To understand and identify the unprecedented risks posed by rapidly advancing artificial intelligence (AI) models, Frontier AI Risk Management Framework in Practice presents a comprehensive assessment of their frontier risks. As Large Language Models (LLMs) general capabilities rapidly evolve and the ",
    "url": "https://arxiv.org/abs/2602.14457",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Bounding Probabilities of Causation with Partial Causal Diagrams",
    "summary": "arXiv:2602.14503v1 Announce Type: new Abstract: Probabilities of causation are fundamental to individual-level explanation and decision making, yet they are inherently counterfactual and not point-identifiable from data in general. Existing bounds either disregard available covariates, require complete causal graphs, or rely on restrictive binary s",
    "url": "https://arxiv.org/abs/2602.14503",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Formally Verifying and Explaining Sepsis Treatment Policies with COOL-MC",
    "summary": "arXiv:2602.14505v1 Announce Type: new Abstract: Safe and interpretable sequential decision-making is critical in healthcare, yet reinforcement learning (RL) policies for sepsis treatment optimization remain opaque and difficult to verify. Standard probabilistic model checkers operate on the full state space, which becomes infeasible for larger MDPs",
    "url": "https://arxiv.org/abs/2602.14505",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Diagnosing Knowledge Conflict in Multimodal Long-Chain Reasoning",
    "summary": "arXiv:2602.14518v1 Announce Type: new Abstract: Multimodal large language models (MLLMs) in long chain-of-thought reasoning often fail when different knowledge sources provide conflicting signals. We formalize these failures under a unified notion of knowledge conflict, distinguishing input-level objective conflict from process-level effective conf",
    "url": "https://arxiv.org/abs/2602.14518",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Disentangling Deception and Hallucination Failures in LLMs",
    "summary": "arXiv:2602.14529v1 Announce Type: new Abstract: Failures in large language models (LLMs) are often analyzed from a behavioral perspective, where incorrect outputs in factual question answering are commonly associated with missing knowledge. In this work, focusing on entity-based factual queries, we suggest that such a view may conflate different fa",
    "url": "https://arxiv.org/abs/2602.14529",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "MATEO: A Multimodal Benchmark for Temporal Reasoning and Planning in LVLMs",
    "summary": "arXiv:2602.14589v1 Announce Type: new Abstract: AI agents need to plan to achieve complex goals that involve orchestrating perception, sub-goal decomposition, and execution. These plans consist of ordered steps structured according to a Temporal Execution Order (TEO, a directed acyclic graph that ensures each step executes only after its preconditi",
    "url": "https://arxiv.org/abs/2602.14589",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Tabular Foundation Models Can Learn Association Rules",
    "summary": "arXiv:2602.14622v1 Announce Type: new Abstract: Association Rule Mining (ARM) is a fundamental task for knowledge discovery in tabular data and is widely used in high-stakes decision-making. Classical ARM methods rely on frequent itemset mining, leading to rule explosion and poor scalability, while recent neural approaches mitigate these issues but",
    "url": "https://arxiv.org/abs/2602.14622",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Arbor: A Framework for Reliable Navigation of Critical Conversation Flows",
    "summary": "arXiv:2602.14643v1 Announce Type: new Abstract: Large language models struggle to maintain strict adherence to structured workflows in high-stakes domains such as healthcare triage. Monolithic approaches that encode entire decision structures within a single prompt are prone to instruction-following degradation as prompt length increases, including",
    "url": "https://arxiv.org/abs/2602.14643",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "From User Preferences to Base Score Extraction Functions in Gradual Argumentation",
    "summary": "arXiv:2602.14674v1 Announce Type: new Abstract: Gradual argumentation is a field of symbolic AI which is attracting attention for its ability to support transparent and contestable AI systems. It is considered a useful tool in domains such as decision-making, recommendation, debate analysis, and others. The outcomes in such domains are usually depe",
    "url": "https://arxiv.org/abs/2602.14674",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "GREAT-EER: Graph Edge Attention Network for Emergency Evacuation Responses",
    "summary": "arXiv:2602.14676v1 Announce Type: new Abstract: Emergency situations that require the evacuation of urban areas can arise from man-made causes (e.g., terrorist attacks or industrial accidents) or natural disasters, the latter becoming more frequent due to climate change. As a result, effective and fast methods to develop evacuation plans are of gre",
    "url": "https://arxiv.org/abs/2602.14676",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Removing Planner Bias in Goal Recognition Through Multi-Plan Dataset Generation",
    "summary": "arXiv:2602.14691v1 Announce Type: new Abstract: Autonomous agents require some form of goal and plan recognition to interact in multiagent settings. Unfortunately, all existing goal recognition datasets suffer from a systematical bias induced by the planning systems that generated them, namely heuristic-based forward search. This means that existin",
    "url": "https://arxiv.org/abs/2602.14691",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Evolutionary System Prompt Learning can Facilitate Reinforcement Learning for LLMs",
    "summary": "arXiv:2602.14697v1 Announce Type: new Abstract: Building agentic systems that can autonomously self-improve from experience is a longstanding goal of AI. Large language models (LLMs) today primarily self-improve via two mechanisms: self-reflection for context updates, and reinforcement learning (RL) for weight updates. In this work, we propose Evol",
    "url": "https://arxiv.org/abs/2602.14697",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "WebWorld: A Large-Scale World Model for Web Agent Training",
    "summary": "arXiv:2602.14721v1 Announce Type: new Abstract: Web agents require massive trajectories to generalize, yet real-world training is constrained by network latency, rate limits, and safety risks. We introduce \\textbf{WebWorld} series, the first open-web simulator trained at scale. While existing simulators are restricted to closed environments with th",
    "url": "https://arxiv.org/abs/2602.14721",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "AI Arms and Influence: Frontier Models Exhibit Sophisticated Reasoning in Simulated Nuclear Crises",
    "summary": "arXiv:2602.14740v1 Announce Type: new Abstract: Today's leading AI models engage in sophisticated behaviour when placed in strategic competition. They spontaneously attempt deception, signaling intentions they do not intend to follow; they demonstrate rich theory of mind, reasoning about adversary beliefs and anticipating their actions; and they ex",
    "url": "https://arxiv.org/abs/2602.14740",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Return of the Schema: Building Complete Datasets for Machine Learning and Reasoning on Knowledge Graphs",
    "summary": "arXiv:2602.14795v1 Announce Type: new Abstract: Datasets for the experimental evaluation of knowledge graph refinement algorithms typically contain only ground facts, retaining very limited schema level knowledge even when such information is available in the source knowledge graphs. This limits the evaluation of methods that rely on rich ontologic",
    "url": "https://arxiv.org/abs/2602.14795",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "World Models for Policy Refinement in StarCraft II",
    "summary": "arXiv:2602.14857v1 Announce Type: new Abstract: Large Language Models (LLMs) have recently shown strong reasoning and generalization capabilities, motivating their use as decision-making policies in complex environments. StarCraft II (SC2), with its massive state-action space and partial observability, is a challenging testbed. However, existing LL",
    "url": "https://arxiv.org/abs/2602.14857",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "EmbeWebAgent: Embedding Web Agents into Any Customized UI",
    "summary": "arXiv:2602.14865v1 Announce Type: new Abstract: Most web agents operate at the human interface level, observing screenshots or raw DOM trees without application-level access, which limits robustness and action expressiveness. In enterprise settings, however, explicit control of both the frontend and backend is available. We present EmbeWebAgent, a ",
    "url": "https://arxiv.org/abs/2602.14865",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Concept Influence: Leveraging Interpretability to Improve Performance and Efficiency in Training Data Attribution",
    "summary": "arXiv:2602.14869v1 Announce Type: new Abstract: As large language models are increasingly trained and fine-tuned, practitioners need methods to identify which training data drive specific behaviors, particularly unintended ones. Training Data Attribution (TDA) methods address this by estimating datapoint influence. Existing approaches like influenc",
    "url": "https://arxiv.org/abs/2602.14869",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Lifted Relational Probabilistic Inference via Implicit Learning",
    "summary": "arXiv:2602.14890v1 Announce Type: new Abstract: Reconciling the tension between inductive learning and deductive reasoning in first-order relational domains is a longstanding challenge in AI. We study the problem of answering queries in a first-order relational probabilistic logic through a joint effort of learning and reasoning, without ever const",
    "url": "https://arxiv.org/abs/2602.14890",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "The Potential of CoT for Reasoning: A Closer Look at Trace Dynamics",
    "summary": "arXiv:2602.14903v1 Announce Type: new Abstract: Chain-of-thought (CoT) prompting is a de-facto standard technique to elicit reasoning-like responses from large language models (LLMs), allowing them to spell out individual steps before giving a final answer. While the resemblance to human-like reasoning is undeniable, the driving forces underpinning",
    "url": "https://arxiv.org/abs/2602.14903",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Position: Introspective Experience from Conversational Environments as a Path to Better Learning",
    "summary": "arXiv:2602.14910v1 Announce Type: new Abstract: Current approaches to AI training treat reasoning as an emergent property of scale. We argue instead that robust reasoning emerges from linguistic self-reflection, itself internalized from high-quality social interaction. Drawing on Vygotskian developmental psychology, we advance three core positions ",
    "url": "https://arxiv.org/abs/2602.14910",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ReusStdFlow: A Standardized Reusability Framework for Dynamic Workflow Construction in Agentic AI",
    "summary": "arXiv:2602.14922v1 Announce Type: new Abstract: To address the ``reusability dilemma'' and structural hallucinations in enterprise Agentic AI,this paper proposes ReusStdFlow, a framework centered on a novel ``Extraction-Storage-Construction'' paradigm. The framework deconstructs heterogeneous, platform-specific Domain Specific Languages (DSLs) into",
    "url": "https://arxiv.org/abs/2602.14922",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "MAC-AMP: A Closed-Loop Multi-Agent Collaboration System for Multi-Objective Antimicrobial Peptide Design",
    "summary": "arXiv:2602.14926v1 Announce Type: new Abstract: To address the global health threat of antimicrobial resistance, antimicrobial peptides (AMP) are being explored for their potent and promising ability to fight resistant pathogens. While artificial intelligence (AI) is being employed to advance AMP discovery and design, most AMP design models struggl",
    "url": "https://arxiv.org/abs/2602.14926",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "On the Semantics of Primary Cause in Hybrid Dynamic Domains",
    "summary": "arXiv:2602.14994v1 Announce Type: new Abstract: Reasoning about actual causes of observed effects is fundamental to the study of rationality. This important problem has been studied since the time of Aristotle, with formal mathematical accounts emerging recently. We live in a world where change due to actions can be both discrete and continuous, th",
    "url": "https://arxiv.org/abs/2602.14994",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Hunt Globally: Deep Research AI Agents for Drug Asset Scouting in Investing, Business Development, and Search & Evaluation",
    "summary": "arXiv:2602.15019v1 Announce Type: new Abstract: Bio-pharmaceutical innovation has shifted: many new drug assets now originate outside the United States and are disclosed primarily via regional, non-English channels. Recent data suggests >85% of patent filings originate outside the U.S., with China accounting for nearly half of the global total; a g",
    "url": "https://arxiv.org/abs/2602.15019",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Training-Induced Bias Toward LLM-Generated Content in Dense Retrieval",
    "summary": "arXiv:2602.10833v1 Announce Type: cross Abstract: Dense retrieval is a promising approach for acquiring relevant context or world knowledge in open-domain natural language processing tasks and is now widely used in information retrieval applications. However, recent reports claim a broad preference for text generated by large language models (LLMs)",
    "url": "https://arxiv.org/abs/2602.10833",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Simulation-Based Study of AI-Assisted Channel Adaptation in UAV-Enabled Cellular Networks",
    "summary": "arXiv:2602.13199v1 Announce Type: cross Abstract: This paper presents a simulation based study of Artificial Intelligence assisted communication channel adaptation in Unmanned Aerial Vehicle enabled cellular networks. The considered system model includes communication channel Ground Base Station Aerial Repeater UAV Base Station Cluster of Cellular ",
    "url": "https://arxiv.org/abs/2602.13199",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Traffic Simulation in Ad Hoc Network of Flying UAVs with Generative AI Adaptation",
    "summary": "arXiv:2602.13200v1 Announce Type: cross Abstract: The purpose of this paper is to model traffic in Ad Hoc network of Unmanned Aerial Vehicles and demonstrate a way for adapting communication channel using Artificial Intelligence. The modeling was based on the original model of Ad Hoc network including 20 Unmanned Aerial Vehicles. The dependences of",
    "url": "https://arxiv.org/abs/2602.13200",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Adversarial Network Imagination: Causal LLMs and Digital Twins for Proactive Telecom Mitigation",
    "summary": "arXiv:2602.13203v1 Announce Type: cross Abstract: Telecommunication networks experience complex failures such as fiber cuts, traffic overloads, and cascading outages. Existing monitoring and digital twin systems are largely reactive, detecting failures only after service degradation occurs. We propose Adversarial Network Imagination, a closed-loop ",
    "url": "https://arxiv.org/abs/2602.13203",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Hybrid Secure Routing in Mobile Ad-hoc Networks (MANETSs)",
    "summary": "arXiv:2602.13204v1 Announce Type: cross Abstract: Because wireless communication is dynamic and has inherent defects, routing algorithms are crucial in the quickly evolving field of mobile ad hoc networks, or MANETs This study looks at the many security problems that MANETs encounter. These problems, which pose major risks to network performance, i",
    "url": "https://arxiv.org/abs/2602.13204",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "A Safety-Constrained Reinforcement Learning Framework for Reliable Wireless Autonomy",
    "summary": "arXiv:2602.13207v1 Announce Type: cross Abstract: Artificial intelligence (AI) and reinforcement learning (RL) have shown significant promise in wireless systems, enabling dynamic spectrum allocation, traffic management, and large-scale Internet of Things (IoT) coordination. However, their deployment in mission-critical applications introduces the ",
    "url": "https://arxiv.org/abs/2602.13207",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Large Language Model (LLM)-enabled Reinforcement Learning for Wireless Network Optimization",
    "summary": "arXiv:2602.13210v1 Announce Type: cross Abstract: Enhancing future wireless networks presents a significant challenge for networking systems due to diverse user demands and the emergence of 6G technology. While reinforcement learning (RL) is a powerful framework, it often encounters difficulties with high-dimensional state spaces and complex enviro",
    "url": "https://arxiv.org/abs/2602.13210",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "An Overlay Multicast Routing Method Based on Network Situational Aware-ness and Hierarchical Multi-Agent Reinforcement Learning",
    "summary": "arXiv:2602.13211v1 Announce Type: cross Abstract: Compared with IP multicast, Overlay Multicast (OM) offers better compatibility and flexible deployment in heterogeneous, cross-domain networks. However, traditional OM struggles to adapt to dynamic traffic due to unawareness of physical resource states, and existing reinforcement learning methods fa",
    "url": "https://arxiv.org/abs/2602.13211",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Computability of Agentic Systems",
    "summary": "arXiv:2602.13222v1 Announce Type: cross Abstract: This paper introduces the Quest Graph, a formal framework for analyzing the capabilities of agentic systems with finite context. We define abstractions that model common reasoning techniques and establish their computational power: the base Quest Graph is equivalent to an unrestricted Turing machine",
    "url": "https://arxiv.org/abs/2602.13222",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "An Agentic AI Control Plane for 6G Network Slice Orchestration, Monitoring, and Trading",
    "summary": "arXiv:2602.13227v1 Announce Type: cross Abstract: 6G networks are expected to be AI-native, intent-driven, and economically programmable, requiring fundamentally new approaches to network slice orchestration. Existing slicing frameworks, largely designed for 5G, rely on static policies and manual workflows and are ill-suited for the dynamic, multi-",
    "url": "https://arxiv.org/abs/2602.13227",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "An Explainable Failure Prediction Framework for Neural Networks in Radio Access Networks",
    "summary": "arXiv:2602.13231v1 Announce Type: cross Abstract: As 5G networks continue to evolve to deliver high speed, low latency, and reliable communications, ensuring uninterrupted service has become increasingly critical. While millimeter wave (mmWave) frequencies enable gigabit data rates, they are highly susceptible to environmental factors, often leadin",
    "url": "https://arxiv.org/abs/2602.13231",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Real-World Design and Deployment of an Embedded GenAI-powered 9-1-1 Calltaking Training System: Experiences and Lessons Learned",
    "summary": "arXiv:2602.13241v1 Announce Type: cross Abstract: Emergency call-takers form the first operational link in public safety response, handling over 240 million calls annually while facing a sustained training crisis: staffing shortages exceed 25\\% in many centers, and preparing a single new hire can require up to 720 hours of one-on-one instruction th",
    "url": "https://arxiv.org/abs/2602.13241",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Judging the Judges: Human Validation of Multi-LLM Evaluation for High-Quality K--12 Science Instructional Materials",
    "summary": "arXiv:2602.13243v1 Announce Type: cross Abstract: Designing high-quality, standards-aligned instructional materials for K--12 science is time-consuming and expertise-intensive. This study examines what human experts notice when reviewing AI-generated evaluations of such materials, aiming to translate their insights into design principles for a futu",
    "url": "https://arxiv.org/abs/2602.13243",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Responsible AI in Business",
    "summary": "arXiv:2602.13244v1 Announce Type: cross Abstract: Artificial intelligence (AI) and Machine Learning (ML) have moved from research and pilot projects into everyday business operations, with generative AI accelerating adoption across processes, products, and services. This paper introduces the concept of Responsible AI for organizational practice, wi",
    "url": "https://arxiv.org/abs/2602.13244",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Global AI Bias Audit for Technical Governance",
    "summary": "arXiv:2602.13246v1 Announce Type: cross Abstract: This paper presents the outputs of the exploratory phase of a global audit of Large Language Models (LLMs) project. In this exploratory phase, I used the Global AI Dataset (GAID) Project as a framework to stress-test the Llama-3 8B model and evaluate geographic and socioeconomic biases in technical ",
    "url": "https://arxiv.org/abs/2602.13246",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Boltz is a Strong Baseline for Atom-level Representation Learning",
    "summary": "arXiv:2602.13249v1 Announce Type: cross Abstract: Foundation models in molecular learning have advanced along two parallel tracks: protein models, which typically utilize evolutionary information to learn amino acid-level representations for folding, and small-molecule models, which focus on learning atom-level representations for property predicti",
    "url": "https://arxiv.org/abs/2602.13249",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Implicit Bias in LLMs for Transgender Populations",
    "summary": "arXiv:2602.13253v1 Announce Type: cross Abstract: Large language models (LLMs) have been shown to exhibit biases against LGBTQ+ populations. While safety training may lessen explicit expressions of bias, previous work has shown that implicit stereotype-driven associations often persist. In this work, we examine implicit bias toward transgender peop",
    "url": "https://arxiv.org/abs/2602.13253",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Learning Physiology-Informed Vocal Spectrotemporal Representations for Speech Emotion Recognition",
    "summary": "arXiv:2602.13259v1 Announce Type: cross Abstract: Speech emotion recognition (SER) is essential for humanoid robot tasks such as social robotic interactions and robotic psychological diagnosis, where interpretable and efficient models are critical for safety and performance. Existing deep models trained on large datasets remain largely uninterpreta",
    "url": "https://arxiv.org/abs/2602.13259",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "A feedback control optimizer for online and hardware-aware training of Spiking Neural Networks",
    "summary": "arXiv:2602.13261v1 Announce Type: cross Abstract: Unlike traditional artificial neural networks (ANNs), biological neuronal networks solve complex cognitive tasks with sparse neuronal activity, recurrent connections, and local learning rules. These mechanisms serve as design principles in Neuromorphic computing, which addresses the critical challen",
    "url": "https://arxiv.org/abs/2602.13261",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Directional Concentration Uncertainty: A representational approach to uncertainty quantification for generative models",
    "summary": "arXiv:2602.13264v1 Announce Type: cross Abstract: In the critical task of making generative models trustworthy and robust, methods for Uncertainty Quantification (UQ) have begun to show encouraging potential. However, many of these methods rely on rigid heuristics that fail to generalize across tasks and modalities. Here, we propose a novel framewo",
    "url": "https://arxiv.org/abs/2602.13264",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "MergePipe: A Budget-Aware Parameter Management System for Scalable LLM Merging",
    "summary": "arXiv:2602.13273v1 Announce Type: cross Abstract: Large language model (LLM) merging has become a key technique in modern LLM development pipelines, enabling the integration of multiple task- or domain-specific expert models without retraining. However, as the number of experts grows, existing merging implementations treat model parameters as unstr",
    "url": "https://arxiv.org/abs/2602.13273",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "LLM-Enhanced Rumor Detection via Virtual Node Induced Edge Prediction",
    "summary": "arXiv:2602.13279v1 Announce Type: cross Abstract: The proliferation of rumors on social networks undermines information credibility. While their dissemination forms complex networks, current detection methods struggle to capture these intricate propagation patterns. Representing each node solely through its textual embeddings neglects the textual c",
    "url": "https://arxiv.org/abs/2602.13279",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "GraFSTNet: Graph-based Frequency SpatioTemporal Network for Cellular Traffic Prediction",
    "summary": "arXiv:2602.13282v1 Announce Type: cross Abstract: With rapid expansion of cellular networks and the proliferation of mobile devices, cellular traffic data exhibits complex temporal dynamics and spatial correlations, posing challenges to accurate traffic prediction. Previous methods often focus predominantly on temporal modeling or depend on predefi",
    "url": "https://arxiv.org/abs/2602.13282",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Agents in the Wild: Safety, Society, and the Illusion of Sociality on Moltbook",
    "summary": "arXiv:2602.13284v1 Announce Type: cross Abstract: We present the first large-scale empirical study of Moltbook, an AI-only social platform where 27,269 agents produced 137,485 posts and 345,580 comments over 9 days. We report three significant findings. (1) Emergent Society: Agents spontaneously develop governance, economies, tribal identities, and",
    "url": "https://arxiv.org/abs/2602.13284",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Explanatory Interactive Machine Learning for Bias Mitigation in Visual Gender Classification",
    "summary": "arXiv:2602.13286v1 Announce Type: cross Abstract: Explanatory interactive learning (XIL) enables users to guide model training in machine learning (ML) by providing feedback on the model's explanations, thereby helping it to focus on features that are relevant to the prediction from the user's perspective. In this study, we explore the capability o",
    "url": "https://arxiv.org/abs/2602.13286",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Evaluating the Impact of Post-Training Quantization on Reliable VQA with Multimodal LLMs",
    "summary": "arXiv:2602.13289v1 Announce Type: cross Abstract: Multimodal Large Language Models (MLLM) are increasingly deployed in domains where both reliability and efficiency are critical. However, current models remain overconfident, producing highly certain but incorrect answers. At the same time, their large size limits deployment on edge devices, necessi",
    "url": "https://arxiv.org/abs/2602.13289",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "AGORA: Agentic Green Orchestration Architecture for Beyond 5G Networks",
    "summary": "arXiv:2602.13290v1 Announce Type: cross Abstract: Effective management and operational decision-making for complex mobile network systems present significant challenges, particularly when addressing conflicting requirements such as efficiency, user satisfaction, and energy-efficient traffic steering. The literature presents various approaches aimed",
    "url": "https://arxiv.org/abs/2602.13290",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Agent Mars: Multi-Agent Simulation for Multi-Planetary Life Exploration and Settlement",
    "summary": "arXiv:2602.13291v1 Announce Type: cross Abstract: Artificial Intelligence (AI) has transformed robotics, healthcare, industry, and scientific discovery, yet a major frontier may lie beyond Earth. Space exploration and settlement offer vast environments and resources, but impose constraints unmatched on Earth: delayed/intermittent communications, ex",
    "url": "https://arxiv.org/abs/2602.13291",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "VisPhyWorld: Probing Physical Reasoning via Code-Driven Video Reconstruction",
    "summary": "arXiv:2602.13294v1 Announce Type: cross Abstract: Evaluating whether Multimodal Large Language Models (MLLMs) genuinely reason about physical dynamics remains challenging. Most existing benchmarks rely on recognition-style protocols such as Visual Question Answering (VQA) and Violation of Expectation (VoE), which can often be answered without commi",
    "url": "https://arxiv.org/abs/2602.13294",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Effect of Convolutional Depth on Image Recognition Performance: VGG vs. ResNet vs. GoogLeNet",
    "summary": "arXiv:2602.13298v1 Announce Type: cross Abstract: Increasing convolutional depth has been central to advances in image recognition, yet deeper networks do not uniformly yield higher accuracy, stable optimization, or efficient computation. We present a controlled comparative study of three canonical convolutional neural network architectures - VGG, ",
    "url": "https://arxiv.org/abs/2602.13298",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "KidMesh: Computational Mesh Reconstruction for Pediatric Congenital Hydronephrosis Using Deep Neural Networks",
    "summary": "arXiv:2602.13299v1 Announce Type: cross Abstract: Pediatric congenital hydronephrosis (CH) is a common urinary tract disorder, primarily caused by obstruction at the renal pelvis-ureter junction. Magnetic resonance urography (MRU) can visualize hydronephrosis, including renal pelvis and calyces, by utilizing the natural contrast provided by water. ",
    "url": "https://arxiv.org/abs/2602.13299",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Spectral Collapse in Diffusion Inversion",
    "summary": "arXiv:2602.13303v1 Announce Type: cross Abstract: Conditional diffusion inversion provides a powerful framework for unpaired image-to-image translation. However, we demonstrate through an extensive analysis that standard deterministic inversion (e.g. DDIM) fails when the source domain is spectrally sparse compared to the target domain (e.g., super-",
    "url": "https://arxiv.org/abs/2602.13303",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Progressive Contrast Registration for High-Fidelity Bidirectional Photoacoustic Microscopy Alignment",
    "summary": "arXiv:2602.13304v1 Announce Type: cross Abstract: High-speed optical-resolution photoacoustic microscopy (OR-PAM) with bidirectional raster scanning doubles imaging speed but introduces coupled domain shift and geometric misalignment between forward and backward scan lines. Existing methods, constrained by brightness constancy assumptions, achieve ",
    "url": "https://arxiv.org/abs/2602.13304",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "WildfireVLM: AI-powered Analysis for Early Wildfire Detection and Risk Assessment Using Satellite Imagery",
    "summary": "arXiv:2602.13305v1 Announce Type: cross Abstract: Wildfires are a growing threat to ecosystems, human lives, and infrastructure, with their frequency and intensity rising due to climate change and human activities. Early detection is critical, yet satellite-based monitoring remains challenging due to faint smoke signals, dynamic weather conditions,",
    "url": "https://arxiv.org/abs/2602.13305",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Fine-Tuning a Large Vision-Language Model for Artwork's Scoring and Critique",
    "summary": "arXiv:2602.13306v1 Announce Type: cross Abstract: Assessing artistic creativity is foundational to creativity research and arts education, yet manual scoring (e.g., Torrance Tests of Creative Thinking) is labor-intensive at scale. Prior machine-learning approaches show promise for visual creativity scoring, but many rely mainly on image features an",
    "url": "https://arxiv.org/abs/2602.13306",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Learning to Select Like Humans: Explainable Active Learning for Medical Imaging",
    "summary": "arXiv:2602.13308v1 Announce Type: cross Abstract: Medical image analysis requires substantial labeled data for model training, yet expert annotation is expensive and time-consuming. Active learning (AL) addresses this challenge by strategically selecting the most informative samples for the annotation purpose, but traditional methods solely rely on",
    "url": "https://arxiv.org/abs/2602.13308",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Adaptive Value Decomposition: Coordinating a Varying Number of Agents in Urban Systems",
    "summary": "arXiv:2602.13309v1 Announce Type: cross Abstract: Multi-agent reinforcement learning (MARL) provides a promising paradigm for coordinating multi-agent systems (MAS). However, most existing methods rely on restrictive assumptions, such as a fixed number of agents and fully synchronous action execution. These assumptions are often violated in urban s",
    "url": "https://arxiv.org/abs/2602.13309",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Visual Para-Thinker: Divide-and-Conquer Reasoning for Visual Comprehension",
    "summary": "arXiv:2602.13310v1 Announce Type: cross Abstract: Existing LLM test-time scaling laws emphasize the emergence of self-reflective behaviors through extended reasoning length. Nevertheless, this vertical scaling strategy often encounters plateaus in exploration as the model becomes locked into specific thinking pattern. By shifting from depth to para",
    "url": "https://arxiv.org/abs/2602.13310",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "PeroMAS: A Multi-agent System of Perovskite Material Discovery",
    "summary": "arXiv:2602.13312v1 Announce Type: cross Abstract: As a pioneer of the third-generation photovoltaic revolution, Perovskite Solar Cells (PSCs) are renowned for their superior optoelectronic performance and cost potential. The development process of PSCs is precise and complex, involving a series of closed-loop workflows such as literature retrieval,",
    "url": "https://arxiv.org/abs/2602.13312",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Agentic Spatio-Temporal Grounding via Collaborative Reasoning",
    "summary": "arXiv:2602.13313v1 Announce Type: cross Abstract: Spatio-Temporal Video Grounding (STVG) aims to retrieve the spatio-temporal tube of a target object or person in a video given a text query. Most existing approaches perform frame-wise spatial localization within a predicted temporal span, resulting in redundant computation, heavy supervision requir",
    "url": "https://arxiv.org/abs/2602.13313",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Sim2Radar: Toward Bridging the Radar Sim-to-Real Gap with VLM-Guided Scene Reconstruction",
    "summary": "arXiv:2602.13314v1 Announce Type: cross Abstract: Millimeter-wave (mmWave) radar provides reliable perception in visually degraded indoor environments (e.g., smoke, dust, and low light), but learning-based radar perception is bottlenecked by the scarcity and cost of collecting and annotating large-scale radar datasets. We present Sim2Radar, an end-",
    "url": "https://arxiv.org/abs/2602.13314",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "IDPruner: Harmonizing Importance and Diversity in Visual Token Pruning for MLLMs",
    "summary": "arXiv:2602.13315v1 Announce Type: cross Abstract: Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities, yet they encounter significant computational bottlenecks due to the massive volume of visual tokens. Consequently, visual token pruning, which substantially reduces the token count, has emerged as a critical techniqu",
    "url": "https://arxiv.org/abs/2602.13315",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Semantic Waveforms for AI-Native 6G Networks",
    "summary": "arXiv:2602.13316v1 Announce Type: cross Abstract: In this paper, we propose a semantic-aware waveform design framework for AI-native 6G networks that jointly optimizes physical layer resource usage and semantic communication efficiency and robustness, while explicitly accounting for the hardware constraints of RF chains. Our approach, called Orthog",
    "url": "https://arxiv.org/abs/2602.13316",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Synthesizing the Kill Chain: A Zero-Shot Framework for Target Verification and Tactical Reasoning on the Edge",
    "summary": "arXiv:2602.13324v1 Announce Type: cross Abstract: Deploying autonomous edge robotics in dynamic military environments is constrained by both scarce domain-specific training data and the computational limits of edge hardware. This paper introduces a hierarchical, zero-shot framework that cascades lightweight object detection with compact Vision-Lang",
    "url": "https://arxiv.org/abs/2602.13324",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "HiST-VLA: A Hierarchical Spatio-Temporal Vision-Language-Action Model for End-to-End Autonomous Driving",
    "summary": "arXiv:2602.13329v1 Announce Type: cross Abstract: Vision-Language-Action (VLA) models offer promising capabilities for autonomous driving through multimodal understanding. However, their utilization in safety-critical scenarios is constrained by inherent limitations, including imprecise numerical reasoning, weak 3D spatial awareness, and high sensi",
    "url": "https://arxiv.org/abs/2602.13329",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "MedScope: Incentivizing \"Think with Videos\" for Clinical Reasoning via Coarse-to-Fine Tool Calling",
    "summary": "arXiv:2602.13332v1 Announce Type: cross Abstract: Long-form clinical videos are central to visual evidence-based decision-making, with growing importance for applications such as surgical robotics and related settings. However, current multimodal large language models typically process videos with passive sampling or weakly grounded inspection, whi",
    "url": "https://arxiv.org/abs/2602.13332",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "An Integrated Causal Inference Framework for Traffic Safety Modeling with Semantic Street-View Visual Features",
    "summary": "arXiv:2602.13339v1 Announce Type: cross Abstract: Macroscopic traffic safety modeling aims to identify critical risk factors for regional crashes, thereby informing targeted policy interventions for safety improvement. However, current approaches rely heavily on static sociodemographic and infrastructure metrics, frequently overlooking the impacts ",
    "url": "https://arxiv.org/abs/2602.13339",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "CellMaster: Collaborative Cell Type Annotation in Single-Cell Analysis",
    "summary": "arXiv:2602.13346v1 Announce Type: cross Abstract: Single-cell RNA-seq (scRNA-seq) enables atlas-scale profiling of complex tissues, revealing rare lineages and transient states. Yet, assigning biologically valid cell identities remains a bottleneck because markers are tissue- and state-dependent, and novel states lack references. We present CellMas",
    "url": "https://arxiv.org/abs/2602.13346",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Visual Foresight for Robotic Stow: A Diffusion-Based World Model from Sparse Snapshots",
    "summary": "arXiv:2602.13347v1 Announce Type: cross Abstract: Automated warehouses execute millions of stow operations, where robots place objects into storage bins. For these systems it is valuable to anticipate how a bin will look from the current observations and the planned stow behavior before real execution. We propose FOREST, a stow-intent-conditioned w",
    "url": "https://arxiv.org/abs/2602.13347",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Exploring the Performance of ML/DL Architectures on the MNIST-1D Dataset",
    "summary": "arXiv:2602.13348v1 Announce Type: cross Abstract: Small datasets like MNIST have historically been instrumental in advancing machine learning research by providing a controlled environment for rapid experimentation and model evaluation. However, their simplicity often limits their utility for distinguishing between advanced neural network architect",
    "url": "https://arxiv.org/abs/2602.13348",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "From Prompt to Production:Automating Brand-Safe Marketing Imagery with Text-to-Image Models",
    "summary": "arXiv:2602.13349v1 Announce Type: cross Abstract: Text-to-image models have made significant strides, producing impressive results in generating images from textual descriptions. However, creating a scalable pipeline for deploying these models in production remains a challenge. Achieving the right balance between automation and human feedback is cr",
    "url": "https://arxiv.org/abs/2602.13349",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Detecting Brick Kiln Infrastructure at Scale: Graph, Foundation, and Remote Sensing Models for Satellite Imagery Data",
    "summary": "arXiv:2602.13350v1 Announce Type: cross Abstract: Brick kilns are a major source of air pollution and forced labor in South Asia, yet large-scale monitoring remains limited by sparse and outdated ground data. We study brick kiln detection at scale using high-resolution satellite imagery and curate a multi city zoom-20 (0.149 meters per pixel) resol",
    "url": "https://arxiv.org/abs/2602.13350",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "A Formal Framework for the Explanation of Finite Automata Decisions",
    "summary": "arXiv:2602.13351v1 Announce Type: cross Abstract: Finite automata (FA) are a fundamental computational abstraction that is widely used in practice for various tasks in computer science, linguistics, biology, electrical engineering, and artificial intelligence. Given an input word, an FA maps the word to a result, in the simple case \"accept\" or \"rej",
    "url": "https://arxiv.org/abs/2602.13351",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Using Deep Learning to Generate Semantically Correct Hindi Captions",
    "summary": "arXiv:2602.13352v1 Announce Type: cross Abstract: Automated image captioning using the content from the image is very appealing when done by harnessing the capability of computer vision and natural language processing. Extensive research has been done in the field with a major focus on the English language which gives the scope for further developm",
    "url": "https://arxiv.org/abs/2602.13352",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "AdaCorrection: Adaptive Offset Cache Correction for Accurate Diffusion Transformers",
    "summary": "arXiv:2602.13357v1 Announce Type: cross Abstract: Diffusion Transformers (DiTs) achieve state-of-the-art performance in high-fidelity image and video generation but suffer from expensive inference due to their iterative denoising structure. While prior methods accelerate sampling by caching intermediate features, they rely on static reuse schedules",
    "url": "https://arxiv.org/abs/2602.13357",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Nonparametric Distribution Regression Re-calibration",
    "summary": "arXiv:2602.13362v1 Announce Type: cross Abstract: A key challenge in probabilistic regression is ensuring that predictive distributions accurately reflect true empirical uncertainty. Minimizing overall prediction error often encourages models to prioritize informativeness over calibration, producing narrow but overconfident predictions. However, in",
    "url": "https://arxiv.org/abs/2602.13362",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Assessing Spear-Phishing Website Generation in Large Language Model Coding Agents",
    "summary": "arXiv:2602.13363v1 Announce Type: cross Abstract: Large Language Models are expanding beyond being a tool humans use and into independent agents that can observe an environment, reason about solutions to problems, make changes that impact those environments, and understand how their actions impacted their environment. One of the most common applica",
    "url": "https://arxiv.org/abs/2602.13363",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "G2CP: A Graph-Grounded Communication Protocol for Verifiable and Efficient Multi-Agent Reasoning",
    "summary": "arXiv:2602.13370v1 Announce Type: cross Abstract: Multi-agent systems powered by Large Language Models face a critical challenge: agents communicate through natural language, leading to semantic drift, hallucination propagation, and inefficient token consumption. We propose G2CP (Graph-Grounded Communication Protocol), a structured agent communicat",
    "url": "https://arxiv.org/abs/2602.13370",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "An Online Reference-Free Evaluation Framework for Flowchart Image-to-Code Generation",
    "summary": "arXiv:2602.13376v1 Announce Type: cross Abstract: Vision-Language Models (VLMs) are increasingly used in document processing pipelines to convert flowchart images into structured code (e.g., Mermaid). In production, these systems process arbitrary inputs for which no ground-truth code exists, making output quality difficult to assess. We propose a ",
    "url": "https://arxiv.org/abs/2602.13376",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Unsafer in Many Turns: Benchmarking and Defending Multi-Turn Safety Risks in Tool-Using Agents",
    "summary": "arXiv:2602.13379v1 Announce Type: cross Abstract: LLM-based agents are becoming increasingly capable, yet their safety lags behind. This creates a gap between what agents can do and should do. This gap widens as agents engage in multi-turn interactions and employ diverse tools, introducing new risks overlooked by existing benchmarks. To systematica",
    "url": "https://arxiv.org/abs/2602.13379",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Protect$^*$: Steerable Retrosynthesis through Neuro-Symbolic State Encoding",
    "summary": "arXiv:2602.13419v1 Announce Type: cross Abstract: Large Language Models (LLMs) have shown remarkable potential in scientific domains like retrosynthesis; yet, they often lack the fine-grained control necessary to navigate complex problem spaces without error. A critical challenge is directing an LLM to avoid specific, chemically sensitive sites on ",
    "url": "https://arxiv.org/abs/2602.13419",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Metabolic cost of information processing in Poisson variational autoencoders",
    "summary": "arXiv:2602.13421v1 Announce Type: cross Abstract: Computation in biological systems is fundamentally energy-constrained, yet standard theories of computation treat energy as freely available. Here, we argue that variational free energy minimization under a Poisson assumption offers a principled path toward an energy-aware theory of computation. Our",
    "url": "https://arxiv.org/abs/2602.13421",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Backdooring Bias in Large Language Models",
    "summary": "arXiv:2602.13427v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly deployed in settings where inducing a bias toward a certain topic can have significant consequences, and backdoor attacks can be used to produce such models. Prior work on backdoor attacks has largely focused on a black-box threat model, with an adversar",
    "url": "https://arxiv.org/abs/2602.13427",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "FlowHOI: Flow-based Semantics-Grounded Generation of Hand-Object Interactions for Dexterous Robot Manipulation",
    "summary": "arXiv:2602.13444v1 Announce Type: cross Abstract: Recent vision-language-action (VLA) models can generate plausible end-effector motions, yet they often fail in long-horizon, contact-rich tasks because the underlying hand-object interaction (HOI) structure is not explicitly represented. An embodiment-agnostic interaction representation that capture",
    "url": "https://arxiv.org/abs/2602.13444",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "End-to-End NOMA with Perfect and Quantized CSI Over Rayleigh Fading Channels",
    "summary": "arXiv:2602.13446v1 Announce Type: cross Abstract: An end-to-end autoencoder (AE) framework is developed for downlink non-orthogonal multiple access (NOMA) over Rayleigh fading channels, which learns interference-aware and channel-adaptive super-constellations. While existing works either assume additive white Gaussian noise channels or treat fading",
    "url": "https://arxiv.org/abs/2602.13446",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "LLM-Powered Automatic Translation and Urgency in Crisis Scenarios",
    "summary": "arXiv:2602.13452v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly proposed for crisis preparedness and response, particularly for multilingual communication. However, their suitability for high-stakes crisis contexts remains insufficiently evaluated. This work examines the performance of state-of-the-art LLMs and machi",
    "url": "https://arxiv.org/abs/2602.13452",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Using Machine Learning to Enhance the Detection of Obfuscated Abusive Words in Swahili: A Focus on Child Safety",
    "summary": "arXiv:2602.13455v1 Announce Type: cross Abstract: The rise of digital technology has dramatically increased the potential for cyberbullying and online abuse, necessitating enhanced measures for detection and prevention, especially among children. This study focuses on detecting abusive obfuscated language in Swahili, a low-resource language that po",
    "url": "https://arxiv.org/abs/2602.13455",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "MoltNet: Understanding Social Behavior of AI Agents in the Agent-Native MoltBook",
    "summary": "arXiv:2602.13458v1 Announce Type: cross Abstract: Large-scale communities of AI agents are becoming increasingly prevalent, creating new environments for agent-agent social interaction. Prior work has examined multi-agent behavior primarily in controlled or small-scale settings, limiting our understanding of emergent social dynamics at scale. The r",
    "url": "https://arxiv.org/abs/2602.13458",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Language Model Memory and Memory Models for Language",
    "summary": "arXiv:2602.13466v1 Announce Type: cross Abstract: The ability of machine learning models to store input information in hidden layer vector embeddings, analogous to the concept of `memory', is widely employed but not well characterized. We find that language model embeddings typically contain relatively little input information regardless of data an",
    "url": "https://arxiv.org/abs/2602.13466",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "How Multimodal Large Language Models Support Access to Visual Information: A Diary Study With Blind and Low Vision People",
    "summary": "arXiv:2602.13469v1 Announce Type: cross Abstract: Multimodal large language models (MLLMs) are changing how Blind and Low Vision (BLV) people access visual information in their daily lives. Unlike traditional visual interpretation tools that provide access through captions and OCR (text recognition through camera input), MLLM-enabled applications s",
    "url": "https://arxiv.org/abs/2602.13469",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Comparing Classifiers: A Case Study Using PyCM",
    "summary": "arXiv:2602.13482v1 Announce Type: cross Abstract: Selecting an optimal classification model requires a robust and comprehensive understanding of the performance of the model. This paper provides a tutorial on the PyCM library, demonstrating its utility in conducting deep-dive evaluations of multi-class classifiers. By examining two different case s",
    "url": "https://arxiv.org/abs/2602.13482",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Finding Highly Interpretable Prompt-Specific Circuits in Language Models",
    "summary": "arXiv:2602.13483v1 Announce Type: cross Abstract: Understanding the internal circuits that language models use to solve tasks remains a central challenge in mechanistic interpretability. Most prior work identifies circuits at the task level by averaging across many prompts, implicitly assuming a single stable mechanism per task. We show that this a",
    "url": "https://arxiv.org/abs/2602.13483",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Preventing Rank Collapse in Federated Low-Rank Adaptation with Client Heterogeneity",
    "summary": "arXiv:2602.13486v1 Announce Type: cross Abstract: Federated low-rank adaptation (FedLoRA) has facilitated communication-efficient and privacy-preserving fine-tuning of foundation models for downstream tasks. In practical federated learning scenarios, client heterogeneity in system resources and data distributions motivates heterogeneous LoRA ranks ",
    "url": "https://arxiv.org/abs/2602.13486",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "What Do We Mean by 'Pilot Study': Early Findings from a Meta-Review of Pilot Study Reporting at CHI",
    "summary": "arXiv:2602.13488v1 Announce Type: cross Abstract: Pilot studies (PS) are ubiquitous in HCI research. CHI papers routinely reference 'pilot studies', 'pilot tests', or 'preliminary studies' to justify design decisions, verify procedures, or motivate methodological choices. Yet despite their frequency, the role of pilot studies in HCI remains concept",
    "url": "https://arxiv.org/abs/2602.13488",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Future of Edge AI in biodiversity monitoring",
    "summary": "arXiv:2602.13496v1 Announce Type: cross Abstract: 1. Many ecological decisions are slowed by the gap between collecting and analysing biodiversity data. Edge computing moves processing closer to the sensor, with edge artificial intelligence (AI) enabling on-device inference, reducing reliance on data transfer and continuous connectivity. In princip",
    "url": "https://arxiv.org/abs/2602.13496",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "TrasMuon: Trust-Region Adaptive Scaling for Orthogonalized Momentum Optimizers",
    "summary": "arXiv:2602.13498v1 Announce Type: cross Abstract: Muon-style optimizers leverage Newton-Schulz (NS) iterations to orthogonalize updates, yielding update geometries that often outperform Adam-series methods. However, this orthogonalization discards magnitude information, rendering training sensitive to step-size hyperparameters and vulnerable to hig",
    "url": "https://arxiv.org/abs/2602.13498",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "From Perceptions To Evidence: Detecting AI-Generated Content In Turkish News Media With A Fine-Tuned Bert Classifier",
    "summary": "arXiv:2602.13504v1 Announce Type: cross Abstract: The rapid integration of large language models into newsroom workflows has raised urgent questions about the prevalence of AI-generated content in online media. While computational studies have begun to quantify this phenomenon in English-language outlets, no empirical investigation exists for Turki",
    "url": "https://arxiv.org/abs/2602.13504",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "$\\gamma$-weakly $\\theta$-up-concavity: Linearizable Non-Convex Optimization with Applications to DR-Submodular and OSS Functions",
    "summary": "arXiv:2602.13506v1 Announce Type: cross Abstract: Optimizing monotone non-convex functions is a fundamental challenge across machine learning and combinatorial optimization. We introduce and study $\\gamma$-weakly $\\theta$-up-concavity, a novel first-order condition that characterizes a broad class of such functions. This condition provides a powerf",
    "url": "https://arxiv.org/abs/2602.13506",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Arming Data Agents with Tribal Knowledge",
    "summary": "arXiv:2602.13521v1 Announce Type: cross Abstract: Natural language to SQL (NL2SQL) translation enables non-expert users to query relational databases through natural language. Recently, NL2SQL agents, powered by the reasoning capabilities of Large Language Models (LLMs), have significantly advanced NL2SQL translation. Nonetheless, NL2SQL agents sti",
    "url": "https://arxiv.org/abs/2602.13521",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Singular Vectors of Attention Heads Align with Features",
    "summary": "arXiv:2602.13524v1 Announce Type: cross Abstract: Identifying feature representations in language models is a central task in mechanistic interpretability. Several recent studies have made an implicit assumption that feature representations can be inferred in some cases from singular vectors of attention matrices. However, sound justification for t",
    "url": "https://arxiv.org/abs/2602.13524",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "On Calibration of Large Language Models: From Response To Capability",
    "summary": "arXiv:2602.13540v1 Announce Type: cross Abstract: Large language models (LLMs) are widely deployed as general-purpose problem solvers, making accurate confidence estimation critical for reliable use. Prior work on LLM calibration largely focuses on response-level confidence, which estimates the correctness of a single generated output. However, thi",
    "url": "https://arxiv.org/abs/2602.13540",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "AISA: Awakening Intrinsic Safety Awareness in Large Language Models against Jailbreak Attacks",
    "summary": "arXiv:2602.13547v1 Announce Type: cross Abstract: Large language models (LLMs) remain vulnerable to jailbreak prompts that elicit harmful or policy-violating outputs, while many existing defenses rely on expensive fine-tuning, intrusive prompt rewriting, or external guardrails that add latency and can degrade helpfulness. We present AISA, a lightwe",
    "url": "https://arxiv.org/abs/2602.13547",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Privacy-Concealing Cooperative Perception for BEV Scene Segmentation",
    "summary": "arXiv:2602.13555v1 Announce Type: cross Abstract: Cooperative perception systems for autonomous driving aim to overcome the limited perception range of a single vehicle by communicating with adjacent agents to share sensing information. While this improves perception performance, these systems also face a significant privacy-leakage issue, as sensi",
    "url": "https://arxiv.org/abs/2602.13555",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Discrete-Space Generative AI Pipeline for Semantic Transmission of Signals",
    "summary": "arXiv:2602.13556v1 Announce Type: cross Abstract: We introduce Discernment, a semantic communication system that transmits the meaning of physical signals (baseband radio and audio) over a technical channel using GenAI models operating in discrete spaces. Discernment dynamically adapts to channel impairments - modeled as erasure channels - by switc",
    "url": "https://arxiv.org/abs/2602.13556",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Mitigating the Safety-utility Trade-off in LLM Alignment via Adaptive Safe Context Learning",
    "summary": "arXiv:2602.13562v1 Announce Type: cross Abstract: While reasoning models have achieved remarkable success in complex reasoning tasks, their increasing power necessitates stringent safety measures. For safety alignment, the core challenge lies in the inherent trade-off between safety and utility. However, prevailing alignment strategies typically co",
    "url": "https://arxiv.org/abs/2602.13562",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "LLM-Confidence Reranker: A Training-Free Approach for Enhancing Retrieval-Augmented Generation Systems",
    "summary": "arXiv:2602.13571v1 Announce Type: cross Abstract: Large language models (LLMs) have revolutionized natural language processing, yet hallucinations in knowledge-intensive tasks remain a critical challenge. Retrieval-augmented generation (RAG) addresses this by integrating external knowledge, but its efficacy depends on accurate document retrieval an",
    "url": "https://arxiv.org/abs/2602.13571",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Elo-Evolve: A Co-evolutionary Framework for Language Model Alignment",
    "summary": "arXiv:2602.13575v1 Announce Type: cross Abstract: Current alignment methods for Large Language Models (LLMs) rely on compressing vast amounts of human preference data into static, absolute reward functions, leading to data scarcity, noise sensitivity, and training instability. We introduce Elo-Evolve, a co-evolutionary framework that redefines alig",
    "url": "https://arxiv.org/abs/2602.13575",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Rubrics as an Attack Surface: Stealthy Preference Drift in LLM Judges",
    "summary": "arXiv:2602.13576v1 Announce Type: cross Abstract: Evaluation and alignment pipelines for large language models increasingly rely on LLM-based judges, whose behavior is guided by natural-language rubrics and validated on benchmarks. We identify a previously under-recognized vulnerability in this workflow, which we term Rubric-Induced Preference Drif",
    "url": "https://arxiv.org/abs/2602.13576",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Two-Stream Interactive Joint Learning of Scene Parsing and Geometric Vision Tasks",
    "summary": "arXiv:2602.13588v1 Announce Type: cross Abstract: Inspired by the human visual system, which operates on two parallel yet interactive streams for contextual and spatial understanding, this article presents Two Interactive Streams (TwInS), a novel bio-inspired joint learning framework capable of simultaneously performing scene parsing and geometric ",
    "url": "https://arxiv.org/abs/2602.13588",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Multi-Modal Sensing and Fusion in mmWave Beamforming for Connected Vehicles: A Transformer Based Framework",
    "summary": "arXiv:2602.13606v1 Announce Type: cross Abstract: Millimeter wave (mmWave) communication, utilizing beamforming techniques to address the inherent path loss limitation, is considered as one of the key technologies to support ever increasing high throughput and low latency demands of connected vehicles. However, adopting standard defined beamforming",
    "url": "https://arxiv.org/abs/2602.13606",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "From What to How: Bridging User Requirements with Software Development Using Large Language Models",
    "summary": "arXiv:2602.13611v1 Announce Type: cross Abstract: Recently, large language models (LLMs) are extensively utilized to enhance development efficiency, leading to numerous benchmarks for evaluating their performance. However, these benchmarks predominantly focus on implementation, overlooking the equally critical aspect of software design. This gap ra",
    "url": "https://arxiv.org/abs/2602.13611",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Anthropomorphism on Risk Perception: The Role of Trust and Domain Knowledge in Decision-Support AI",
    "summary": "arXiv:2602.13625v1 Announce Type: cross Abstract: Anthropomorphic design is routinely used to make conversational agents more approachable and engaging. Yet its influence on users' perceptions remains poorly understood. Drawing on psychological theories, we propose that anthropomorphism influences risk perception via two complementary forms of trus",
    "url": "https://arxiv.org/abs/2602.13625",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Hierarchical Audio-Visual-Proprioceptive Fusion for Precise Robotic Manipulation",
    "summary": "arXiv:2602.13640v1 Announce Type: cross Abstract: Existing robotic manipulation methods primarily rely on visual and proprioceptive observations, which may struggle to infer contact-related interaction states in partially observable real-world environments. Acoustic cues, by contrast, naturally encode rich interaction dynamics during contact, yet r",
    "url": "https://arxiv.org/abs/2602.13640",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "PT-RAG: Structure-Fidelity Retrieval-Augmented Generation for Academic Papers",
    "summary": "arXiv:2602.13647v1 Announce Type: cross Abstract: Retrieval-augmented generation (RAG) is increasingly applied to question-answering over long academic papers, where accurate evidence allocation under a fixed token budget is critical. Existing approaches typically flatten academic papers into unstructured chunks during preprocessing, which destroys",
    "url": "https://arxiv.org/abs/2602.13647",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "KorMedMCQA-V: A Multimodal Benchmark for Evaluating Vision-Language Models on the Korean Medical Licensing Examination",
    "summary": "arXiv:2602.13650v1 Announce Type: cross Abstract: We introduce KorMedMCQA-V, a Korean medical licensing-exam-style multimodal multiple-choice question answering benchmark for evaluating vision-language models (VLMs). The dataset consists of 1,534 questions with 2,043 associated images from Korean Medical Licensing Examinations (2012-2023), with abo",
    "url": "https://arxiv.org/abs/2602.13650",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Cumulative Utility Parity for Fair Federated Learning under Intermittent Client Participation",
    "summary": "arXiv:2602.13651v1 Announce Type: cross Abstract: In real-world federated learning (FL) systems, client participation is intermittent, heterogeneous, and often correlated with data characteristics or resource constraints. Existing fairness approaches in FL primarily focus on equalizing loss or accuracy conditional on participation, implicitly assum",
    "url": "https://arxiv.org/abs/2602.13651",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "LeafNet: A Large-Scale Dataset and Comprehensive Benchmark for Foundational Vision-Language Understanding of Plant Diseases",
    "summary": "arXiv:2602.13662v1 Announce Type: cross Abstract: Foundation models and vision-language pre-training have significantly advanced Vision-Language Models (VLMs), enabling multimodal processing of visual and linguistic data. However, their application in domain-specific agricultural tasks, such as plant pathology, remains limited due to the lack of la",
    "url": "https://arxiv.org/abs/2602.13662",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ALMo: Interactive Aim-Limit-Defined, Multi-Objective System for Personalized High-Dose-Rate Brachytherapy Treatment Planning and Visualization for Cervical Cancer",
    "summary": "arXiv:2602.13666v1 Announce Type: cross Abstract: In complex clinical decision-making, clinicians must often track a variety of competing metrics defined by aim (ideal) and limit (strict) thresholds. Sifting through these high-dimensional tradeoffs to infer the optimal patient-specific strategy is cognitively demanding and historically prone to var",
    "url": "https://arxiv.org/abs/2602.13666",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "MAS-on-the-Fly: Dynamic Adaptation of LLM-based Multi-Agent Systems at Test Time",
    "summary": "arXiv:2602.13671v1 Announce Type: cross Abstract: Large Language Model (LLM)-based multi-agent systems (MAS) have emerged as a promising paradigm for solving complex tasks. However, existing works often rely on manual designs or \"one-size-fits-all\" automation, lacking dynamic adaptability after deployment. Inspired by how biological systems adapt, ",
    "url": "https://arxiv.org/abs/2602.13671",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Transferable XAI: Relating Understanding Across Domains with Explanation Transfer",
    "summary": "arXiv:2602.13675v1 Announce Type: cross Abstract: Current Explainable AI (XAI) focuses on explaining a single application, but when encountering related applications, users may rely on their prior understanding from previous explanations. This leads to either overgeneralization and AI overreliance, or burdensome independent memorization. Indeed, re",
    "url": "https://arxiv.org/abs/2602.13675",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "An Ensemble Learning Approach towards Waste Segmentation in Cluttered Environment",
    "summary": "arXiv:2602.13681v1 Announce Type: cross Abstract: Environmental pollution is a critical global issue, with recycling emerging as one of the most viable solutions. This study focuses on waste segregation, a crucial step in recycling processes to obtain raw material. Recent advancements in computer vision have significantly contributed to waste class",
    "url": "https://arxiv.org/abs/2602.13681",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "On the Sparsifiability of Correlation Clustering: Approximation Guarantees under Edge Sampling",
    "summary": "arXiv:2602.13684v1 Announce Type: cross Abstract: Correlation Clustering (CC) is a fundamental unsupervised learning primitive whose strongest LP-based approximation guarantees require $\\Theta(n^3)$ triangle inequality constraints and are prohibitive at scale. We initiate the study of \\emph{sparsification--approximation trade-offs} for CC, asking h",
    "url": "https://arxiv.org/abs/2602.13684",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "AuTAgent: A Reinforcement Learning Framework for Tool-Augmented Audio Reasoning",
    "summary": "arXiv:2602.13685v1 Announce Type: cross Abstract: Large Audio Language Models (LALMs) excel at perception but struggle with complex reasoning requiring precise acoustic measurements. While external tools can extract fine-grained features like exact tempo or pitch, effective integration remains challenging: naively using all tools causes information",
    "url": "https://arxiv.org/abs/2602.13685",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Pailitao-VL: Unified Embedding and Reranker for Real-Time Multi-Modal Industrial Search",
    "summary": "arXiv:2602.13704v1 Announce Type: cross Abstract: In this work, we presented Pailitao-VL, a comprehensive multi-modal retrieval system engineered for high-precision, real-time industrial search. We here address three critical challenges in the current SOTA solution: insufficient retrieval granularity, vulnerability to environmental noise, and prohi",
    "url": "https://arxiv.org/abs/2602.13704",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "HybridFlow: A Two-Step Generative Policy for Robotic Manipulation",
    "summary": "arXiv:2602.13718v1 Announce Type: cross Abstract: Limited by inference latency, existing robot manipulation policies lack sufficient real-time interaction capability with the environment. Although faster generation methods such as flow matching are gradually replacing diffusion methods, researchers are pursuing even faster generation suitable for i",
    "url": "https://arxiv.org/abs/2602.13718",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "OmniScience: A Large-scale Multi-modal Dataset for Scientific Image Understanding",
    "summary": "arXiv:2602.13758v1 Announce Type: cross Abstract: Multimodal Large Language Models demonstrate strong performance on natural image understanding, yet exhibit limited capability in interpreting scientific images, including but not limited to schematic diagrams, experimental characterizations, and analytical charts. This limitation is particularly pr",
    "url": "https://arxiv.org/abs/2602.13758",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "MOTIF: Learning Action Motifs for Few-shot Cross-Embodiment Transfer",
    "summary": "arXiv:2602.13764v1 Announce Type: cross Abstract: While vision-language-action (VLA) models have advanced generalist robotic learning, cross-embodiment transfer remains challenging due to kinematic heterogeneity and the high cost of collecting sufficient real-world demonstrations to support fine-tuning. Existing cross-embodiment policies typically ",
    "url": "https://arxiv.org/abs/2602.13764",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Comparables XAI: Faithful Example-based AI Explanations with Counterfactual Trace Adjustments",
    "summary": "arXiv:2602.13784v1 Announce Type: cross Abstract: Explaining with examples is an intuitive way to justify AI decisions. However, it is challenging to understand how a decision value should change relative to the examples with many features differing by large amounts. We draw from real estate valuation that uses Comparables-examples with known value",
    "url": "https://arxiv.org/abs/2602.13784",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "MechPert: Mechanistic Consensus as an Inductive Bias for Unseen Perturbation Prediction",
    "summary": "arXiv:2602.13791v1 Announce Type: cross Abstract: Predicting transcriptional responses to unseen genetic perturbations is essential for understanding gene regulation and prioritizing large-scale perturbation experiments. Existing approaches either rely on static, potentially incomplete knowledge graphs, or prompt language models for functionally si",
    "url": "https://arxiv.org/abs/2602.13791",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Mean Flow Policy with Instantaneous Velocity Constraint for One-step Action Generation",
    "summary": "arXiv:2602.13810v1 Announce Type: cross Abstract: Learning expressive and efficient policy functions is a promising direction in reinforcement learning (RL). While flow-based policies have recently proven effective in modeling complex action distributions with a fast deterministic sampling process, they still face a trade-off between expressiveness",
    "url": "https://arxiv.org/abs/2602.13810",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "DTBench: A Synthetic Benchmark for Document-to-Table Extraction",
    "summary": "arXiv:2602.13812v1 Announce Type: cross Abstract: Document-to-table (Doc2Table) extraction derives structured tables from unstructured documents under a target schema, enabling reliable and verifiable SQL-based data analytics. Although large language models (LLMs) have shown promise in flexible information extraction, their ability to produce preci",
    "url": "https://arxiv.org/abs/2602.13812",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Pawsterior: Variational Flow Matching for Structured Simulation-Based Inference",
    "summary": "arXiv:2602.13813v1 Announce Type: cross Abstract: We introduce Pawsterior, a variational flow-matching framework for improved and extended simulation-based inference (SBI). Many SBI problems involve posteriors constrained by structured domains, such as bounded physical parameters or hybrid discrete-continuous variables, yet standard flow-matching m",
    "url": "https://arxiv.org/abs/2602.13813",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "What happens when reviewers receive AI feedback in their reviews?",
    "summary": "arXiv:2602.13817v1 Announce Type: cross Abstract: AI is reshaping academic research, yet its role in peer review remains polarising and contentious. Advocates see its potential to reduce reviewer burden and improve quality, while critics warn of risks to fairness, accountability, and trust. At ICLR 2025, an official AI feedback tool was deployed to",
    "url": "https://arxiv.org/abs/2602.13817",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Automated Prediction of Paravalvular Regurgitation before Transcatheter Aortic Valve Implantation",
    "summary": "arXiv:2602.13842v1 Announce Type: cross Abstract: Severe aortic stenosis is a common and life-threatening condition in elderly patients, often treated with Transcatheter Aortic Valve Implantation (TAVI). Despite procedural advances, paravalvular aortic regurgitation (PVR) remains one of the most frequent post-TAVI complications, with a proven impac",
    "url": "https://arxiv.org/abs/2602.13842",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Evaluating LLM-Generated ACSL Annotations for Formal Verification",
    "summary": "arXiv:2602.13851v1 Announce Type: cross Abstract: Formal specifications are crucial for building verifiable and dependable software systems, yet generating accurate and verifiable specifications for real-world C programs remains challenging. This paper empirically evaluates the extent to which formal-analysis tools can automatically generate and ve",
    "url": "https://arxiv.org/abs/2602.13851",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "GSRM: Generative Speech Reward Model for Speech RLHF",
    "summary": "arXiv:2602.13891v1 Announce Type: cross Abstract: Recent advances in speech language models, such as GPT-4o Voice Mode and Gemini Live, have demonstrated promising speech generation capabilities. Nevertheless, the aesthetic naturalness of the synthesized audio still lags behind that of human speech. Enhancing generation quality requires a reliable ",
    "url": "https://arxiv.org/abs/2602.13891",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "RPGD: RANSAC-P3P Gradient Descent for Extrinsic Calibration in 3D Human Pose Estimation",
    "summary": "arXiv:2602.13901v1 Announce Type: cross Abstract: In this paper, we propose RPGD (RANSAC-P3P Gradient Descent), a human-pose-driven extrinsic calibration framework that robustly aligns MoCap-based 3D skeletal data with monocular or multi-view RGB cameras using only natural human motion. RPGD formulates extrinsic calibration as a coarse-to-fine prob",
    "url": "https://arxiv.org/abs/2602.13901",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Sufficient Conditions for Stability of Minimum-Norm Interpolating Deep ReLU Networks",
    "summary": "arXiv:2602.13910v1 Announce Type: cross Abstract: Algorithmic stability is a classical framework for analyzing the generalization error of learning algorithms. It predicts that an algorithm has small generalization error if it is insensitive to small perturbations in the training set such as the removal or replacement of a training point. While sta",
    "url": "https://arxiv.org/abs/2602.13910",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Common Knowledge Always, Forever",
    "summary": "arXiv:2602.13914v1 Announce Type: cross Abstract: There has been an increasing interest in topological semantics for epistemic logic, which has been shown to be useful for, e.g., modelling evidence, degrees of belief, and self-reference. We introduce a polytopological PDL capable of expressing common knowledge and various generalizations and show i",
    "url": "https://arxiv.org/abs/2602.13914",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "A Comparative Analysis of Social Network Topology in Reddit and Moltbook",
    "summary": "arXiv:2602.13920v1 Announce Type: cross Abstract: Recent advances in agent-mediated systems have enabled a new paradigm of social network simulation, where AI agents interact with human-like autonomy. This evolution has fostered the emergence of agent-driven social networks such as Moltbook, a Reddit-like platform populated entirely by AI agents. D",
    "url": "https://arxiv.org/abs/2602.13920",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "GREPO: A Benchmark for Graph Neural Networks on Repository-Level Bug Localization",
    "summary": "arXiv:2602.13921v1 Announce Type: cross Abstract: Repository-level bug localization-the task of identifying where code must be modified to fix a bug-is a critical software engineering challenge. Standard Large Language Modles (LLMs) are often unsuitable for this task due to context window limitations that prevent them from processing entire code re",
    "url": "https://arxiv.org/abs/2602.13921",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "An Adaptive Model Selection Framework for Demand Forecasting under Horizon-Induced Degradation to Support Business Strategy and Operations",
    "summary": "arXiv:2602.13939v1 Announce Type: cross Abstract: Business environments characterized by structural demand intermittency, high variability, and multi-step planning horizons require robust and reproducible model selection mechanisms. Empirical evidence shows that no forecasting model is universally dominant and that relative rankings vary across err",
    "url": "https://arxiv.org/abs/2602.13939",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "You Can Learn Tokenization End-to-End with Reinforcement Learning",
    "summary": "arXiv:2602.13940v1 Announce Type: cross Abstract: Tokenization is a hardcoded compression step which remains in the training pipeline of Large Language Models (LLMs), despite a general trend towards architectures becoming increasingly end-to-end. Prior work has shown promising results at scale in bringing this compression step inside the LLMs' arch",
    "url": "https://arxiv.org/abs/2602.13940",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Experiential Reinforcement Learning",
    "summary": "arXiv:2602.13949v1 Announce Type: cross Abstract: Reinforcement learning has become the central approach for language models (LMs) to learn from environmental reward or feedback. In practice, the environmental feedback is usually sparse and delayed. Learning from such signals is challenging, as LMs must implicitly infer how observed failures should",
    "url": "https://arxiv.org/abs/2602.13949",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Eureka-Audio: Triggering Audio Intelligence in Compact Language Models",
    "summary": "arXiv:2602.13954v1 Announce Type: cross Abstract: We present Eureka-Audio, a compact yet high-performance audio language model that achieves competitive performance against models that are 4 to 18 times larger across a broad range of audio understanding benchmarks. Despite containing only 1.7B parameters, Eureka-Audio demonstrates strong performanc",
    "url": "https://arxiv.org/abs/2602.13954",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Chemical Language Models for Natural Products: A State-Space Model Approach",
    "summary": "arXiv:2602.13958v1 Announce Type: cross Abstract: Language models are widely used in chemistry for molecular property prediction and small-molecule generation, yet Natural Products (NPs) remain underexplored despite their importance in drug discovery. To address this gap, we develop NP-specific chemical language models (NPCLMs) by pre-training stat",
    "url": "https://arxiv.org/abs/2602.13958",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "DAIAN: Deep Adaptive Intent-Aware Network for CTR Prediction in Trigger-Induced Recommendation",
    "summary": "arXiv:2602.13971v1 Announce Type: cross Abstract: Recommendation systems are essential for personalizing e-commerce shopping experiences. Among these, Trigger-Induced Recommendation (TIR) has emerged as a key scenario, which utilizes a trigger item (explicitly represents a user's instantaneous interest), enabling precise, real-time recommendations.",
    "url": "https://arxiv.org/abs/2602.13971",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "WoVR: World Models as Reliable Simulators for Post-Training VLA Policies with RL",
    "summary": "arXiv:2602.13977v1 Announce Type: cross Abstract: Reinforcement learning (RL) promises to unlock capabilities beyond imitation learning for Vision-Language-Action (VLA) models, but its requirement for massive real-world interaction prevents direct deployment on physical robots. Recent work attempts to use learned world models as simulators for poli",
    "url": "https://arxiv.org/abs/2602.13977",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "The Sufficiency-Conciseness Trade-off in LLM Self-Explanation from an Information Bottleneck Perspective",
    "summary": "arXiv:2602.14002v1 Announce Type: cross Abstract: Large Language Models increasingly rely on self-explanations, such as chain of thought reasoning, to improve performance on multi step question answering. While these explanations enhance accuracy, they are often verbose and costly to generate, raising the question of how much explanation is truly n",
    "url": "https://arxiv.org/abs/2602.14002",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Named Entity Recognition for Payment Data Using NLP",
    "summary": "arXiv:2602.14009v1 Announce Type: cross Abstract: Named Entity Recognition (NER) has emerged as a critical component in automating financial transaction processing, particularly in extracting structured information from unstructured payment data. This paper presents a comprehensive analysis of state-of-the-art NER algorithms specifically designed f",
    "url": "https://arxiv.org/abs/2602.14009",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "A Deployment-Friendly Foundational Framework for Efficient Computational Pathology",
    "summary": "arXiv:2602.14010v1 Announce Type: cross Abstract: Pathology foundation models (PFMs) have enabled robust generalization in computational pathology through large-scale datasets and expansive architectures, but their substantial computational cost, particularly for gigapixel whole slide images, limits clinical accessibility and scalability. Here, we ",
    "url": "https://arxiv.org/abs/2602.14010",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "From SFT to RL: Demystifying the Post-Training Pipeline for LLM-based Vulnerability Detection",
    "summary": "arXiv:2602.14012v1 Announce Type: cross Abstract: The integration of LLMs into vulnerability detection (VD) has shifted the field toward interpretable and context-aware analysis. While post-training methods have shown promise in general coding tasks, their systematic application to VD remains underexplored. In this paper, we present the first compr",
    "url": "https://arxiv.org/abs/2602.14012",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "EIDOS: Latent-Space Predictive Learning for Time Series Foundation Models",
    "summary": "arXiv:2602.14024v1 Announce Type: cross Abstract: Most time series foundation models are pretrained by directly predicting future observations, which often yields weakly structured latent representations that capture surface noise rather than coherent and predictable temporal dynamics. In this work, we introduce EIDOS, a foundation model family tha",
    "url": "https://arxiv.org/abs/2602.14024",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "BitDance: Scaling Autoregressive Generative Models with Binary Tokens",
    "summary": "arXiv:2602.14041v1 Announce Type: cross Abstract: We present BitDance, a scalable autoregressive (AR) image generator that predicts binary visual tokens instead of codebook indices. With high-entropy binary latents, BitDance lets each token represent up to $2^{256}$ states, yielding a compact yet highly expressive discrete representation. Sampling ",
    "url": "https://arxiv.org/abs/2602.14041",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Restoration Adaptation for Semantic Segmentation on Low Quality Images",
    "summary": "arXiv:2602.14042v1 Announce Type: cross Abstract: In real-world scenarios, the performance of semantic segmentation often deteriorates when processing low-quality (LQ) images, which may lack clear semantic structures and high-frequency details. Although image restoration techniques offer a promising direction for enhancing degraded visual content, ",
    "url": "https://arxiv.org/abs/2602.14042",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Beyond Static Snapshots: Dynamic Modeling and Forecasting of Group-Level Value Evolution with Large Language Models",
    "summary": "arXiv:2602.14043v1 Announce Type: cross Abstract: Social simulation is critical for mining complex social dynamics and supporting data-driven decision making. LLM-based methods have emerged as powerful tools for this task by leveraging human-like social questionnaire responses to model group behaviors. Existing LLM-based approaches predominantly fo",
    "url": "https://arxiv.org/abs/2602.14043",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "UniST-Pred: A Robust Unified Framework for Spatio-Temporal Traffic Forecasting in Transportation Networks Under Disruptions",
    "summary": "arXiv:2602.14049v1 Announce Type: cross Abstract: Spatio-temporal traffic forecasting is a core component of intelligent transportation systems, supporting various downstream tasks such as signal control and network-level traffic management. In real-world deployments, forecasting models must operate under structural and observational uncertainties,",
    "url": "https://arxiv.org/abs/2602.14049",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Annotation-Efficient Vision-Language Model Adaptation to the Polish Language Using the LLaVA Framework",
    "summary": "arXiv:2602.14073v1 Announce Type: cross Abstract: Most vision-language models (VLMs) are trained on English-centric data, limiting their performance in other languages and cultural contexts. This restricts their usability for non-English-speaking users and hinders the development of multimodal systems that reflect diverse linguistic and cultural re",
    "url": "https://arxiv.org/abs/2602.14073",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Policy Gradient with Adaptive Entropy Annealing for Continual Fine-Tuning",
    "summary": "arXiv:2602.14078v1 Announce Type: cross Abstract: Despite their success, large pretrained vision models remain vulnerable to catastrophic forgetting when adapted to new tasks in class-incremental settings. Parameter-efficient fine-tuning (PEFT) alleviates this by restricting trainable parameters, yet most approaches still rely on cross-entropy (CE)",
    "url": "https://arxiv.org/abs/2602.14078",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Empty Shelves or Lost Keys? Recall Is the Bottleneck for Parametric Factuality",
    "summary": "arXiv:2602.14080v1 Announce Type: cross Abstract: Standard factuality evaluations of LLMs treat all errors alike, obscuring whether failures arise from missing knowledge (empty shelves) or from limited access to encoded facts (lost keys). We propose a behavioral framework that profiles factual knowledge at the level of facts rather than questions, ",
    "url": "https://arxiv.org/abs/2602.14080",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "TabTracer: Monte Carlo Tree Search for Complex Table Reasoning with Large Language Models",
    "summary": "arXiv:2602.14089v1 Announce Type: cross Abstract: Large language models (LLMs) have emerged as powerful tools for natural language table reasoning, where there are two main categories of methods. Prompt-based approaches rely on language-only inference or one-pass program generation without step-level verification. Agent-based approaches use tools i",
    "url": "https://arxiv.org/abs/2602.14089",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "SemanticFeels: Semantic Labeling during In-Hand Manipulation",
    "summary": "arXiv:2602.14099v1 Announce Type: cross Abstract: As robots become increasingly integrated into everyday tasks, their ability to perceive both the shape and properties of objects during in-hand manipulation becomes critical for adaptive and intelligent behavior. We present SemanticFeels, an extension of the NeuralFeels framework that integrates sem",
    "url": "https://arxiv.org/abs/2602.14099",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Anticipating Adversary Behavior in DevSecOps Scenarios through Large Language Models",
    "summary": "arXiv:2602.14106v1 Announce Type: cross Abstract: The most valuable asset of any cloud-based organization is data, which is increasingly exposed to sophisticated cyberattacks. Until recently, the implementation of security measures in DevOps environments was often considered optional by many government entities and critical national services operat",
    "url": "https://arxiv.org/abs/2602.14106",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Toward Autonomous O-RAN: A Multi-Scale Agentic AI Framework for Real-Time Network Control and Management",
    "summary": "arXiv:2602.14117v1 Announce Type: cross Abstract: Open Radio Access Networks (O-RAN) promise flexible 6G network access through disaggregated, software-driven components and open interfaces, but this programmability also increases operational complexity. Multiple control loops coexist across the service management layer and RAN Intelligent Controll",
    "url": "https://arxiv.org/abs/2602.14117",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "DenseMLLM: Standard Multimodal LLMs are Intrinsic Dense Predictors",
    "summary": "arXiv:2602.14134v1 Announce Type: cross Abstract: Multimodal Large Language Models (MLLMs) have demonstrated exceptional capabilities in high-level visual understanding. However, extending these models to fine-grained dense prediction tasks, such as semantic segmentation and depth estimation, typically necessitates the incorporation of complex, tas",
    "url": "https://arxiv.org/abs/2602.14134",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Detection of On-Ground Chestnuts Using Artificial Intelligence Toward Automated Picking",
    "summary": "arXiv:2602.14140v1 Announce Type: cross Abstract: Traditional mechanized chestnut harvesting is too costly for small producers, non-selective, and prone to damaging nuts. Accurate, reliable detection of chestnuts on the orchard floor is crucial for developing low-cost, vision-guided automated harvesting technology. However, developing a reliable ch",
    "url": "https://arxiv.org/abs/2602.14140",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "When Test-Time Guidance Is Enough: Fast Image and Video Editing with Diffusion Guidance",
    "summary": "arXiv:2602.14157v1 Announce Type: cross Abstract: Text-driven image and video editing can be naturally cast as inpainting problems, where masked regions are reconstructed to remain consistent with both the observed content and the editing prompt. Recent advances in test-time guidance for diffusion and flow models provide a principled framework for ",
    "url": "https://arxiv.org/abs/2602.14157",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "A Multi-Agent Framework for Medical AI: Leveraging Fine-Tuned GPT, LLaMA, and DeepSeek R1 for Evidence-Based and Bias-Aware Clinical Query Processing",
    "summary": "arXiv:2602.14158v1 Announce Type: cross Abstract: Large language models (LLMs) show promise for healthcare question answering, but clinical use is limited by weak verification, insufficient evidence grounding, and unreliable confidence signalling. We propose a multi-agent medical QA framework that combines complementary LLMs with evidence retrieval",
    "url": "https://arxiv.org/abs/2602.14158",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Deep Dense Exploration for LLM Reinforcement Learning via Pivot-Driven Resampling",
    "summary": "arXiv:2602.14169v1 Announce Type: cross Abstract: Effective exploration is a key challenge in reinforcement learning for large language models: discovering high-quality trajectories within a limited sampling budget from the vast natural language sequence space. Existing methods face notable limitations: GRPO samples exclusively from the root, satur",
    "url": "https://arxiv.org/abs/2602.14169",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Towards Spatial Transcriptomics-driven Pathology Foundation Models",
    "summary": "arXiv:2602.14177v1 Announce Type: cross Abstract: Spatial transcriptomics (ST) provides spatially resolved measurements of gene expression, enabling characterization of the molecular landscape of human tissue beyond histological assessment as well as localized readouts that can be aligned with morphology. Concurrently, the success of multimodal fou",
    "url": "https://arxiv.org/abs/2602.14177",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "UniWeTok: An Unified Binary Tokenizer with Codebook Size $\\mathit{2^{128}}$ for Unified Multimodal Large Language Model",
    "summary": "arXiv:2602.14178v1 Announce Type: cross Abstract: Unified Multimodal Large Language Models (MLLMs) require a visual representation that simultaneously supports high-fidelity reconstruction, complex semantic extraction, and generative suitability. However, existing visual tokenizers typically struggle to satisfy these conflicting objectives within a",
    "url": "https://arxiv.org/abs/2602.14178",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "GPT-5 vs Other LLMs in Long Short-Context Performance",
    "summary": "arXiv:2602.14188v1 Announce Type: cross Abstract: With the significant expansion of the context window in Large Language Models (LLMs), these models are theoretically capable of processing millions of tokens in a single pass. However, research indicates a significant gap between this theoretical capacity and the practical ability of models to robus",
    "url": "https://arxiv.org/abs/2602.14188",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Knowing When Not to Answer: Abstention-Aware Scientific Reasoning",
    "summary": "arXiv:2602.14189v1 Announce Type: cross Abstract: Large language models are increasingly used to answer and verify scientific claims, yet existing evaluations typically assume that a model must always produce a definitive answer. In scientific settings, however, unsupported or uncertain conclusions can be more harmful than abstaining. We study this",
    "url": "https://arxiv.org/abs/2602.14189",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "GeoEyes: On-Demand Visual Focusing for Evidence-Grounded Understanding of Ultra-High-Resolution Remote Sensing Imagery",
    "summary": "arXiv:2602.14201v1 Announce Type: cross Abstract: The \"thinking-with-images\" paradigm enables multimodal large language models (MLLMs) to actively explore visual scenes via zoom-in tools. This is essential for ultra-high-resolution (UHR) remote sensing VQA, where task-relevant cues are sparse and tiny. However, we observe a consistent failure mode ",
    "url": "https://arxiv.org/abs/2602.14201",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "SkillJect: Automating Stealthy Skill-Based Prompt Injection for Coding Agents with Trace-Driven Closed-Loop Refinement",
    "summary": "arXiv:2602.14211v1 Announce Type: cross Abstract: Agent skills are becoming a core abstraction in coding agents, packaging long-form instructions and auxiliary scripts to extend tool-augmented behaviors. This abstraction introduces an under-measured attack surface: skill-based prompt injection, where poisoned skills can steer agents away from user ",
    "url": "https://arxiv.org/abs/2602.14211",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Reasoning Language Models for complex assessments tasks: Evaluating parental cooperation from child protection case reports",
    "summary": "arXiv:2602.14216v1 Announce Type: cross Abstract: Purpose: Reasoning language models (RLMs) have demonstrated significant advances in solving complex reasoning tasks. We examined their potential to assess parental cooperation during CPS interventions using case reports, a case factor characterized by ambiguous and conflicting information. Methods: ",
    "url": "https://arxiv.org/abs/2602.14216",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Evaluating LLMs in Finance Requires Explicit Bias Consideration",
    "summary": "arXiv:2602.14233v1 Announce Type: cross Abstract: Large Language Models (LLMs) are increasingly integrated into financial workflows, but evaluation practice has not kept up. Finance-specific biases can inflate performance, contaminate backtests, and make reported results useless for any deployment claim. We identify five recurring biases in financi",
    "url": "https://arxiv.org/abs/2602.14233",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Dual-Signal Adaptive KV-Cache Optimization for Long-Form Video Understanding in Vision-Language Models",
    "summary": "arXiv:2602.14236v1 Announce Type: cross Abstract: Vision-Language Models (VLMs) face a critical memory bottleneck when processing long-form video content due to the linear growth of the Key-Value (KV) cache with sequence length. Existing solutions predominantly employ reactive eviction strategies that compute full attention matrices before discardi",
    "url": "https://arxiv.org/abs/2602.14236",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "AbracADDbra: Touch-Guided Object Addition by Decoupling Placement and Editing Subtasks",
    "summary": "arXiv:2602.14237v1 Announce Type: cross Abstract: Instruction-based object addition is often hindered by the ambiguity of text-only prompts or the tedious nature of mask-based inputs. To address this usability gap, we introduce AbracADDbra, a user-friendly framework that leverages intuitive touch priors to spatially ground succinct instructions for",
    "url": "https://arxiv.org/abs/2602.14237",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "A Hybrid TGN-SEAL Model for Dynamic Graph Link Prediction",
    "summary": "arXiv:2602.14239v1 Announce Type: cross Abstract: Predicting links in sparse, continuously evolving networks is a central challenge in network science. Conventional heuristic methods and deep learning models, including Graph Neural Networks (GNNs), are typically designed for static graphs and thus struggle to capture temporal dependencies. Snapshot",
    "url": "https://arxiv.org/abs/2602.14239",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Multi-Agent Debate: A Unified Agentic Framework for Tabular Anomaly Detection",
    "summary": "arXiv:2602.14251v1 Announce Type: cross Abstract: Tabular anomaly detection is often handled by single detectors or static ensembles, even though strong performance on tabular data typically comes from heterogeneous model families (e.g., tree ensembles, deep tabular networks, and tabular foundation models) that frequently disagree under distributio",
    "url": "https://arxiv.org/abs/2602.14251",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "AD-Bench: A Real-World, Trajectory-Aware Advertising Analytics Benchmark for LLM Agents",
    "summary": "arXiv:2602.14257v1 Announce Type: cross Abstract: While Large Language Model (LLM) agents have achieved remarkable progress in complex reasoning tasks, evaluating their performance in real-world environments has become a critical problem. Current benchmarks, however, are largely restricted to idealized simulations, failing to address the practical ",
    "url": "https://arxiv.org/abs/2602.14257",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Cross-household Transfer Learning Approach with LSTM-based Demand Forecasting",
    "summary": "arXiv:2602.14267v1 Announce Type: cross Abstract: With the rapid increase in residential heat pump (HP) installations, optimizing hot water production in households is essential, yet it faces major technical and scalability challenges. Adapting production to actual household needs requires accurate forecasting of hot water demand to ensure comfort ",
    "url": "https://arxiv.org/abs/2602.14267",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "A Rational Analysis of the Effects of Sycophantic AI",
    "summary": "arXiv:2602.14270v1 Announce Type: cross Abstract: People increasingly use large language models (LLMs) to explore ideas, gather information, and make sense of the world. In these interactions, they encounter agents that are overly agreeable. We argue that this sycophancy poses a unique epistemic risk to how individuals come to see the world: unlike",
    "url": "https://arxiv.org/abs/2602.14270",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Integrating Unstructured Text into Causal Inference: Empirical Evidence from Real Data",
    "summary": "arXiv:2602.14274v1 Announce Type: cross Abstract: Causal inference, a critical tool for informing business decisions, traditionally relies heavily on structured data. However, in many real-world scenarios, such data can be incomplete or unavailable. This paper presents a framework that leverages transformer-based language models to perform causal i",
    "url": "https://arxiv.org/abs/2602.14274",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Reverse N-Wise Output-Oriented Testing for AI/ML and Quantum Computing Systems",
    "summary": "arXiv:2602.14275v1 Announce Type: cross Abstract: Artificial intelligence/machine learning (AI/ML) systems and emerging quantum computing software present unprecedented testing challenges characterized by high-dimensional/continuous input spaces, probabilistic/non-deterministic output distributions, behavioral correctness defined exclusively over o",
    "url": "https://arxiv.org/abs/2602.14275",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Whom to Query for What: Adaptive Group Elicitation via Multi-Turn LLM Interactions",
    "summary": "arXiv:2602.14279v1 Announce Type: cross Abstract: Eliciting information to reduce uncertainty about latent group-level properties from surveys and other collective assessments requires allocating limited questioning effort under real costs and missing data. Although large language models enable adaptive, multi-turn interactions in natural language,",
    "url": "https://arxiv.org/abs/2602.14279",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "FMMD: A multimodal open peer review dataset based on F1000Research",
    "summary": "arXiv:2602.14285v1 Announce Type: cross Abstract: Automated scholarly paper review (ASPR) has entered the coexistence phase with traditional peer review, where artificial intelligence (AI) systems are increasingly incorporated into real-world manuscript evaluation. In parallel, research on automated and AI-assisted peer review has proliferated. Des",
    "url": "https://arxiv.org/abs/2602.14285",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "KernelBlaster: Continual Cross-Task CUDA Optimization via Memory-Augmented In-Context Reinforcement Learning",
    "summary": "arXiv:2602.14293v1 Announce Type: cross Abstract: Optimizing CUDA code across multiple generations of GPU architectures is challenging, as achieving peak performance requires an extensive exploration of an increasingly complex, hardware-specific optimization space. Traditional compilers are constrained by fixed heuristics, whereas finetuning Large ",
    "url": "https://arxiv.org/abs/2602.14293",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Machine Learning as a Tool (MLAT): A Framework for Integrating Statistical ML Models as Callable Tools within LLM Agent Workflows",
    "summary": "arXiv:2602.14295v1 Announce Type: cross Abstract: We introduce Machine Learning as a Tool (MLAT), a design pattern in which pre-trained statistical machine learning models are exposed as callable tools within large language model (LLM) agent workflows. This allows an orchestrating agent to invoke quantitative predictions when needed and reason abou",
    "url": "https://arxiv.org/abs/2602.14295",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Does Socialization Emerge in AI Agent Society? A Case Study of Moltbook",
    "summary": "arXiv:2602.14299v1 Announce Type: cross Abstract: As large language model agents increasingly populate networked environments, a fundamental question arises: do artificial intelligence (AI) agent societies undergo convergence dynamics similar to human social systems? Lately, Moltbook approximates a plausible future scenario in which autonomous agen",
    "url": "https://arxiv.org/abs/2602.14299",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "DeepFusion: Accelerating MoE Training via Federated Knowledge Distillation from Heterogeneous Edge Devices",
    "summary": "arXiv:2602.14301v1 Announce Type: cross Abstract: Recent Mixture-of-Experts (MoE)-based large language models (LLMs) such as Qwen-MoE and DeepSeek-MoE are transforming generative AI in natural language processing. However, these models require vast and diverse training data. Federated learning (FL) addresses this challenge by leveraging private dat",
    "url": "https://arxiv.org/abs/2602.14301",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Offline Learning of Nash Stable Coalition Structures with Possibly Overlapping Coalitions",
    "summary": "arXiv:2602.14321v1 Announce Type: cross Abstract: Coalition formation concerns strategic collaborations of selfish agents that form coalitions based on their preferences. It is often assumed that coalitions are disjoint and preferences are fully known, which may not hold in practice. In this paper, we thus present a new model of coalition formation",
    "url": "https://arxiv.org/abs/2602.14321",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Train Less, Learn More: Adaptive Efficient Rollout Optimization for Group-Based Reinforcement Learning",
    "summary": "arXiv:2602.14338v1 Announce Type: cross Abstract: Reinforcement learning (RL) plays a central role in large language model (LLM) post-training. Among existing approaches, Group Relative Policy Optimization (GRPO) is widely used, especially for RL with verifiable rewards (RLVR) fine-tuning. In GRPO, each query prompts the LLM to generate a group of ",
    "url": "https://arxiv.org/abs/2602.14338",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Zero-Shot Instruction Following in RL via Structured LTL Representations",
    "summary": "arXiv:2602.14344v1 Announce Type: cross Abstract: We study instruction following in multi-task reinforcement learning, where an agent must zero-shot execute novel tasks not seen during training. In this setting, linear temporal logic (LTL) has recently been adopted as a powerful framework for specifying structured, temporally extended tasks. While ",
    "url": "https://arxiv.org/abs/2602.14344",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "AXE: An Agentic eXploit Engine for Confirming Zero-Day Vulnerability Reports",
    "summary": "arXiv:2602.14345v1 Announce Type: cross Abstract: Vulnerability detection tools are widely adopted in software projects, yet they often overwhelm maintainers with false positives and non-actionable reports. Automated exploitation systems can help validate these reports; however, existing approaches typically operate in isolation from detection pipe",
    "url": "https://arxiv.org/abs/2602.14345",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "WIMLE: Uncertainty-Aware World Models with IMLE for Sample-Efficient Continuous Control",
    "summary": "arXiv:2602.14351v1 Announce Type: cross Abstract: Model-based reinforcement learning promises strong sample efficiency but often underperforms in practice due to compounding model error, unimodal world models that average over multi-modal dynamics, and overconfident predictions that bias learning. We introduce WIMLE, a model-based method that exten",
    "url": "https://arxiv.org/abs/2602.14351",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Key Considerations for Domain Expert Involvement in LLM Design and Evaluation: An Ethnographic Study",
    "summary": "arXiv:2602.14357v1 Announce Type: cross Abstract: Large Language Models (LLMs) are increasingly developed for use in complex professional domains, yet little is known about how teams design and evaluate these systems in practice. This paper examines the challenges and trade-offs in LLM development through a 12-week ethnographic study of a team buil",
    "url": "https://arxiv.org/abs/2602.14357",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "High Precision Audience Expansion via Extreme Classification in a Two-Sided Marketplace",
    "summary": "arXiv:2602.14358v1 Announce Type: cross Abstract: Airbnb search must balance a worldwide, highly varied supply of homes with guests whose location, amenity, style, and price expectations differ widely. Meeting those expectations hinges on an efficient retrieval stage that surfaces only the listings a guest might realistically book, before resource ",
    "url": "https://arxiv.org/abs/2602.14358",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "A Trajectory-Based Safety Audit of Clawdbot (OpenClaw)",
    "summary": "arXiv:2602.14364v1 Announce Type: cross Abstract: Clawdbot is a self-hosted, tool-using personal AI agent with a broad action space spanning local execution and web-mediated workflows, which raises heightened safety and security concerns under ambiguity and adversarial steering. We present a trajectory-centric evaluation of Clawdbot across six risk",
    "url": "https://arxiv.org/abs/2602.14364",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Image-based Joint-level Detection for Inflammation in Rheumatoid Arthritis from Small and Imbalanced Data",
    "summary": "arXiv:2602.14365v1 Announce Type: cross Abstract: Rheumatoid arthritis (RA) is an autoimmune disease characterized by systemic joint inflammation. Early diagnosis and tight follow-up are essential to the management of RA, as ongoing inflammation can cause irreversible joint damage. The detection of arthritis is important for diagnosis and assessmen",
    "url": "https://arxiv.org/abs/2602.14365",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "InnoEval: On Research Idea Evaluation as a Knowledge-Grounded, Multi-Perspective Reasoning Problem",
    "summary": "arXiv:2602.14367v1 Announce Type: cross Abstract: The rapid evolution of Large Language Models has catalyzed a surge in scientific idea production, yet this leap has not been accompanied by a matching advance in idea evaluation. The fundamental nature of scientific evaluation needs knowledgeable grounding, collective deliberation, and multi-criteri",
    "url": "https://arxiv.org/abs/2602.14367",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Differentially Private Retrieval-Augmented Generation",
    "summary": "arXiv:2602.14374v1 Announce Type: cross Abstract: Retrieval-augmented generation (RAG) is a widely used framework for reducing hallucinations in large language models (LLMs) on domain-specific tasks by retrieving relevant documents from a database to support accurate responses. However, when the database contains sensitive corpora, such as medical ",
    "url": "https://arxiv.org/abs/2602.14374",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Adapting VACE for Real-Time Autoregressive Video Diffusion",
    "summary": "arXiv:2602.14381v1 Announce Type: cross Abstract: We describe an adaptation of VACE (Video All-in-one Creation and Editing) for real-time autoregressive video generation. VACE provides unified video control (reference guidance, structural conditioning, inpainting, and temporal extension) but assumes bidirectional attention over full sequences, maki",
    "url": "https://arxiv.org/abs/2602.14381",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "pFedNavi: Structure-Aware Personalized Federated Vision-Language Navigation for Embodied AI",
    "summary": "arXiv:2602.14401v1 Announce Type: cross Abstract: Vision-Language Navigation VLN requires large-scale trajectory instruction data from private indoor environments, raising significant privacy concerns. Federated Learning FL mitigates this by keeping data on-device, but vanilla FL struggles under VLNs' extreme cross-client heterogeneity in environme",
    "url": "https://arxiv.org/abs/2602.14401",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "TruthStance: An Annotated Dataset of Conversations on Truth Social",
    "summary": "arXiv:2602.14406v1 Announce Type: cross Abstract: Argument mining and stance detection are central to understanding how opinions are formed and contested in online discourse. However, most publicly available resources focus on mainstream platforms such as Twitter and Reddit, leaving conversational structure on alt-tech platforms comparatively under",
    "url": "https://arxiv.org/abs/2602.14406",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Feature Recalibration Based Olfactory-Visual Multimodal Model for Fine-Grained Rice Deterioration Detection",
    "summary": "arXiv:2602.14408v1 Announce Type: cross Abstract: Multimodal methods are widely used in rice deterioration detection, which exhibit limited capability in representing and extracting fine-grained abnormal features. Moreover, these methods rely on devices, such as hyperspectral cameras and mass spectrometers, increasing detection costs and prolonging",
    "url": "https://arxiv.org/abs/2602.14408",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "The geometry of invariant learning: an information-theoretic analysis of data augmentation and generalization",
    "summary": "arXiv:2602.14423v1 Announce Type: cross Abstract: Data augmentation is one of the most widely used techniques to improve generalization in modern machine learning, often justified by its ability to promote invariance to label-irrelevant transformations. However, its theoretical role remains only partially understood. In this work, we propose an inf",
    "url": "https://arxiv.org/abs/2602.14423",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "S2D: Selective Spectral Decay for Quantization-Friendly Conditioning of Neural Activations",
    "summary": "arXiv:2602.14432v1 Announce Type: cross Abstract: Activation outliers in large-scale transformer models pose a fundamental challenge to model quantization, creating excessively large ranges that cause severe accuracy drops during quantization. We empirically observe that outlier severity intensifies with pre-training scale (e.g., progressing from C",
    "url": "https://arxiv.org/abs/2602.14432",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Synthetic Reader Panels: Tournament-Based Ideation with LLM Personas for Autonomous Publishing",
    "summary": "arXiv:2602.14433v1 Announce Type: cross Abstract: We present a system for autonomous book ideation that replaces human focus groups with synthetic reader panels -- diverse collections of LLM-instantiated reader personas that evaluate book concepts through structured tournament competitions. Each persona is defined by demographic attributes (age gro",
    "url": "https://arxiv.org/abs/2602.14433",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Broken Chains: The Cost of Incomplete Reasoning in LLMs",
    "summary": "arXiv:2602.14444v1 Announce Type: cross Abstract: Reasoning-specialized models like OpenAI's 5.1 and DeepSeek-V3.2 allocate substantial inference compute to extended chain-of-thought (CoT) traces, yet reasoning tokens incur significant costs. How do different reasoning modalities of code, natural language, hybrid, or none do perform under token con",
    "url": "https://arxiv.org/abs/2602.14444",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Selective Synchronization Attention",
    "summary": "arXiv:2602.14445v1 Announce Type: cross Abstract: The Transformer architecture has become the foundation of modern deep learning, yet its core self-attention mechanism suffers from quadratic computational complexity and lacks grounding in biological neural computation. We propose Selective Synchronization Attention (SSA), a novel attention mechanis",
    "url": "https://arxiv.org/abs/2602.14445",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "WiSparse: Boosting LLM Inference Efficiency with Weight-Aware Mixed Activation Sparsity",
    "summary": "arXiv:2602.14452v1 Announce Type: cross Abstract: Large Language Models (LLMs) offer strong capabilities but incur high inference costs due to dense computation and memory access. Training-free activation sparsity is a promising approach for efficient LLM inference, yet existing methods often rely solely on activation information and uniform sparsi",
    "url": "https://arxiv.org/abs/2602.14452",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Silent Inconsistency in Data-Parallel Full Fine-Tuning: Diagnosing Worker-Level Optimization Misalignment",
    "summary": "arXiv:2602.14462v1 Announce Type: cross Abstract: Data-parallel (DP) training with synchronous all-reduce is a dominant paradigm for full-parameter fine-tuning of large language models (LLMs). While parameter synchronization guarantees numerical equivalence of model weights after each iteration, it does not necessarily imply alignment of worker-lev",
    "url": "https://arxiv.org/abs/2602.14462",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "CoCoDiff: Correspondence-Consistent Diffusion Model for Fine-grained Style Transfer",
    "summary": "arXiv:2602.14464v1 Announce Type: cross Abstract: Transferring visual style between images while preserving semantic correspondence between similar objects remains a central challenge in computer vision. While existing methods have made great strides, most of them operate at global level but overlook region-wise and even pixel-wise semantic corresp",
    "url": "https://arxiv.org/abs/2602.14464",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Socially-Weighted Alignment: A Game-Theoretic Framework for Multi-Agent LLM Systems",
    "summary": "arXiv:2602.14471v1 Announce Type: cross Abstract: Deploying large language model (LLM) agents in shared environments introduces a fundamental tension between individual alignment and collective stability: locally rational decisions can impose negative externalities that degrade system-level performance. We propose Socially-Weighted Alignment (SWA),",
    "url": "https://arxiv.org/abs/2602.14471",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Learning Transferability: A Two-Stage Reinforcement Learning Approach for Enhancing Quadruped Robots' Performance in U-Shaped Stair Climbing",
    "summary": "arXiv:2602.14473v1 Announce Type: cross Abstract: Quadruped robots are employed in various scenarios in building construction. However, autonomous stair climbing across different indoor staircases remains a major challenge for robot dogs to complete building construction tasks. In this project, we employed a two-stage end-to-end deep reinforcement ",
    "url": "https://arxiv.org/abs/2602.14473",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "When OpenClaw AI Agents Teach Each Other: Peer Learning Patterns in the Moltbook Community",
    "summary": "arXiv:2602.14477v1 Announce Type: cross Abstract: Peer learning, where learners teach and learn from each other, is foundational to educational practice. A novel phenomenon has emerged: AI agents forming communities where they teach each other skills, share discoveries, and collaboratively build knowledge. This paper presents an educational data mi",
    "url": "https://arxiv.org/abs/2602.14477",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "On the Rate-Distortion-Complexity Tradeoff for Semantic Communication",
    "summary": "arXiv:2602.14481v1 Announce Type: cross Abstract: Semantic communication is a novel communication paradigm that focuses on conveying the user's intended meaning rather than the bit-wise transmission of source signals. One of the key challenges is to effectively represent and extract the semantic meaning of any given source signals. While deep learn",
    "url": "https://arxiv.org/abs/2602.14481",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "TikArt: Aperture-Guided Observation for Fine-Grained Visual Reasoning via Reinforcement Learning",
    "summary": "arXiv:2602.14482v1 Announce Type: cross Abstract: We address fine-grained visual reasoning in multimodal large language models (MLLMs), where key evidence may reside in tiny objects, cluttered regions, or subtle markings that are lost under a single global image encoding. We introduce TikArt (Thinking Aperture), an aperture-guided agent that casts ",
    "url": "https://arxiv.org/abs/2602.14482",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Revisiting the Platonic Representation Hypothesis: An Aristotelian View",
    "summary": "arXiv:2602.14486v1 Announce Type: cross Abstract: The Platonic Representation Hypothesis suggests that representations from neural networks are converging to a common statistical model of reality. We show that the existing metrics used to measure representational similarity are confounded by network scale: increasing model depth or width can system",
    "url": "https://arxiv.org/abs/2602.14486",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "BETA-Labeling for Multilingual Dataset Construction in Low-Resource IR",
    "summary": "arXiv:2602.14488v1 Announce Type: cross Abstract: IR in low-resource languages remains limited by the scarcity of high-quality, task-specific annotated datasets. Manual annotation is expensive and difficult to scale, while using large language models (LLMs) as automated annotators introduces concerns about label reliability, bias, and evaluation va",
    "url": "https://arxiv.org/abs/2602.14488",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Parameter-Efficient Fine-Tuning of LLMs with Mixture of Space Experts",
    "summary": "arXiv:2602.14490v1 Announce Type: cross Abstract: Large Language Models (LLMs) have achieved remarkable progress, with Parameter-Efficient Fine-Tuning (PEFT) emerging as a key technique for downstream task adaptation. However, existing PEFT methods mainly operate in Euclidean space, fundamentally limiting their capacity to capture complex geometric",
    "url": "https://arxiv.org/abs/2602.14490",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "TWISTED-RL: Hierarchical Skilled Agents for Knot-Tying without Human Demonstrations",
    "summary": "arXiv:2602.14526v1 Announce Type: cross Abstract: Robotic knot-tying represents a fundamental challenge in robotics due to the complex interactions between deformable objects and strict topological constraints. We present TWISTED-RL, a framework that improves upon the previous state-of-the-art in demonstration-free knot-tying (TWISTED), which smart",
    "url": "https://arxiv.org/abs/2602.14526",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Explainable Token-level Noise Filtering for LLM Fine-tuning Datasets",
    "summary": "arXiv:2602.14536v1 Announce Type: cross Abstract: Large Language Models (LLMs) have seen remarkable advancements, achieving state-of-the-art results in diverse applications. Fine-tuning, an important step for adapting LLMs to specific downstream tasks, typically involves further training on corresponding datasets. However, a fundamental discrepancy",
    "url": "https://arxiv.org/abs/2602.14536",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Governing AI Forgetting: Auditing for Machine Unlearning Compliance",
    "summary": "arXiv:2602.14553v1 Announce Type: cross Abstract: Despite legal mandates for the right to be forgotten, AI operators routinely fail to comply with data deletion requests. While machine unlearning (MU) provides a technical solution to remove personal data's influence from trained models, ensuring compliance remains challenging due to the fundamental",
    "url": "https://arxiv.org/abs/2602.14553",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Fluid-Agent Reinforcement Learning",
    "summary": "arXiv:2602.14559v1 Announce Type: cross Abstract: The primary focus of multi-agent reinforcement learning (MARL) has been to study interactions among a fixed number of agents embedded in an environment. However, in the real world, the number of agents is neither fixed nor known a priori. Moreover, an agent can decide to create other agents (for exa",
    "url": "https://arxiv.org/abs/2602.14559",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Decoupled Continuous-Time Reinforcement Learning via Hamiltonian Flow",
    "summary": "arXiv:2602.14587v1 Announce Type: cross Abstract: Many real-world control problems, ranging from finance to robotics, evolve in continuous time with non-uniform, event-driven decisions. Standard discrete-time reinforcement learning (RL), based on fixed-step Bellman updates, struggles in this setting: as time gaps shrink, the $Q$-function collapses ",
    "url": "https://arxiv.org/abs/2602.14587",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Automated Classification of Source Code Changes Based on Metrics Clustering in the Software Development Process",
    "summary": "arXiv:2602.14591v1 Announce Type: cross Abstract: This paper presents an automated method for classifying source code changes during the software development process based on clustering of change metrics. The method consists of two steps: clustering of metric vectors computed for each code change, followed by expert mapping of the resulting cluster",
    "url": "https://arxiv.org/abs/2602.14591",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "OPBench: A Graph Benchmark to Combat the Opioid Crisis",
    "summary": "arXiv:2602.14602v1 Announce Type: cross Abstract: The opioid epidemic continues to ravage communities worldwide, straining healthcare systems, disrupting families, and demanding urgent computational solutions. To combat this lethal opioid crisis, graph learning methods have emerged as a promising paradigm for modeling complex drug-related phenomena",
    "url": "https://arxiv.org/abs/2602.14602",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Towards Selection as Power: Bounding Decision Authority in Autonomous Agents",
    "summary": "arXiv:2602.14606v1 Announce Type: cross Abstract: Autonomous agentic systems are increasingly deployed in regulated, high-stakes domains where decisions may be irreversible and institutionally constrained. Existing safety approaches emphasize alignment, interpretability, or action-level filtering. We argue that these mechanisms are necessary but in",
    "url": "https://arxiv.org/abs/2602.14606",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "LongAudio-RAG: Event-Grounded Question Answering over Multi-Hour Long Audio",
    "summary": "arXiv:2602.14612v1 Announce Type: cross Abstract: Long-duration audio is increasingly common in industrial and consumer settings, yet reviewing multi-hour recordings is impractical, motivating systems that answer natural-language queries with precise temporal grounding and minimal hallucination. Existing audio-language models show promise, but long",
    "url": "https://arxiv.org/abs/2602.14612",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "VariViT: A Vision Transformer for Variable Image Sizes",
    "summary": "arXiv:2602.14615v1 Announce Type: cross Abstract: Vision Transformers (ViTs) have emerged as the state-of-the-art architecture in representation learning, leveraging self-attention mechanisms to excel in various tasks. ViTs split images into fixed-size patches, constraining them to a predefined size and necessitating pre-processing steps like resiz",
    "url": "https://arxiv.org/abs/2602.14615",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Breaking Data Efficiency Dilemma: A Federated and Augmented Learning Framework For Alzheimer's Disease Detection via Speech",
    "summary": "arXiv:2602.14655v1 Announce Type: cross Abstract: Early diagnosis of Alzheimer's Disease (AD) is crucial for delaying its progression. While AI-based speech detection is non-invasive and cost-effective, it faces a critical data efficiency dilemma due to medical data scarcity and privacy barriers. Therefore, we propose FAL-AD, a novel framework that",
    "url": "https://arxiv.org/abs/2602.14655",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ST-EVO: Towards Generative Spatio-Temporal Evolution of Multi-Agent Communication Topologies",
    "summary": "arXiv:2602.14681v1 Announce Type: cross Abstract: LLM-powered Multi-Agent Systems (MAS) have emerged as an effective approach towards collaborative intelligence, and have attracted wide research interests. Among them, ``self-evolving'' MAS, treated as a more flexible and powerful technical route, can construct task-adaptive workflows or communicati",
    "url": "https://arxiv.org/abs/2602.14681",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Exposing Diversity Bias in Deep Generative Models: Statistical Origins and Correction of Diversity Error",
    "summary": "arXiv:2602.14682v1 Announce Type: cross Abstract: Deep generative models have achieved great success in producing high-quality samples, making them a central tool across machine learning applications. Beyond sample quality, an important yet less systematically studied question is whether trained generative models faithfully capture the diversity of",
    "url": "https://arxiv.org/abs/2602.14682",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "SynthSAEBench: Evaluating Sparse Autoencoders on Scalable Realistic Synthetic Data",
    "summary": "arXiv:2602.14687v1 Announce Type: cross Abstract: Improving Sparse Autoencoders (SAEs) requires benchmarks that can precisely validate architectural innovations. However, current SAE benchmarks on LLMs are often too noisy to differentiate architectural improvements, and current synthetic data experiments are too small-scale and unrealistic to provi",
    "url": "https://arxiv.org/abs/2602.14687",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Exposing the Systematic Vulnerability of Open-Weight Models to Prefill Attacks",
    "summary": "arXiv:2602.14689v1 Announce Type: cross Abstract: As the capabilities of large language models continue to advance, so does their potential for misuse. While closed-source models typically rely on external defenses, open-weight models must primarily depend on internal safeguards to mitigate harmful behavior. Prior red-teaming research has largely f",
    "url": "https://arxiv.org/abs/2602.14689",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Qute: Towards Quantum-Native Database",
    "summary": "arXiv:2602.14699v1 Announce Type: cross Abstract: This paper envisions a quantum database (Qute) that treats quantum computation as a first-class execution option. Unlike prior simulation-based methods that either run quantum algorithms on classical machines or adapt existing databases for quantum simulation, Qute instead (i) compiles an extended f",
    "url": "https://arxiv.org/abs/2602.14699",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Orcheo: A Modular Full-Stack Platform for Conversational Search",
    "summary": "arXiv:2602.14710v1 Announce Type: cross Abstract: Conversational search (CS) requires a complex software engineering pipeline that integrates query reformulation, ranking, and response generation. CS researchers currently face two barriers: the lack of a unified framework for efficiently sharing contributions with the community, and the difficulty ",
    "url": "https://arxiv.org/abs/2602.14710",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ManeuverNet: A Soft Actor-Critic Framework for Precise Maneuvering of Double-Ackermann-Steering Robots with Optimized Reward Functions",
    "summary": "arXiv:2602.14726v1 Announce Type: cross Abstract: Autonomous control of double-Ackermann-steering robots is essential in agricultural applications, where robots must execute precise and complex maneuvers within a limited space. Classical methods, such as the Timed Elastic Band (TEB) planner, can address this problem, but they rely on parameter tuni",
    "url": "https://arxiv.org/abs/2602.14726",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Scale redundancy and soft gauge fixing in positively homogeneous neural networks",
    "summary": "arXiv:2602.14729v1 Announce Type: cross Abstract: Neural networks with positively homogeneous activations exhibit an exact continuous reparametrization symmetry: neuron-wise rescalings generate parameter-space orbits along which the input--output function is invariant. We interpret this symmetry as a gauge redundancy and introduce gauge-adapted coo",
    "url": "https://arxiv.org/abs/2602.14729",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Inner Loop Inference for Pretrained Transformers: Unlocking Latent Capabilities Without Training",
    "summary": "arXiv:2602.14759v1 Announce Type: cross Abstract: Deep Learning architectures, and in particular Transformers, are conventionally viewed as a composition of layers. These layers are actually often obtained as the sum of two contributions: a residual path that copies the input and the output of a Transformer block. As a consequence, the inner repres",
    "url": "https://arxiv.org/abs/2602.14759",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Residual Connections and the Causal Shift: Uncovering a Structural Misalignment in Transformers",
    "summary": "arXiv:2602.14760v1 Announce Type: cross Abstract: Large Language Models (LLMs) are trained with next-token prediction, implemented in autoregressive Transformers via causal masking for parallelism. This creates a subtle misalignment: residual connections tie activations to the current token, while supervision targets the next token, potentially pro",
    "url": "https://arxiv.org/abs/2602.14760",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Universal Algorithm-Implicit Learning",
    "summary": "arXiv:2602.14761v1 Announce Type: cross Abstract: Current meta-learning methods are constrained to narrow task distributions with fixed feature and label spaces, limiting applicability. Moreover, the current meta-learning literature uses key terms like \"universal\" and \"general-purpose\" inconsistently and lacks precise definitions, hindering compara",
    "url": "https://arxiv.org/abs/2602.14761",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Unlocking Reasoning Capability on Machine Translation in Large Language Models",
    "summary": "arXiv:2602.14763v1 Announce Type: cross Abstract: Reasoning-oriented large language models (RLMs) achieve strong gains on tasks such as mathematics and coding by generating explicit intermediate reasoning. However, their impact on machine translation (MT) remains underexplored. We systematically evaluate several open- and closed-weights RLMs on the",
    "url": "https://arxiv.org/abs/2602.14763",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Multi-Agent Comedy Club: Investigating Community Discussion Effects on LLM Humor Generation",
    "summary": "arXiv:2602.14770v1 Announce Type: cross Abstract: Prior work has explored multi-turn interaction and feedback for LLM writing, but evaluations still largely center on prompts and localized feedback, leaving persistent public reception in online communities underexamined. We test whether broadcast community discussion improves stand-up comedy writin",
    "url": "https://arxiv.org/abs/2602.14770",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "GOT-JEPA: Generic Object Tracking with Model Adaptation and Occlusion Handling using Joint-Embedding Predictive Architecture",
    "summary": "arXiv:2602.14771v1 Announce Type: cross Abstract: The human visual system tracks objects by integrating current observations with previously observed information, adapting to target and scene changes, and reasoning about occlusion at fine granularity. In contrast, recent generic object trackers are often optimized for training targets, which limits",
    "url": "https://arxiv.org/abs/2602.14771",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "A Geometric Analysis of Small-sized Language Model Hallucinations",
    "summary": "arXiv:2602.14778v1 Announce Type: cross Abstract: Hallucinations -- fluent but factually incorrect responses -- pose a major challenge to the reliability of language models, especially in multi-step or agentic settings. This work investigates hallucinations in small-sized LLMs through a geometric perspective, starting from the hypothesis that when ",
    "url": "https://arxiv.org/abs/2602.14778",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "What hackers talk about when they talk about AI: Early-stage diffusion of a cybercrime innovation",
    "summary": "arXiv:2602.14783v1 Announce Type: cross Abstract: The rapid expansion of artificial intelligence (AI) is raising concerns about its potential to transform cybercrime. Beyond empowering novice offenders, AI stands to intensify the scale and sophistication of attacks by seasoned cybercriminals. This paper examines the evolving relationship between cy",
    "url": "https://arxiv.org/abs/2602.14783",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "VIPA: Visual Informative Part Attention for Referring Image Segmentation",
    "summary": "arXiv:2602.14788v1 Announce Type: cross Abstract: Referring Image Segmentation (RIS) aims to segment a target object described by a natural language expression. Existing methods have evolved by leveraging the vision information into the language tokens. To more effectively exploit visual contexts for fine-grained segmentation, we propose a novel Vi",
    "url": "https://arxiv.org/abs/2602.14788",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Debiasing Central Fixation Confounds Reveals a Peripheral \"Sweet Spot\" for Human-like Scanpaths in Hard-Attention Vision",
    "summary": "arXiv:2602.14834v1 Announce Type: cross Abstract: Human eye movements in visual recognition reflect a balance between foveal sampling and peripheral context. Task-driven hard-attention models for vision are often evaluated by how well their scanpaths match human gaze. However, common scanpath metrics can be strongly confounded by dataset-specific c",
    "url": "https://arxiv.org/abs/2602.14834",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Atomix: Timely, Transactional Tool Use for Reliable Agentic Workflows",
    "summary": "arXiv:2602.14849v1 Announce Type: cross Abstract: LLM agents increasingly act on external systems, yet tool effects are immediate. Under failures, speculation, or contention, losing branches can leak unintended side effects with no safe rollback. We introduce Atomix, a runtime that provides progress-aware transactional semantics for agent tool call",
    "url": "https://arxiv.org/abs/2602.14849",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "The Well-Tempered Classifier: Some Elementary Properties of Temperature Scaling",
    "summary": "arXiv:2602.14862v1 Announce Type: cross Abstract: Temperature scaling is a simple method that allows to control the uncertainty of probabilistic models. It is mostly used in two contexts: improving the calibration of classifiers and tuning the stochasticity of large language models (LLMs). In both cases, temperature scaling is the most popular meth",
    "url": "https://arxiv.org/abs/2602.14862",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Goldilocks RL: Tuning Task Difficulty to Escape Sparse Rewards for Reasoning",
    "summary": "arXiv:2602.14868v1 Announce Type: cross Abstract: Reinforcement learning has emerged as a powerful paradigm for unlocking reasoning capabilities in large language models. However, relying on sparse rewards makes this process highly sample-inefficient, as models must navigate vast search spaces with minimal feedback. While classic curriculum learnin",
    "url": "https://arxiv.org/abs/2602.14868",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "On the Learning Dynamics of RLVR at the Edge of Competence",
    "summary": "arXiv:2602.14872v1 Announce Type: cross Abstract: Reinforcement learning with verifiable rewards (RLVR) has been a main driver of recent breakthroughs in large reasoning models. Yet it remains a mystery how rewards based solely on final outcomes can help overcome the long-horizon barrier to extended reasoning. To understand this, we develop a theor",
    "url": "https://arxiv.org/abs/2602.14872",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "CT-Bench: A Benchmark for Multimodal Lesion Understanding in Computed Tomography",
    "summary": "arXiv:2602.14879v1 Announce Type: cross Abstract: Artificial intelligence (AI) can automatically delineate lesions on computed tomography (CT) and generate radiology report content, yet progress is limited by the scarcity of publicly available CT datasets with lesion-level annotations. To bridge this gap, we introduce CT-Bench, a first-of-its-kind ",
    "url": "https://arxiv.org/abs/2602.14879",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Numerical exploration of the range of shape functionals using neural networks",
    "summary": "arXiv:2602.14881v1 Announce Type: cross Abstract: We introduce a novel numerical framework for the exploration of Blaschke--Santal\\'o diagrams, which are efficient tools characterizing the possible inequalities relating some given shape functionals. We introduce a parametrization of convex bodies in arbitrary dimensions using a specific invertible ",
    "url": "https://arxiv.org/abs/2602.14881",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Picking the Right Specialist: Attentive Neural Process-based Selection of Task-Specialized Models as Tools for Agentic Healthcare Systems",
    "summary": "arXiv:2602.14901v1 Announce Type: cross Abstract: Task-specialized models form the backbone of agentic healthcare systems, enabling the agents to answer clinical queries across tasks such as disease diagnosis, localization, and report generation. Yet, for a given task, a single \"best\" model rarely exists. In practice, each task is better served by ",
    "url": "https://arxiv.org/abs/2602.14901",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "BFS-PO: Best-First Search for Large Reasoning Models",
    "summary": "arXiv:2602.14917v1 Announce Type: cross Abstract: Large Reasoning Models (LRMs) such as OpenAI o1 and DeepSeek-R1 have shown excellent performance in reasoning tasks using long reasoning chains. However, this has also led to a significant increase of computational costs and the generation of verbose output, a phenomenon known as overthinking. The t",
    "url": "https://arxiv.org/abs/2602.14917",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "BHyGNN+: Unsupervised Representation Learning for Heterophilic Hypergraphs",
    "summary": "arXiv:2602.14919v1 Announce Type: cross Abstract: Hypergraph Neural Networks (HyGNNs) have demonstrated remarkable success in modeling higher-order relationships among entities. However, their performance often degrades on heterophilic hypergraphs, where nodes connected by the same hyperedge tend to have dissimilar semantic representations or belon",
    "url": "https://arxiv.org/abs/2602.14919",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "AnchorWeave: World-Consistent Video Generation with Retrieved Local Spatial Memories",
    "summary": "arXiv:2602.14941v1 Announce Type: cross Abstract: Maintaining spatial world consistency over long horizons remains a central challenge for camera-controllable video generation. Existing memory-based approaches often condition generation on globally reconstructed 3D scenes by rendering anchor videos from the reconstructed geometry in the history. Ho",
    "url": "https://arxiv.org/abs/2602.14941",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "PhyScensis: Physics-Augmented LLM Agents for Complex Physical Scene Arrangement",
    "summary": "arXiv:2602.14968v1 Announce Type: cross Abstract: Automatically generating interactive 3D environments is crucial for scaling up robotic data collection in simulation. While prior work has primarily focused on 3D asset placement, it often overlooks the physical relationships between objects (e.g., contact, support, balance, and containment), which ",
    "url": "https://arxiv.org/abs/2602.14968",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ThermEval: A Structured Benchmark for Evaluation of Vision-Language Models on Thermal Imagery",
    "summary": "arXiv:2602.14989v1 Announce Type: cross Abstract: Vision language models (VLMs) achieve strong performance on RGB imagery, but they do not generalize to thermal images. Thermal sensing plays a critical role in settings where visible light fails, including nighttime surveillance, search and rescue, autonomous driving, and medical screening. Unlike R",
    "url": "https://arxiv.org/abs/2602.14989",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Spectral Convolution on Orbifolds for Geometric Deep Learning",
    "summary": "arXiv:2602.14997v1 Announce Type: cross Abstract: Geometric deep learning (GDL) deals with supervised learning on data domains that go beyond Euclidean structure, such as data with graph or manifold structure. Due to the demand that arises from application-related data, there is a need to identify further topological and geometric structures with w",
    "url": "https://arxiv.org/abs/2602.14997",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Cold-Start Personalization via Training-Free Priors from Structured World Models",
    "summary": "arXiv:2602.15012v1 Announce Type: cross Abstract: Cold-start personalization requires inferring user preferences through interaction when no user-specific historical data is available. The core challenge is a routing problem: each task admits dozens of preference dimensions, yet individual users care about only a few, and which ones matter depends ",
    "url": "https://arxiv.org/abs/2602.15012",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Rethinking Diffusion Models with Symmetries through Canonicalization with Applications to Molecular Graph Generation",
    "summary": "arXiv:2602.15022v1 Announce Type: cross Abstract: Many generative tasks in chemistry and science involve distributions invariant to group symmetries (e.g., permutation and rotation). A common strategy enforces invariance and equivariance through architectural constraints such as equivariant denoisers and invariant priors. In this paper, we challeng",
    "url": "https://arxiv.org/abs/2602.15022",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Long Context, Less Focus: A Scaling Gap in LLMs Revealed through Privacy and Personalization",
    "summary": "arXiv:2602.15028v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly deployed in privacy-critical and personalization-oriented scenarios, yet the role of context length in shaping privacy leakage and personalization effectiveness remains largely unexplored. We introduce a large-scale benchmark, PAPerBench, to systematical",
    "url": "https://arxiv.org/abs/2602.15028",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Mastering NIM and Impartial Games with Weak Neural Networks: An AlphaZero-inspired Multi-Frame Approach",
    "summary": "arXiv:2411.06403v3 Announce Type: replace Abstract: We study impartial games under fixed-latency, fixed-scale quantised inference (FSQI). In this fixed-scale, bounded-range regime, we prove that inference is simulable by constant-depth polynomial-size Boolean circuits (AC0). This yields a worst-case representational barrier: single-frame agents in ",
    "url": "https://arxiv.org/abs/2411.06403",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "A representational framework for learning and encoding structurally enriched trajectories in complex agent environments",
    "summary": "arXiv:2503.13194v3 Announce Type: replace Abstract: The ability of artificial intelligence agents to make optimal decisions and generalise them to different domains and tasks is compromised in complex scenarios. One way to address this issue has focused on learning efficient representations of the world and on how the actions of agents affect them ",
    "url": "https://arxiv.org/abs/2503.13194",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "RV-Syn: Rational and Verifiable Mathematical Reasoning Data Synthesis based on Structured Function Library",
    "summary": "arXiv:2504.20426v3 Announce Type: replace Abstract: The advancement of reasoning capabilities in Large Language Models (LLMs) requires substantial amounts of high-quality reasoning data, particularly in mathematics. Existing data synthesis methods, such as data augmentation from annotated training sets or direct question generation based on relevan",
    "url": "https://arxiv.org/abs/2504.20426",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "On the Eligibility of LLMs for Counterfactual Reasoning: A Decompositional Study",
    "summary": "arXiv:2505.11839v2 Announce Type: replace Abstract: Counterfactual reasoning has emerged as a crucial technique for generalizing the reasoning capabilities of large language models (LLMs). By generating and analyzing counterfactual scenarios, researchers can assess the adaptability and reliability of model decision-making. Although prior work has s",
    "url": "https://arxiv.org/abs/2505.11839",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "It's the Thought that Counts: Evaluating the Attempts of Frontier LLMs to Persuade on Harmful Topics",
    "summary": "arXiv:2506.02873v4 Announce Type: replace Abstract: Persuasion is a powerful capability of large language models (LLMs) that both enables beneficial applications (e.g. helping people quit smoking) and raises significant risks (e.g. large-scale, targeted political manipulation). Prior work has found models possess a significant and growing persuasiv",
    "url": "https://arxiv.org/abs/2506.02873",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Making Slow Thinking Faster: Compressing LLM Chain-of-Thought via Step Entropy",
    "summary": "arXiv:2508.03346v2 Announce Type: replace Abstract: Large Language Models (LLMs) using Chain-of-Thought (CoT) prompting excel at complex reasoning but generate verbose thought processes with considerable redundancy, leading to increased inference costs and reduced efficiency. We introduce a novel CoT compression framework based on step entropy, a m",
    "url": "https://arxiv.org/abs/2508.03346",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Large Language Models as Oracles for Ontology Alignment",
    "summary": "arXiv:2508.08500v2 Announce Type: replace Abstract: There are many methods and systems to tackle the ontology alignment problem, yet a major challenge persists in producing high-quality mappings among a set of input ontologies. Adopting a human-in-the-loop approach during the alignment process has become essential in applications requiring very acc",
    "url": "https://arxiv.org/abs/2508.08500",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "AI sustains higher strategic tension than humans in chess",
    "summary": "arXiv:2508.13213v3 Announce Type: replace Abstract: Strategic decision-making requires balancing immediate opportunities against long-term objectives: a tension fundamental to competitive environments. We investigate this trade-off in chess by analyzing the dynamics of human and AI gameplay through a network-based metric that quantifies piece-to-pi",
    "url": "https://arxiv.org/abs/2508.13213",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Internal Planning in Language Models: Characterizing Horizon and Branch Awareness",
    "summary": "arXiv:2509.25260v2 Announce Type: replace Abstract: The extent to which decoder-only language models (LMs) engage in planning, that is, organizing intermediate computations to support coherent long-range generation, remains an important question, with implications for interpretability, reliability, and principled model design. Planning involves str",
    "url": "https://arxiv.org/abs/2509.25260",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "GuidedSampling: Steering LLMs Towards Diverse Candidate Solutions at Inference-Time",
    "summary": "arXiv:2510.03777v2 Announce Type: replace Abstract: Repeated Sampling (RS) is a simple inference-time algorithm that has been shown to improve model performance on complex tasks. Although it is an effective way of scaling inference time, it often struggles to generate diverse solution candidates, frequently relying on the same underlying approach t",
    "url": "https://arxiv.org/abs/2510.03777",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "SAFER: Risk-Constrained Sample-then-Filter in Large Language Models",
    "summary": "arXiv:2510.10193v3 Announce Type: replace Abstract: As large language models (LLMs) are increasingly deployed in risk-sensitive applications such as real-world open-ended question answering (QA), ensuring the trustworthiness of their outputs has become critical. Existing selective conformal prediction (SCP) methods provide statistical guarantees by",
    "url": "https://arxiv.org/abs/2510.10193",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "OmniVideoBench: Towards Audio-Visual Understanding Evaluation for Omni MLLMs",
    "summary": "arXiv:2510.10689v2 Announce Type: replace Abstract: Recent advances in multimodal large language models (MLLMs) have demonstrated substantial potential in video understanding. However, existing benchmarks fail to comprehensively evaluate synergistic reasoning capabilities across audio and visual modalities, often neglecting either one of the modali",
    "url": "https://arxiv.org/abs/2510.10689",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ParaCook: On Time-Efficient Planning for Multi-Agent Systems",
    "summary": "arXiv:2510.11608v2 Announce Type: replace Abstract: Large Language Models (LLMs) exhibit strong reasoning abilities for planning long-horizon, real-world tasks, yet existing agent benchmarks focus on task completion while neglecting time efficiency in parallel and asynchronous operations. To address this, we present ParaCook, a benchmark for time-e",
    "url": "https://arxiv.org/abs/2510.11608",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "An Agentic Framework with LLMs for Solving Complex Vehicle Routing Problems",
    "summary": "arXiv:2510.16701v2 Announce Type: replace Abstract: Complex vehicle routing problems (VRPs) remain a fundamental challenge, demanding substantial expert effort for intent interpretation and algorithm design. While large language models (LLMs) offer a promising path toward automation, current approaches still rely on external intervention, which res",
    "url": "https://arxiv.org/abs/2510.16701",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "AlphaOPT: Formulating Optimization Programs with Self-Improving LLM Experience Library",
    "summary": "arXiv:2510.18428v3 Announce Type: replace Abstract: Optimization modeling underlies critical decision-making across industries, yet remains difficult to automate: natural-language problem descriptions must be translated into precise mathematical formulations and executable solver code. Existing LLM-based approaches typically rely on brittle prompti",
    "url": "https://arxiv.org/abs/2510.18428",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Human-Centered LLM-Agent System for Detecting Anomalous Digital Asset Transactions",
    "summary": "arXiv:2510.20102v2 Announce Type: replace Abstract: We present HCLA, a human-centered multi-agent system for anomaly detection in digital-asset transactions. The system integrates three cognitively aligned roles: Rule Abstraction, Evidence Scoring, and Expert-Style Justification. These roles operate in a conversational workflow that enables non-exp",
    "url": "https://arxiv.org/abs/2510.20102",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Dataforge: Agentic Platform for Autonomous Data Engineering",
    "summary": "arXiv:2511.06185v2 Announce Type: replace Abstract: The growing demand for artificial intelligence (AI) applications in materials discovery, molecular modeling, and climate science has made data preparation a critical but labor-intensive bottleneck. Raw data from diverse sources must be cleaned, normalized, and transformed to become AI-ready, where",
    "url": "https://arxiv.org/abs/2511.06185",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "AgenticSciML: Collaborative Multi-Agent Systems for Emergent Discovery in Scientific Machine Learning",
    "summary": "arXiv:2511.07262v2 Announce Type: replace Abstract: Scientific Machine Learning (SciML) integrates data-driven inference with physical modeling to solve complex problems in science and engineering. However, the design of SciML architectures, loss formulations, and training strategies remains an expert-driven research process, requiring extensive ex",
    "url": "https://arxiv.org/abs/2511.07262",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ARCTraj: A Dataset and Benchmark of Human Reasoning Trajectories for Abstract Problem Solving",
    "summary": "arXiv:2511.11079v3 Announce Type: replace Abstract: We present ARCTraj, a dataset and methodological framework for modeling human reasoning through complex visual tasks in the Abstraction and Reasoning Corpus (ARC). While ARC has inspired extensive research on abstract reasoning, most existing approaches rely on static input-output supervision, whi",
    "url": "https://arxiv.org/abs/2511.11079",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Uncertainty-Aware Measurement of Scenario Suite Representativeness for Autonomous Systems",
    "summary": "arXiv:2511.14853v2 Announce Type: replace Abstract: Assuring the trustworthiness and safety of AI systems, e.g., autonomous vehicles (AV), depends critically on the data-related safety properties, e.g., representativeness, completeness, etc., of the datasets used for their training and testing. Among these properties, this paper focuses on represen",
    "url": "https://arxiv.org/abs/2511.14853",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Training Multimodal Large Reasoning Models Needs Better Thoughts: A Three-Stage Framework for Long Chain-of-Thought Synthesis and Selection",
    "summary": "arXiv:2512.18956v2 Announce Type: replace Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning tasks through long Chain-of-Thought (CoT) reasoning. Extending these successes to multimodal reasoning remains challenging due to the increased complexity of integrating diverse input modalities and the sca",
    "url": "https://arxiv.org/abs/2512.18956",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Recontextualization Mitigates Specification Gaming without Modifying the Specification",
    "summary": "arXiv:2512.19027v2 Announce Type: replace Abstract: Developers often struggle to specify correct training labels and rewards. Perhaps they don't need to. We propose recontextualization, which reduces how often language models \"game\" training signals, performing misbehaviors those signals mistakenly reinforce. We show recontextualization prevents mo",
    "url": "https://arxiv.org/abs/2512.19027",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs",
    "summary": "arXiv:2601.00097v3 Announce Type: replace Abstract: We design a large-language-model (LLM) agent system that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agent",
    "url": "https://arxiv.org/abs/2601.00097",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "From Stories to Cities to Games: A Qualitative Evaluation of Behaviour Planning",
    "summary": "arXiv:2601.04911v2 Announce Type: replace Abstract: The primary objective of a diverse planning approach is to generate a set of plans that are distinct from one another. Such an approach is applied in a variety of real-world domains, including risk management, automated stream data analysis, and malware detection. More recently, a novel diverse pl",
    "url": "https://arxiv.org/abs/2601.04911",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Explainable AI: Learning from the Learners",
    "summary": "arXiv:2601.05525v2 Announce Type: replace Abstract: Artificial intelligence now outperforms humans in several scientific and engineering tasks, yet its internal representations often remain opaque. In this Perspective, we argue that explainable artificial intelligence (XAI), combined with causal reasoning, enables {\\it learning from the learners}. ",
    "url": "https://arxiv.org/abs/2601.05525",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Internal Deployment Gaps in AI Regulation",
    "summary": "arXiv:2601.08005v3 Announce Type: replace Abstract: Frontier AI regulations primarily focus on systems deployed to external users, where deployment is more visible and subject to outside scrutiny. However, high-stakes applications can occur internally when companies deploy highly capable systems within their own organizations, such as for automatin",
    "url": "https://arxiv.org/abs/2601.08005",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Aeon: High-Performance Neuro-Symbolic Memory Management for Long-Horizon LLM Agents",
    "summary": "arXiv:2601.15311v2 Announce Type: replace Abstract: Large Language Models (LLMs) are fundamentally constrained by the quadratic computational cost of self-attention and the \"Lost in the Middle\" phenomenon, where reasoning capabilities degrade as context windows expand. Existing solutions, primarily \"Flat RAG\" architectures relying on vector databas",
    "url": "https://arxiv.org/abs/2601.15311",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Beyond In-Domain Detection: SpikeScore for Cross-Domain Hallucination Detection",
    "summary": "arXiv:2601.19245v4 Announce Type: replace Abstract: Hallucination detection is critical for deploying large language models (LLMs) in real-world applications. Existing hallucination detection methods achieve strong performance when the training and test data come from the same domain, but they suffer from poor cross-domain generalization. In this p",
    "url": "https://arxiv.org/abs/2601.19245",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ScholarGym: Benchmarking Large Language Model Capabilities in the Information-Gathering Stage of Deep Research",
    "summary": "arXiv:2601.21654v2 Announce Type: replace Abstract: Large language models have advanced from single-turn question answering to deep research systems that iteratively decompose research questions, invoke retrieval tools, and synthesize information across multiple rounds. Evaluating such systems typically involves scoring their final research reports",
    "url": "https://arxiv.org/abs/2601.21654",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Learning Decentralized LLM Collaboration with Multi-Agent Actor Critic",
    "summary": "arXiv:2601.21972v3 Announce Type: replace Abstract: Recent work has explored optimizing LLM collaboration through Multi-Agent Reinforcement Learning (MARL). However, most MARL fine-tuning approaches rely on predefined execution protocols, which often require centralized execution. Decentralized LLM collaboration is more appealing in practice, as ag",
    "url": "https://arxiv.org/abs/2601.21972",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Persuasion Propagation in LLM Agents",
    "summary": "arXiv:2602.00851v2 Announce Type: replace Abstract: Modern AI agents increasingly combine conversational interaction with autonomous task execution, such as coding and web research, raising a natural question: what happens when an agent engaged in long-horizon tasks is subjected to user persuasion? We study how belief-level intervention can influen",
    "url": "https://arxiv.org/abs/2602.00851",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ROMA: Recursive Open Meta-Agent Framework for Long-Horizon Multi-Agent Systems",
    "summary": "arXiv:2602.01848v2 Announce Type: replace Abstract: Current agentic frameworks underperform on long-horizon tasks. As reasoning depth increases, sequential orchestration becomes brittle, context windows impose hard limits that degrade performance, and opaque execution traces make failures difficult to localize or debug. We introduce ROMA (Recursive",
    "url": "https://arxiv.org/abs/2602.01848",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "PATHWAYS: Evaluating Investigation and Context Discovery in AI Web Agents",
    "summary": "arXiv:2602.05354v2 Announce Type: replace Abstract: We introduce PATHWAYS, a benchmark of 250 multi-step decision tasks that test whether web-based agents can discover and correctly use hidden contextual information. Across both closed and open models, agents typically navigate to relevant pages but retrieve decisive hidden evidence in only a small",
    "url": "https://arxiv.org/abs/2602.05354",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "OmniVideo-R1: Reinforcing Audio-visual Reasoning with Query Intention and Modality Attention",
    "summary": "arXiv:2602.05847v2 Announce Type: replace Abstract: While humans perceive the world through diverse modalities that operate synergistically to support a holistic understanding of their surroundings, existing omnivideo models still face substantial challenges on audio-visual understanding tasks. In this paper, we propose OmniVideo-R1, a novel reinfo",
    "url": "https://arxiv.org/abs/2602.05847",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents",
    "summary": "arXiv:2602.06855v3 Announce Type: replace Abstract: LLM agents hold significant promise for advancing scientific research. To accelerate this progress, we introduce AIRS-Bench (the AI Research Science Benchmark), a suite of 20 tasks sourced from state-of-the-art machine learning papers. These tasks span diverse domains, including language modeling,",
    "url": "https://arxiv.org/abs/2602.06855",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "LQA: A Lightweight Quantized-Adaptive Framework for Vision-Language Models on the Edge",
    "summary": "arXiv:2602.07849v2 Announce Type: replace Abstract: Deploying Vision-Language Models (VLMs) on edge devices is challenged by resource constraints and performance degradation under distribution shifts. While test-time adaptation (TTA) can counteract such shifts, existing methods are too resource-intensive for on-device deployment. To address this ch",
    "url": "https://arxiv.org/abs/2602.07849",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "When Evaluation Becomes a Side Channel: Regime Leakage and Structural Mitigations for Alignment Assessment",
    "summary": "arXiv:2602.08449v3 Announce Type: replace Abstract: Safety evaluation for advanced AI systems assumes that behavior observed under evaluation predicts behavior in deployment. This assumption weakens for agents with situational awareness, which may exploit regime leakage, cues distinguishing evaluation from deployment, to implement conditional polic",
    "url": "https://arxiv.org/abs/2602.08449",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "GPT-4o Lacks Core Features of Theory of Mind",
    "summary": "arXiv:2602.12150v2 Announce Type: replace Abstract: Do Large Language Models (LLMs) possess a Theory of Mind (ToM)? Research into this question has focused on evaluating LLMs against benchmarks and found success across a range of social tasks. However, these evaluations do not test for the actual representations posited by ToM: namely, a causal mod",
    "url": "https://arxiv.org/abs/2602.12150",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Consistency of Large Reasoning Models Under Multi-Turn Attacks",
    "summary": "arXiv:2602.13093v2 Announce Type: replace Abstract: Large reasoning models with reasoning capabilities achieve state-of-the-art performance on complex tasks, but their robustness under multi-turn adversarial pressure remains underexplored. We evaluate nine frontier reasoning models under adversarial attacks. Our findings reveal that reasoning confe",
    "url": "https://arxiv.org/abs/2602.13093",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "LightX3ECG: A Lightweight and eXplainable Deep Learning System for 3-lead Electrocardiogram Classification",
    "summary": "arXiv:2207.12381v2 Announce Type: replace-cross Abstract: Cardiovascular diseases (CVDs) are a group of heart and blood vessel disorders that is one of the most serious dangers to human health, and the number of such patients is still growing. Early and accurate detection plays a key role in successful treatment and intervention. Electrocardiogram ",
    "url": "https://arxiv.org/abs/2207.12381",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "TKN: Transformer-based Keypoint Prediction Network For Real-time Video Prediction",
    "summary": "arXiv:2303.09807v3 Announce Type: replace-cross Abstract: Video prediction is a complex time-series forecasting task with great potential in many use cases. However, traditional methods prioritize accuracy and overlook slow prediction speeds due to complex model structures, redundant information, and excessive GPU memory consumption. These methods ",
    "url": "https://arxiv.org/abs/2303.09807",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "When is Offline Policy Selection Sample Efficient for Reinforcement Learning?",
    "summary": "arXiv:2312.02355v2 Announce Type: replace-cross Abstract: Offline reinforcement learning algorithms often require careful hyperparameter tuning. Before deployment, we need to select amongst a set of candidate policies. However, there is limited understanding about the fundamental limits of this offline policy selection (OPS) problem. In this work w",
    "url": "https://arxiv.org/abs/2312.02355",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Sparse MeZO: Less Parameters for Better Performance in Zeroth-Order LLM Fine-Tuning",
    "summary": "arXiv:2402.15751v2 Announce Type: replace-cross Abstract: While fine-tuning large language models (LLMs) for specific tasks often yields impressive results, it comes at the cost of memory inefficiency due to back-propagation in gradient-based training. Memory-efficient Zeroth-order (MeZO) optimizers, recently proposed to address this issue, only re",
    "url": "https://arxiv.org/abs/2402.15751",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "When Attention Collapses: How Degenerate Layers in LLMs Enable Smaller, Stronger Models",
    "summary": "arXiv:2404.08634v4 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are known for their performance, but we uncover a significant structural inefficiency: a phenomenon we term attention collapse. In many pre-trained decoder-style LLMs, the attention matrices in deeper layers degenerate, collapsing to near rank-one structures. The",
    "url": "https://arxiv.org/abs/2404.08634",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Exact Solution to Data-Driven Inverse Optimization of MILPs in Finite Time via Gradient-Based Methods",
    "summary": "arXiv:2405.14273v5 Announce Type: replace-cross Abstract: A data-driven inverse optimization problem (DDIOP) seeks to estimate an objective function (i.e., weights) that is consistent with observed optimal-solution data, and is important in many applications, including those involving mixed integer linear programs (MILPs). In the DDIOP for MILPs, t",
    "url": "https://arxiv.org/abs/2405.14273",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Experimental Evaluation of ROS-Causal in Real-World Human-Robot Spatial Interaction Scenarios",
    "summary": "arXiv:2406.04955v2 Announce Type: replace-cross Abstract: Deploying robots in human-shared environments requires a deep understanding of how nearby agents and objects interact. Employing causal inference to model cause-and-effect relationships facilitates the prediction of human behaviours and enables the anticipation of robot interventions. Howeve",
    "url": "https://arxiv.org/abs/2406.04955",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Synergizing Foundation Models and Federated Learning: A Survey",
    "summary": "arXiv:2406.12844v2 Announce Type: replace-cross Abstract: Over the past few years, the landscape of Artificial Intelligence (AI) has been reshaped by the emergence of Foundation Models (FMs). Pre-trained on massive datasets, these models exhibit exceptional performance across diverse downstream tasks through adaptation techniques like fine-tuning a",
    "url": "https://arxiv.org/abs/2406.12844",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Resource-Efficient Personal Large Language Models Fine-Tuning with Collaborative Edge Computing",
    "summary": "arXiv:2408.10746v2 Announce Type: replace-cross Abstract: Large language models (LLMs) have unlocked a plethora of powerful applications at the network edge, such as intelligent personal assistants. Data privacy and security concerns have prompted a shift towards edge-based fine-tuning of personal LLMs, away from cloud reliance. However, this raise",
    "url": "https://arxiv.org/abs/2408.10746",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Model-based Large Language Model Customization as Service",
    "summary": "arXiv:2410.10481v5 Announce Type: replace-cross Abstract: Prominent Large Language Model (LLM) services from providers like OpenAI and Google excel at general tasks but often underperform on domain-specific applications. Current customization services for these LLMs typically require users to upload data for fine-tuning, posing significant privacy ",
    "url": "https://arxiv.org/abs/2410.10481",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Automated Proof Generation for Rust Code via Self-Evolution",
    "summary": "arXiv:2410.15756v3 Announce Type: replace-cross Abstract: Ensuring correctness is crucial for code generation. Formal verification offers a definitive assurance of correctness, but demands substantial human effort in proof construction and hence raises a pressing need for automation. The primary obstacle lies in the severe lack of data-there is muc",
    "url": "https://arxiv.org/abs/2410.15756",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "VCDF: A Validated Consensus-Driven Framework for Time Series Causal Discovery",
    "summary": "arXiv:2410.19412v2 Announce Type: replace-cross Abstract: Time series causal discovery is essential for understanding dynamic systems, yet many existing methods remain sensitive to noise, non-stationarity, and sampling variability. We propose the Validated Consensus-Driven Framework (VCDF), a simple and method-agnostic layer that improves robustnes",
    "url": "https://arxiv.org/abs/2410.19412",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Cautious Optimizers: Improving Training with One Line of Code",
    "summary": "arXiv:2411.16085v4 Announce Type: replace-cross Abstract: AdamW has been the default optimizer for transformer pretraining. For many years, our community searched for faster and more stable optimizers with only constrained positive outcomes. In this work, we propose a \\textbf{one-line modification in Pytorch} to any momentum-based optimizer, which ",
    "url": "https://arxiv.org/abs/2411.16085",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "LVLM-COUNT: Enhancing the Counting Ability of Large Vision-Language Models",
    "summary": "arXiv:2412.00686v4 Announce Type: replace-cross Abstract: Counting is a fundamental operation for various real-world visual tasks, requiring both object recognition and robust counting capabilities. Despite their advanced visual perception, large vision-language models (LVLMs) are known to struggle with counting tasks. In this work, we evaluate the",
    "url": "https://arxiv.org/abs/2412.00686",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Bayesian Flow Is All You Need to Sample Out-of-Distribution Chemical Spaces",
    "summary": "arXiv:2412.11439v5 Announce Type: replace-cross Abstract: Generating novel molecules with higher properties than the training space, namely the out-of-distribution generation, is important for de novo drug design. However, it is not easy for distribution learning-based models, for example diffusion models, to solve this challenge as these methods a",
    "url": "https://arxiv.org/abs/2412.11439",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Dataset Distillation via Committee Voting",
    "summary": "arXiv:2501.07575v2 Announce Type: replace-cross Abstract: Dataset distillation aims to synthesize a compact yet representative dataset that preserves the essential characteristics of the original data for efficient model training. Existing methods mainly focus on improving data-synthetic alignment or scaling distillation to large datasets. In this ",
    "url": "https://arxiv.org/abs/2501.07575",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Adaptive Width Neural Networks",
    "summary": "arXiv:2501.15889v5 Announce Type: replace-cross Abstract: For almost 70 years, researchers have typically selected the width of neural networks' layers either manually or through automated hyperparameter tuning methods such as grid search and, more recently, neural architecture search. This paper challenges the status quo by introducing an easy-to-",
    "url": "https://arxiv.org/abs/2501.15889",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "The Majority Vote Paradigm Shift: When Popular Meets Optimal",
    "summary": "arXiv:2502.12581v4 Announce Type: replace-cross Abstract: Reliably labelling data typically requires annotations from multiple human workers. However, humans are far from being perfect. Hence, it is a common practice to aggregate labels gathered from multiple annotators to make a more confident estimate of the true label. Among many aggregation met",
    "url": "https://arxiv.org/abs/2502.12581",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Less is More: Improving LLM Alignment via Preference Data Selection",
    "summary": "arXiv:2502.14560v4 Announce Type: replace-cross Abstract: Direct Preference Optimization (DPO) has emerged as a promising approach for aligning large language models with human preferences. While prior work mainly extends DPO from the aspect of the objective function, we instead improve DPO from the largely overlooked but critical aspect of data se",
    "url": "https://arxiv.org/abs/2502.14560",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "RapidPen: Fully Automated IP-to-Shell Penetration Testing with LLM-based Agents",
    "summary": "arXiv:2502.16730v2 Announce Type: replace-cross Abstract: We present RapidPen, a fully automated penetration testing (pentesting) framework that addresses the challenge of achieving an initial foothold (IP-to-Shell) without human intervention. Unlike prior approaches that focus primarily on post-exploitation or require a human-in-the-loop, RapidPen",
    "url": "https://arxiv.org/abs/2502.16730",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Deep Reinforcement Learning based Autonomous Decision-Making for Cooperative UAVs: A Search and Rescue Real World Application",
    "summary": "arXiv:2502.20326v2 Announce Type: replace-cross Abstract: This paper presents the first end-to-end framework that combines guidance, navigation, and centralised task allocation for multiple UAVs performing autonomous search-and-rescue (SAR) in GNSS-denied indoor environments. A Twin Delayed Deep Deterministic Policy Gradient controller is trained w",
    "url": "https://arxiv.org/abs/2502.20326",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Contextual Quantum Neural Networks for Stock Price Prediction",
    "summary": "arXiv:2503.01884v2 Announce Type: replace-cross Abstract: In this paper, we apply quantum machine learning (QML) to predict the stock prices of multiple assets using a contextual quantum neural network. Our approach captures recent trends to predict future stock price distributions, moving beyond traditional models that focus on entire historical d",
    "url": "https://arxiv.org/abs/2503.01884",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Simulating the Real World: A Unified Survey of Multimodal Generative Models",
    "summary": "arXiv:2503.04641v3 Announce Type: replace-cross Abstract: Understanding and replicating the real world is a critical challenge in Artificial General Intelligence (AGI) research. To achieve this, many existing approaches, such as world models, aim to capture the fundamental principles governing the physical world, enabling more accurate simulations ",
    "url": "https://arxiv.org/abs/2503.04641",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Robust Multi-Objective Controlled Decoding of Large Language Models",
    "summary": "arXiv:2503.08796v2 Announce Type: replace-cross Abstract: We introduce Robust Multi-Objective Decoding (RMOD), a novel inference-time algorithm that robustly aligns Large Language Models (LLMs) to multiple human objectives (e.g., instruction-following, helpfulness, safety) by maximizing the worst-case rewards. RMOD formulates the robust decoding pr",
    "url": "https://arxiv.org/abs/2503.08796",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Heuristic Methods are Good Teachers to Distill MLPs for Graph Link Prediction",
    "summary": "arXiv:2504.06193v3 Announce Type: replace-cross Abstract: Link prediction is a crucial graph-learning task with applications including citation prediction and product recommendation. Distilling Graph Neural Networks (GNNs) teachers into Multi-Layer Perceptrons (MLPs) students has emerged as an effective approach to achieve strong performance and re",
    "url": "https://arxiv.org/abs/2504.06193",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Modeling AI-Human Collaboration as a Multi-Agent Adaptation",
    "summary": "arXiv:2504.20903v3 Announce Type: replace-cross Abstract: We formalize AI-human collaboration through an agent-based simulation that distinguishes optimization-based AI search from satisficing-based human adaptation. Using an NK model, we examine how these distinct decision heuristics interact across modular and sequenced task structures. For modul",
    "url": "https://arxiv.org/abs/2504.20903",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "SecRepoBench: Benchmarking Code Agents for Secure Code Completion in Real-World Repositories",
    "summary": "arXiv:2504.21205v3 Announce Type: replace-cross Abstract: This paper introduces SecRepoBench, a benchmark to evaluate code agents on secure code completion in real-world repositories. SecRepoBench has 318 code completion tasks in 27 C/C++ repositories, covering 15 CWEs. We evaluate 29 standalone LLMs and 15 code agents across 3 state-of-the-art age",
    "url": "https://arxiv.org/abs/2504.21205",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Sparse Latent Factor Forecaster (SLFF) with Iterative Inference for Transparent Multi-Horizon Commodity Futures Prediction",
    "summary": "arXiv:2505.06795v5 Announce Type: replace-cross Abstract: Amortized variational inference in latent-variable forecasters creates a deployment gap: the test-time encoder approximates a training-time optimization-refined latent, but without access to future targets. This gap introduces unnecessary forecast error and interpretability challenges. In th",
    "url": "https://arxiv.org/abs/2505.06795",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Benchmarking Retrieval-Augmented Generation for Chemistry",
    "summary": "arXiv:2505.07671v2 Announce Type: replace-cross Abstract: Retrieval-augmented generation (RAG) has emerged as a powerful framework for enhancing large language models (LLMs) with external knowledge, particularly in scientific domains that demand specialized and dynamic information. Despite its promise, the application of RAG in the chemistry domain",
    "url": "https://arxiv.org/abs/2505.07671",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Benchmarking of CPU-intensive Stream Data Processing in The Edge Computing Systems",
    "summary": "arXiv:2505.07755v2 Announce Type: replace-cross Abstract: Edge computing has emerged as a pivotal technology, offering significant advantages such as low latency, enhanced data security, and reduced reliance on centralized cloud infrastructure. These benefits are crucial for applications requiring real-time data processing or strict security measur",
    "url": "https://arxiv.org/abs/2505.07755",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Scalable LLM Reasoning Acceleration with Low-rank Distillation",
    "summary": "arXiv:2505.07861v3 Announce Type: replace-cross Abstract: Due to long generations, large language model (LLM) math reasoning demands significant computational resources and time. While many existing efficient inference methods have been developed with excellent performance preservation on language tasks, they often severely degrade math performance",
    "url": "https://arxiv.org/abs/2505.07861",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Heterogeneity-Aware Client Sampling for Optimal and Efficient Federated Learning",
    "summary": "arXiv:2505.11304v2 Announce Type: replace-cross Abstract: Federated learning (FL) commonly involves clients with diverse communication and computational capabilities. Such heterogeneity can significantly distort the optimization dynamics and lead to objective inconsistency, where the global model converges to an incorrect stationary point potential",
    "url": "https://arxiv.org/abs/2505.11304",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Residual Feature Integration is Sufficient to Prevent Negative Transfer",
    "summary": "arXiv:2505.11771v2 Announce Type: replace-cross Abstract: Transfer learning has become a central paradigm in modern machine learning, yet it suffers from the long-standing problem of negative transfer, where leveraging source representations can harm rather than help performance on the target task. Although empirical remedies have been proposed, th",
    "url": "https://arxiv.org/abs/2505.11771",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Single Image Reflection Separation via Dual Prior Interaction Transformer",
    "summary": "arXiv:2505.12641v3 Announce Type: replace-cross Abstract: Single image reflection separation aims to separate the transmission and reflection layers from a mixed image. Existing methods typically combine general priors from pre-trained models with task-specific priors such as text prompts and reflection detection. However, the transmission prior, a",
    "url": "https://arxiv.org/abs/2505.12641",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Advancing Software Quality: A Standards-Focused Review of LLM-Based Assurance Techniques",
    "summary": "arXiv:2505.13766v3 Announce Type: replace-cross Abstract: Software Quality Assurance (SQA) is critical for delivering reliable, secure, and efficient software products. The Software Quality Assurance Process aims to provide assurance that work products and processes comply with predefined provisions and plans. Recent advancements in Large Language ",
    "url": "https://arxiv.org/abs/2505.13766",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Know When to Abstain: Optimal Selective Classification with Likelihood Ratios",
    "summary": "arXiv:2505.15008v2 Announce Type: replace-cross Abstract: Selective classification enhances the reliability of predictive models by allowing them to abstain from making uncertain predictions. In this work, we revisit the design of optimal selection functions through the lens of the Neyman--Pearson lemma, a classical result in statistics that charac",
    "url": "https://arxiv.org/abs/2505.15008",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "MoESD: Unveil Speculative Decoding's Potential for Accelerating Sparse MoE",
    "summary": "arXiv:2505.19645v4 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have achieved remarkable success across many applications, with Mixture of Experts (MoE) models demonstrating great potential. Compared to traditional dense models, MoEs achieve better performance with less computation. Speculative decoding (SD) is a widely used ",
    "url": "https://arxiv.org/abs/2505.19645",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Multi-Objective Neural Network-Assisted Design Optimization of Soft Fin-Ray Fingers for Enhanced Grasping Performance",
    "summary": "arXiv:2506.00494v2 Announce Type: replace-cross Abstract: The internal structure of the Fin-Ray fingers plays a significant role in their adaptability and grasping performance. However, modeling the grasp force and deformation behavior for design purposes is challenging. When the Fin-Ray finger becomes more rigid and capable of exerting higher forc",
    "url": "https://arxiv.org/abs/2506.00494",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "KVCache Cache in the Wild: Characterizing and Optimizing KVCache Cache at a Large Cloud Provider",
    "summary": "arXiv:2506.02634v5 Announce Type: replace-cross Abstract: Serving large language models (LLMs) is important for cloud providers, and caching intermediate results (KV\\$) after processing each request substantially improves serving throughput and latency. However, there is limited understanding of how LLM serving benefits from KV\\$ caching, where sys",
    "url": "https://arxiv.org/abs/2506.02634",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Multi-Spectral Gaussian Splatting with Neural Color Representation",
    "summary": "arXiv:2506.03407v2 Announce Type: replace-cross Abstract: We present MS-Splatting -- a multi-spectral 3D Gaussian Splatting (3DGS) framework that is able to generate multi-view consistent novel views from images of multiple, independent cameras with different spectral domains. In contrast to previous approaches, our method does not require cross-mo",
    "url": "https://arxiv.org/abs/2506.03407",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "High Accuracy, Less Talk (HALT): Reliable LLMs through Capability-Aligned Finetuning",
    "summary": "arXiv:2506.04051v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) currently respond to every prompt. However, they can produce incorrect answers when they lack knowledge or capability -- a problem known as hallucination. We instead propose post-training an LLM to generate content only when confident in its correctness and to ot",
    "url": "https://arxiv.org/abs/2506.04051",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Improving Data Efficiency for LLM Reinforcement Fine-tuning Through Difficulty-targeted Online Data Selection and Rollout Replay",
    "summary": "arXiv:2506.05316v4 Announce Type: replace-cross Abstract: Reinforcement learning (RL) has become an effective approach for fine-tuning large language models (LLMs), particularly to enhance their reasoning capabilities. However, RL fine-tuning remains highly resource-intensive, and existing work has largely overlooked the problem of data efficiency.",
    "url": "https://arxiv.org/abs/2506.05316",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "RuleReasoner: Reinforced Rule-based Reasoning via Domain-aware Dynamic Sampling",
    "summary": "arXiv:2506.08672v2 Announce Type: replace-cross Abstract: Rule-based reasoning is acknowledged as one of the fundamental problems of reasoning. While recent studies show that large reasoning models (LRMs) have remarkable reasoning capabilities enhanced by reinforcement learning (RL), real applications still face severe challenges due to variations ",
    "url": "https://arxiv.org/abs/2506.08672",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Enhancing Delta Compression in LLMs via SVD-based Quantization Error Minimization",
    "summary": "arXiv:2506.11087v3 Announce Type: replace-cross Abstract: Supervised Fine-Tuning (SFT) empowers Large Language Models (LLMs) with exceptional performance on specialized tasks, but it yields dense, high-dimensional delta parameters that pose severe storage and distribution challenges. Singular Value Decomposition (SVD)-based compression offers a com",
    "url": "https://arxiv.org/abs/2506.11087",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Foundation Models in Autonomous Driving: A Survey on Scenario Generation and Scenario Analysis",
    "summary": "arXiv:2506.11526v4 Announce Type: replace-cross Abstract: For autonomous vehicles, safe navigation in complex environments depends on handling a broad range of diverse and rare driving scenarios. Simulation- and scenario-based testing have emerged as key approaches to development and validation of autonomous driving systems. Traditional scenario ge",
    "url": "https://arxiv.org/abs/2506.11526",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "HYPER: A Foundation Model for Inductive Link Prediction with Knowledge Hypergraphs",
    "summary": "arXiv:2506.12362v2 Announce Type: replace-cross Abstract: Inductive link prediction with knowledge hypergraphs is the task of predicting missing hyperedges involving completely novel entities (i.e., nodes unseen during training). Existing methods for inductive link prediction with knowledge hypergraphs assume a fixed relational vocabulary and, as a",
    "url": "https://arxiv.org/abs/2506.12362",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "NeuronSeek: On Stability and Expressivity of Task-driven Neurons",
    "summary": "arXiv:2506.15715v2 Announce Type: replace-cross Abstract: Drawing inspiration from our human brain that designs different neurons for different tasks, recent advances in deep learning have explored modifying a network's neurons to develop so-called task-driven neurons. Prototyping task-driven neurons (referred to as NeuronSeek) employs symbolic reg",
    "url": "https://arxiv.org/abs/2506.15715",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "An Agentic System for Rare Disease Diagnosis with Traceable Reasoning",
    "summary": "arXiv:2506.20430v3 Announce Type: replace-cross Abstract: Rare diseases affect over 300 million individuals worldwide, yet timely and accurate diagnosis remains an urgent challenge. Patients often endure a prolonged diagnostic odyssey exceeding five years, marked by repeated referrals, misdiagnoses, and unnecessary interventions, leading to delayed",
    "url": "https://arxiv.org/abs/2506.20430",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Vision Transformers for Multi-Variable Climate Downscaling: Emulating Regional Climate Models with a Shared Encoder and Multi-Decoder Architecture",
    "summary": "arXiv:2506.22447v2 Announce Type: replace-cross Abstract: Global Climate Models (GCMs) are critical for simulating large-scale climate dynamics, but their coarse spatial resolution limits their applicability in regional studies. Regional Climate Models (RCMs) address this limitation through dynamical downscaling, albeit at considerable computationa",
    "url": "https://arxiv.org/abs/2506.22447",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Chain of Thought in Order: Discovering Learning-Friendly Orders for Arithmetic",
    "summary": "arXiv:2506.23875v2 Announce Type: replace-cross Abstract: The chain of thought, i.e., step-by-step reasoning, is one of the fundamental mechanisms of Transformers. While the design of intermediate reasoning steps has been extensively studied and shown to critically influence performance on mathematical, multi-step reasoning tasks, the ordering of t",
    "url": "https://arxiv.org/abs/2506.23875",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "SPATIA: Multimodal Generation and Prediction of Spatial Cell Phenotypes",
    "summary": "arXiv:2507.04704v2 Announce Type: replace-cross Abstract: Understanding how cellular morphology, gene expression, and spatial context jointly shape tissue function is a central challenge in biology. Image-based spatial transcriptomics technologies now provide high-resolution measurements of cell images and gene expression profiles, but existing met",
    "url": "https://arxiv.org/abs/2507.04704",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "wd1: Weighted Policy Optimization for Reasoning in Diffusion Language Models",
    "summary": "arXiv:2507.08838v2 Announce Type: replace-cross Abstract: Improving the reasoning capabilities of diffusion-based large language models (dLLMs) through reinforcement learning (RL) remains an open problem. The intractability of dLLMs likelihood function necessitates approximating the current, old, and reference policy likelihoods at each policy opti",
    "url": "https://arxiv.org/abs/2507.08838",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "A Disentangled Representation Learning Framework for Low-altitude Network Coverage Prediction",
    "summary": "arXiv:2507.14186v2 Announce Type: replace-cross Abstract: The expansion of the low-altitude economy has underscored the significance of Low-Altitude Network Coverage (LANC) prediction for designing aerial corridors. While accurate LANC forecasting hinges on the antenna beam patterns of Base Stations (BSs), these patterns are typically proprietary a",
    "url": "https://arxiv.org/abs/2507.14186",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "A Pragmatist Robot: Learning to Plan Tasks by Experiencing the Real World",
    "summary": "arXiv:2507.16713v2 Announce Type: replace-cross Abstract: Large language models (LLMs) have emerged as the dominant paradigm for robotic task planning using natural language instructions. However, trained on general internet data, LLMs are not inherently aligned with the embodiment, skill sets, and limitations of real-world robotic systems. Inspire",
    "url": "https://arxiv.org/abs/2507.16713",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Virne: A Comprehensive Benchmark for RL-based Network Resource Allocation in NFV",
    "summary": "arXiv:2507.19234v2 Announce Type: replace-cross Abstract: Resource allocation (RA) is critical to efficient service deployment in Network Function Virtualization (NFV), a transformative networking paradigm. Recently, deep Reinforcement Learning (RL)-based methods have been showing promising potential to address this complexity. However, the lack of",
    "url": "https://arxiv.org/abs/2507.19234",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning",
    "summary": "arXiv:2507.19457v2 Announce Type: replace-cross Abstract: Large language models (LLMs) are increasingly adapted to downstream tasks via reinforcement learning (RL) methods like Group Relative Policy Optimization (GRPO), which often require thousands of rollouts to learn new tasks. We argue that the interpretable nature of language often provides a ",
    "url": "https://arxiv.org/abs/2507.19457",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "FGBench: A Dataset and Benchmark for Molecular Property Reasoning at Functional Group-Level in Large Language Models",
    "summary": "arXiv:2508.01055v4 Announce Type: replace-cross Abstract: Large language models (LLMs) have gained significant attention in chemistry. However, most existing datasets center on molecular-level property prediction and overlook the role of fine-grained functional group (FG) information. Incorporating FG-level data can provide valuable prior knowledge",
    "url": "https://arxiv.org/abs/2508.01055",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Simulating Cyberattacks through a Breach Attack Simulation (BAS) Platform empowered by Security Chaos Engineering (SCE)",
    "summary": "arXiv:2508.03882v2 Announce Type: replace-cross Abstract: In today digital landscape, organizations face constantly evolving cyber threats, making it essential to discover slippery attack vectors through novel techniques like Security Chaos Engineering (SCE), which allows teams to test defenses and identify vulnerabilities effectively. This paper p",
    "url": "https://arxiv.org/abs/2508.03882",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Beyond Prompt-Induced Lies: Investigating LLM Deception on Benign Prompts",
    "summary": "arXiv:2508.06361v3 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are widely deployed in reasoning, planning, and decision-making tasks, making their trustworthiness critical. A significant and underexplored risk is intentional deception, where an LLM deliberately fabricates or conceals information to serve a hidden objective. ",
    "url": "https://arxiv.org/abs/2508.06361",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Lightning Prediction under Uncertainty: DeepLight with Hazy Loss",
    "summary": "arXiv:2508.07428v2 Announce Type: replace-cross Abstract: Lightning, a common feature of severe meteorological conditions, poses significant risks, from direct human injuries to substantial economic losses. These risks are further exacerbated by climate change. Early and accurate prediction of lightning would enable preventive measures to safeguard",
    "url": "https://arxiv.org/abs/2508.07428",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Robust MultiSpecies Agricultural Segmentation Across Devices, Seasons, and Sensors Using Hierarchical DINOv2 Models",
    "summary": "arXiv:2508.07514v2 Announce Type: replace-cross Abstract: Reliable plant species and damage segmentation for herbicide field research trials requires models that can withstand substantial real-world variation across seasons, geographies, devices, and sensing modalities. Most deep learning approaches trained on controlled datasets fail to generalize",
    "url": "https://arxiv.org/abs/2508.07514",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Zono-Conformal Prediction: Zonotope-Based Uncertainty Quantification for Regression and Classification Tasks",
    "summary": "arXiv:2508.11025v2 Announce Type: replace-cross Abstract: Conformal prediction is a popular uncertainty quantification method that augments a base predictor to return sets of predictions with statistically valid coverage guarantees. However, current methods are often computationally expensive and data-intensive, as they require constructing an unce",
    "url": "https://arxiv.org/abs/2508.11025",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Why Synthetic Isn't Real Yet: A Diagnostic Framework for Contact Center Dialogue Generation",
    "summary": "arXiv:2508.18210v2 Announce Type: replace-cross Abstract: Synthetic data is increasingly critical for contact centers, where privacy constraints and data scarcity limit the availability of real conversations. However, generating synthetic dialogues that are realistic and useful for downstream applications remains challenging. In this work, we bench",
    "url": "https://arxiv.org/abs/2508.18210",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Towards Production-Worthy Simulation for Autonomous Cyber Operations",
    "summary": "arXiv:2508.19278v2 Announce Type: replace-cross Abstract: Simulated environments have proven invaluable in Autonomous Cyber Operations (ACO) where Reinforcement Learning (RL) agents can be trained without the computational overhead of emulation. These environments must accurately represent cybersecurity scenarios while producing the necessary signa",
    "url": "https://arxiv.org/abs/2508.19278",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "CellINR: Implicitly Overcoming Photo-induced Artifacts in 4D Live Fluorescence Microscopy",
    "summary": "arXiv:2508.19300v2 Announce Type: replace-cross Abstract: 4D live fluorescence microscopy is often compromised by prolonged high intensity illumination which induces photobleaching and phototoxic effects that generate photo-induced artifacts and severely impair image continuity and detail recovery. To address this challenge, we propose the CellINR ",
    "url": "https://arxiv.org/abs/2508.19300",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "A Financial Brain Scan of the LLM",
    "summary": "arXiv:2508.21285v2 Announce Type: replace-cross Abstract: Emerging techniques in computer science make it possible to \"brain scan\" large language models (LLMs), identify the plain-English concepts that guide their reasoning, and steer them while holding other factors constant. We show that this approach can map LLM-generated economic forecasts to c",
    "url": "https://arxiv.org/abs/2508.21285",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ART: Adaptive Resampling-based Training for Imbalanced Classification",
    "summary": "arXiv:2509.00955v2 Announce Type: replace-cross Abstract: Traditional resampling methods for handling class imbalance typically uses fixed distributions, undersampling the majority or oversampling the minority. These static strategies ignore changes in class-wise learning difficulty, which can limit the overall performance of the model. This paper ",
    "url": "https://arxiv.org/abs/2509.00955",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Large Language Model Integration with Reinforcement Learning to Augment Decision-Making in Autonomous Cyber Operations",
    "summary": "arXiv:2509.05311v2 Announce Type: replace-cross Abstract: Reinforcement Learning (RL) has shown great potential for autonomous decision-making in the cybersecurity domain, enabling agents to learn through direct environment interaction. However, RL agents in Autonomous Cyber Operations (ACO) typically learn from scratch, requiring them to execute u",
    "url": "https://arxiv.org/abs/2509.05311",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Reinforcement Learning-Based Market Making as a Stochastic Control on Non-Stationary Limit Order Book Dynamics",
    "summary": "arXiv:2509.12456v2 Announce Type: replace-cross Abstract: Reinforcement Learning has emerged as a promising framework for developing adaptive and data-driven strategies, enabling market makers to optimize decision-making policies based on interactions with the limit order book environment. This paper explores the integration of a reinforcement lear",
    "url": "https://arxiv.org/abs/2509.12456",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Curriculum Multi-Task Self-Supervision Improves Lightweight Architectures for Onboard Satellite Hyperspectral Image Segmentation",
    "summary": "arXiv:2509.13229v2 Announce Type: replace-cross Abstract: Hyperspectral imaging (HSI) captures detailed spectral signatures across hundreds of contiguous bands per pixel, being indispensable for remote sensing applications such as land-cover classification, change detection, and environmental monitoring. Due to the high dimensionality of HSI data a",
    "url": "https://arxiv.org/abs/2509.13229",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Complexity Bounds for Smooth Multiobjective Optimization",
    "summary": "arXiv:2509.13550v2 Announce Type: replace-cross Abstract: We study the oracle complexity of finding $\\varepsilon$-Pareto stationary points in smooth multiobjective optimization with $m$ objectives. Progress is measured by the Pareto stationarity gap $\\mathcal{G}(x)$, the norm of the best convex combination of objective gradients. Our analysis relie",
    "url": "https://arxiv.org/abs/2509.13550",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "DiffusionNFT: Online Diffusion Reinforcement with Forward Process",
    "summary": "arXiv:2509.16117v2 Announce Type: replace-cross Abstract: Online reinforcement learning (RL) has been central to post-training language models, but its extension to diffusion models remains challenging due to intractable likelihoods. Recent works discretize the reverse sampling process to enable GRPO-style training, yet they inherit fundamental dra",
    "url": "https://arxiv.org/abs/2509.16117",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Evolution of Concepts in Language Model Pre-Training",
    "summary": "arXiv:2509.17196v2 Announce Type: replace-cross Abstract: Language models obtain extensive capabilities through pre-training. However, the pre-training process remains a black box. In this work, we track linear interpretable feature evolution across pre-training snapshots using a sparse dictionary learning method called crosscoders. We find that mo",
    "url": "https://arxiv.org/abs/2509.17196",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Through the Lens of Human-Human Collaboration: A Configurable Research Platform for Exploring Human-Agent Collaboration",
    "summary": "arXiv:2509.18008v2 Announce Type: replace-cross Abstract: Intelligent systems have traditionally been designed as tools rather than collaborators, often lacking critical characteristics that collaboration partnerships require. Recent advances in large language model (LLM) agents open new opportunities for human-LLM-agent collaboration by enabling n",
    "url": "https://arxiv.org/abs/2509.18008",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "AECBench: A Hierarchical Benchmark for Knowledge Evaluation of Large Language Models in the AEC Field",
    "summary": "arXiv:2509.18776v3 Announce Type: replace-cross Abstract: Large language models (LLMs), as a novel information technology, are seeing increasing adoption in the Architecture, Engineering, and Construction (AEC) field. They have shown their potential to streamline processes throughout the building lifecycle. However, the robustness and reliability o",
    "url": "https://arxiv.org/abs/2509.18776",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "The Rogue Scalpel: Activation Steering Compromises LLM Safety",
    "summary": "arXiv:2509.22067v2 Announce Type: replace-cross Abstract: Activation steering is a promising technique for controlling LLM behavior by adding semantically meaningful vectors directly into a model's hidden states during inference. It is often framed as a precise, interpretable, and potentially safer alternative to fine-tuning. We demonstrate the opp",
    "url": "https://arxiv.org/abs/2509.22067",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Differentially Private Two-Stage Gradient Descent for Instrumental Variable Regression",
    "summary": "arXiv:2509.22794v3 Announce Type: replace-cross Abstract: We study instrumental variable regression (IVaR) under differential privacy constraints. Classical IVaR methods (like two-stage least squares regression) rely on solving moment equations that directly use sensitive covariates and instruments, creating significant risks of privacy leakage and",
    "url": "https://arxiv.org/abs/2509.22794",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ReliabilityRAG: Effective and Provably Robust Defense for RAG-based Web-Search",
    "summary": "arXiv:2509.23519v2 Announce Type: replace-cross Abstract: Retrieval-Augmented Generation (RAG) enhances Large Language Models by grounding their outputs in external documents. These systems, however, remain vulnerable to attacks on the retrieval corpus, such as prompt injection. RAG-based search systems (e.g., Google's Search AI Overview) present a",
    "url": "https://arxiv.org/abs/2509.23519",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "LLM DNA: Tracing Model Evolution via Functional Representations",
    "summary": "arXiv:2509.24496v2 Announce Type: replace-cross Abstract: The explosive growth of large language models (LLMs) has created a vast but opaque landscape: millions of models exist, yet their evolutionary relationships through fine-tuning, distillation, or adaptation are often undocumented or unclear, complicating LLM management. Existing methods are l",
    "url": "https://arxiv.org/abs/2509.24496",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "VoiceBridge: General Speech Restoration with One-step Latent Bridge Models",
    "summary": "arXiv:2509.25275v3 Announce Type: replace-cross Abstract: Bridge models have been investigated in speech enhancement but are mostly single-task, with constrained general speech restoration (GSR) capability. In this work, we propose VoiceBridge, a one-step latent bridge model (LBM) for GSR, capable of efficiently reconstructing 48 kHz fullband speec",
    "url": "https://arxiv.org/abs/2509.25275",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "BiasFreeBench: a Benchmark for Mitigating Bias in Large Language Model Responses",
    "summary": "arXiv:2510.00232v2 Announce Type: replace-cross Abstract: Existing studies on bias mitigation methods for large language models (LLMs) use diverse baselines and metrics to evaluate debiasing performance, leading to inconsistent comparisons among them. Moreover, their evaluations are mostly based on the comparison between LLMs' probabilities of bias",
    "url": "https://arxiv.org/abs/2510.00232",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Measuring Physical-World Privacy Awareness of Large Language Models: An Evaluation Benchmark",
    "summary": "arXiv:2510.02356v3 Announce Type: replace-cross Abstract: The deployment of Large Language Models (LLMs) in embodied agents creates an urgent need to measure their privacy awareness in the physical world. Existing evaluation methods, however, are confined to natural language based scenarios. To bridge this gap, we introduce EAPrivacy, a comprehensi",
    "url": "https://arxiv.org/abs/2510.02356",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Where to Add PDE Diffusion in Transformers",
    "summary": "arXiv:2510.03272v3 Announce Type: replace-cross Abstract: Transformers enable powerful content-based global routing via self-attention, but they lack an explicit local geometric prior along the sequence axis. As a result, the placement of locality-inducing modules in hybrid architectures has largely been empirical. We study a simple deterministic P",
    "url": "https://arxiv.org/abs/2510.03272",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "RACE Attention: A Strictly Linear-Time Attention for Long-Sequence Training",
    "summary": "arXiv:2510.04008v3 Announce Type: replace-cross Abstract: Softmax Attention has a quadratic time complexity in sequence length, which becomes prohibitive to run at long contexts, even with highly optimized GPU kernels. For example, FlashAttention-2/3 (exact, GPU-optimized implementations of Softmax Attention) cannot complete a single forward-backwa",
    "url": "https://arxiv.org/abs/2510.04008",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "SECA: Semantically Equivalent and Coherent Attacks for Eliciting LLM Hallucinations",
    "summary": "arXiv:2510.04398v3 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are increasingly deployed in high-risk domains. However, state-of-the-art LLMs often exhibit hallucinations, raising serious concerns about their reliability. Prior work has explored adversarial attacks to elicit hallucinations in LLMs, but these methods often re",
    "url": "https://arxiv.org/abs/2510.04398",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Inverse Mixed-Integer Programming: Learning Constraints then Objective Functions",
    "summary": "arXiv:2510.04455v2 Announce Type: replace-cross Abstract: Data-driven inverse optimization for mixed-integer linear programs (MILPs), which seeks to learn an objective function and constraints consistent with observed decisions, is important for building accurate mathematical models in a variety of domains, including power systems and scheduling. H",
    "url": "https://arxiv.org/abs/2510.04455",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Dual Goal Representations",
    "summary": "arXiv:2510.06714v2 Announce Type: replace-cross Abstract: In this work, we introduce dual goal representations for goal-conditioned reinforcement learning (GCRL). A dual goal representation characterizes a state by \"the set of temporal distances from all other states\"; in other words, it encodes a state through its relations to every other state, m",
    "url": "https://arxiv.org/abs/2510.06714",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "The Speech-LLM Takes It All: A Truly Fully End-to-End Spoken Dialogue State Tracking Approach",
    "summary": "arXiv:2510.09424v2 Announce Type: replace-cross Abstract: This paper presents a comparative study of context management strategies for end-to-end Spoken Dialog State Tracking using Speech-LLMs. We systematically evaluate traditional multimodal context (combining text history and spoken current turn), full spoken history, and compressed spoken histo",
    "url": "https://arxiv.org/abs/2510.09424",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Discrete State Diffusion Models: A Sample Complexity Perspective",
    "summary": "arXiv:2510.10854v2 Announce Type: replace-cross Abstract: Diffusion models have demonstrated remarkable performance in generating high-dimensional samples across domains such as vision, language, and the sciences. Although continuous-state diffusion models have been extensively studied both empirically and theoretically, discrete-state diffusion mo",
    "url": "https://arxiv.org/abs/2510.10854",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Challenges and Requirements for Benchmarking Time Series Foundation Models",
    "summary": "arXiv:2510.13654v2 Announce Type: replace-cross Abstract: Time Series Foundation Models (TSFMs) represent a new paradigm for time-series forecasting, promising zero-shot predictions without the need for task-specific training or fine-tuning. However, similar to Large Language Models (LLMs), the evaluation of TSFMs is challenging: as training corpor",
    "url": "https://arxiv.org/abs/2510.13654",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Model-agnostic Selective Labeling with Provable Statistical Guarantees",
    "summary": "arXiv:2510.14581v3 Announce Type: replace-cross Abstract: Obtaining high-quality labels for large datasets is expensive, requiring massive annotations from human experts. While AI models offer a cost-effective alternative by predicting labels, their label quality is compromised by the unavoidable labeling errors. Existing methods mitigate this issu",
    "url": "https://arxiv.org/abs/2510.14581",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Algorithmic Primitives and Compositional Geometry of Reasoning in Language Models",
    "summary": "arXiv:2510.15987v2 Announce Type: replace-cross Abstract: How do latent and inference time computations enable large language models (LLMs) to solve multi-step reasoning? We introduce a framework for tracing and steering algorithmic primitives that underlie model reasoning. Our approach links reasoning traces to internal activations and evaluates a",
    "url": "https://arxiv.org/abs/2510.15987",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Learning under Quantization for High-Dimensional Linear Regression",
    "summary": "arXiv:2510.18259v3 Announce Type: replace-cross Abstract: The use of low-bit quantization has emerged as an indispensable technique for enabling the efficient training of large-scale models. Despite its widespread empirical success, a rigorous theoretical understanding of its impact on learning performance remains notably absent, even in the simple",
    "url": "https://arxiv.org/abs/2510.18259",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Top-Down Semantic Refinement for Image Captioning",
    "summary": "arXiv:2510.22391v2 Announce Type: replace-cross Abstract: Large Vision-Language Models (VLMs) face an inherent contradiction in image captioning: their powerful single-step generation capabilities often lead to a myopic decision-making process. This makes it difficult to maintain global narrative coherence while capturing rich details, a limitation",
    "url": "https://arxiv.org/abs/2510.22391",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Batch Speculative Decoding Done Right",
    "summary": "arXiv:2510.22876v3 Announce Type: replace-cross Abstract: Speculative decoding must produce outputs distribution identical to standard autoregressive generation-this output equivalence is not an optimization target but the defining criterion of valid speculative decoding. We demonstrate that all existing batch speculative decoding implementations v",
    "url": "https://arxiv.org/abs/2510.22876",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "AthenaBench: A Dynamic Benchmark for Evaluating LLMs in Cyber Threat Intelligence",
    "summary": "arXiv:2511.01144v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have demonstrated strong capabilities in natural language reasoning, yet their application to Cyber Threat Intelligence (CTI) remains limited. CTI analysis involves distilling large volumes of unstructured reports into actionable knowledge, a process where LLMs c",
    "url": "https://arxiv.org/abs/2511.01144",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Importance Ranking in Complex Networks via Influence-aware Causal Node Embedding",
    "summary": "arXiv:2511.01228v3 Announce Type: replace-cross Abstract: Understanding and quantifying node importance is a fundamental problem in network science and engineering, underpinning a wide range of applications such as influence maximization, social recommendation, and network dismantling. Prior research often relies on centrality measures or advanced ",
    "url": "https://arxiv.org/abs/2511.01228",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "On the Mechanisms of Collaborative Learning in VAE Recommenders",
    "summary": "arXiv:2511.06781v2 Announce Type: replace-cross Abstract: Variational Autoencoders (VAEs) are a powerful alternative to matrix factorization for recommendation. A common technique in VAE-based collaborative filtering (CF) consists in applying binary input masking to user interaction vectors, which improves performance but remains underexplored theo",
    "url": "https://arxiv.org/abs/2511.06781",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Formal Reasoning About Confidence and Automated Verification of Neural Networks",
    "summary": "arXiv:2511.07293v2 Announce Type: replace-cross Abstract: In the last decade, a large body of work has emerged on robustness of neural networks, i.e., checking if the decision remains unchanged when the input is slightly perturbed. However, most of these approaches ignore the confidence of a neural network on its output. In this work, we aim to dev",
    "url": "https://arxiv.org/abs/2511.07293",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "MURPHY: Multi-Turn GRPO for Self Correcting Code Generation",
    "summary": "arXiv:2511.07833v2 Announce Type: replace-cross Abstract: Reinforcement Learning with Verifiable Rewards(RLVR) has emerged as a powerful framework for enhancing the reasoning capabilities of large language models (LLMs). However, existing approaches such as Group Relative Policy Optimization (GRPO) and its variants, while effective on reasoning ben",
    "url": "https://arxiv.org/abs/2511.07833",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Algorithms Trained on Normal Chest X-rays Can Predict Health Insurance Types",
    "summary": "arXiv:2511.11030v5 Announce Type: replace-cross Abstract: Artificial intelligence is revealing what medicine never intended to encode. Deep vision models, trained on chest X-rays, can now detect not only disease but also invisible traces of social inequality. In this study, we show that state-of-the-art architectures (DenseNet121, SwinV2-B, MedMamb",
    "url": "https://arxiv.org/abs/2511.11030",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Evolution Strategies at the Hyperscale",
    "summary": "arXiv:2511.16652v2 Announce Type: replace-cross Abstract: Evolution Strategies (ES) is a class of powerful black-box optimisation methods that are highly parallelisable and can handle non-differentiable and noisy objectives. However, na\\\"ive ES becomes prohibitively expensive at scale on GPUs due to the low arithmetic intensity of batched matrix mu",
    "url": "https://arxiv.org/abs/2511.16652",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ESPO: Entropy Importance Sampling Policy Optimization",
    "summary": "arXiv:2512.00499v2 Announce Type: replace-cross Abstract: Reinforcement learning (RL) has become a central component of post-training for large language models (LLMs), particularly for complex reasoning tasks that require stable optimization over long generation horizons. However, achieving performance at scale often introduces a fundamental trade-",
    "url": "https://arxiv.org/abs/2512.00499",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "RRPO: Robust Reward Policy Optimization for LLM-based Emotional TTS",
    "summary": "arXiv:2512.04552v3 Announce Type: replace-cross Abstract: Differentiable reinforcement learning (RL) frameworks like DiffRO offer a powerful approach for controllable text-to-speech (TTS), but are vulnerable to reward hacking, particularly for nuanced tasks like emotion control. The policy model can exploit a vanilla Reward Model (RM) by generating",
    "url": "https://arxiv.org/abs/2512.04552",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ArtistMus: A Globally Diverse, Artist-Centric Benchmark for Retrieval-Augmented Music Question Answering",
    "summary": "arXiv:2512.05430v2 Announce Type: replace-cross Abstract: Recent advances in large language models (LLMs) have transformed open-domain question answering, yet their effectiveness in music-related reasoning remains limited due to sparse music knowledge in pretraining data. While music information retrieval and computational musicology have explored ",
    "url": "https://arxiv.org/abs/2512.05430",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Learning Patient-Specific Disease Dynamics with Latent Flow Matching for Longitudinal Imaging Generation",
    "summary": "arXiv:2512.09185v3 Announce Type: replace-cross Abstract: Understanding disease progression is a central clinical challenge with direct implications for early diagnosis and personalized treatment. While recent generative approaches have attempted to model progression, key mismatches remain: disease dynamics are inherently continuous and monotonic, ",
    "url": "https://arxiv.org/abs/2512.09185",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ALERT Open Dataset and Input-Size-Agnostic Vision Transformer for Driver Activity Recognition using IR-UWB",
    "summary": "arXiv:2512.12206v2 Announce Type: replace-cross Abstract: Distracted driving contributes to fatal crashes worldwide. To address this, researchers are using driver activity recognition (DAR) with impulse radio ultra-wideband (IR-UWB) radar, which offers advantages such as interference resistance, low power consumption, and privacy preservation. Howe",
    "url": "https://arxiv.org/abs/2512.12206",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Network Level Evaluation of Hangup Susceptibility of HRGCs using Deep Learning and Sensing Techniques: A Goal Towards Safer Future",
    "summary": "arXiv:2512.12832v2 Announce Type: replace-cross Abstract: Steep-profiled Highway Railway Grade Crossings (HRGCs) pose safety hazards to vehicles with low ground clearance, which may become stranded on the tracks, creating risks of train vehicle collisions. This research develops a framework for network level evaluation of hang-up susceptibility of ",
    "url": "https://arxiv.org/abs/2512.12832",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Writing in Symbiosis: Mapping Human Creative Agency in the AI Era",
    "summary": "arXiv:2512.13697v2 Announce Type: replace-cross Abstract: The proliferation of Large Language Models (LLMs) raises a critical question about what it means to be human when we share an increasingly symbiotic relationship with persuasive and creative machines. This paper examines patterns of human-AI coevolution in creative writing, investigating how",
    "url": "https://arxiv.org/abs/2512.13697",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "IntentMiner: Intent Inversion Attack via Tool Call Analysis in the Model Context Protocol",
    "summary": "arXiv:2512.14166v2 Announce Type: replace-cross Abstract: The evolution of Large Language Models (LLMs) into Agentic AI has established the Model Context Protocol (MCP) as the standard for connecting reasoning engines with external tools. Although this decoupled architecture fosters modularity, it simultaneously shatters the traditional trust bound",
    "url": "https://arxiv.org/abs/2512.14166",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Emergent human-like working memory from artificial neurons with intrinsic plasticity",
    "summary": "arXiv:2512.15829v2 Announce Type: replace-cross Abstract: Working memory enables the brain to integrate transient information for rapid decision-making. Artificial networks typically replicate this via recurrent or parallel architectures, yet incur high energy costs and noise sensitivity. Here we report IPNet, a hardware-software co-designed neurom",
    "url": "https://arxiv.org/abs/2512.15829",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Adaptive Agents in Spatial Double-Auction Markets: Modeling the Emergence of Industrial Symbiosis",
    "summary": "arXiv:2512.17979v2 Announce Type: replace-cross Abstract: Industrial symbiosis fosters circularity by enabling firms to repurpose residual resources, yet its emergence is constrained by socio-spatial frictions that shape costs, matching opportunities, and market efficiency. Existing models often overlook the interaction between spatial structure, m",
    "url": "https://arxiv.org/abs/2512.17979",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Multi-LLM Thematic Analysis with Dual Reliability Metrics: Combining Cohen's Kappa and Semantic Similarity for Qualitative Research Validation",
    "summary": "arXiv:2512.20352v2 Announce Type: replace-cross Abstract: Qualitative research faces a critical reliability challenge: traditional inter-rater agreement methods require multiple human coders, are time-intensive, and often yield moderate consistency. We present a multi-perspective validation framework for LLM-based thematic analysis that combines en",
    "url": "https://arxiv.org/abs/2512.20352",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Nightjar: Dynamic Adaptive Speculative Decoding for Large Language Models Serving",
    "summary": "arXiv:2512.22420v2 Announce Type: replace-cross Abstract: Speculative decoding (SD) accelerates LLM inference by verifying draft tokens in parallel. However, this method presents a critical trade-off: it improves throughput in low-load, memory-bound systems but degrades performance in high-load, compute-bound environments due to verification overhe",
    "url": "https://arxiv.org/abs/2512.22420",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Vision-Based Early Fault Diagnosis and Self-Recovery for Strawberry Harvesting Robots",
    "summary": "arXiv:2601.02085v2 Announce Type: replace-cross Abstract: Strawberry harvesting robots faced persistent challenges such as low integration of visual perception, fruit-gripper misalignment, empty grasping/misgrasp, and strawberry slippage from the gripper due to insufficient gripping force, all of which compromised harvesting stability and efficienc",
    "url": "https://arxiv.org/abs/2601.02085",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "FormationEval, an open multiple-choice benchmark for petroleum geoscience",
    "summary": "arXiv:2601.02158v2 Announce Type: replace-cross Abstract: This paper presents FormationEval, an open multiple-choice question benchmark for evaluating language models on petroleum geoscience and subsurface disciplines. The dataset contains 505 questions across seven domains including petrophysics, petroleum geology and reservoir engineering, derive",
    "url": "https://arxiv.org/abs/2601.02158",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Context Volume Drives Performance: Tackling Domain Shift in Extremely Low-Resource Translation via RAG",
    "summary": "arXiv:2601.09982v2 Announce Type: replace-cross Abstract: Neural Machine Translation (NMT) models for low-resource languages suffer significant performance degradation under domain shift. We quantify this challenge using Dhao, an indigenous language of Eastern Indonesia with no digital footprint beyond the New Testament (NT). When applied to the un",
    "url": "https://arxiv.org/abs/2601.09982",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Orthogonalized Policy Optimization:Decoupling Sampling Geometry from Optimization Geometry in RLHF",
    "summary": "arXiv:2601.12415v3 Announce Type: replace-cross Abstract: Large language model alignment objectives are often presented as a collection of distinct algorithms, such as PPO, DPO, IPO, and their variants, each motivated by different derivations. In this work, we argue that this diversity obscures a simpler underlying structure. At a fundamental level",
    "url": "https://arxiv.org/abs/2601.12415",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Improved Bug Localization with AI Agents Leveraging Hypothesis and Dynamic Cognition",
    "summary": "arXiv:2601.12522v2 Announce Type: replace-cross Abstract: Software bugs cost technology providers (e.g., AT&amp;T) billions annually and cause developers to spend roughly 50% of their time on bug resolution. Traditional methods for bug localization often analyze the suspiciousness of code components (e.g., methods, documents) in isolation, overlook",
    "url": "https://arxiv.org/abs/2601.12522",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum",
    "summary": "arXiv:2601.14172v3 Announce Type: replace-cross Abstract: We study sentence-level detection of the 19 human values in the refined Schwartz continuum in about 74k English sentences from news and political manifestos (ValueEval'24 corpus). Each sentence is annotated with value presence, yielding a binary moral-presence label and a 19-way multi-label ",
    "url": "https://arxiv.org/abs/2601.14172",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "An Agentic Operationalization of DISARM for FIMI Investigation on Social Media",
    "summary": "arXiv:2601.15109v2 Announce Type: replace-cross Abstract: The interoperability of data and intelligence across allied partners and their respective end-user groups is considered a foundational enabler of the collective defense capability -- both conventional and hybrid -- of NATO countries. Foreign Information Manipulation and Interference (FIMI) a",
    "url": "https://arxiv.org/abs/2601.15109",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Tracing 3D Anatomy in 2D Strokes: A Multi-Stage Projection Driven Approach to Cervical Spine Fracture Identification",
    "summary": "arXiv:2601.15235v2 Announce Type: replace-cross Abstract: Cervical spine fractures are critical medical conditions requiring precise and efficient detection for effective clinical management. This study explores the viability of 2D projection-based vertebra segmentation for vertebra-level fracture detection in 3D CT volumes, presenting an end-to-en",
    "url": "https://arxiv.org/abs/2601.15235",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "GRIP: Algorithm-Agnostic Machine Unlearning for Mixture-of-Experts via Geometric Router Constraints",
    "summary": "arXiv:2601.16905v2 Announce Type: replace-cross Abstract: Machine unlearning (MU) for large language models has become critical for AI safety, yet existing methods fail to generalize to Mixture-of-Experts (MoE) architectures. We identify that traditional unlearning methods exploit MoE's architectural vulnerability: they manipulate routers to redire",
    "url": "https://arxiv.org/abs/2601.16905",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "From Fuzzy to Exact: The Halo Architecture for Infinite-Depth Reasoning via Rational Arithmetic",
    "summary": "arXiv:2601.18702v4 Announce Type: replace-cross Abstract: The prevailing scaling paradigm of Large Language Models (LLMs) rests on a substrate of \"Fuzzy\" floating-point arithmetic. To mitigate the inherent instability of this approximate foundation, modern architectures have erected a complex scaffolding of structural and numerical heuristics--Comp",
    "url": "https://arxiv.org/abs/2601.18702",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Interpreting Emergent Extreme Events in Multi-Agent Systems",
    "summary": "arXiv:2601.20538v2 Announce Type: replace-cross Abstract: Large language model-powered multi-agent systems have emerged as powerful tools for simulating complex human-like systems. The interactions within these systems often lead to extreme events whose origins remain obscured by the black box of emergence. Interpreting these events is critical for",
    "url": "https://arxiv.org/abs/2601.20538",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Reinforcement Learning via Self-Distillation",
    "summary": "arXiv:2601.20802v2 Announce Type: replace-cross Abstract: Large language models are increasingly post-trained with reinforcement learning in verifiable domains such as code and math. Yet, current methods for reinforcement learning with verifiable rewards (RLVR) learn only from a scalar outcome reward per attempt, creating a severe credit-assignment",
    "url": "https://arxiv.org/abs/2601.20802",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "A Decomposable Forward Process in Diffusion Models for Time-Series Forecasting",
    "summary": "arXiv:2601.21812v2 Announce Type: replace-cross Abstract: We introduce a model-agnostic forward diffusion process for time-series forecasting that decomposes signals into spectral components, preserving structured temporal patterns such as seasonality more effectively than standard diffusion. Unlike prior work that modifies the network architecture",
    "url": "https://arxiv.org/abs/2601.21812",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ShotFinder: Imagination-Driven Open-Domain Video Shot Retrieval via Web Search",
    "summary": "arXiv:2601.23232v3 Announce Type: replace-cross Abstract: In recent years, large language models (LLMs) have made rapid progress in information retrieval, yet existing research has mainly focused on text or static multimodal settings. Open-domain video shot retrieval, which involves richer temporal structure and more complex semantics, still lacks ",
    "url": "https://arxiv.org/abs/2601.23232",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "From Associations to Activations: Comparing Behavioral and Hidden-State Semantic Geometry in LLMs",
    "summary": "arXiv:2602.00628v2 Announce Type: replace-cross Abstract: We investigate the extent to which an LLM's hidden-state geometry can be recovered from its behavior in psycholinguistic experiments. Across eight instruction-tuned transformer models, we run two experimental paradigms -- similarity-based forced choice and free association -- over a shared 5",
    "url": "https://arxiv.org/abs/2602.00628",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Unifying Ranking and Generation in Query Auto-Completion via Retrieval-Augmented Generation and Multi-Objective Alignment",
    "summary": "arXiv:2602.01023v4 Announce Type: replace-cross Abstract: Query Auto-Completion (QAC) suggests query completions as users type, helping them articulate intent and reach results more efficiently. Existing approaches face fundamental challenges: traditional retrieve-and-rank pipelines have limited long-tail coverage and require extensive feature engi",
    "url": "https://arxiv.org/abs/2602.01023",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Cross-Modal Purification and Fusion for Small-Object RGB-D Transmission-Line Defect Detection",
    "summary": "arXiv:2602.01696v3 Announce Type: replace-cross Abstract: Transmission line defect detection remains challenging for automated UAV inspection due to the dominance of small-scale defects, complex backgrounds, and illumination variations. Existing RGB-based detectors, despite recent progress, struggle to distinguish geometrically subtle defects from ",
    "url": "https://arxiv.org/abs/2602.01696",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Cardinality-Preserving Attention Channels for Graph Transformers in Molecular Property Prediction",
    "summary": "arXiv:2602.02201v4 Announce Type: replace-cross Abstract: Molecular property prediction is crucial for drug discovery when labeled data are scarce. This work presents \\modelname, a graph transformer augmented with a query-conditioned cardinality-preserving attention (CPA) channel that retains dynamic support-size signals complementary to static cen",
    "url": "https://arxiv.org/abs/2602.02201",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "RPG-AE: Neuro-Symbolic Graph Autoencoders with Rare Pattern Mining for Provenance-Based Anomaly Detection",
    "summary": "arXiv:2602.02929v2 Announce Type: replace-cross Abstract: Advanced Persistent Threats (APTs) are sophisticated, long-term cyberattacks that are difficult to detect because they operate stealthily and often blend into normal system behavior. This paper presents a neuro-symbolic anomaly detection framework that combines a Graph Autoencoder (GAE) with",
    "url": "https://arxiv.org/abs/2602.02929",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Reinforcement Learning with Promising Tokens for Large Language Models",
    "summary": "arXiv:2602.03195v2 Announce Type: replace-cross Abstract: Reinforcement learning (RL) has emerged as a key paradigm for aligning and optimizing large language models (LLMs). Standard approaches treat the LLM as the policy and apply RL directly over the full vocabulary space. However, this formulation includes the massive tail of contextually irrele",
    "url": "https://arxiv.org/abs/2602.03195",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Accelerating Scientific Research with Gemini: Case Studies and Common Techniques",
    "summary": "arXiv:2602.03837v2 Announce Type: replace-cross Abstract: Recent advances in large language models (LLMs) have opened new avenues for accelerating scientific research. While models are increasingly capable of assisting with routine tasks, their ability to contribute to novel, expert-level mathematical discovery is less understood. We present a coll",
    "url": "https://arxiv.org/abs/2602.03837",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Privileged Information Distillation for Language Models",
    "summary": "arXiv:2602.04942v3 Announce Type: replace-cross Abstract: Training-time privileged information (PI) can enable language models to succeed on tasks they would otherwise fail, making it a powerful tool for reinforcement learning in hard, long-horizon settings. However, transferring capabilities learned with PI to policies that must act without it at ",
    "url": "https://arxiv.org/abs/2602.04942",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Metric Hedonic Games on the Line",
    "summary": "arXiv:2602.05888v2 Announce Type: replace-cross Abstract: Hedonic games are fundamental models for investigating the formation of coalitions among a set of strategic agents, where every agent has a certain utility for every possible coalition of agents it can be part of. To avoid the intractability of defining exponentially many utilities for all p",
    "url": "https://arxiv.org/abs/2602.05888",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Self-Improving World Modelling with Latent Actions",
    "summary": "arXiv:2602.06130v2 Announce Type: replace-cross Abstract: Internal modelling of the world -- predicting transitions between previous states $X$ and next states $Y$ under actions $Z$ -- is essential to reasoning and planning for LLMs and VLMs. Learning such models typically requires costly action-labelled trajectories. We propose SWIRL, a self-impro",
    "url": "https://arxiv.org/abs/2602.06130",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "On the Non-Identifiability of Steering Vectors in Large Language Models",
    "summary": "arXiv:2602.06801v2 Announce Type: replace-cross Abstract: Activation steering methods are widely used to control large language model (LLM) behavior and are often interpreted as revealing meaningful internal representations. This interpretation assumes steering directions are identifiable and uniquely recoverable from input-output behavior. We show",
    "url": "https://arxiv.org/abs/2602.06801",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ShallowJail: Steering Jailbreaks against Large Language Models",
    "summary": "arXiv:2602.07107v2 Announce Type: replace-cross Abstract: Large Language Models(LLMs) have been successful in numerous fields. Alignment has usually been applied to prevent them from harmful purposes. However, aligned LLMs remain vulnerable to jailbreak attacks that deliberately mislead them into producing harmful outputs. Existing jailbreaks are e",
    "url": "https://arxiv.org/abs/2602.07107",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Fin-RATE: A Real-world Financial Analytics and Tracking Evaluation Benchmark for LLMs on SEC Filings",
    "summary": "arXiv:2602.07294v3 Announce Type: replace-cross Abstract: With the increasing deployment of Large Language Models (LLMs) in the finance domain, LLMs are increasingly expected to parse complex regulatory disclosures. However, existing benchmarks often focus on isolated details, failing to reflect the complexity of professional analysis that requires",
    "url": "https://arxiv.org/abs/2602.07294",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "VividFace: Real-Time and Realistic Facial Expression Shadowing for Humanoid Robots",
    "summary": "arXiv:2602.07506v2 Announce Type: replace-cross Abstract: Humanoid facial expression shadowing enables robots to realistically imitate human facial expressions in real time, which is critical for lifelike, facially expressive humanoid robots and affective human-robot interaction. Existing progress in humanoid facial expression imitation remains lim",
    "url": "https://arxiv.org/abs/2602.07506",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Debugging code world models",
    "summary": "arXiv:2602.07672v2 Announce Type: replace-cross Abstract: Code World Models (CWMs) are language models trained to simulate program execution by predicting explicit runtime state after every executed command. This execution-based world modeling enables internal verification within the model, offering an alternative to natural language chain-of-thoug",
    "url": "https://arxiv.org/abs/2602.07672",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Language Modeling and Understanding Through Paraphrase Generation and Detection",
    "summary": "arXiv:2602.08274v2 Announce Type: replace-cross Abstract: Language enables humans to share knowledge, reason about the world, and pass on strategies for survival and innovation across generations. At the heart of this process is not just the ability to communicate but also the remarkable flexibility in how we can express ourselves. We can express t",
    "url": "https://arxiv.org/abs/2602.08274",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Predictive Query Language: A Domain-Specific Language for Predictive Modeling on Relational Databases",
    "summary": "arXiv:2602.09572v2 Announce Type: replace-cross Abstract: The purpose of predictive modeling on relational data is to predict future or missing values in a relational database, for example, future purchases of a user, risk of readmission of the patient, or the likelihood that a financial transaction is fraudulent. Typically powered by machine learn",
    "url": "https://arxiv.org/abs/2602.09572",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Kunlun: Establishing Scaling Laws for Massive-Scale Recommendation Systems through Unified Architecture Design",
    "summary": "arXiv:2602.10016v2 Announce Type: replace-cross Abstract: Deriving predictable scaling laws that govern the relationship between model performance and computational investment is crucial for designing and allocating resources in massive-scale recommendation systems. While such laws are established for large language models, they remain challenging ",
    "url": "https://arxiv.org/abs/2602.10016",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Anonymization-Enhanced Privacy Protection for Mobile GUI Agents: Available but Invisible",
    "summary": "arXiv:2602.10139v2 Announce Type: replace-cross Abstract: Mobile Graphical User Interface (GUI) agents have demonstrated strong capabilities in automating complex smartphone tasks by leveraging multimodal large language models (MLLMs) and system-level control interfaces. However, this paradigm introduces significant privacy risks, as agents typical",
    "url": "https://arxiv.org/abs/2602.10139",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "C^2ROPE: Causal Continuous Rotary Positional Encoding for 3D Large Multimodal-Models Reasoning",
    "summary": "arXiv:2602.10551v2 Announce Type: replace-cross Abstract: Recent advances in 3D Large Multimodal Models (LMMs) built on Large Language Models (LLMs) have established the alignment of 3D visual features with LLM representations as the dominant paradigm. However, the inherited Rotary Position Embedding (RoPE) introduces limitations for multimodal pro",
    "url": "https://arxiv.org/abs/2602.10551",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "LAP: Language-Action Pre-Training Enables Zero-shot Cross-Embodiment Transfer",
    "summary": "arXiv:2602.10556v2 Announce Type: replace-cross Abstract: A long-standing goal in robotics is a generalist policy that can be deployed zero-shot on new robot embodiments without per-embodiment adaptation. Despite large-scale multi-embodiment pre-training, existing Vision-Language-Action models (VLAs) remain tightly coupled to their training embodim",
    "url": "https://arxiv.org/abs/2602.10556",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "In-the-Wild Model Organisms: Mitigating Undesirable Emergent Behaviors in Production LLM Post-Training via Data Attribution",
    "summary": "arXiv:2602.11079v2 Announce Type: replace-cross Abstract: We propose activation-based data attribution, a method that traces behavioral changes in post-trained language models to responsible training datapoints. By computing activation-difference vectors for both test prompts and preference pairs and ranking by cosine similarity, we identify datapo",
    "url": "https://arxiv.org/abs/2602.11079",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "The Manifold of the Absolute: Religious Perennialism as Generative Inference",
    "summary": "arXiv:2602.11368v2 Announce Type: replace-cross Abstract: This paper formalizes religious epistemology through the mathematics of Variational Autoencoders. We model religious traditions as distinct generative mappings from a shared, low-dimensional latent space to the high-dimensional space of observable cultural forms, and define three competing g",
    "url": "https://arxiv.org/abs/2602.11368",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ReaDy-Go: Real-to-Sim Dynamic 3D Gaussian Splatting Simulation for Environment-Specific Visual Navigation with Moving Obstacles",
    "summary": "arXiv:2602.11575v2 Announce Type: replace-cross Abstract: Visual navigation models often struggle in real-world dynamic environments due to limited robustness to the sim-to-real gap and the difficulty of training policies tailored to target deployment environments (e.g., households, restaurants, and factories). Although real-to-sim navigation simul",
    "url": "https://arxiv.org/abs/2602.11575",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Zooming without Zooming: Region-to-Image Distillation for Fine-Grained Multimodal Perception",
    "summary": "arXiv:2602.11858v2 Announce Type: replace-cross Abstract: Multimodal Large Language Models (MLLMs) excel at broad visual understanding but still struggle with fine-grained perception, where decisive evidence is small and easily overwhelmed by global context. Recent \"Thinking-with-Images\" methods alleviate this by iteratively zooming in and out regi",
    "url": "https://arxiv.org/abs/2602.11858",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "ExtractBench: A Benchmark and Evaluation Methodology for Complex Structured Extraction",
    "summary": "arXiv:2602.12247v2 Announce Type: replace-cross Abstract: Unstructured documents like PDFs contain valuable structured information, but downstream systems require this data in reliable, standardized formats. LLMs are increasingly deployed to automate this extraction, making accuracy and reliability paramount. However, progress is bottlenecked by tw",
    "url": "https://arxiv.org/abs/2602.12247",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Why Deep Jacobian Spectra Separate: Depth-Induced Scaling and Singular-Vector Alignment",
    "summary": "arXiv:2602.12384v2 Announce Type: replace-cross Abstract: Understanding why gradient-based training in deep networks exhibits strong implicit bias remains challenging, in part because tractable singular-value dynamics are typically available only for balanced deep linear models. We propose an alternative route based on two theoretically grounded an",
    "url": "https://arxiv.org/abs/2602.12384",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Agent Skills for Large Language Models: Architecture, Acquisition, Security, and the Path Forward",
    "summary": "arXiv:2602.12430v2 Announce Type: replace-cross Abstract: The transition from monolithic language models to modular, skill-equipped agents marks a defining shift in how large language models (LLMs) are deployed in practice. Rather than encoding all procedural knowledge within model weights, agent skills -- composable packages of instructions, code,",
    "url": "https://arxiv.org/abs/2602.12430",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "MedXIAOHE: A Comprehensive Recipe for Building Medical MLLMs",
    "summary": "arXiv:2602.12705v2 Announce Type: replace-cross Abstract: We present MedXIAOHE, a medical vision-language foundation model designed to advance general-purpose medical understanding and reasoning in real-world clinical applications. MedXIAOHE achieves state-of-the-art performance across diverse medical benchmarks and surpasses leading closed-source ",
    "url": "https://arxiv.org/abs/2602.12705",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  },
  {
    "title": "Prior-Guided Symbolic Regression: Towards Scientific Consistency in Equation Discovery",
    "summary": "arXiv:2602.13021v2 Announce Type: replace-cross Abstract: Symbolic Regression (SR) aims to discover interpretable equations from observational data, with the potential to reveal underlying principles behind natural phenomena. However, existing approaches often fall into the Pseudo-Equation Trap: producing equations that fit observations well but re",
    "url": "https://arxiv.org/abs/2602.13021",
    "source": "Arxiv AI",
    "published_at": "2026-02-17T05:00:00+00:00"
  }
]