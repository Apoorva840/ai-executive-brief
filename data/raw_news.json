[
  {
    "title": "Converge Bio raises $25M, backed by Bessemer and execs from Meta, OpenAI, Wiz",
    "summary": "AI drug discovery startup Converge Bio raised $25 million in a Series A led by Bessemer Venture Partners, with additional backing from executives at Meta, OpenAI, and Wiz.",
    "url": "https://techcrunch.com/2026/01/13/ai-drug-discovery-startup-converge-bio-pulls-in-25m-from-bessemer-and-execs-from-meta-openai-and-wiz/",
    "source": "TechCrunch AI"
  },
  {
    "title": "Meta bought 1 GW of solar this week",
    "summary": "The social media company inked three deals in the U.S. to power its data centers and offset its carbon footprint.",
    "url": "https://techcrunch.com/2025/10/31/meta-bought-1-gw-of-solar-this-week/",
    "source": "TechCrunch AI"
  },
  {
    "title": "How one AI startup is helping rice farmers battle climate change",
    "summary": "Mitti Labs is working with The Nature Conservancy to expand the use of climate-friendly rice farming practices in India. The startup uses its AI to verify reductions in methane emissions.",
    "url": "https://techcrunch.com/2025/08/26/how-one-ai-startup-is-helping-rice-farmers-battle-climate-change/",
    "source": "TechCrunch AI"
  },
  {
    "title": "Harvard dropouts to launch ‘always on’ AI smart glasses that listen and record every conversation",
    "summary": "After developing a facial-recognition app for Meta’s Ray-Ban glasses and doxing random people, two former Harvard students are now launching a startup that makes smart glasses with an always-on microphone.",
    "url": "https://techcrunch.com/2025/08/20/harvard-dropouts-to-launch-always-on-ai-smart-glasses-that-listen-and-record-every-conversation/",
    "source": "TechCrunch AI"
  },
  {
    "title": "Meta to add 100MW of solar power from US gear",
    "summary": "The social media company is adding another tranche of solar to power a new AI data center in South Carolina.",
    "url": "https://techcrunch.com/2025/08/20/meta-to-add-100-mw-of-solar-power-from-u-s-gear/",
    "source": "TechCrunch AI"
  },
  {
    "title": "Perplexity accused of scraping websites that explicitly blocked AI scraping",
    "summary": "Internet giant Cloudflare says it detected Perplexity crawling and scraping websites, even after customers had added technical blocks telling Perplexity not to scrape their pages.",
    "url": "https://techcrunch.com/2025/08/04/perplexity-accused-of-scraping-websites-that-explicitly-blocked-ai-scraping/",
    "source": "TechCrunch AI"
  },
  {
    "title": "Obvio’s stop sign cameras use AI to root out unsafe drivers",
    "summary": "American streets are incredibly dangerous for pedestrians. A San Carlos, California-based startup called Obvio thinks it can change that by installing cameras at stop signs -- a solution the founders also say won’t create a panopticon.",
    "url": "https://techcrunch.com/2025/06/04/obvios-stop-sign-cameras-use-ai-to-root-out-unsafe-drivers/",
    "source": "TechCrunch AI"
  },
  {
    "title": "Breakneck data center growth challenges Microsoft’s sustainability goals",
    "summary": "Microsoft's sustainability goals are imperiled by its push into AI and cloud services.",
    "url": "https://techcrunch.com/2025/06/02/breakneck-data-center-growth-challenges-microsofts-sustainability-goals/",
    "source": "TechCrunch AI"
  },
  {
    "title": "Gridcare thinks more than 100 GW of data center capacity is hiding in the grid",
    "summary": "Gridcare raised $13.3 million for its data platform that finds underutilized capacity on the electrical grid.",
    "url": "https://techcrunch.com/2025/05/27/gridcare-thinks-more-than-100-gw-of-data-center-capacity-is-hiding-in-the-grid/",
    "source": "TechCrunch AI"
  },
  {
    "title": "Meta adds another 650 MW of solar power to its AI push",
    "summary": "The company already has more than 12 gigawatts of capacity in its renewable power portfolio.",
    "url": "https://techcrunch.com/2025/05/22/meta-adds-another-650-mw-of-solar-power-to-its-ai-push/",
    "source": "TechCrunch AI"
  },
  {
    "title": "Who are climate-conscious consumers? Not who you’d expect, says Northwind Climate",
    "summary": "Rather than divide people into demographic buckets, Northwind Climate analyzes survey responses for behavioral clues.",
    "url": "https://techcrunch.com/2025/04/01/who-are-climate-conscious-consumers-not-who-youd-expect-says-northwind-climate/",
    "source": "TechCrunch AI"
  },
  {
    "title": "Data centers love solar: Here’s a comprehensive guide to deals over 100 megawatts",
    "summary": "New and expanded data centers are expected to double the sector’s power demand by 2029 as tech companies rush to capitalize on AI.",
    "url": "https://techcrunch.com/2025/03/30/data-centers-love-solar-heres-a-comprehensive-guide-to-deals-over-100-megawatts/",
    "source": "TechCrunch AI"
  },
  {
    "title": "Nvidia thinks AI can solve electrical grid problems caused by AI",
    "summary": "The Open Power AI Consortium says it will use domain-specific AI models to tackle problems in the power industry.",
    "url": "https://techcrunch.com/2025/03/20/nvidia-thinks-ai-can-solve-electrical-grid-problems-caused-by-ai/",
    "source": "TechCrunch AI"
  },
  {
    "title": "Solar notches another win as Microsoft adds 475 MW to power its AI data centers",
    "summary": "The company recently signed a deal with energy provider AES for three solar projects across the Midwest.",
    "url": "https://techcrunch.com/2025/03/20/solar-notches-another-win-as-microsoft-adds-475-mw-to-power-its-ai-data-centers/",
    "source": "TechCrunch AI"
  },
  {
    "title": "Geothermal could power nearly all new data centers through 2030",
    "summary": "Geothermal resources have enormous potential to provide the sort of consistent power that data centers crave.",
    "url": "https://techcrunch.com/2025/03/11/geothermal-could-power-nearly-all-new-data-centers-through-2030/",
    "source": "TechCrunch AI"
  },
  {
    "title": "ElevenLabs now lets authors create and publish audiobooks on its own platform",
    "summary": "Voice AI company ElevenLabs is now letting authors publish AI-generated audiobooks on its own Reader app, TechCrunch has learned and the company confirmed. The announcement comes days after the company partnered with Spotify for AI-narrated audiobooks. ElevenLabs, which raised a $180 million mega-round last month, started inviting authors to try ou",
    "url": "https://techcrunch.com/2025/02/25/elevenlabs-is-now-letting-authors-create-and-publish-audiobooks-on-its-own-platform/",
    "source": "TechCrunch AI"
  },
  {
    "title": "Data center tweaks could unlock 76 GW of new power capacity in the US",
    "summary": "A new study argues that data centers could be ideal demand-response participants because they have the potential to be flexible.",
    "url": "https://techcrunch.com/2025/02/13/data-center-tweaks-could-unlock-76-gw-of-new-power-capacity-in-the-u-s/",
    "source": "TechCrunch AI"
  },
  {
    "title": "YouTube AI updates include auto dubbing expansion, age ID tech, and more",
    "summary": "In his annual letter, YouTube CEO Neal Mohan dubbed AI one of the company&#8217;s four &#8220;big bets&#8221; for 2025. The executive pointed to the company&#8217;s investments in AI tools for creators, including ones for video ideas, thumbnails, and language translation. The latter feature will roll out to all creators in YouTube&#8217;s Partner P",
    "url": "https://techcrunch.com/2025/02/11/youtube-ai-updates-to-include-expansion-of-auto-dubbing-age-identifying-tech-and-more/",
    "source": "TechCrunch AI"
  },
  {
    "title": "Self Inspection raises $3M for its AI-powered vehicle inspections",
    "summary": "A number of startups are racing to make vehicle inspections faster, easier, and cheaper. Self Inspection, a startup based in San Diego, thinks it has them all beat with its AI-powered service &#8212; and now it has convinced outside investors. Self Inspection, founded in 2021, is set to announce Thursday it&#8217;s raised $3 million in [&#8230;]",
    "url": "https://techcrunch.com/2025/02/07/self-inspection-raises-3m-for-its-ai-powered-vehicle-inspections/",
    "source": "TechCrunch AI"
  },
  {
    "title": "Meta turns to solar — again — in its data center-building boom",
    "summary": "The announcement comes as Meta CEO Mark Zuckerberg maintains the company’s ambitious AI strategy, which will require hefty capital investments in data centers.",
    "url": "https://techcrunch.com/2025/01/31/meta-turns-to-solar-again-in-its-data-center-building-boom/",
    "source": "TechCrunch AI"
  },
  {
    "title": "This is the most misunderstood graph in AI",
    "summary": "MIT Technology Review Explains: Let our writers untangle the complex, messy world of technology to help you understand what’s coming next. You can read more from the series here. Every time OpenAI, Google, or Anthropic drops a new frontier large language model, the AI community holds its breath. It doesn’t exhale until METR, an AI&#8230;",
    "url": "https://www.technologyreview.com/2026/02/05/1132254/this-is-the-most-misunderstood-graph-in-ai/",
    "source": "MIT Technology Review AI"
  },
  {
    "title": "From guardrails to governance: A CEO’s guide for securing agentic systems",
    "summary": "The previous article in this series, “Rules fail at the prompt, succeed at the boundary,” focused on the first AI-orchestrated espionage campaign and the failure of prompt-level control. This article is the prescription. The question every CEO is now getting from their board is some version of: What do we do about agent risk? Across&#8230;",
    "url": "https://www.technologyreview.com/2026/02/04/1131014/from-guardrails-to-governance-a-ceos-guide-for-securing-agentic-systems/",
    "source": "MIT Technology Review AI"
  },
  {
    "title": "What we’ve been getting wrong about AI’s truth crisis",
    "summary": "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&#160;sign up here. What would it take to convince you that the era of truth decay we were long warned about—where AI content dupes us, shapes our beliefs even when we catch the lie, and&#8230;",
    "url": "https://www.technologyreview.com/2026/02/02/1132068/what-weve-been-getting-wrong-about-ais-truth-crisis/",
    "source": "MIT Technology Review AI"
  },
  {
    "title": "The crucial first step for designing a successful enterprise AI system",
    "summary": "Many organizations rushed into generative AI, only to see pilots fail to deliver value. Now, companies want measurable outcomes—but how do you design for success? At Mistral AI, we partner with global industry leaders to co-design tailored AI solutions that solve their most difficult problems. Whether it’s increasing CX productivity with Cisco, bui",
    "url": "https://www.technologyreview.com/2026/02/02/1131822/the-crucial-first-step-for-designing-a-successful-enterprise-ai-system/",
    "source": "MIT Technology Review AI"
  },
  {
    "title": "Inside the marketplace powering bespoke AI deepfakes of real women",
    "summary": "Civitai—an online marketplace for buying and selling AI-generated content, backed by the venture capital firm Andreessen Horowitz—is letting users buy custom instruction files for generating celebrity deepfakes. Some of these files were specifically designed to make pornographic images banned by the site, a new analysis has found. The study, from r",
    "url": "https://www.technologyreview.com/2026/01/30/1131945/inside-the-marketplace-powering-bespoke-ai-deepfakes-of-real-women/",
    "source": "MIT Technology Review AI"
  },
  {
    "title": "The AI Hype Index: Grok makes porn, and Claude Code nails your job",
    "summary": "Everyone is panicking because AI is very bad; everyone is panicking because AI is very good. It’s just that you never know which one you’re going to get. Grok is a pornography machine. Claude Code can do anything from building websites to reading your MRI. So of course Gen Z is spooked by what this&#8230;",
    "url": "https://www.technologyreview.com/2026/01/29/1131787/the-ai-hype-index-grok-makes-porn-claude-code-nails-your-job/",
    "source": "MIT Technology Review AI"
  },
  {
    "title": "DHS is using Google and Adobe AI to make videos",
    "summary": "The US Department of Homeland Security is using AI video generators from Google and Adobe to make and edit content shared with the public, a new document reveals. It comes as immigration agencies have flooded social media with content to support President Trump&#8217;s mass deportation agenda—some of which appears to be made with AI—and as&#8230;",
    "url": "https://www.technologyreview.com/2026/01/29/1131938/dhs-is-using-google-and-adobe-ai-to-make-videos/",
    "source": "MIT Technology Review AI"
  },
  {
    "title": "What AI “remembers” about you is privacy’s next frontier",
    "summary": "The ability to remember you and your preferences is rapidly becoming a big selling point for AI chatbots and agents.&#160; Earlier this month, Google announced Personal Intelligence, a new way for people to interact with the company’s Gemini chatbot that draws on their Gmail, photos, search, and YouTube histories to make Gemini “more personal, proa",
    "url": "https://www.technologyreview.com/2026/01/28/1131835/what-ai-remembers-about-you-is-privacys-next-frontier/",
    "source": "MIT Technology Review AI"
  },
  {
    "title": "Rules fail at the prompt, succeed at the boundary",
    "summary": "From the Gemini Calendar prompt-injection attack of 2026 to the September 2025 state-sponsored hack using Anthropic’s Claude code as an automated intrusion engine, the coercion of human-in-the-loop agentic actions and fully autonomous agentic workflows are the new attack vector for hackers. In the Anthropic case, roughly 30 organizations across tec",
    "url": "https://www.technologyreview.com/2026/01/28/1131003/rules-fail-at-the-prompt-succeed-at-the-boundary/",
    "source": "MIT Technology Review AI"
  },
  {
    "title": "OpenAI’s latest product lets you vibe code science",
    "summary": "OpenAI just revealed what its new in-house team, OpenAI for Science, has been up to. The firm has released a free LLM-powered tool for scientists called Prism, which embeds ChatGPT in a text editor for writing scientific papers. The idea is to put ChatGPT front and center inside software that scientists use to write up&#8230;",
    "url": "https://www.technologyreview.com/2026/01/27/1131793/openais-latest-product-lets-you-vibe-code-science/",
    "source": "MIT Technology Review AI"
  },
  {
    "title": "Railway secures $100 million to challenge AWS with AI-native cloud infrastructure",
    "summary": "Railway, a San Francisco-based cloud platform that has quietly amassed two million developers without spending a dollar on marketing, announced Thursday that it raised $100 million in a Series B funding round, as surging demand for artificial intelligence applications exposes the limitations of legacy cloud infrastructure.TQ Ventures led the round,",
    "url": "https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud",
    "source": "VentureBeat AI"
  },
  {
    "title": "Claude Code costs up to $200 a month. Goose does the same thing for free.",
    "summary": "The artificial intelligence coding revolution comes with a catch: it&#x27;s expensive.Claude Code, Anthropic&#x27;s terminal-based AI agent that can write, debug, and deploy code autonomously, has captured the imagination of software developers worldwide. But its pricing — ranging from $20 to $200 per month depending on usage — has sparked a growin",
    "url": "https://venturebeat.com/infrastructure/claude-code-costs-up-to-usd200-a-month-goose-does-the-same-thing-for-free",
    "source": "VentureBeat AI"
  },
  {
    "title": "Listen Labs raises $69M after viral billboard hiring stunt to scale AI customer interviews",
    "summary": "Alfred Wahlforss was running out of options. His startup, Listen Labs, needed to hire over 100 engineers, but competing against Mark Zuckerberg&#x27;s $100 million offers seemed impossible. So he spent $5,000 — a fifth of his marketing budget — on a billboard in San Francisco displaying what looked like gibberish: five strings of random numbers.The",
    "url": "https://venturebeat.com/technology/listen-labs-raises-usd69m-after-viral-billboard-hiring-stunt-to-scale-ai",
    "source": "VentureBeat AI"
  },
  {
    "title": "Salesforce rolls out new Slackbot AI agent as it battles Microsoft and Google in workplace AI",
    "summary": "Salesforce on Tuesday launched an entirely rebuilt version of Slackbot, the company&#x27;s workplace assistant, transforming it from a simple notification tool into what executives describe as a fully powered AI agent capable of searching enterprise data, drafting documents, and taking action on behalf of employees.The new Slackbot, now generally a",
    "url": "https://venturebeat.com/technology/salesforce-rolls-out-new-slackbot-ai-agent-as-it-battles-microsoft-and",
    "source": "VentureBeat AI"
  },
  {
    "title": "Anthropic launches Cowork, a Claude Desktop agent that works in your files — no coding required",
    "summary": "Anthropic released Cowork on Monday, a new AI agent capability that extends the power of its wildly successful Claude Code tool to non-technical users — and according to company insiders, the team built the entire feature in approximately a week and a half, largely using Claude Code itself.The launch marks a major inflection point in the race to de",
    "url": "https://venturebeat.com/technology/anthropic-launches-cowork-a-claude-desktop-agent-that-works-in-your-files-no",
    "source": "VentureBeat AI"
  },
  {
    "title": "Nous Research's NousCoder-14B is an open-source coding model landing right in the Claude Code moment",
    "summary": "Nous Research, the open-source artificial intelligence startup backed by crypto venture firm Paradigm, released a new competitive programming model on Monday that it says matches or exceeds several larger proprietary systems — trained in just four days using 48 of Nvidia&#x27;s latest B200 graphics processors.The model, called NousCoder-14B, is ano",
    "url": "https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in",
    "source": "VentureBeat AI"
  },
  {
    "title": "The creator of Claude Code just revealed his workflow, and developers are losing their minds",
    "summary": "When the creator of the world&#x27;s most advanced coding agent speaks, Silicon Valley doesn&#x27;t just listen — it takes notes.For the past week, the engineering community has been dissecting a thread on X from Boris Cherny, the creator and head of Claude Code at Anthropic. What began as a casual sharing of his personal terminal setup has spirale",
    "url": "https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are",
    "source": "VentureBeat AI"
  },
  {
    "title": "Loyalty Is Dead in Silicon Valley",
    "summary": "Founders used to be wedded to their companies. Now, anyone can be lured away for the right price.",
    "url": "https://www.wired.com/story/model-behavior-loyalty-is-dead-in-silicon-valley/",
    "source": "Wired AI"
  },
  {
    "title": "ICE and CBP’s Face-Recognition App Can’t Actually Verify Who People Are",
    "summary": "ICE has used Mobile Fortify to identify immigrants and citizens alike over 100,000 times, by one estimate. It wasn't built to work like that—and only got approved after DHS abandoned its own privacy rules.",
    "url": "https://www.wired.com/story/cbp-ice-dhs-mobile-fortify-face-recognition-verify-identity/",
    "source": "Wired AI"
  },
  {
    "title": "Hollywood Is Losing Audiences to AI Fatigue",
    "summary": "Entertainment about or made with artificial intelligence has been missing the mark with viewers over the past year.",
    "url": "https://www.wired.com/story/hollywood-is-losing-audiences-to-ai-fatigue/",
    "source": "Wired AI"
  },
  {
    "title": "A New AI Math Startup Just Cracked 4 Previously Unsolved Problems",
    "summary": "Axiom says its AI found solutions to several long-standing math problems, a sign of the technology’s steadily advancing reasoning capabilities.",
    "url": "https://www.wired.com/story/a-new-ai-math-ai-startup-just-cracked-4-previously-unsolved-problems/",
    "source": "Wired AI"
  },
  {
    "title": "Mistral's New Ultra-Fast Translation Model Gives Big AI Labs a Run for Their Money",
    "summary": "“Too many GPUs makes you lazy,” says the French startup’s vice president of science operations, as the company carves out a different path than the major US AI companies.",
    "url": "https://www.wired.com/story/mistral-voxtral-real-time-ai-translation/",
    "source": "Wired AI"
  },
  {
    "title": "AI Bots Are Now a Significant Source of Web Traffic",
    "summary": "New data shows AI bots pushing deeper into the web, prompting publishers to roll out more aggressive defenses.",
    "url": "https://www.wired.com/story/ai-bots-are-now-a-signifigant-source-of-web-traffic/",
    "source": "Wired AI"
  },
  {
    "title": "HHS Is Making an AI Tool to Create Hypotheses About Vaccine Injury Claims",
    "summary": "Experts worry Robert F. Kennedy Jr.’s Health Department will use an internal AI tool to analyze vaccine injury claims in a way that furthers his anti-vaccine agenda.",
    "url": "https://www.wired.com/story/hhs-is-making-an-ai-tool-to-create-hypotheses-about-vaccine-injury-claims/",
    "source": "Wired AI"
  },
  {
    "title": "I Infiltrated Moltbook, the AI-Only Social Network Where Humans Aren’t Allowed",
    "summary": "I went undercover on Moltbook and loved role-playing as a conscious bot. But rather than a novel breakthrough, the AI-only site is a crude rehashing of sci-fi fantasies.",
    "url": "https://www.wired.com/story/i-infiltrated-moltbook-ai-only-social-network/",
    "source": "Wired AI"
  },
  {
    "title": "‘Fallout’ Producer Jonathan Nolan on AI: ‘We’re in Such a Frothy Moment’",
    "summary": "The Westworld showrunner thinks AI will be good for burgeoning filmmakers, but not for Hollywood blockbusters.",
    "url": "https://www.wired.com/story/the-big-interview-podcast-jonathan-nolan-fallout/",
    "source": "Wired AI"
  },
  {
    "title": "Elon Musk Is Rolling xAI Into SpaceX—Creating the World’s Most Valuable Private Company",
    "summary": "By fusing SpaceX and xAI—which acquired X last year—Elon Musk tightens his grip over technologies that shape national security, social media, and artificial intelligence.",
    "url": "https://www.wired.com/story/spacex-acquires-xai-elon-musk/",
    "source": "Wired AI"
  },
  {
    "title": "Knowledge Model Prompting Increases LLM Performance on Planning Tasks",
    "summary": "arXiv:2602.03900v1 Announce Type: new Abstract: Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have come under scrutiny as LLMs' ability to reason at all has come into quest",
    "url": "https://arxiv.org/abs/2602.03900",
    "source": "Arxiv AI"
  },
  {
    "title": "Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation",
    "summary": "arXiv:2602.03950v1 Announce Type: new Abstract: Mathematical problem solving is a fundamental benchmark for assessing the reasoning capabilities of artificial intelligence and a gateway to applications in education, science, and engineering where reliable symbolic reasoning is essential. Although recent advances in multi-agent LLM-based systems hav",
    "url": "https://arxiv.org/abs/2602.03950",
    "source": "Arxiv AI"
  },
  {
    "title": "AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent",
    "summary": "arXiv:2602.03955v1 Announce Type: new Abstract: While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes AgentArk, a novel framework to distill multi-agent dynamics into the weights",
    "url": "https://arxiv.org/abs/2602.03955",
    "source": "Arxiv AI"
  },
  {
    "title": "Active Epistemic Control for Query-Efficient Verified Planning",
    "summary": "arXiv:2602.03974v1 Announce Type: new Abstract: Planning in interactive environments is challenging under partial observability: task-critical preconditions (e.g., object locations or container states) may be unknown at decision time, yet grounding them through interaction is costly. Learned world models can cheaply predict missing facts, but predi",
    "url": "https://arxiv.org/abs/2602.03974",
    "source": "Arxiv AI"
  },
  {
    "title": "Adaptive Test-Time Compute Allocation via Learned Heuristics over Categorical Structure",
    "summary": "arXiv:2602.03975v1 Announce Type: new Abstract: Test-time computation has become a primary driver of progress in large language model (LLM) reasoning, but it is increasingly bottlenecked by expensive verification. In many reasoning systems, a large fraction of verifier calls are spent on redundant or unpromising intermediate hypotheses. We study re",
    "url": "https://arxiv.org/abs/2602.03975",
    "source": "Arxiv AI"
  },
  {
    "title": "Monitorability as a Free Gift: How RLVR Spontaneously Aligns Reasoning",
    "summary": "arXiv:2602.03978v1 Announce Type: new Abstract: As Large Reasoning Models (LRMs) are increasingly deployed, auditing their chain-of-thought (CoT) traces for safety becomes critical. Recent work has reported that monitorability--the degree to which CoT faithfully and informatively reflects internal computation--can appear as a \"free gift\" during the",
    "url": "https://arxiv.org/abs/2602.03978",
    "source": "Arxiv AI"
  },
  {
    "title": "When AI Persuades: Adversarial Explanation Attacks on Human Trust in AI-Assisted Decision Making",
    "summary": "arXiv:2602.04003v1 Announce Type: new Abstract: Most adversarial threats in artificial intelligence target the computational behavior of models rather than the humans who rely on them. Yet modern AI systems increasingly operate within human decision loops, where users interpret and act on model recommendations. Large Language Models generate fluent",
    "url": "https://arxiv.org/abs/2602.04003",
    "source": "Arxiv AI"
  },
  {
    "title": "Axiomatic Foundations of Counterfactual Explanations",
    "summary": "arXiv:2602.04028v1 Announce Type: new Abstract: Explaining autonomous and intelligent systems is critical in order to improve trust in their decisions. Counterfactuals have emerged as one of the most compelling forms of explanation. They address ``why not'' questions by revealing how decisions could be altered. Despite the growing literature, most ",
    "url": "https://arxiv.org/abs/2602.04028",
    "source": "Arxiv AI"
  },
  {
    "title": "Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL",
    "summary": "arXiv:2602.04089v1 Announce Type: new Abstract: Large language models (LLMs) achieve strong performance when all task-relevant information is available upfront, as in static prediction and instruction-following problems. However, many real-world decision-making tasks are inherently online: crucial information must be acquired through interaction, f",
    "url": "https://arxiv.org/abs/2602.04089",
    "source": "Arxiv AI"
  },
  {
    "title": "Interfaze: The Future of AI is built on Task-Specific Small Models",
    "summary": "arXiv:2602.04101v1 Announce Type: new Abstract: We present Interfaze, a system that treats modern LLM applications as a problem of building and acting over context, not just picking the right monolithic model. Instead of a single transformer, we combine (i) a stack of heterogeneous DNNs paired with small language models as perception modules for OC",
    "url": "https://arxiv.org/abs/2602.04101",
    "source": "Arxiv AI"
  },
  {
    "title": "OMG-Agent: Toward Robust Missing Modality Generation with Decoupled Coarse-to-Fine Agentic Workflows",
    "summary": "arXiv:2602.04144v1 Announce Type: new Abstract: Data incompleteness severely impedes the reliability of multimodal systems. Existing reconstruction methods face distinct bottlenecks: conventional parametric/generative models are prone to hallucinations due to over-reliance on internal memory, while retrieval-augmented frameworks struggle with retri",
    "url": "https://arxiv.org/abs/2602.04144",
    "source": "Arxiv AI"
  },
  {
    "title": "Steering LLMs via Scalable Interactive Oversight",
    "summary": "arXiv:2602.04210v1 Announce Type: new Abstract: As Large Language Models increasingly automate complex, long-horizon tasks such as \\emph{vibe coding}, a supervision gap has emerged. While models excel at execution, users often struggle to guide them effectively due to insufficient domain expertise, the difficulty of articulating precise intent, and",
    "url": "https://arxiv.org/abs/2602.04210",
    "source": "Arxiv AI"
  },
  {
    "title": "InterPReT: Interactive Policy Restructuring and Training Enable Effective Imitation Learning from Laypersons",
    "summary": "arXiv:2602.04213v1 Announce Type: new Abstract: Imitation learning has shown success in many tasks by learning from expert demonstrations. However, most existing work relies on large-scale demonstrations from technical professionals and close monitoring of the training process. These are challenging for a layperson when they want to teach the agent",
    "url": "https://arxiv.org/abs/2602.04213",
    "source": "Arxiv AI"
  },
  {
    "title": "Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search",
    "summary": "arXiv:2602.04248v1 Announce Type: new Abstract: Inference-time scaling strategies, particularly Monte Carlo Tree Search (MCTS), have significantly enhanced the reasoning capabilities of Large Language Models (LLMs). However, current approaches remain predominantly stateless, discarding successful reasoning patterns after each problem instance and f",
    "url": "https://arxiv.org/abs/2602.04248",
    "source": "Arxiv AI"
  },
  {
    "title": "Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning",
    "summary": "arXiv:2602.04284v1 Announce Type: new Abstract: Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To th",
    "url": "https://arxiv.org/abs/2602.04284",
    "source": "Arxiv AI"
  },
  {
    "title": "From Assumptions to Actions: Turning LLM Reasoning into Uncertainty-Aware Planning for Embodied Agents",
    "summary": "arXiv:2602.04326v1 Announce Type: new Abstract: Embodied agents operating in multi-agent, partially observable, and decentralized environments must plan and act despite pervasive uncertainty about hidden objects and collaborators' intentions. Recent advances in applying Large Language Models (LLMs) to embodied agents have addressed many long-standi",
    "url": "https://arxiv.org/abs/2602.04326",
    "source": "Arxiv AI"
  },
  {
    "title": "Digital Twins & ZeroConf AI: Structuring Automated Intelligent Pipelines for Industrial Applications",
    "summary": "arXiv:2602.04385v1 Announce Type: new Abstract: The increasing complexity of Cyber-Physical Systems (CPS), particularly in the industrial domain, has amplified the challenges associated with the effective integration of Artificial Intelligence (AI) and Machine Learning (ML) techniques. Fragmentation across IoT and IIoT technologies, manifested thro",
    "url": "https://arxiv.org/abs/2602.04385",
    "source": "Arxiv AI"
  },
  {
    "title": "ReThinker: Scientific Reasoning by Rethinking with Guided Reflection and Confidence Control",
    "summary": "arXiv:2602.04496v1 Announce Type: new Abstract: Expert-level scientific reasoning remains challenging for large language models, particularly on benchmarks such as Humanity's Last Exam (HLE), where rigid tool pipelines, brittle multi-agent coordination, and inefficient test-time scaling often limit performance. We introduce ReThinker, a confidence-",
    "url": "https://arxiv.org/abs/2602.04496",
    "source": "Arxiv AI"
  },
  {
    "title": "From Competition to Collaboration: Designing Sustainable Mechanisms Between LLMs and Online Forums",
    "summary": "arXiv:2602.04572v1 Announce Type: new Abstract: While Generative AI (GenAI) systems draw users away from (Q&amp;A) forums, they also depend on the very data those forums produce to improve their performance. Addressing this paradox, we propose a framework of sequential interaction, in which a GenAI system proposes questions to a forum that can publ",
    "url": "https://arxiv.org/abs/2602.04572",
    "source": "Arxiv AI"
  },
  {
    "title": "Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration",
    "summary": "arXiv:2602.04575v2 Announce Type: new Abstract: For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' manifested as the Intent-Execution Gap (i.e., the fu",
    "url": "https://arxiv.org/abs/2602.04575",
    "source": "Arxiv AI"
  },
  {
    "title": "WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning",
    "summary": "arXiv:2602.04634v1 Announce Type: new Abstract: Recent advancements in Large Language Models (LLMs) have largely focused on depth scaling, where a single agent solves long-horizon problems with multi-turn reasoning and tool use. However, as tasks grow broader, the key bottleneck shifts from individual competence to organizational capability. In thi",
    "url": "https://arxiv.org/abs/2602.04634",
    "source": "Arxiv AI"
  },
  {
    "title": "Agentic AI in Healthcare & Medicine: A Seven-Dimensional Taxonomy for Empirical Evaluation of LLM-based Agents",
    "summary": "arXiv:2602.04813v1 Announce Type: new Abstract: Large Language Model (LLM)-based agents that plan, use tools and act has begun to shape healthcare and medicine. Reported studies demonstrate competence on various tasks ranging from EHR analysis and differential diagnosis to treatment planning and research workflows. Yet the literature largely consis",
    "url": "https://arxiv.org/abs/2602.04813",
    "source": "Arxiv AI"
  },
  {
    "title": "Are AI Capabilities Increasing Exponentially? A Competing Hypothesis",
    "summary": "arXiv:2602.04836v1 Announce Type: new Abstract: Rapidly increasing AI capabilities have substantial real-world consequences, ranging from AI safety concerns to labor market consequences. The Model Evaluation & Threat Research (METR) report argues that AI capabilities have exhibited exponential growth since 2019. In this note, we argue that the data",
    "url": "https://arxiv.org/abs/2602.04836",
    "source": "Arxiv AI"
  },
  {
    "title": "Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing",
    "summary": "arXiv:2602.04837v1 Announce Type: new Abstract: Open-ended self-improving agents can autonomously modify their own structural designs to advance their capabilities and overcome the limits of pre-defined architectures, thus reducing reliance on human intervention. We introduce Group-Evolving Agents (GEA), a new paradigm for open-ended self-improveme",
    "url": "https://arxiv.org/abs/2602.04837",
    "source": "Arxiv AI"
  },
  {
    "title": "Fluid Representations in Reasoning Models",
    "summary": "arXiv:2602.04843v1 Announce Type: new Abstract: Reasoning language models, which generate long chains of thought, dramatically outperform non-reasoning language models on abstract problems. However, the internal model mechanisms that allow this superior performance remain poorly understood. We present a mechanistic analysis of how QwQ-32B - a model",
    "url": "https://arxiv.org/abs/2602.04843",
    "source": "Arxiv AI"
  },
  {
    "title": "Merged ChemProt-DrugProt for Relation Extraction from Biomedical Literature",
    "summary": "arXiv:2405.18605v2 Announce Type: cross Abstract: The extraction of chemical-gene relations plays a pivotal role in understanding the intricate interactions between chemical compounds and genes, with significant implications for drug discovery, disease understanding, and biomedical research. This paper presents a data set created by merging the Che",
    "url": "https://arxiv.org/abs/2405.18605",
    "source": "Arxiv AI"
  },
  {
    "title": "HybridQuestion: Human-AI Collaboration for Identifying High-Impact Research Questions",
    "summary": "arXiv:2602.03849v1 Announce Type: cross Abstract: The \"AI Scientist\" paradigm is transforming scientific research by automating key stages of the research process, from idea generation to scholarly writing. This shift is expected to accelerate discovery and expand the scope of scientific inquiry. However, a key question remains unclear: can AI scie",
    "url": "https://arxiv.org/abs/2602.03849",
    "source": "Arxiv AI"
  },
  {
    "title": "WebAccessVL: Making an Accessible Web via Violation-Conditioned VLM",
    "summary": "arXiv:2602.03850v1 Announce Type: cross Abstract: We present a vision-language model (VLM) that automatically edits website HTML to address Web Content Accessibility Guidelines 2 (WCAG2) violations. We formulate this as a supervised image-conditioned program synthesis task, where the model learns to correct HTML given the HTML and its rendering. We",
    "url": "https://arxiv.org/abs/2602.03850",
    "source": "Arxiv AI"
  },
  {
    "title": "Perceptions of AI-CBT: Trust and Barriers in Chinese Postgrads",
    "summary": "arXiv:2602.03852v1 Announce Type: cross Abstract: The mental well-being of graduate students is an increasing concern, yet the adoption of scalable support remains uneven. Artificial intelligence-powered cognitive behavioral therapy chatbots (AI-CBT) offer low barrier help, but little is known about how Chinese postgraduates perceive and use them. ",
    "url": "https://arxiv.org/abs/2602.03852",
    "source": "Arxiv AI"
  },
  {
    "title": "PaperX: A Unified Framework for Multimodal Academic Presentation Generation with Scholar DAG",
    "summary": "arXiv:2602.03866v2 Announce Type: cross Abstract: Transforming scientific papers into multimodal presentation content is essential for research dissemination but remains labor intensive. Existing automated solutions typically treat each format as an isolated downstream task, leading to redundant processing and semantic inconsistency. We introduce P",
    "url": "https://arxiv.org/abs/2602.03866",
    "source": "Arxiv AI"
  },
  {
    "title": "Benchmarking Automatic Speech Recognition for Indian Languages in Agricultural Contexts",
    "summary": "arXiv:2602.03868v1 Announce Type: cross Abstract: The digitization of agricultural advisory services in India requires robust Automatic Speech Recognition (ASR) systems capable of accurately transcribing domain-specific terminology in multiple Indian languages. This paper presents a benchmarking framework for evaluating ASR performance in agricultu",
    "url": "https://arxiv.org/abs/2602.03868",
    "source": "Arxiv AI"
  },
  {
    "title": "Understanding the Impact of Differentially Private Training on Memorization of Long-Tailed Data",
    "summary": "arXiv:2602.03872v1 Announce Type: cross Abstract: Recent research shows that modern deep learning models achieve high predictive accuracy partly by memorizing individual training samples. Such memorization raises serious privacy concerns, motivating the widespread adoption of differentially private training algorithms such as DP-SGD. However, a gro",
    "url": "https://arxiv.org/abs/2602.03872",
    "source": "Arxiv AI"
  },
  {
    "title": "Decoding Ambiguous Emotions with Test-Time Scaling in Audio-Language Models",
    "summary": "arXiv:2602.03873v1 Announce Type: cross Abstract: Emotion recognition from human speech is a critical enabler for socially aware conversational AI. However, while most prior work frames emotion recognition as a categorical classification problem, real-world affective states are often ambiguous, overlapping, and context-dependent, posing significant",
    "url": "https://arxiv.org/abs/2602.03873",
    "source": "Arxiv AI"
  },
  {
    "title": "Reversible Deep Learning for 13C NMR in Chemoinformatics: On Structures and Spectra",
    "summary": "arXiv:2602.03875v2 Announce Type: cross Abstract: We introduce a reversible deep learning model for 13C NMR that uses a single conditional invertible neural network for both directions between molecular structures and spectra. The network is built from i-RevNet style bijective blocks, so the forward map and its inverse are available by construction",
    "url": "https://arxiv.org/abs/2602.03875",
    "source": "Arxiv AI"
  },
  {
    "title": "GOPO: Policy Optimization using Ranked Rewards",
    "summary": "arXiv:2602.03876v1 Announce Type: cross Abstract: Standard reinforcement learning from human feedback (RLHF) trains a reward model on pairwise preference data and then uses it for policy optimization. However, while reward models are optimized to capture relative preferences, existing policy optimization techniques rely on absolute reward magnitude",
    "url": "https://arxiv.org/abs/2602.03876",
    "source": "Arxiv AI"
  },
  {
    "title": "TruKAN: Towards More Efficient Kolmogorov-Arnold Networks Using Truncated Power Functions",
    "summary": "arXiv:2602.03879v1 Announce Type: cross Abstract: To address the trade-off between computational efficiency and adherence to Kolmogorov-Arnold Network (KAN) principles, we propose TruKAN, a new architecture based on the KAN structure and learnable activation functions. TruKAN replaces the B-spline basis in KAN with a family of truncated power funct",
    "url": "https://arxiv.org/abs/2602.03879",
    "source": "Arxiv AI"
  },
  {
    "title": "DiGAN: Diffusion-Guided Attention Network for Early Alzheimer's Disease Detection",
    "summary": "arXiv:2602.03881v1 Announce Type: cross Abstract: Early diagnosis of Alzheimer's disease (AD) remains a major challenge due to the subtle and temporally irregular progression of structural brain changes in the prodromal stages. Existing deep learning approaches require large longitudinal datasets and often fail to model the temporal continuity and ",
    "url": "https://arxiv.org/abs/2602.03881",
    "source": "Arxiv AI"
  },
  {
    "title": "PriorProbe: Recovering Individual-Level Priors for Personalizing Neural Networks in Facial Expression Recognition",
    "summary": "arXiv:2602.03882v1 Announce Type: cross Abstract: Incorporating individual-level cognitive priors offers an important route to personalizing neural networks, yet accurately eliciting such priors remains challenging: existing methods either fail to uniquely identify them or introduce systematic biases. Here, we introduce PriorProbe, a novel elicitat",
    "url": "https://arxiv.org/abs/2602.03882",
    "source": "Arxiv AI"
  },
  {
    "title": "Explainable Computer Vision Framework for Automated Pore Detection and Criticality Assessment in Additive Manufacturing",
    "summary": "arXiv:2602.03883v1 Announce Type: cross Abstract: Internal porosity remains a critical defect mode in additively manufactured components, compromising structural performance and limiting industrial adoption. Automated defect detection methods exist but lack interpretability, preventing engineers from understanding the physical basis of criticality ",
    "url": "https://arxiv.org/abs/2602.03883",
    "source": "Arxiv AI"
  },
  {
    "title": "Sounding Highlights: Dual-Pathway Audio Encoders for Audio-Visual Video Highlight Detection",
    "summary": "arXiv:2602.03891v2 Announce Type: cross Abstract: Audio-visual video highlight detection aims to automatically identify the most salient moments in videos by leveraging both visual and auditory cues. However, existing models often underutilize the audio modality, focusing on high-level semantic features while failing to fully leverage the rich, dyn",
    "url": "https://arxiv.org/abs/2602.03891",
    "source": "Arxiv AI"
  },
  {
    "title": "Audit After Segmentation: Reference-Free Mask Quality Assessment for Language-Referred Audio-Visual Segmentation",
    "summary": "arXiv:2602.03892v1 Announce Type: cross Abstract: Language-referred audio-visual segmentation (Ref-AVS) aims to segment target objects described by natural language by jointly reasoning over video, audio, and text. Beyond generating segmentation masks, providing rich and interpretable diagnoses of mask quality remains largely underexplored. In this",
    "url": "https://arxiv.org/abs/2602.03892",
    "source": "Arxiv AI"
  },
  {
    "title": "Vision Transformers for Zero-Shot Clustering of Animal Images: A Comparative Benchmarking Study",
    "summary": "arXiv:2602.03894v1 Announce Type: cross Abstract: Manual labeling of animal images remains a significant bottleneck in ecological research, limiting the scale and efficiency of biodiversity monitoring efforts. This study investigates whether state-of-the-art Vision Transformer (ViT) foundation models can reduce thousands of unlabeled animal images ",
    "url": "https://arxiv.org/abs/2602.03894",
    "source": "Arxiv AI"
  },
  {
    "title": "Byzantine Machine Learning: MultiKrum and an optimal notion of robustness",
    "summary": "arXiv:2602.03899v1 Announce Type: cross Abstract: Aggregation rules are the cornerstone of distributed (or federated) learning in the presence of adversaries, under the so-called Byzantine threat model. They are also interesting mathematical objects from the point of view of robust mean estimation. The Krum aggregation rule has been extensively stu",
    "url": "https://arxiv.org/abs/2602.03899",
    "source": "Arxiv AI"
  },
  {
    "title": "All-Atom GPCR-Ligand Simulation via Residual Isometric Latent Flow",
    "summary": "arXiv:2602.03902v1 Announce Type: cross Abstract: G-protein-coupled receptors (GPCRs), primary targets for over one-third of approved therapeutics, rely on intricate conformational transitions to transduce signals. While Molecular Dynamics (MD) is essential for elucidating this transduction process, particularly within ligand-bound complexes, conve",
    "url": "https://arxiv.org/abs/2602.03902",
    "source": "Arxiv AI"
  },
  {
    "title": "GeoIB: Geometry-Aware Information Bottleneck via Statistical-Manifold Compression",
    "summary": "arXiv:2602.03906v1 Announce Type: cross Abstract: Information Bottleneck (IB) is widely used, but in deep learning, it is usually implemented through tractable surrogates, such as variational bounds or neural mutual information (MI) estimators, rather than directly controlling the MI I(X;Z) itself. The looseness and estimator-dependent bias can mak",
    "url": "https://arxiv.org/abs/2602.03906",
    "source": "Arxiv AI"
  },
  {
    "title": "HY3D-Bench: Generation of 3D Assets",
    "summary": "arXiv:2602.03907v1 Announce Type: cross Abstract: While recent advances in neural representations and generative models have revolutionized 3D content creation, the field remains constrained by significant data processing bottlenecks. To address this, we introduce HY3D-Bench, an open-source ecosystem designed to establish a unified, high-quality fo",
    "url": "https://arxiv.org/abs/2602.03907",
    "source": "Arxiv AI"
  },
  {
    "title": "Entropy-Aware Structural Alignment for Zero-Shot Handwritten Chinese Character Recognition",
    "summary": "arXiv:2602.03913v1 Announce Type: cross Abstract: Zero-shot Handwritten Chinese Character Recognition (HCCR) aims to recognize unseen characters by leveraging radical-based semantic compositions. However, existing approaches often treat characters as flat radical sequences, neglecting the hierarchical topology and the uneven information density of ",
    "url": "https://arxiv.org/abs/2602.03913",
    "source": "Arxiv AI"
  },
  {
    "title": "Phaedra: Learning High-Fidelity Discrete Tokenization for the Physical Science",
    "summary": "arXiv:2602.03915v1 Announce Type: cross Abstract: Tokens are discrete representations that allow modern deep learning to scale by transforming high-dimensional data into sequences that can be efficiently learned, generated, and generalized to new tasks. These have become foundational for image and video generation and, more recently, physical simul",
    "url": "https://arxiv.org/abs/2602.03915",
    "source": "Arxiv AI"
  },
  {
    "title": "SpecMD: A Comprehensive Study On Speculative Expert Prefetching",
    "summary": "arXiv:2602.03921v1 Announce Type: cross Abstract: Mixture-of-Experts (MoE) models enable sparse expert activation, meaning that only a subset of the model's parameters is used during each inference. However, to translate this sparsity into practical performance, an expert caching mechanism is required. Previous works have proposed hardware-centric ",
    "url": "https://arxiv.org/abs/2602.03921",
    "source": "Arxiv AI"
  },
  {
    "title": "WIND: Weather Inverse Diffusion for Zero-Shot Atmospheric Modeling",
    "summary": "arXiv:2602.03924v1 Announce Type: cross Abstract: Deep learning has revolutionized weather and climate modeling, yet the current landscape remains fragmented: highly specialized models are typically trained individually for distinct tasks. To unify this landscape, we introduce WIND, a single pre-trained foundation model capable of replacing special",
    "url": "https://arxiv.org/abs/2602.03924",
    "source": "Arxiv AI"
  },
  {
    "title": "First-Principles AI finds crystallization of fractional quantum Hall liquids",
    "summary": "arXiv:2602.03927v1 Announce Type: cross Abstract: When does a fractional quantum Hall (FQH) liquid crystallize? Addressing this question requires a framework that treats fractionalization and crystallization on equal footing, especially in strong Landau-level mixing regime. Here, we introduce MagNet, a self-attention neural-network variational wave",
    "url": "https://arxiv.org/abs/2602.03927",
    "source": "Arxiv AI"
  },
  {
    "title": "Linguistic Blind Spots in Clinical Decision Extraction",
    "summary": "arXiv:2602.03942v1 Announce Type: cross Abstract: Extracting medical decisions from clinical notes is a key step for clinical decision support and patient-facing care summaries. We study how the linguistic characteristics of clinical decisions vary across decision categories and whether these differences explain extraction failures. Using MedDec di",
    "url": "https://arxiv.org/abs/2602.03942",
    "source": "Arxiv AI"
  },
  {
    "title": "Semantic Rate Distortion and Posterior Design: Compute Constraints, Multimodality, and Strategic Inference",
    "summary": "arXiv:2602.03949v1 Announce Type: cross Abstract: We study strategic Gaussian semantic compression under rate and compute constraints, where an encoder and decoder optimize distinct quadratic objectives. A latent Gaussian state generates a task dependent semantic variable, and the decoder best responds via MMSE estimation, reducing the encoder's pr",
    "url": "https://arxiv.org/abs/2602.03949",
    "source": "Arxiv AI"
  },
  {
    "title": "Structural shifts in institutional participation and collaboration within the AI arXiv preprint research ecosystem",
    "summary": "arXiv:2602.03969v1 Announce Type: cross Abstract: The emergence of large language models (LLMs) represents a significant technological shift within the scientific ecosystem, particularly within the field of artificial intelligence (AI). This paper examines structural changes in the AI research landscape using a dataset of arXiv preprints (cs.AI) fr",
    "url": "https://arxiv.org/abs/2602.03969",
    "source": "Arxiv AI"
  },
  {
    "title": "Fixed Budget is No Harder Than Fixed Confidence in Best-Arm Identification up to Logarithmic Factors",
    "summary": "arXiv:2602.03972v1 Announce Type: cross Abstract: The best-arm identification (BAI) problem is one of the most fundamental problems in interactive machine learning, which has two flavors: the fixed-budget setting (FB) and the fixed-confidence setting (FC). For $K$-armed bandits with the unique best arm, the optimal sample complexities for both sett",
    "url": "https://arxiv.org/abs/2602.03972",
    "source": "Arxiv AI"
  },
  {
    "title": "Transformers perform adaptive partial pooling",
    "summary": "arXiv:2602.03980v1 Announce Type: cross Abstract: Because language is creative, any reasonable language model must generalize, deciding what to say in novel contexts by using information from similar contexts. But what about contexts that are not novel but merely infrequent? In hierarchical regression, the model's predictions for behavior in a cont",
    "url": "https://arxiv.org/abs/2602.03980",
    "source": "Arxiv AI"
  },
  {
    "title": "DeXposure-FM: A Time-series, Graph Foundation Model for Credit Exposures and Stability on Decentralized Financial Networks",
    "summary": "arXiv:2602.03981v1 Announce Type: cross Abstract: Credit exposure in Decentralized Finance (DeFi) is often implicit and token-mediated, creating a dense web of inter-protocol dependencies. Thus, a shock to one token may result in significant and uncontrolled contagion effects. As the DeFi ecosystem becomes increasingly linked with traditional finan",
    "url": "https://arxiv.org/abs/2602.03981",
    "source": "Arxiv AI"
  },
  {
    "title": "When Chains of Thought Don't Matter: Causal Bypass in Large Language Models",
    "summary": "arXiv:2602.03994v1 Announce Type: cross Abstract: Chain-of-thought (CoT) prompting is widely assumed to expose a model's reasoning process and improve transparency. We attempted to enforce this assumption by penalizing unfaithful reasoning, but found that surface-level compliance does not guarantee causal reliance. Our central finding is negative: ",
    "url": "https://arxiv.org/abs/2602.03994",
    "source": "Arxiv AI"
  },
  {
    "title": "Rational ANOVA Networks",
    "summary": "arXiv:2602.04006v1 Announce Type: cross Abstract: Deep neural networks typically treat nonlinearities as fixed primitives (e.g., ReLU), limiting both interpretability and the granularity of control over the induced function class. While recent additive models (like KANs) attempt to address this using splines, they often suffer from computational in",
    "url": "https://arxiv.org/abs/2602.04006",
    "source": "Arxiv AI"
  },
  {
    "title": "PromptSplit: Revealing Prompt-Level Disagreement in Generative Models",
    "summary": "arXiv:2602.04009v1 Announce Type: cross Abstract: Prompt-guided generative AI models have rapidly expanded across vision and language domains, producing realistic and diverse outputs from textual inputs. The growing variety of such models, trained with different data and architectures, calls for principled methods to identify which types of prompts",
    "url": "https://arxiv.org/abs/2602.04009",
    "source": "Arxiv AI"
  },
  {
    "title": "Understanding and Guiding Layer Placement in Parameter-Efficient Fine-Tuning of Large Language Models",
    "summary": "arXiv:2602.04019v1 Announce Type: cross Abstract: As large language models (LLMs) continue to grow, the cost of full-parameter fine-tuning has made parameter-efficient fine-tuning (PEFT) the default strategy for downstream adaptation. Constraints from inference latency in scalable serving and fine-tuning cost in edge or rapid-deployment settings ma",
    "url": "https://arxiv.org/abs/2602.04019",
    "source": "Arxiv AI"
  },
  {
    "title": "PluRel: Synthetic Data unlocks Scaling Laws for Relational Foundation Models",
    "summary": "arXiv:2602.04029v1 Announce Type: cross Abstract: Relational Foundation Models (RFMs) facilitate data-driven decision-making by learning from complex multi-table databases. However, the diverse relational databases needed to train such models are rarely public due to privacy constraints. While there are methods to generate synthetic tabular data of",
    "url": "https://arxiv.org/abs/2602.04029",
    "source": "Arxiv AI"
  },
  {
    "title": "On the Credibility of Evaluating LLMs using Survey Questions",
    "summary": "arXiv:2602.04033v1 Announce Type: cross Abstract: Recent studies evaluate the value orientation of large language models (LLMs) using adapted social surveys, typically by prompting models with survey questions and comparing their responses to average human responses. This paper identifies limitations in this methodology that, depending on the exact",
    "url": "https://arxiv.org/abs/2602.04033",
    "source": "Arxiv AI"
  },
  {
    "title": "Principles of Lipschitz continuity in neural networks",
    "summary": "arXiv:2602.04078v1 Announce Type: cross Abstract: Deep learning has achieved remarkable success across a wide range of domains, significantly expanding the frontiers of what is achievable in artificial intelligence. Yet, despite these advances, critical challenges remain -- most notably, ensuring robustness to small input perturbations and generali",
    "url": "https://arxiv.org/abs/2602.04078",
    "source": "Arxiv AI"
  },
  {
    "title": "Structure-Informed Estimation for Pilot-Limited MIMO Channels via Tensor Decomposition",
    "summary": "arXiv:2602.04083v1 Announce Type: cross Abstract: Channel estimation in wideband multiple-input multiple-output (MIMO) systems faces fundamental pilot overhead limitations in high-dimensional beyond-5G and sixth-generation (6G) scenarios. This paper presents a hybrid tensor-neural architecture that formulates pilot-limited channel estimation as low",
    "url": "https://arxiv.org/abs/2602.04083",
    "source": "Arxiv AI"
  },
  {
    "title": "A computational account of dreaming: learning and memory consolidation",
    "summary": "arXiv:2602.04095v1 Announce Type: cross Abstract: A number of studies have concluded that dreaming is mostly caused by randomly arriving internal signals because \"dream contents are random impulses\", and argued that dream sleep is unlikely to play an important part in our intellectual capacity. On the contrary, numerous functional studies have reve",
    "url": "https://arxiv.org/abs/2602.04095",
    "source": "Arxiv AI"
  },
  {
    "title": "DMS2F-HAD: A Dual-branch Mamba-based Spatial-Spectral Fusion Network for Hyperspectral Anomaly Detection",
    "summary": "arXiv:2602.04102v1 Announce Type: cross Abstract: Hyperspectral anomaly detection (HAD) aims to identify rare and irregular targets in high-dimensional hyperspectral images (HSIs), which are often noisy and unlabelled data. Existing deep learning methods either fail to capture long-range spectral dependencies (e.g., convolutional neural networks) o",
    "url": "https://arxiv.org/abs/2602.04102",
    "source": "Arxiv AI"
  },
  {
    "title": "Tinker Tales: Supporting Child-AI Collaboration through Co-Creative Storytelling with Educational Scaffolding",
    "summary": "arXiv:2602.04109v1 Announce Type: cross Abstract: Artificial intelligence (AI) is increasingly framed as a collaborative partner in creative activities, yet children's interactions with AI have largely been studied in AI-led instructional settings rather than co-creative collaboration. This leaves open questions about how children can meaningfully ",
    "url": "https://arxiv.org/abs/2602.04109",
    "source": "Arxiv AI"
  },
  {
    "title": "Toward Effective Multimodal Graph Foundation Model: A Divide-and-Conquer Based Approach",
    "summary": "arXiv:2602.04116v1 Announce Type: cross Abstract: Graph Foundation Models (GFMs) have achieved remarkable success in generalizing across diverse domains. However, they mainly focus on Text-Attributed Graphs (TAGs), leaving Multimodal-Attributed Graphs (MAGs) largely untapped. Developing Multimodal Graph Foundation Models (MGFMs) allows for leveragi",
    "url": "https://arxiv.org/abs/2602.04116",
    "source": "Arxiv AI"
  },
  {
    "title": "Scalable Explainability-as-a-Service (XaaS) for Edge AI Systems",
    "summary": "arXiv:2602.04120v1 Announce Type: cross Abstract: Though Explainable AI (XAI) has made significant advancements, its inclusion in edge and IoT systems is typically ad-hoc and inefficient. Most current methods are \"coupled\" in such a way that they generate explanations simultaneously with model inferences. As a result, these approaches incur redunda",
    "url": "https://arxiv.org/abs/2602.04120",
    "source": "Arxiv AI"
  },
  {
    "title": "From Lemmas to Dependencies: What Signals Drive Light Verbs Classification?",
    "summary": "arXiv:2602.04127v1 Announce Type: cross Abstract: Light verb constructions (LVCs) are a challenging class of verbal multiword expressions, especially in Turkish, where rich morphology and productive complex predicates create minimal contrasts between idiomatic predicate meanings and literal verb--argument uses. This paper asks what signals drive LV",
    "url": "https://arxiv.org/abs/2602.04127",
    "source": "Arxiv AI"
  },
  {
    "title": "KGLAMP: Knowledge Graph-guided Language model for Adaptive Multi-robot Planning and Replanning",
    "summary": "arXiv:2602.04129v1 Announce Type: cross Abstract: Heterogeneous multi-robot systems are increasingly deployed in long-horizon missions that require coordination among robots with diverse capabilities. However, existing planning approaches struggle to construct accurate symbolic representations and maintain plan consistency in dynamic environments. ",
    "url": "https://arxiv.org/abs/2602.04129",
    "source": "Arxiv AI"
  },
  {
    "title": "JSynFlow: Japanese Synthesised Flowchart Visual Question Answering Dataset built with Large Language Models",
    "summary": "arXiv:2602.04142v2 Announce Type: cross Abstract: Vision and language models (VLMs) are expected to analyse complex documents, such as those containing flowcharts, through a question-answering (QA) interface. The ability to recognise and interpret these flowcharts is in high demand, as they provide valuable insights unavailable in text-only explana",
    "url": "https://arxiv.org/abs/2602.04142",
    "source": "Arxiv AI"
  },
  {
    "title": "MA3DSG: Multi-Agent 3D Scene Graph Generation for Large-Scale Indoor Environments",
    "summary": "arXiv:2602.04152v1 Announce Type: cross Abstract: Current 3D scene graph generation (3DSGG) approaches heavily rely on a single-agent assumption and small-scale environments, exhibiting limited scalability to real-world scenarios. In this work, we introduce Multi-Agent 3D Scene Graph Generation (MA3DSG) model, the first framework designed to tackle",
    "url": "https://arxiv.org/abs/2602.04152",
    "source": "Arxiv AI"
  },
  {
    "title": "Pruning for Generalization: A Transfer-Oriented Spatiotemporal Graph Framework",
    "summary": "arXiv:2602.04153v1 Announce Type: cross Abstract: Multivariate time series forecasting in graph-structured domains is critical for real-world applications, yet existing spatiotemporal models often suffer from performance degradation under data scarcity and cross-domain shifts. We address these challenges through the lens of structure-aware context ",
    "url": "https://arxiv.org/abs/2602.04153",
    "source": "Arxiv AI"
  },
  {
    "title": "Improving 2D Diffusion Models for 3D Medical Imaging with Inter-Slice Consistent Stochasticity",
    "summary": "arXiv:2602.04162v1 Announce Type: cross Abstract: 3D medical imaging is in high demand and essential for clinical diagnosis and scientific research. Currently, diffusion models (DMs) have become an effective tool for medical imaging reconstruction thanks to their ability to learn rich, high-quality data priors. However, learning the 3D data distrib",
    "url": "https://arxiv.org/abs/2602.04162",
    "source": "Arxiv AI"
  },
  {
    "title": "Topology-Aware Revival for Efficient Sparse Training",
    "summary": "arXiv:2602.04166v1 Announce Type: cross Abstract: Static sparse training is a promising route to efficient learning by committing to a fixed mask pattern, yet the constrained structure reduces robustness. Early pruning decisions can lock the network into a brittle structure that is difficult to escape, especially in deep reinforcement learning (RL)",
    "url": "https://arxiv.org/abs/2602.04166",
    "source": "Arxiv AI"
  },
  {
    "title": "HoloEv-Net: Efficient Event-based Action Recognition via Holographic Spatial Embedding and Global Spectral Gating",
    "summary": "arXiv:2602.04182v1 Announce Type: cross Abstract: Event-based Action Recognition (EAR) has attracted significant attention due to the high temporal resolution and high dynamic range of event cameras. However, existing methods typically suffer from (i) the computational redundancy of dense voxel representations, (ii) structural redundancy inherent i",
    "url": "https://arxiv.org/abs/2602.04182",
    "source": "Arxiv AI"
  },
  {
    "title": "Natural Language Instructions for Scene-Responsive Human-in-the-Loop Motion Planning in Autonomous Driving using Vision-Language-Action Models",
    "summary": "arXiv:2602.04184v1 Announce Type: cross Abstract: Instruction-grounded driving, where passenger language guides trajectory planning, requires vehicles to understand intent before motion. However, most prior instruction-following planners rely on simulation or fixed command vocabularies, limiting real-world generalization. doScenes, the first real-w",
    "url": "https://arxiv.org/abs/2602.04184",
    "source": "Arxiv AI"
  },
  {
    "title": "From Helpfulness to Toxic Proactivity: Diagnosing Behavioral Misalignment in LLM Agents",
    "summary": "arXiv:2602.04197v1 Announce Type: cross Abstract: The enhanced capabilities of LLM-based agents come with an emergency for model planning and tool-use abilities. Attributing to helpful-harmless trade-off from LLM alignment, agents typically also inherit the flaw of \"over-refusal\", which is a passive failure mode. However, the proactive planning and",
    "url": "https://arxiv.org/abs/2602.04197",
    "source": "Arxiv AI"
  },
  {
    "title": "Enforcing Monotonic Progress in Legal Cross-Examination: Preventing Long-Horizon Stagnation in LLM-Based Inquiry",
    "summary": "arXiv:2602.04206v1 Announce Type: cross Abstract: Large language models (LLMs) exhibit impressive linguistic fluency but struggle to reliably complete long-horizon tasks under explicit procedural constraints. In legal cross-examination, purely proba-bilistic generation often maintains behavioral coherence while failing to ensure procedural advancem",
    "url": "https://arxiv.org/abs/2602.04206",
    "source": "Arxiv AI"
  },
  {
    "title": "SCALE: Self-uncertainty Conditioned Adaptive Looking and Execution for Vision-Language-Action Models",
    "summary": "arXiv:2602.04208v1 Announce Type: cross Abstract: Vision-Language-Action (VLA) models have emerged as a promising paradigm for general-purpose robotic control, with test-time scaling (TTS) gaining attention to enhance robustness beyond training. However, existing TTS methods for VLAs require additional training, verifiers, and multiple forward pass",
    "url": "https://arxiv.org/abs/2602.04208",
    "source": "Arxiv AI"
  },
  {
    "title": "Language Models Struggle to Use Representations Learned In-Context",
    "summary": "arXiv:2602.04212v1 Announce Type: cross Abstract: Though large language models (LLMs) have enabled great success across a wide variety of tasks, they still appear to fall short of one of the loftier goals of artificial intelligence research: creating an artificial system that can adapt its behavior to radically new contexts upon deployment. One imp",
    "url": "https://arxiv.org/abs/2602.04212",
    "source": "Arxiv AI"
  },
  {
    "title": "OAT: Ordered Action Tokenization",
    "summary": "arXiv:2602.04215v1 Announce Type: cross Abstract: Autoregressive policies offer a compelling foundation for scalable robot learning by enabling discrete abstraction, token-level reasoning, and flexible inference. However, applying autoregressive modeling to continuous robot actions requires an effective action tokenization scheme. Existing approach",
    "url": "https://arxiv.org/abs/2602.04215",
    "source": "Arxiv AI"
  },
  {
    "title": "RAPO: Risk-Aware Preference Optimization for Generalizable Safe Reasoning",
    "summary": "arXiv:2602.04224v1 Announce Type: cross Abstract: Large Reasoning Models (LRMs) have achieved tremendous success with their chain-of-thought (CoT) reasoning, yet also face safety issues similar to those of basic language models. In particular, while algorithms are designed to guide them to deliberately refuse harmful prompts with safe reasoning, th",
    "url": "https://arxiv.org/abs/2602.04224",
    "source": "Arxiv AI"
  },
  {
    "title": "ACIL: Active Class Incremental Learning for Image Classification",
    "summary": "arXiv:2602.04252v1 Announce Type: cross Abstract: Continual learning (or class incremental learning) is a realistic learning scenario for computer vision systems, where deep neural networks are trained on episodic data, and the data from previous episodes are generally inaccessible to the model. Existing research in this domain has primarily focuse",
    "url": "https://arxiv.org/abs/2602.04252",
    "source": "Arxiv AI"
  },
  {
    "title": "AppleVLM: End-to-end Autonomous Driving with Advanced Perception and Planning-Enhanced Vision-Language Models",
    "summary": "arXiv:2602.04256v1 Announce Type: cross Abstract: End-to-end autonomous driving has emerged as a promising paradigm integrating perception, decision-making, and control within a unified learning framework. Recently, Vision-Language Models (VLMs) have gained significant attention for their potential to enhance the robustness and generalization of en",
    "url": "https://arxiv.org/abs/2602.04256",
    "source": "Arxiv AI"
  },
  {
    "title": "From Dead Neurons to Deep Approximators: Deep Bernstein Networks as a Provable Alternative to Residual Layers",
    "summary": "arXiv:2602.04264v1 Announce Type: cross Abstract: Residual connections are the de facto standard for mitigating vanishing gradients, yet they impose structural constraints and fail to address the inherent inefficiencies of piecewise linear activations. We show that Deep Bernstein Networks (which utilizes Bernstein polynomials as activation function",
    "url": "https://arxiv.org/abs/2602.04264",
    "source": "Arxiv AI"
  },
  {
    "title": "Thickening-to-Thinning: Reward Shaping via Human-Inspired Learning Dynamics for LLM Reasoning",
    "summary": "arXiv:2602.04265v1 Announce Type: cross Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a promising paradigm for enhancing reasoning in Large Language Models (LLMs). However, it frequently encounters challenges such as entropy collapse, excessive verbosity, and insufficient exploration for hard problems. Crucially, ex",
    "url": "https://arxiv.org/abs/2602.04265",
    "source": "Arxiv AI"
  },
  {
    "title": "SkeletonGaussian: Editable 4D Generation through Gaussian Skeletonization",
    "summary": "arXiv:2602.04271v1 Announce Type: cross Abstract: 4D generation has made remarkable progress in synthesizing dynamic 3D objects from input text, images, or videos. However, existing methods often represent motion as an implicit deformation field, which limits direct control and editability. To address this issue, we propose SkeletonGaussian, a nove",
    "url": "https://arxiv.org/abs/2602.04271",
    "source": "Arxiv AI"
  },
  {
    "title": "Multi Objective Design Optimization of Non Pneumatic Passenger Car Tires Using Finite Element Modeling, Machine Learning, and Particle swarm Optimization and Bayesian Optimization Algorithms",
    "summary": "arXiv:2602.04277v1 Announce Type: cross Abstract: Non Pneumatic tires offer a promising alternative to pneumatic tires. However, their discontinuous spoke structures present challenges in stiffness tuning, durability, and high speed vibration. This study introduces an integrated generative design and machine learning driven framework to optimize UP",
    "url": "https://arxiv.org/abs/2602.04277",
    "source": "Arxiv AI"
  },
  {
    "title": "Contextual Drag: How Errors in the Context Affect LLM Reasoning",
    "summary": "arXiv:2602.04288v1 Announce Type: cross Abstract: Central to many self-improvement pipelines for large language models (LLMs) is the assumption that models can improve by reflecting on past mistakes. We study a phenomenon termed contextual drag: the presence of failed attempts in the context biases subsequent generations toward structurally similar",
    "url": "https://arxiv.org/abs/2602.04288",
    "source": "Arxiv AI"
  },
  {
    "title": "Disentangling Causal Importance from Emergent Structure in Multi-Expert Orchestration",
    "summary": "arXiv:2602.04291v1 Announce Type: cross Abstract: Multi-expert systems, where multiple Large Language Models (LLMs) collaborate to solve complex tasks, are increasingly adopted for high-performance reasoning and generation. However, the orchestration policies governing expert interaction and sequencing remain largely opaque. We introduce INFORM, an",
    "url": "https://arxiv.org/abs/2602.04291",
    "source": "Arxiv AI"
  },
  {
    "title": "How Few-shot Demonstrations Affect Prompt-based Defenses Against LLM Jailbreak Attacks",
    "summary": "arXiv:2602.04294v1 Announce Type: cross Abstract: Large Language Models (LLMs) face increasing threats from jailbreak attacks that bypass safety alignment. While prompt-based defenses such as Role-Oriented Prompts (RoP) and Task-Oriented Prompts (ToP) have shown effectiveness, the role of few-shot demonstrations in these defense strategies remains ",
    "url": "https://arxiv.org/abs/2602.04294",
    "source": "Arxiv AI"
  },
  {
    "title": "ProxyWar: Dynamic Assessment of LLM Code Generation in Game Arenas",
    "summary": "arXiv:2602.04296v1 Announce Type: cross Abstract: Large language models (LLMs) have revolutionized automated code generation, yet the evaluation of their real-world effectiveness remains limited by static benchmarks and simplistic metrics. We present ProxyWar, a novel framework that systematically assesses code generation quality by embedding LLM-g",
    "url": "https://arxiv.org/abs/2602.04296",
    "source": "Arxiv AI"
  },
  {
    "title": "Revisiting Prompt Sensitivity in Large Language Models for Text Classification: The Role of Prompt Underspecification",
    "summary": "arXiv:2602.04297v1 Announce Type: cross Abstract: Large language models (LLMs) are widely used as zero-shot and few-shot classifiers, where task behaviour is largely controlled through prompting. A growing number of works have observed that LLMs are sensitive to prompt variations, with small changes leading to large changes in performance. However,",
    "url": "https://arxiv.org/abs/2602.04297",
    "source": "Arxiv AI"
  },
  {
    "title": "Beyond Static Cropping: Layer-Adaptive Visual Localization and Decoding Enhancement",
    "summary": "arXiv:2602.04304v1 Announce Type: cross Abstract: Large Vision-Language Models (LVLMs) have advanced rapidly by aligning visual patches with the text embedding space, but a fixed visual-token budget forces images to be resized to a uniform pretraining resolution, often erasing fine-grained details and causing hallucinations via over-reliance on lan",
    "url": "https://arxiv.org/abs/2602.04304",
    "source": "Arxiv AI"
  },
  {
    "title": "DeFrame: Debiasing Large Language Models Against Framing Effects",
    "summary": "arXiv:2602.04306v1 Announce Type: cross Abstract: As large language models (LLMs) are increasingly deployed in real-world applications, ensuring their fair responses across demographics has become crucial. Despite many efforts, an ongoing challenge is hidden bias: LLMs appear fair under standard evaluations, but can produce biased responses outside",
    "url": "https://arxiv.org/abs/2602.04306",
    "source": "Arxiv AI"
  },
  {
    "title": "Efficient Equivariant High-Order Crystal Tensor Prediction via Cartesian Local-Environment Many-Body Coupling",
    "summary": "arXiv:2602.04323v1 Announce Type: cross Abstract: End-to-end prediction of high-order crystal tensor properties from atomic structures remains challenging: while spherical-harmonic equivariant models are expressive, their Clebsch-Gordan tensor products incur substantial compute and memory costs for higher-order targets. We propose the Cartesian Env",
    "url": "https://arxiv.org/abs/2602.04323",
    "source": "Arxiv AI"
  },
  {
    "title": "Fine-tuning Pre-trained Vision-Language Models in a Human-Annotation-Free Manner",
    "summary": "arXiv:2602.04337v1 Announce Type: cross Abstract: Large-scale vision-language models (VLMs) such as CLIP exhibit strong zero-shot generalization, but adapting them to downstream tasks typically requires costly labeled data. Existing unsupervised self-training methods rely on pseudo-labeling, yet often suffer from unreliable confidence filtering, co",
    "url": "https://arxiv.org/abs/2602.04337",
    "source": "Arxiv AI"
  },
  {
    "title": "Explicit Uncertainty Modeling for Active CLIP Adaptation with Dual Prompt Tuning",
    "summary": "arXiv:2602.04340v1 Announce Type: cross Abstract: Pre-trained vision-language models such as CLIP exhibit strong transferability, yet adapting them to downstream image classification tasks under limited annotation budgets remains challenging. In active learning settings, the model must select the most informative samples for annotation from a large",
    "url": "https://arxiv.org/abs/2602.04340",
    "source": "Arxiv AI"
  },
  {
    "title": "UnMaskFork: Test-Time Scaling for Masked Diffusion via Deterministic Action Branching",
    "summary": "arXiv:2602.04344v1 Announce Type: cross Abstract: Test-time scaling strategies have effectively leveraged inference-time compute to enhance the reasoning abilities of Autoregressive Large Language Models. In this work, we demonstrate that Masked Diffusion Language Models (MDLMs) are inherently amenable to advanced search strategies, owing to their ",
    "url": "https://arxiv.org/abs/2602.04344",
    "source": "Arxiv AI"
  },
  {
    "title": "VecSet-Edit: Unleashing Pre-trained LRM for Mesh Editing from Single Image",
    "summary": "arXiv:2602.04349v1 Announce Type: cross Abstract: 3D editing has emerged as a critical research area to provide users with flexible control over 3D assets. While current editing approaches predominantly focus on 3D Gaussian Splatting or multi-view images, the direct editing of 3D meshes remains underexplored. Prior attempts, such as VoxHammer, rely",
    "url": "https://arxiv.org/abs/2602.04349",
    "source": "Arxiv AI"
  },
  {
    "title": "Counterfactual Explanations for Hypergraph Neural Networks",
    "summary": "arXiv:2602.04360v1 Announce Type: cross Abstract: Hypergraph neural networks (HGNNs) effectively model higher-order interactions in many real-world systems but remain difficult to interpret, limiting their deployment in high-stakes settings. We introduce CF-HyperGNNExplainer, a counterfactual explanation method for HGNNs that identifies the minimal",
    "url": "https://arxiv.org/abs/2602.04360",
    "source": "Arxiv AI"
  },
  {
    "title": "SparVAR: Exploring Sparsity in Visual AutoRegressive Modeling for Training-Free Acceleration",
    "summary": "arXiv:2602.04361v1 Announce Type: cross Abstract: Visual AutoRegressive (VAR) modeling has garnered significant attention for its innovative next-scale prediction paradigm. However, mainstream VAR paradigms attend to all tokens across historical scales at each autoregressive step. As the next scale resolution grows, the computational complexity of ",
    "url": "https://arxiv.org/abs/2602.04361",
    "source": "Arxiv AI"
  },
  {
    "title": "Beyond KL Divergence: Policy Optimization with Flexible Bregman Divergences for LLM Reasoning",
    "summary": "arXiv:2602.04380v1 Announce Type: cross Abstract: Policy optimization methods like Group Relative Policy Optimization (GRPO) and its variants have achieved strong results on mathematical reasoning and code generation tasks. Despite extensive exploration of reward processing strategies and training dynamics, all existing group-based methods exclusiv",
    "url": "https://arxiv.org/abs/2602.04380",
    "source": "Arxiv AI"
  },
  {
    "title": "Enabling Real-Time Colonoscopic Polyp Segmentation on Commodity CPUs via Ultra-Lightweight Architecture",
    "summary": "arXiv:2602.04381v1 Announce Type: cross Abstract: Early detection of colorectal cancer hinges on real-time, accurate polyp identification and resection. Yet current high-precision segmentation models rely on GPUs, making them impractical to deploy in primary hospitals, mobile endoscopy units, or capsule robots. To bridge this gap, we present the Ul",
    "url": "https://arxiv.org/abs/2602.04381",
    "source": "Arxiv AI"
  },
  {
    "title": "Blockchain Federated Learning for Sustainable Retail: Reducing Waste through Collaborative Demand Forecasting",
    "summary": "arXiv:2602.04384v1 Announce Type: cross Abstract: Effective demand forecasting is crucial for reducing food waste. However, data privacy concerns often hinder collaboration among retailers, limiting the potential for improved predictive accuracy. In this study, we explore the application of Federated Learning (FL) in Sustainable Supply Chain Manage",
    "url": "https://arxiv.org/abs/2602.04384",
    "source": "Arxiv AI"
  },
  {
    "title": "LoRDO: Distributed Low-Rank Optimization with Infrequent Communication",
    "summary": "arXiv:2602.04396v1 Announce Type: cross Abstract: Distributed training of foundation models via $\\texttt{DDP}$ is limited by interconnect bandwidth. While infrequent communication strategies reduce synchronization frequency, they remain bottlenecked by the memory and communication requirements of optimizer states. Low-rank optimizers can alleviate ",
    "url": "https://arxiv.org/abs/2602.04396",
    "source": "Arxiv AI"
  },
  {
    "title": "Bi-directional Bias Attribution: Debiasing Large Language Models without Modifying Prompts",
    "summary": "arXiv:2602.04398v1 Announce Type: cross Abstract: Large language models (LLMs) have demonstrated impressive capabilities across a wide range of natural language processing tasks. However, their outputs often exhibit social biases, raising fairness concerns. Existing debiasing methods, such as fine-tuning on additional datasets or prompt engineering",
    "url": "https://arxiv.org/abs/2602.04398",
    "source": "Arxiv AI"
  },
  {
    "title": "Performative Learning Theory",
    "summary": "arXiv:2602.04402v1 Announce Type: cross Abstract: Performative predictions influence the very outcomes they aim to forecast. We study performative predictions that affect a sample (e.g., only existing users of an app) and/or the whole population (e.g., all potential app users). This raises the question of how well models generalize under performati",
    "url": "https://arxiv.org/abs/2602.04402",
    "source": "Arxiv AI"
  },
  {
    "title": "History-Guided Iterative Visual Reasoning with Self-Correction",
    "summary": "arXiv:2602.04413v1 Announce Type: cross Abstract: Self-consistency methods are the core technique for improving the reasoning reliability of multimodal large language models (MLLMs). By generating multiple reasoning results through repeated sampling and selecting the best answer via voting, they play an important role in cross-modal tasks. However,",
    "url": "https://arxiv.org/abs/2602.04413",
    "source": "Arxiv AI"
  },
  {
    "title": "Med-MMFL: A Multimodal Federated Learning Benchmark in Healthcare",
    "summary": "arXiv:2602.04416v1 Announce Type: cross Abstract: Federated learning (FL) enables collaborative model training across decentralized medical institutions while preserving data privacy. However, medical FL benchmarks remain scarce, with existing efforts focusing mainly on unimodal or bimodal modalities and a limited range of medical tasks. This gap u",
    "url": "https://arxiv.org/abs/2602.04416",
    "source": "Arxiv AI"
  },
  {
    "title": "EMA Policy Gradient: Taming Reinforcement Learning for LLMs with EMA Anchor and Top-k KL",
    "summary": "arXiv:2602.04417v1 Announce Type: cross Abstract: Reinforcement Learning (RL) has enabled Large Language Models (LLMs) to acquire increasingly complex reasoning and agentic behaviors. In this work, we propose two simple techniques to improve policy gradient algorithms for LLMs. First, we replace the fixed anchor policy during RL with an Exponential",
    "url": "https://arxiv.org/abs/2602.04417",
    "source": "Arxiv AI"
  },
  {
    "title": "SPEAR: An Engineering Case Study of Multi-Agent Coordination for Smart Contract Auditing",
    "summary": "arXiv:2602.04418v1 Announce Type: cross Abstract: We present SPEAR, a multi-agent coordination framework for smart contract auditing that applies established MAS patterns in a realistic security analysis workflow. SPEAR models auditing as a coordinated mission carried out by specialized agents: a Planning Agent prioritizes contracts using risk-awar",
    "url": "https://arxiv.org/abs/2602.04418",
    "source": "Arxiv AI"
  },
  {
    "title": "No One-Size-Fits-All: Building Systems For Translation to Bashkir, Kazakh, Kyrgyz, Tatar and Chuvash Using Synthetic And Original Data",
    "summary": "arXiv:2602.04442v1 Announce Type: cross Abstract: We explore machine translation for five Turkic language pairs: Russian-Bashkir, Russian-Kazakh, Russian-Kyrgyz, English-Tatar, English-Chuvash. Fine-tuning nllb-200-distilled-600M with LoRA on synthetic data achieved chrF++ 49.71 for Kazakh and 46.94 for Bashkir. Prompting DeepSeek-V3.2 with retriev",
    "url": "https://arxiv.org/abs/2602.04442",
    "source": "Arxiv AI"
  },
  {
    "title": "Mixture of Masters: Sparse Chess Language Models with Player Routing",
    "summary": "arXiv:2602.04447v1 Announce Type: cross Abstract: Modern chess language models are dense transformers trained on millions of games played by thousands of high-rated individuals. However, these monolithic networks tend to collapse into mode-averaged behavior, where stylistic boundaries are blurred, and rare but effective strategies are suppressed. T",
    "url": "https://arxiv.org/abs/2602.04447",
    "source": "Arxiv AI"
  },
  {
    "title": "RASA: Routing-Aware Safety Alignment for Mixture-of-Experts Models",
    "summary": "arXiv:2602.04448v1 Announce Type: cross Abstract: Mixture-of-Experts (MoE) language models introduce unique challenges for safety alignment due to their sparse routing mechanisms, which can enable degenerate optimization behaviors under standard full-parameter fine-tuning. In our preliminary experiments, we observe that naively applying full-parame",
    "url": "https://arxiv.org/abs/2602.04448",
    "source": "Arxiv AI"
  },
  {
    "title": "Growth First, Care Second? Tracing the Landscape of LLM Value Preferences in Everyday Dilemmas",
    "summary": "arXiv:2602.04456v1 Announce Type: cross Abstract: People increasingly seek advice online from both human peers and large language model (LLM)-based chatbots. Such advice rarely involves identifying a single correct answer; instead, it typically requires navigating trade-offs among competing values. We aim to characterize how LLMs navigate value tra",
    "url": "https://arxiv.org/abs/2602.04456",
    "source": "Arxiv AI"
  },
  {
    "title": "Is Micro Domain-Adaptive Pre-Training Effective for Real-World Operations? Multi-Step Evaluation Reveals Potential and Bottlenecks",
    "summary": "arXiv:2602.04466v1 Announce Type: cross Abstract: When applying LLMs to real-world enterprise operations, LLMs need to handle proprietary knowledge in small domains of specific operations ($\\textbf{micro domains}$). A previous study shows micro domain-adaptive pre-training ($\\textbf{mDAPT}$) with fewer documents is effective, similarly to DAPT in l",
    "url": "https://arxiv.org/abs/2602.04466",
    "source": "Arxiv AI"
  },
  {
    "title": "LLM-Empowered Cooperative Content Caching in Vehicular Fog Caching-Assisted Platoon Networks",
    "summary": "arXiv:2602.04471v1 Announce Type: cross Abstract: This letter proposes a novel three-tier content caching architecture for Vehicular Fog Caching (VFC)-assisted platoon, where the VFC is formed by the vehicles driving near the platoon. The system strategically coordinates storage across local platoon vehicles, dynamic VFC clusters, and cloud server ",
    "url": "https://arxiv.org/abs/2602.04471",
    "source": "Arxiv AI"
  },
  {
    "title": "Discovering Mechanistic Models of Neural Activity: System Identification in an in Silico Zebrafish",
    "summary": "arXiv:2602.04492v1 Announce Type: cross Abstract: Constructing mechanistic models of neural circuits is a fundamental goal of neuroscience, yet verifying such models is limited by the lack of ground truth. To rigorously test model discovery, we establish an in silico testbed using neuromechanical simulations of a larval zebrafish as a transparent g",
    "url": "https://arxiv.org/abs/2602.04492",
    "source": "Arxiv AI"
  },
  {
    "title": "BrainVista: Modeling Naturalistic Brain Dynamics as Multimodal Next-Token Prediction",
    "summary": "arXiv:2602.04512v1 Announce Type: cross Abstract: Naturalistic fMRI characterizes the brain as a dynamic predictive engine driven by continuous sensory streams. However, modeling the causal forward evolution in realistic neural simulation is impeded by the timescale mismatch between multimodal inputs and the complex topology of cortical networks. T",
    "url": "https://arxiv.org/abs/2602.04512",
    "source": "Arxiv AI"
  },
  {
    "title": "Learning the Value Systems of Agents with Preference-based and Inverse Reinforcement Learning",
    "summary": "arXiv:2602.04518v1 Announce Type: cross Abstract: Agreement Technologies refer to open computer systems in which autonomous software agents interact with one another, typically on behalf of humans, in order to come to mutually acceptable agreements. With the advance of AI systems in recent years, it has become apparent that such agreements, in orde",
    "url": "https://arxiv.org/abs/2602.04518",
    "source": "Arxiv AI"
  },
  {
    "title": "SLUM-i: Semi-supervised Learning for Urban Mapping of Informal Settlements and Data Quality Benchmarking",
    "summary": "arXiv:2602.04525v1 Announce Type: cross Abstract: Rapid urban expansion has fueled the growth of informal settlements in major cities of low- and middle-income countries, with Lahore and Karachi in Pakistan and Mumbai in India serving as prominent examples. However, large-scale mapping of these settlements is severely constrained not only by the sc",
    "url": "https://arxiv.org/abs/2602.04525",
    "source": "Arxiv AI"
  },
  {
    "title": "LycheeDecode: Accelerating Long-Context LLM Inference via Hybrid-Head Sparse Decoding",
    "summary": "arXiv:2602.04541v1 Announce Type: cross Abstract: The proliferation of long-context large language models (LLMs) exposes a key bottleneck: the rapidly expanding key-value cache during decoding, which imposes heavy memory and latency costs. While recent approaches attempt to alleviate this by sharing a single set of crucial tokens across layers, suc",
    "url": "https://arxiv.org/abs/2602.04541",
    "source": "Arxiv AI"
  },
  {
    "title": "Continual Learning through Control Minimization",
    "summary": "arXiv:2602.04542v1 Announce Type: cross Abstract: Catastrophic forgetting remains a fundamental challenge for neural networks when tasks are trained sequentially. In this work, we reformulate continual learning as a control problem where learning and preservation signals compete within neural activity dynamics. We convert regularization penalties i",
    "url": "https://arxiv.org/abs/2602.04542",
    "source": "Arxiv AI"
  },
  {
    "title": "OmniRad: A Radiological Foundation Model for Multi-Task Medical Image Analysis",
    "summary": "arXiv:2602.04547v1 Announce Type: cross Abstract: Radiological analysis increasingly benefits from pretrained visual representations that can support heterogeneous downstream tasks across imaging modalities. In this work, we introduce OmniRad, a self-supervised radiological foundation model pretrained on 1.2 million medical images, designed with ra",
    "url": "https://arxiv.org/abs/2602.04547",
    "source": "Arxiv AI"
  },
  {
    "title": "Dual Mind World Model Inspired Network Digital Twin for Access Scheduling",
    "summary": "arXiv:2602.04566v1 Announce Type: cross Abstract: Emerging networked systems such as industrial IoT and real-time cyber-physical infrastructures demand intelligent scheduling strategies capable of adapting to dynamic traffic, deadlines, and interference constraints. In this work, we present a novel Digital Twin-enabled scheduling framework inspired",
    "url": "https://arxiv.org/abs/2602.04566",
    "source": "Arxiv AI"
  },
  {
    "title": "Trust The Typical",
    "summary": "arXiv:2602.04581v1 Announce Type: cross Abstract: Current approaches to LLM safety fundamentally rely on a brittle cat-and-mouse game of identifying and blocking known threats via guardrails. We argue for a fresh approach: robust safety comes not from enumerating what is harmful, but from deeply understanding what is safe. We introduce Trust The Ty",
    "url": "https://arxiv.org/abs/2602.04581",
    "source": "Arxiv AI"
  },
  {
    "title": "VILLAIN at AVerImaTeC: Verifying Image-Text Claims via Multi-Agent Collaboration",
    "summary": "arXiv:2602.04587v1 Announce Type: cross Abstract: This paper describes VILLAIN, a multimodal fact-checking system that verifies image-text claims through prompt-based multi-agent collaboration. For the AVerImaTeC shared task, VILLAIN employs vision-language model agents across multiple stages of fact-checking. Textual and visual evidence is retriev",
    "url": "https://arxiv.org/abs/2602.04587",
    "source": "Arxiv AI"
  },
  {
    "title": "RexBERT: Context Specialized Bidirectional Encoders for E-commerce",
    "summary": "arXiv:2602.04605v1 Announce Type: cross Abstract: Encoder-only transformers remain indispensable in retrieval, classification, and ranking systems where latency, stability, and cost are paramount. Most general purpose encoders, however, are trained on generic corpora with limited coverage of specialized domains. We introduce RexBERT, a family of BE",
    "url": "https://arxiv.org/abs/2602.04605",
    "source": "Arxiv AI"
  },
  {
    "title": "A Human-Centered Privacy Approach (HCP) to AI",
    "summary": "arXiv:2602.04616v1 Announce Type: cross Abstract: As the paradigm of Human-Centered AI (HCAI) gains prominence, its benefits to society are accompanied by significant ethical concerns, one of which is the protection of individual privacy. This chapter provides a comprehensive overview of privacy within HCAI, proposing a human-centered privacy (HCP)",
    "url": "https://arxiv.org/abs/2602.04616",
    "source": "Arxiv AI"
  },
  {
    "title": "Towards Structured, State-Aware, and Execution-Grounded Reasoning for Software Engineering Agents",
    "summary": "arXiv:2602.04640v1 Announce Type: cross Abstract: Software Engineering (SE) agents have shown promising abilities in supporting various SE tasks. Current SE agents remain fundamentally reactive, making decisions mainly based on conversation history and the most recent response. However, this reactive design provides no explicit structure or persist",
    "url": "https://arxiv.org/abs/2602.04640",
    "source": "Arxiv AI"
  },
  {
    "title": "Rethinking the Design Space of Reinforcement Learning for Diffusion Models: On the Importance of Likelihood Estimation Beyond Loss Design",
    "summary": "arXiv:2602.04663v1 Announce Type: cross Abstract: Reinforcement learning has been widely applied to diffusion and flow models for visual tasks such as text-to-image generation. However, these tasks remain challenging because diffusion models have intractable likelihoods, which creates a barrier for directly applying popular policy-gradient type met",
    "url": "https://arxiv.org/abs/2602.04663",
    "source": "Arxiv AI"
  },
  {
    "title": "Delving into Muon and Beyond: Deep Analysis and Extensions",
    "summary": "arXiv:2602.04669v1 Announce Type: cross Abstract: The Muon optimizer has recently attracted considerable attention for its strong empirical performance and use of orthogonalized updates on matrix-shaped parameters, yet its underlying mechanisms and relationship to adaptive optimizers such as Adam remain insufficiently understood. In this work, we a",
    "url": "https://arxiv.org/abs/2602.04669",
    "source": "Arxiv AI"
  },
  {
    "title": "Overstating Attitudes, Ignoring Networks: LLM Biases in Simulating Misinformation Susceptibility",
    "summary": "arXiv:2602.04674v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly used as proxies for human judgment in computational social science, yet their ability to reproduce patterns of susceptibility to misinformation remains unclear. We test whether LLM-simulated survey respondents, prompted with participant profiles drawn fr",
    "url": "https://arxiv.org/abs/2602.04674",
    "source": "Arxiv AI"
  },
  {
    "title": "Let Experts Feel Uncertainty: A Multi-Expert Label Distribution Approach to Probabilistic Time Series Forecasting",
    "summary": "arXiv:2602.04678v1 Announce Type: cross Abstract: Time series forecasting in real-world applications requires both high predictive accuracy and interpretable uncertainty quantification. Traditional point prediction methods often fail to capture the inherent uncertainty in time series data, while existing probabilistic approaches struggle to balance",
    "url": "https://arxiv.org/abs/2602.04678",
    "source": "Arxiv AI"
  },
  {
    "title": "Audio ControlNet for Fine-Grained Audio Generation and Editing",
    "summary": "arXiv:2602.04680v1 Announce Type: cross Abstract: We study the fine-grained text-to-audio (T2A) generation task. While recent models can synthesize high-quality audio from text descriptions, they often lack precise control over attributes such as loudness, pitch, and sound events. Unlike prior approaches that retrain models for specific control typ",
    "url": "https://arxiv.org/abs/2602.04680",
    "source": "Arxiv AI"
  },
  {
    "title": "DRMOT: A Dataset and Framework for RGBD Referring Multi-Object Tracking",
    "summary": "arXiv:2602.04692v1 Announce Type: cross Abstract: Referring Multi-Object Tracking (RMOT) aims to track specific targets based on language descriptions and is vital for interactive AI systems such as robotics and autonomous driving. However, existing RMOT models rely solely on 2D RGB data, making it challenging to accurately detect and associate tar",
    "url": "https://arxiv.org/abs/2602.04692",
    "source": "Arxiv AI"
  },
  {
    "title": "Addressing Corpus Knowledge Poisoning Attacks on RAG Using Sparse Attention",
    "summary": "arXiv:2602.04711v2 Announce Type: cross Abstract: Retrieval Augmented Generation (RAG) is a highly effective paradigm for keeping LLM-based responses up-to-date and reducing the likelihood of hallucinations. Yet, RAG was recently shown to be quite vulnerable to corpus knowledge poisoning: an attacker injects misleading documents to the corpus to st",
    "url": "https://arxiv.org/abs/2602.04711",
    "source": "Arxiv AI"
  },
  {
    "title": "SAR-RAG: ATR Visual Question Answering by Semantic Search, Retrieval, and MLLM Generation",
    "summary": "arXiv:2602.04712v1 Announce Type: cross Abstract: We present a visual-context image retrieval-augmented generation (ImageRAG) assisted AI agent for automatic target recognition (ATR) of synthetic aperture radar (SAR). SAR is a remote sensing method used in defense and security applications to detect and monitor the positions of military vehicles, w",
    "url": "https://arxiv.org/abs/2602.04712",
    "source": "Arxiv AI"
  },
  {
    "title": "Adaptive Prompt Elicitation for Text-to-Image Generation",
    "summary": "arXiv:2602.04713v1 Announce Type: cross Abstract: Aligning text-to-image generation with user intent remains challenging, for users who provide ambiguous inputs and struggle with model idiosyncrasies. We propose Adaptive Prompt Elicitation (APE), a technique that adaptively asks visual queries to help users refine prompts without extensive writing.",
    "url": "https://arxiv.org/abs/2602.04713",
    "source": "Arxiv AI"
  },
  {
    "title": "Identifying Intervenable and Interpretable Features via Orthogonality Regularization",
    "summary": "arXiv:2602.04718v1 Announce Type: cross Abstract: With recent progress on fine-tuning language models around a fixed sparse autoencoder, we disentangle the decoder matrix into almost orthogonal features. This reduces interference and superposition between the features, while keeping performance on the target dataset essentially unchanged. Our ortho",
    "url": "https://arxiv.org/abs/2602.04718",
    "source": "Arxiv AI"
  },
  {
    "title": "Supporting software engineering tasks with agentic AI: Demonstration on document retrieval and test scenario generation",
    "summary": "arXiv:2602.04726v1 Announce Type: cross Abstract: The introduction of large language models ignited great retooling and rethinking of the software development models. The ensuing response of software engineering research yielded a massive body of tools and approaches. In this paper, we join the hassle by introducing agentic AI solutions for two tas",
    "url": "https://arxiv.org/abs/2602.04726",
    "source": "Arxiv AI"
  },
  {
    "title": "From Data to Behavior: Predicting Unintended Model Behaviors Before Training",
    "summary": "arXiv:2602.04735v1 Announce Type: cross Abstract: Large Language Models (LLMs) can acquire unintended biases from seemingly benign training data even without explicit cues or malicious content. Existing methods struggle to detect such risks before fine-tuning, making post hoc evaluation costly and inefficient. To address this challenge, we introduc",
    "url": "https://arxiv.org/abs/2602.04735",
    "source": "Arxiv AI"
  },
  {
    "title": "Alignment Drift in Multimodal LLMs: A Two-Phase, Longitudinal Evaluation of Harm Across Eight Model Releases",
    "summary": "arXiv:2602.04739v1 Announce Type: cross Abstract: Multimodal large language models (MLLMs) are increasingly deployed in real-world systems, yet their safety under adversarial prompting remains underexplored. We present a two-phase evaluation of MLLM harmlessness using a fixed benchmark of 726 adversarial prompts authored by 26 professional red team",
    "url": "https://arxiv.org/abs/2602.04739",
    "source": "Arxiv AI"
  },
  {
    "title": "Exploiting contextual information to improve stance detection in informal political discourse with LLMs",
    "summary": "arXiv:2602.04750v1 Announce Type: cross Abstract: This study investigates the use of Large Language Models (LLMs) for political stance detection in informal online discourse, where language is often sarcastic, ambiguous, and context-dependent. We explore whether providing contextual information, specifically user profile summaries derived from hist",
    "url": "https://arxiv.org/abs/2602.04750",
    "source": "Arxiv AI"
  },
  {
    "title": "Comparative Insights on Adversarial Machine Learning from Industry and Academia: A User-Study Approach",
    "summary": "arXiv:2602.04753v1 Announce Type: cross Abstract: An exponential growth of Machine Learning and its Generative AI applications brings with it significant security challenges, often referred to as Adversarial Machine Learning (AML). In this paper, we conducted two comprehensive studies to explore the perspectives of industry professionals and studen",
    "url": "https://arxiv.org/abs/2602.04753",
    "source": "Arxiv AI"
  },
  {
    "title": "When Silence Is Golden: Can LLMs Learn to Abstain in Temporal QA and Beyond?",
    "summary": "arXiv:2602.04755v1 Announce Type: cross Abstract: Large language models (LLMs) rarely admit uncertainty, often producing fluent but misleading answers, rather than abstaining (i.e., refusing to answer). This weakness is even evident in temporal question answering, where models frequently ignore time-sensitive evidence and conflate facts across diff",
    "url": "https://arxiv.org/abs/2602.04755",
    "source": "Arxiv AI"
  },
  {
    "title": "Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty",
    "summary": "arXiv:2602.04763v1 Announce Type: cross Abstract: Multi-agent systems are increasingly equipped with heterogeneous multimodal sensors, enabling richer perception but introducing modality-specific and agent-dependent uncertainty. Existing multi-agent collaboration frameworks typically reason at the agent level, assume homogeneous sensing, and handle",
    "url": "https://arxiv.org/abs/2602.04763",
    "source": "Arxiv AI"
  },
  {
    "title": "Billion-Scale Graph Foundation Models",
    "summary": "arXiv:2602.04768v1 Announce Type: cross Abstract: Graph-structured data underpins many critical applications. While foundation models have transformed language and vision via large-scale pretraining and lightweight adaptation, extending this paradigm to general, real-world graphs is challenging. In this work, we present Graph Billion- Foundation-Fu",
    "url": "https://arxiv.org/abs/2602.04768",
    "source": "Arxiv AI"
  },
  {
    "title": "Team, Then Trim: An Assembly-Line LLM Framework for High-Quality Tabular Data Generation",
    "summary": "arXiv:2602.04785v1 Announce Type: cross Abstract: While tabular data is fundamental to many real-world machine learning (ML) applications, acquiring high-quality tabular data is usually labor-intensive and expensive. Limited by the scarcity of observations, tabular datasets often exhibit critical deficiencies, such as class imbalance, selection bia",
    "url": "https://arxiv.org/abs/2602.04785",
    "source": "Arxiv AI"
  },
  {
    "title": "Skin Tokens: A Learned Compact Representation for Unified Autoregressive Rigging",
    "summary": "arXiv:2602.04805v1 Announce Type: cross Abstract: The rapid proliferation of generative 3D models has created a critical bottleneck in animation pipelines: rigging. Existing automated methods are fundamentally limited by their approach to skinning, treating it as an ill-posed, high-dimensional regression task that is inefficient to optimize and is ",
    "url": "https://arxiv.org/abs/2602.04805",
    "source": "Arxiv AI"
  },
  {
    "title": "Beyond Rewards in Reinforcement Learning for Cyber Defence",
    "summary": "arXiv:2602.04809v1 Announce Type: cross Abstract: Recent years have seen an explosion of interest in autonomous cyber defence agents trained to defend computer networks using deep reinforcement learning. These agents are typically trained in cyber gym environments using dense, highly engineered reward functions which combine many penalties and ince",
    "url": "https://arxiv.org/abs/2602.04809",
    "source": "Arxiv AI"
  },
  {
    "title": "SE-Bench: Benchmarking Self-Evolution with Knowledge Internalization",
    "summary": "arXiv:2602.04811v1 Announce Type: cross Abstract: True self-evolution requires agents to act as lifelong learners that internalize novel experiences to solve future problems. However, rigorously measuring this foundational capability is hindered by two obstacles: the entanglement of prior knowledge, where ``new'' knowledge may appear in pre-trainin",
    "url": "https://arxiv.org/abs/2602.04811",
    "source": "Arxiv AI"
  },
  {
    "title": "Toward Reliable and Explainable Nail Disease Classification: Leveraging Adversarial Training and Grad-CAM Visualization",
    "summary": "arXiv:2602.04820v1 Announce Type: cross Abstract: Human nail diseases are gradually observed over all age groups, especially among older individuals, often going ignored until they become severe. Early detection and accurate diagnosis of such conditions are important because they sometimes reveal our body's health problems. But it is challenging du",
    "url": "https://arxiv.org/abs/2602.04820",
    "source": "Arxiv AI"
  },
  {
    "title": "Safe Urban Traffic Control via Uncertainty-Aware Conformal Prediction and World-Model Reinforcement Learning",
    "summary": "arXiv:2602.04821v1 Announce Type: cross Abstract: Urban traffic management demands systems that simultaneously predict future conditions, detect anomalies, and take safe corrective actions -- all while providing reliability guarantees. We present STREAM-RL, a unified framework that introduces three novel algorithmic contributions: (1) PU-GAT+, an U",
    "url": "https://arxiv.org/abs/2602.04821",
    "source": "Arxiv AI"
  },
  {
    "title": "It's not a Lottery, it's a Race: Understanding How Gradient Descent Adapts the Network's Capacity to the Task",
    "summary": "arXiv:2602.04832v1 Announce Type: cross Abstract: Our theoretical understanding of neural networks is lagging behind their empirical success. One of the important unexplained phenomena is why and how, during the process of training with gradient descent, the theoretical capacity of neural networks is reduced to an effective capacity that fits the t",
    "url": "https://arxiv.org/abs/2602.04832",
    "source": "Arxiv AI"
  },
  {
    "title": "El Agente Estructural: An Artificially Intelligent Molecular Editor",
    "summary": "arXiv:2602.04849v1 Announce Type: cross Abstract: We present El Agente Estructural, a multimodal, natural-language-driven geometry-generation and manipulation agent for autonomous chemistry and molecular modelling. Unlike molecular generation or editing via generative models, Estructural mimics how human experts directly manipulate molecular system",
    "url": "https://arxiv.org/abs/2602.04849",
    "source": "Arxiv AI"
  },
  {
    "title": "El Agente Quntur: A research collaborator agent for quantum chemistry",
    "summary": "arXiv:2602.04850v1 Announce Type: cross Abstract: Quantum chemistry is a foundational enabling tool for the fields of chemistry, materials science, computational biology and others. Despite of its power, the practical application of quantum chemistry simulations remains in the hands of qualified experts due to methodological complexity, software he",
    "url": "https://arxiv.org/abs/2602.04850",
    "source": "Arxiv AI"
  },
  {
    "title": "From Evaluation to Design: Using Potential Energy Surface Smoothness Metrics to Guide Machine Learning Interatomic Potential Architectures",
    "summary": "arXiv:2602.04861v1 Announce Type: cross Abstract: Machine Learning Interatomic Potentials (MLIPs) sometimes fail to reproduce the physical smoothness of the quantum potential energy surface (PES), leading to erroneous behavior in downstream simulations that standard energy and force regression evaluations can miss. Existing evaluations, such as mic",
    "url": "https://arxiv.org/abs/2602.04861",
    "source": "Arxiv AI"
  },
  {
    "title": "Subliminal Effects in Your Data: A General Mechanism via Log-Linearity",
    "summary": "arXiv:2602.04863v1 Announce Type: cross Abstract: Training modern large language models (LLMs) has become a veritable smorgasbord of algorithms and datasets designed to elicit particular behaviors, making it critical to develop techniques to understand the effects of datasets on the model's properties. This is exacerbated by recent experiments that",
    "url": "https://arxiv.org/abs/2602.04863",
    "source": "Arxiv AI"
  },
  {
    "title": "CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation",
    "summary": "arXiv:2602.04868v1 Announce Type: cross Abstract: Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite",
    "url": "https://arxiv.org/abs/2602.04868",
    "source": "Arxiv AI"
  },
  {
    "title": "Multi-layer Cross-Attention is Provably Optimal for Multi-modal In-context Learning",
    "summary": "arXiv:2602.04872v1 Announce Type: cross Abstract: Recent progress has rapidly advanced our understanding of the mechanisms underlying in-context learning in modern attention-based neural networks. However, existing results focus exclusively on unimodal data; in contrast, the theoretical underpinnings of in-context learning for multi-modal data rema",
    "url": "https://arxiv.org/abs/2602.04872",
    "source": "Arxiv AI"
  },
  {
    "title": "Rethinking the Trust Region in LLM Reinforcement Learning",
    "summary": "arXiv:2602.04879v1 Announce Type: cross Abstract: Reinforcement learning (RL) has become a cornerstone for fine-tuning Large Language Models (LLMs), with Proximal Policy Optimization (PPO) serving as the de facto standard algorithm. Despite its ubiquity, we argue that the core ratio clipping mechanism in PPO is structurally ill-suited for the large",
    "url": "https://arxiv.org/abs/2602.04879",
    "source": "Arxiv AI"
  },
  {
    "title": "Contrastive Continual Learning for Model Adaptability in Internet of Things",
    "summary": "arXiv:2602.04881v1 Announce Type: cross Abstract: Internet of Things (IoT) deployments operate in nonstationary, dynamic environments where factors such as sensor drift, evolving user behavior, and heterogeneous user privacy requirements can affect application utility. Continual learning (CL) addresses this by adapting models over time without cata",
    "url": "https://arxiv.org/abs/2602.04881",
    "source": "Arxiv AI"
  },
  {
    "title": "Protein Autoregressive Modeling via Multiscale Structure Generation",
    "summary": "arXiv:2602.04883v1 Announce Type: cross Abstract: We present protein autoregressive modeling (PAR), the first multi-scale autoregressive framework for protein backbone generation via coarse-to-fine next-scale prediction. Using the hierarchical nature of proteins, PAR generates structures that mimic sculpting a statue, forming a coarse topology and ",
    "url": "https://arxiv.org/abs/2602.04883",
    "source": "Arxiv AI"
  },
  {
    "title": "Benchmarking Large Language Models for Diagnosing Students' Cognitive Skills from Handwritten Math Work",
    "summary": "arXiv:2504.00843v2 Announce Type: replace Abstract: Students' handwritten math work provides a rich resource for diagnosing cognitive skills, as it captures intermediate reasoning beyond final answers. We investigate how current large language models (LLMs) perform in diagnosing cognitive skills from such work. However, student responses vary widel",
    "url": "https://arxiv.org/abs/2504.00843",
    "source": "Arxiv AI"
  },
  {
    "title": "OmniCellTOSG: The First Cell Text-Omic Signaling Graphs Dataset for Graph Language Foundation Modeling",
    "summary": "arXiv:2504.02148v2 Announce Type: replace Abstract: With the rapid growth of large-scale single-cell omic datasets, omic foundation models (FMs) have emerged as powerful tools for advancing research in life sciences and precision medicine. However, most existing omic FMs rely primarily on numerical transcriptomic data by sorting genes as sequences,",
    "url": "https://arxiv.org/abs/2504.02148",
    "source": "Arxiv AI"
  },
  {
    "title": "Toward Multiphysics-Informed Machine Learning for Sustainable Data Center Operations: Intelligence Evolution with Deployable Solutions for Computing Infrastructure",
    "summary": "arXiv:2505.19414v2 Announce Type: replace Abstract: The revolution in artificial intelligence (AI) has brought sustainable challenges in data center management due to the high carbon emissions and short cooling response time associated with high-power density racks. While machine learning (ML) offers promise for intelligent management, its adoption",
    "url": "https://arxiv.org/abs/2505.19414",
    "source": "Arxiv AI"
  },
  {
    "title": "Can LLMs Reconcile Knowledge Conflicts in Counterfactual Reasoning",
    "summary": "arXiv:2506.15732v4 Announce Type: replace Abstract: Large Language Models have been shown to contain extensive world knowledge in their parameters, enabling impressive performance on many knowledge intensive tasks. However, when deployed in novel settings, LLMs often encounter situations where they must integrate parametric knowledge with new or un",
    "url": "https://arxiv.org/abs/2506.15732",
    "source": "Arxiv AI"
  },
  {
    "title": "MixGRPO: Unlocking Flow-based GRPO Efficiency with Mixed ODE-SDE",
    "summary": "arXiv:2507.21802v5 Announce Type: replace Abstract: Although GRPO substantially enhances flow matching models in human preference alignment of image generation, methods such as FlowGRPO and DanceGRPO still exhibit inefficiency due to the necessity of sampling and optimizing over all denoising steps specified by the Markov Decision Process (MDP). In",
    "url": "https://arxiv.org/abs/2507.21802",
    "source": "Arxiv AI"
  },
  {
    "title": "Building Scaffolding Dialogue Data with LLM-Simulated Novices",
    "summary": "arXiv:2508.04428v2 Announce Type: replace Abstract: High-quality, multi-turn instructional dialogues between novices and experts are essential for developing AI systems that support teaching, learning, and decision-making. These dialogues often involve scaffolding -- the process by which an expert supports a novice's thinking through questions, fee",
    "url": "https://arxiv.org/abs/2508.04428",
    "source": "Arxiv AI"
  },
  {
    "title": "STELAR-VISION: Self-Topology-Aware Efficient Learning for Aligned Reasoning in Vision",
    "summary": "arXiv:2508.08688v3 Announce Type: replace Abstract: Vision-language models (VLMs) have made significant strides in reasoning, yet they often struggle with complex multimodal tasks and tend to generate overly verbose outputs. A key limitation is their reliance on chain-of-thought (CoT) reasoning, despite many tasks benefiting from alternative topolo",
    "url": "https://arxiv.org/abs/2508.08688",
    "source": "Arxiv AI"
  },
  {
    "title": "Transduction is All You Need for Structured Data Workflows",
    "summary": "arXiv:2508.15610v3 Announce Type: replace Abstract: This paper introduces Agentics, a functional agentic AI framework for building LLM-based structured data workflow pipelines. Designed for both research and practical applications, Agentics offers a new data-centric paradigm in which agents are embedded within data types, enabling logical transduct",
    "url": "https://arxiv.org/abs/2508.15610",
    "source": "Arxiv AI"
  },
  {
    "title": "Information Templates: A New Paradigm for Intelligent Active Feature Acquisition",
    "summary": "arXiv:2508.18380v2 Announce Type: replace Abstract: Active feature acquisition (AFA) is an instance-adaptive paradigm in which, at inference time, a policy sequentially chooses which features to acquire (at a cost) before predicting. Existing approaches either train reinforcement learning policies, which deal with a difficult MDP, or greedy policie",
    "url": "https://arxiv.org/abs/2508.18380",
    "source": "Arxiv AI"
  },
  {
    "title": "A Novel Framework for Uncertainty-Driven Adaptive Exploration",
    "summary": "arXiv:2509.03219v5 Announce Type: replace Abstract: Adaptive exploration methods propose ways to learn complex policies via alternating between exploration and exploitation. An important question for such methods is to determine the appropriate moment to switch between exploration and exploitation and vice versa. This is critical in domains that re",
    "url": "https://arxiv.org/abs/2509.03219",
    "source": "Arxiv AI"
  },
  {
    "title": "Building Coding Agents via Entropy-Enhanced Multi-Turn Preference Optimization",
    "summary": "arXiv:2509.12434v3 Announce Type: replace Abstract: Software engineering presents complex, multi-step challenges for Large Language Models (LLMs), requiring reasoning over large codebases and coordinated tool use. The difficulty of these tasks is exemplified by benchmarks like SWE-bench, where current LLMs still struggle to resolve real-world issue",
    "url": "https://arxiv.org/abs/2509.12434",
    "source": "Arxiv AI"
  },
  {
    "title": "Plug-and-Play Emotion Graphs for Compositional Prompting in Zero-Shot Speech Emotion Recognition",
    "summary": "arXiv:2509.25458v2 Announce Type: replace Abstract: Large audio-language models (LALMs) exhibit strong zero-shot performance across speech tasks but struggle with speech emotion recognition (SER) due to weak paralinguistic modeling and limited cross-modal reasoning. We propose Compositional Chain-of-Thought Prompting for Emotion Reasoning (CCoT-Emo",
    "url": "https://arxiv.org/abs/2509.25458",
    "source": "Arxiv AI"
  },
  {
    "title": "Scaling Agents for Computer Use",
    "summary": "arXiv:2510.02250v2 Announce Type: replace Abstract: Computer-use agents (CUAs) hold promise for automating everyday digital tasks, but their performance on long-horizon, complex problems remains unreliable. Single-rollout execution is brittle, with small errors compounding over time and leading to high variance in outcomes. While prior work has att",
    "url": "https://arxiv.org/abs/2510.02250",
    "source": "Arxiv AI"
  },
  {
    "title": "How Catastrophic is Your LLM? Certifying Risk in Conversation",
    "summary": "arXiv:2510.03969v3 Announce Type: replace Abstract: Large Language Models (LLMs) can produce catastrophic responses in conversational settings that pose serious risks to public safety and security. Existing evaluations often fail to fully reveal these vulnerabilities because they rely on fixed attack prompt sequences, lack statistical guarantees, a",
    "url": "https://arxiv.org/abs/2510.03969",
    "source": "Arxiv AI"
  },
  {
    "title": "Improving Multimodal Brain Encoding Model with Dynamic Subject-awareness Routing",
    "summary": "arXiv:2510.04670v3 Announce Type: replace Abstract: Naturalistic fMRI encoding must handle multimodal inputs, shifting fusion styles, and pronounced inter-subject variability. We introduce AFIRE (Agnostic Framework for Multimodal fMRI Response Encoding), an agnostic interface that standardizes time-aligned post-fusion tokens from varied encoders, a",
    "url": "https://arxiv.org/abs/2510.04670",
    "source": "Arxiv AI"
  },
  {
    "title": "DeepAgent: A General Reasoning Agent with Scalable Toolsets",
    "summary": "arXiv:2510.21618v3 Announce Type: replace Abstract: Large reasoning models have demonstrated strong problem-solving abilities, yet real-world tasks often require external tools and long-horizon interactions. Existing agent frameworks typically follow predefined workflows, which limit autonomous and global task completion. In this paper, we introduc",
    "url": "https://arxiv.org/abs/2510.21618",
    "source": "Arxiv AI"
  },
  {
    "title": "Mixed-Density Diffuser: Efficient Planning with Non-Uniform Temporal Resolution",
    "summary": "arXiv:2510.23026v4 Announce Type: replace Abstract: Recent studies demonstrate that diffusion planners benefit from sparse-step planning over single-step planning. Training models to skip steps in their trajectories helps capture long-term dependencies without additional memory or computational cost. However, predicting excessively sparse plans deg",
    "url": "https://arxiv.org/abs/2510.23026",
    "source": "Arxiv AI"
  },
  {
    "title": "DTS: Enhancing Large Reasoning Models via Decoding Tree Sketching",
    "summary": "arXiv:2511.00640v2 Announce Type: replace Abstract: Large Reasoning Models (LRMs) achieve remarkable inference-time improvements through parallel thinking. However, existing methods rely on redundant sampling of reasoning trajectories, failing to effectively explore the reasoning space to uncover high-quality solutions. To address these limitations",
    "url": "https://arxiv.org/abs/2511.00640",
    "source": "Arxiv AI"
  },
  {
    "title": "Extending RLVR to Open-Ended Tasks via Verifiable Multiple-Choice Reformulation",
    "summary": "arXiv:2511.02463v3 Announce Type: replace Abstract: Reinforcement Learning with Verifiable Rewards(RLVR) has demonstrated great potential in enhancing the reasoning capabilities of large language models (LLMs). However, its success has thus far been largely confined to the mathematical and programming domains with clear and automatically checkable ",
    "url": "https://arxiv.org/abs/2511.02463",
    "source": "Arxiv AI"
  },
  {
    "title": "Simulating the Visual World with Artificial Intelligence: A Roadmap",
    "summary": "arXiv:2511.08585v3 Announce Type: replace Abstract: The landscape of video generation is shifting, from a focus on generating visually appealing clips to building virtual environments that support interaction and maintain physical plausibility. These developments point toward the emergence of video foundation models that function not only as visual",
    "url": "https://arxiv.org/abs/2511.08585",
    "source": "Arxiv AI"
  },
  {
    "title": "CastMind: An Interaction-Driven Agentic Reasoning Framework for Cognition-Inspired Time Series Forecasting",
    "summary": "arXiv:2511.08947v2 Announce Type: replace Abstract: Time series forecasting plays a crucial role in decision-making across many real-world applications. Despite substantial progress, most existing methods still treat forecasting as a static, single-pass regression problem. In contrast, human experts form predictions through iterative reasoning that",
    "url": "https://arxiv.org/abs/2511.08947",
    "source": "Arxiv AI"
  },
  {
    "title": "Incremental Maintenance of DatalogMTL Materialisations",
    "summary": "arXiv:2511.12169v3 Announce Type: replace Abstract: DatalogMTL extends the classical Datalog language with metric temporal logic (MTL), enabling expressive reasoning over temporal data. While existing reasoning approaches, such as materialisation based and automata based methods, offer soundness and completeness, they lack support for handling effi",
    "url": "https://arxiv.org/abs/2511.12169",
    "source": "Arxiv AI"
  },
  {
    "title": "M^3-Bench: Multi-Modal, Multi-Hop, Multi-Threaded Tool-Using MLLM Agent Benchmark",
    "summary": "arXiv:2511.17729v4 Announce Type: replace Abstract: We present M^3-Bench, the first benchmark for evaluating multimodal tool use under the Model Context Protocol. The benchmark targets realistic, multi-hop and multi-threaded workflows that require visual grounding and textual reasoning, cross-tool dependencies, and persistence of intermediate resou",
    "url": "https://arxiv.org/abs/2511.17729",
    "source": "Arxiv AI"
  },
  {
    "title": "Sample from What You See: Visuomotor Policy Learning via Diffusion Bridge with Observation-Embedded Stochastic Differential Equation",
    "summary": "arXiv:2512.07212v2 Announce Type: replace Abstract: Imitation learning with diffusion models has advanced robotic control by capturing the multi-modal action distributions. However, existing methods typically treat observations only as high-level conditions to the denoising network, rather than integrating them into the stochastic dynamics of the d",
    "url": "https://arxiv.org/abs/2512.07212",
    "source": "Arxiv AI"
  },
  {
    "title": "User-Feedback-Driven Adaptation for Vision-and-Language Navigation",
    "summary": "arXiv:2512.10322v2 Announce Type: replace Abstract: Real-world deployment of Vision-and-Language Navigation (VLN) agents is constrained by the scarcity of reliable supervision after offline training. While recent adaptation methods attempt to mitigate distribution shifts via environment-driven self-supervision (e.g., entropy minimization), these si",
    "url": "https://arxiv.org/abs/2512.10322",
    "source": "Arxiv AI"
  },
  {
    "title": "Agentic Explainable Artificial Intelligence (Agentic XAI) Approach To Explore Better Explanation",
    "summary": "arXiv:2512.21066v2 Announce Type: replace Abstract: Explainable artificial intelligence (XAI) enables data-driven understanding of factor associations with response variables, yet communicating XAI outputs to laypersons remains challenging, hindering trust in AI-based predictions. Large language models (LLMs) have emerged as promising tools for tra",
    "url": "https://arxiv.org/abs/2512.21066",
    "source": "Arxiv AI"
  },
  {
    "title": "EvoFSM: Controllable Self-Evolution for Deep Research with Finite State Machines",
    "summary": "arXiv:2601.09465v2 Announce Type: replace Abstract: While LLM-based agents have shown promise for deep research, most existing approaches rely on fixed workflows that struggle to adapt to real-world, open-ended queries. Recent work therefore explores self-evolution by allowing agents to rewrite their own code or prompts to improve problem-solving a",
    "url": "https://arxiv.org/abs/2601.09465",
    "source": "Arxiv AI"
  },
  {
    "title": "Resilient Routing: Risk-Aware Dynamic Routing in Smart Logistics via Spatiotemporal Graph Learning",
    "summary": "arXiv:2601.13632v2 Announce Type: replace Abstract: With the rapid development of the e-commerce industry, the logistics network is experiencing unprecedented pressure. The traditional static routing strategy most time cannot tolerate the traffic congestion and fluctuating retail demand. In this paper, we propose a Risk-Aware Dynamic Routing(RADR) ",
    "url": "https://arxiv.org/abs/2601.13632",
    "source": "Arxiv AI"
  },
  {
    "title": "DEEPMED: Building a Medical DeepResearch Agent via Multi-hop Med-Search Data and Turn-Controlled Agentic Training & Inference",
    "summary": "arXiv:2601.18496v2 Announce Type: replace Abstract: Medical reasoning models remain constrained by parametric knowledge and are thus susceptible to forgetting and hallucinations. DeepResearch (DR) models ground outputs in verifiable evidence from tools and perform strongly in general domains, but their direct transfer to medical field yields relati",
    "url": "https://arxiv.org/abs/2601.18496",
    "source": "Arxiv AI"
  },
  {
    "title": "Beyond In-Domain Detection: SpikeScore for Cross-Domain Hallucination Detection",
    "summary": "arXiv:2601.19245v2 Announce Type: replace Abstract: Hallucination detection is critical for deploying large language models (LLMs) in real-world applications. Existing hallucination detection methods achieve strong performance when the training and test data come from the same domain, but they suffer from poor cross-domain generalization. In this p",
    "url": "https://arxiv.org/abs/2601.19245",
    "source": "Arxiv AI"
  },
  {
    "title": "Concise Geometric Description as a Bridge: Unleashing the Potential of LLM for Plane Geometry Problem Solving",
    "summary": "arXiv:2601.21164v2 Announce Type: replace Abstract: Plane Geometry Problem Solving (PGPS) is a multimodal reasoning task that aims to solve a plane geometric problem based on a geometric diagram and problem textual descriptions. Although Large Language Models (LLMs) possess strong reasoning skills, their direct application to PGPS is hindered by th",
    "url": "https://arxiv.org/abs/2601.21164",
    "source": "Arxiv AI"
  },
  {
    "title": "Latent Chain-of-Thought as Planning: Decoupling Reasoning from Verbalization",
    "summary": "arXiv:2601.21358v2 Announce Type: replace Abstract: Chain-of-Thought (CoT) empowers Large Language Models (LLMs) to tackle complex problems, but remains constrained by the computational cost and reasoning path collapse when grounded in discrete token spaces. Recent latent reasoning approaches attempt to optimize efficiency by performing reasoning w",
    "url": "https://arxiv.org/abs/2601.21358",
    "source": "Arxiv AI"
  },
  {
    "title": "MemOCR: Layout-Aware Visual Memory for Efficient Long-Horizon Reasoning",
    "summary": "arXiv:2601.21468v2 Announce Type: replace Abstract: Long-horizon agentic reasoning necessitates effectively compressing growing interaction histories into a limited context window. Most existing memory systems serialize history as text, where token-level cost is uniform and scales linearly with length, often spending scarce budget on low-value deta",
    "url": "https://arxiv.org/abs/2601.21468",
    "source": "Arxiv AI"
  },
  {
    "title": "Learning Decentralized LLM Collaboration with Multi-Agent Actor Critic",
    "summary": "arXiv:2601.21972v2 Announce Type: replace Abstract: Recent work has explored optimizing LLM collaboration through Multi-Agent Reinforcement Learning (MARL). However, most MARL fine-tuning approaches rely on predefined execution protocols, which often require centralized execution. Decentralized LLM collaboration is more appealing in practice, as ag",
    "url": "https://arxiv.org/abs/2601.21972",
    "source": "Arxiv AI"
  },
  {
    "title": "Scaling Multiagent Systems with Process Rewards",
    "summary": "arXiv:2601.23228v2 Announce Type: replace Abstract: While multiagent systems have shown promise for tackling complex tasks via specialization, finetuning multiple agents simultaneously faces two key challenges: (1) credit assignment across agents, and (2) sample efficiency of expensive multiagent rollouts. In this work, we propose finetuning multia",
    "url": "https://arxiv.org/abs/2601.23228",
    "source": "Arxiv AI"
  },
  {
    "title": "ConvexBench: Can LLMs Recognize Convex Functions?",
    "summary": "arXiv:2602.01075v2 Announce Type: replace Abstract: Convex analysis is a modern branch of mathematics with many applications. As Large Language Models (LLMs) start to automate research-level math and sciences, it is important for LLMs to demonstrate the ability to understand and reason with convexity. We introduce \\cb, a scalable and mechanically v",
    "url": "https://arxiv.org/abs/2602.01075",
    "source": "Arxiv AI"
  },
  {
    "title": "CreditAudit: 2$^\\text{nd}$ Dimension for LLM Evaluation and Selection",
    "summary": "arXiv:2602.02515v2 Announce Type: replace Abstract: Leaderboard scores on public benchmarks have been steadily rising and converging, with many frontier language models now separated by only marginal differences. However, these scores often fail to match users' day to day experience, because system prompts, output protocols, and interaction modes e",
    "url": "https://arxiv.org/abs/2602.02515",
    "source": "Arxiv AI"
  },
  {
    "title": "Building Interpretable Models for Moral Decision-Making",
    "summary": "arXiv:2602.03351v2 Announce Type: replace Abstract: We build a custom transformer model to study how neural networks make moral decisions on trolley-style dilemmas. The model processes structured scenarios using embeddings that encode who is affected, how many people, and which outcome they belong to. Our 2-layer architecture achieves 77% accuracy ",
    "url": "https://arxiv.org/abs/2602.03351",
    "source": "Arxiv AI"
  },
  {
    "title": "Multi-Excitation Projective Simulation with a Many-Body Physics Inspired Inductive Bias",
    "summary": "arXiv:2402.10192v4 Announce Type: replace-cross Abstract: With the impressive progress of deep learning, applications relying on machine learning are increasingly being integrated into daily life. However, most deep learning models have an opaque, oracle-like nature making it difficult to interpret and understand their decisions. This problem led t",
    "url": "https://arxiv.org/abs/2402.10192",
    "source": "Arxiv AI"
  },
  {
    "title": "Policy Learning with a Language Bottleneck",
    "summary": "arXiv:2405.04118v3 Announce Type: replace-cross Abstract: Modern AI systems such as self-driving cars and game-playing agents achieve superhuman performance, but often lack human-like generalization, interpretability, and inter-operability with human users. Inspired by the rich interactions between language and decision-making in humans, we introdu",
    "url": "https://arxiv.org/abs/2405.04118",
    "source": "Arxiv AI"
  },
  {
    "title": "No Screening is More Efficient with Multiple Objects",
    "summary": "arXiv:2408.10077v3 Announce Type: replace-cross Abstract: We study efficient mechanism design for allocating multiple heterogeneous objects. The aim is to maximize the residual surplus, the total value generated from an allocation minus the costs of screening. We discover a robust trend indicating that no-screening mechanisms, such as serial dictat",
    "url": "https://arxiv.org/abs/2408.10077",
    "source": "Arxiv AI"
  },
  {
    "title": "Deep Multimodal Learning with Missing Modality: A Survey",
    "summary": "arXiv:2409.07825v4 Announce Type: replace-cross Abstract: During multimodal model training and testing, certain data modalities may be absent due to sensor limitations, cost constraints, privacy concerns, or data loss, negatively affecting performance. Multimodal learning techniques designed to handle missing modalities can mitigate this by ensurin",
    "url": "https://arxiv.org/abs/2409.07825",
    "source": "Arxiv AI"
  },
  {
    "title": "Learning to Explore with Lagrangians for Bandits under Unknown Linear Constraints",
    "summary": "arXiv:2410.18844v2 Announce Type: replace-cross Abstract: Pure exploration in bandits formalises multiple real-world problems, such as tuning hyper-parameters or conducting user studies to test a set of items, where different safety, resource, and fairness constraints on the decision space naturally appear. We study these problems as pure explorati",
    "url": "https://arxiv.org/abs/2410.18844",
    "source": "Arxiv AI"
  },
  {
    "title": "LLM-ABBA: Understanding time series via symbolic approximation",
    "summary": "arXiv:2411.18506v5 Announce Type: replace-cross Abstract: The success of large language models (LLMs) for time series has been demonstrated in previous work. Utilizing a symbolic time series representation, one can efficiently bridge the gap between LLMs and time series. However, the remaining challenge is to exploit the semantic information hidden",
    "url": "https://arxiv.org/abs/2411.18506",
    "source": "Arxiv AI"
  },
  {
    "title": "AI-Powered CPS-Enabled Vulnerable-User-Aware Urban Transportation Digital Twin: Methods and Applications",
    "summary": "arXiv:2501.10396v3 Announce Type: replace-cross Abstract: We present methods and applications for the development of digital twins (DT) for urban traffic management. While the majority of studies on the DT focus on its ``eyes,\" which is the emerging sensing and perception like object detection and tracking, what really distinguishes the DT from a t",
    "url": "https://arxiv.org/abs/2501.10396",
    "source": "Arxiv AI"
  },
  {
    "title": "DISCOVER: Identifying Patterns of Daily Living in Human Activities from Smart Home Data",
    "summary": "arXiv:2503.01733v3 Announce Type: replace-cross Abstract: Smart homes equipped with ambient sensors offer a transformative approach to continuous health monitoring and assisted living. Traditional research in this domain primarily focuses on Human Activity Recognition (HAR), which relies on mapping sensor data to a closed set of predefined activity",
    "url": "https://arxiv.org/abs/2503.01733",
    "source": "Arxiv AI"
  },
  {
    "title": "Persuade Me if You Can: A Framework for Evaluating Persuasion Effectiveness and Susceptibility Among Large Language Models",
    "summary": "arXiv:2503.01829v3 Announce Type: replace-cross Abstract: Large Language Models (LLMs) demonstrate persuasive capabilities that rival human-level persuasion. While these capabilities can be used for social good, they also present risks of potential misuse. Beyond the concern of how LLMs persuade others, their own susceptibility to persuasion poses ",
    "url": "https://arxiv.org/abs/2503.01829",
    "source": "Arxiv AI"
  },
  {
    "title": "Large Language Model as Meta-Surrogate for Data-Driven Many-Task Optimization: A Proof-of-Principle Study",
    "summary": "arXiv:2503.08301v3 Announce Type: replace-cross Abstract: In many-task optimization scenarios, surrogate models are valuable for mitigating the computational burden of repeated fitness evaluations across tasks. This study proposes a novel meta-surrogate framework to assist many-task optimization, by leveraging the knowledge transfer strengths and e",
    "url": "https://arxiv.org/abs/2503.08301",
    "source": "Arxiv AI"
  },
  {
    "title": "Explainable Sentiment Analysis with DeepSeek-R1: Performance, Efficiency, and Few-Shot Learning",
    "summary": "arXiv:2503.11655v5 Announce Type: replace-cross Abstract: Large language models (LLMs) have transformed sentiment analysis, yet balancing accuracy, efficiency, and explainability remains a critical challenge. This study presents the first comprehensive evaluation of DeepSeek-R1--an open-source reasoning model--against OpenAI's GPT-4o and GPT-4o-min",
    "url": "https://arxiv.org/abs/2503.11655",
    "source": "Arxiv AI"
  },
  {
    "title": "LLM Agents for Education: Advances and Applications",
    "summary": "arXiv:2503.11733v2 Announce Type: replace-cross Abstract: Large Language Model (LLM) agents are transforming education by automating complex pedagogical tasks and enhancing both teaching and learning processes. In this survey, we present a systematic review of recent advances in applying LLM agents to address key challenges in educational settings,",
    "url": "https://arxiv.org/abs/2503.11733",
    "source": "Arxiv AI"
  },
  {
    "title": "AccidentSim: Generating Vehicle Collision Videos with Physically Realistic Collision Trajectories from Real-World Accident Reports",
    "summary": "arXiv:2503.20654v3 Announce Type: replace-cross Abstract: Collecting real-world vehicle accident videos for autonomous driving research is challenging due to their rarity and complexity. While existing driving video generation methods may produce visually realistic videos, they often fail to deliver physically realistic simulations because they lac",
    "url": "https://arxiv.org/abs/2503.20654",
    "source": "Arxiv AI"
  },
  {
    "title": "Beyond speculation: Measuring the growing presence of LLM-generated texts in multilingual disinformation",
    "summary": "arXiv:2503.23242v2 Announce Type: replace-cross Abstract: Increased sophistication of large language models (LLMs) and the consequent quality of generated multilingual text raises concerns about potential disinformation misuse. While humans struggle to distinguish LLM-generated content from human-written texts, the scholarly debate about their impa",
    "url": "https://arxiv.org/abs/2503.23242",
    "source": "Arxiv AI"
  },
  {
    "title": "Adaptive Helpfulness-Harmlessness Alignment with Preference Vectors",
    "summary": "arXiv:2504.20106v3 Announce Type: replace-cross Abstract: Ensuring that large language models (LLMs) are both helpful and harmless is a critical challenge, as overly strict constraints can lead to excessive refusals, while permissive models risk generating harmful content. Existing approaches, such as reinforcement learning from human feedback (RLH",
    "url": "https://arxiv.org/abs/2504.20106",
    "source": "Arxiv AI"
  },
  {
    "title": "Dynamic and Distributed Routing in IoT Networks based on Multi-Objective Q-Learning",
    "summary": "arXiv:2505.00918v4 Announce Type: replace-cross Abstract: IoT networks often face conflicting routing goals such as maximizing packet delivery, minimizing delay, and conserving limited battery energy. These priorities can also change dynamically: for example, an emergency alert requires high reliability, while routine monitoring prioritizes energy ",
    "url": "https://arxiv.org/abs/2505.00918",
    "source": "Arxiv AI"
  },
  {
    "title": "RL in Name Only? Analyzing the Structural Assumptions in RL post-training for LLMs",
    "summary": "arXiv:2505.13697v4 Announce Type: replace-cross Abstract: Reinforcement learning based post-training of large language models (LLMs) has recently gained attention, particularly following the release of DeepSeek R1, which applied GRPO for fine-tuning. Amid the growing claims around improved reasoning abilities attributed to RL post-training, we crit",
    "url": "https://arxiv.org/abs/2505.13697",
    "source": "Arxiv AI"
  },
  {
    "title": "Are Graph Attention Networks Able to Model Structural Information?",
    "summary": "arXiv:2505.21288v2 Announce Type: replace-cross Abstract: Graph Attention Networks (GATs) have emerged as powerful models for learning expressive representations from such data by adaptively weighting neighboring nodes through attention mechanisms. However, most existing approaches primarily rely on node attributes and direct neighborhood connectio",
    "url": "https://arxiv.org/abs/2505.21288",
    "source": "Arxiv AI"
  },
  {
    "title": "CodeSense: a Real-World Benchmark and Dataset for Code Semantic Reasoning",
    "summary": "arXiv:2506.00750v3 Announce Type: replace-cross Abstract: Understanding and reasoning about code semantics is essential for enhancing code LLMs' abilities to solve real-world software engineering (SE) tasks. Although several code reasoning benchmarks exist, most rely on synthetic datasets or educational coding problems and focus on coarse-grained r",
    "url": "https://arxiv.org/abs/2506.00750",
    "source": "Arxiv AI"
  },
  {
    "title": "GRAM: Spatial general-purpose audio representation models for real-world applications",
    "summary": "arXiv:2506.00934v5 Announce Type: replace-cross Abstract: Audio foundation models learn general-purpose audio representations that facilitate a wide range of downstream tasks. While the performance of these models has greatly increased for conventional single-channel, dry audio clips, their success in real-world acoustic environments with reverbera",
    "url": "https://arxiv.org/abs/2506.00934",
    "source": "Arxiv AI"
  },
  {
    "title": "REASONING COMPILER: LLM-Guided Optimizations for Efficient Model Serving",
    "summary": "arXiv:2506.01374v5 Announce Type: replace-cross Abstract: While model serving has unlocked unprecedented capabilities, the high cost of serving large-scale models continues to be a significant barrier to widespread accessibility and rapid innovation. Compiler optimizations have long driven substantial performance improvements, but existing compiler",
    "url": "https://arxiv.org/abs/2506.01374",
    "source": "Arxiv AI"
  },
  {
    "title": "Graph Persistence goes Spectral",
    "summary": "arXiv:2506.06571v3 Announce Type: replace-cross Abstract: Including intricate topological information (e.g., cycles) provably enhances the expressivity of message-passing graph neural networks (GNNs) beyond the Weisfeiler-Leman (WL) hierarchy. Consequently, Persistent Homology (PH) methods are increasingly employed for graph representation learning",
    "url": "https://arxiv.org/abs/2506.06571",
    "source": "Arxiv AI"
  },
  {
    "title": "DeepVideo-R1: Video Reinforcement Fine-Tuning via Difficulty-aware Regressive GRPO",
    "summary": "arXiv:2506.07464v5 Announce Type: replace-cross Abstract: Recent works have demonstrated the effectiveness of reinforcement learning (RL)-based post-training for enhancing the reasoning capabilities of large language models (LLMs). In particular, Group Relative Policy Optimization (GRPO) has shown impressive success using a PPO-style reinforcement ",
    "url": "https://arxiv.org/abs/2506.07464",
    "source": "Arxiv AI"
  },
  {
    "title": "TRACE: Transparent Web Reliability Assessment with Contextual Explanations",
    "summary": "arXiv:2506.12072v3 Announce Type: replace-cross Abstract: In an era of AI-generated misinformation flooding the web, existing tools struggle to empower users with nuanced, transparent assessments of content credibility. They often default to binary (true/false) classifications without contextual justifications, leaving users vulnerable to disinform",
    "url": "https://arxiv.org/abs/2506.12072",
    "source": "Arxiv AI"
  },
  {
    "title": "Taking the GP Out of the Loop",
    "summary": "arXiv:2506.12818v2 Announce Type: replace-cross Abstract: Bayesian optimization (BO) has traditionally solved black-box problems where function evaluation is expensive and, therefore, observations are few. Recently, however, there has been growing interest in applying BO to problems where function evaluation is cheaper and observations are more ple",
    "url": "https://arxiv.org/abs/2506.12818",
    "source": "Arxiv AI"
  },
  {
    "title": "Accurate and scalable exchange-correlation with deep learning",
    "summary": "arXiv:2506.14665v5 Announce Type: replace-cross Abstract: Density Functional Theory (DFT) is the most widely used electronic structure method for predicting the properties of molecules and materials. Although DFT is, in principle, an exact reformulation of the Schr\\\"odinger equation, practical applications rely on approximations to the unknown exch",
    "url": "https://arxiv.org/abs/2506.14665",
    "source": "Arxiv AI"
  },
  {
    "title": "Generative Adversarial Evasion and Out-of-Distribution Detection for UAV Cyber-Attacks",
    "summary": "arXiv:2506.21142v2 Announce Type: replace-cross Abstract: The growing integration of UAVs into civilian airspace underscores the need for resilient and intelligent intrusion detection systems (IDS), as traditional anomaly detection methods often fail to identify novel threats. A common approach treats unfamiliar attacks as out-of-distribution (OOD)",
    "url": "https://arxiv.org/abs/2506.21142",
    "source": "Arxiv AI"
  },
  {
    "title": "AI-Generated Video Detection via Perceptual Straightening",
    "summary": "arXiv:2507.00583v4 Announce Type: replace-cross Abstract: The rapid advancement of generative AI enables highly realistic synthetic videos, posing significant challenges for content authentication and raising urgent concerns about misuse. Existing detection methods often struggle with generalization and capturing subtle temporal inconsistencies. We",
    "url": "https://arxiv.org/abs/2507.00583",
    "source": "Arxiv AI"
  },
  {
    "title": "Geometry-aware 4D Video Generation for Robot Manipulation",
    "summary": "arXiv:2507.01099v3 Announce Type: replace-cross Abstract: Understanding and predicting dynamics of the physical world can enhance a robot's ability to plan and interact effectively in complex environments. While recent video generation models have shown strong potential in modeling dynamic scenes, generating videos that are both temporally coherent",
    "url": "https://arxiv.org/abs/2507.01099",
    "source": "Arxiv AI"
  },
  {
    "title": "Investigating Redundancy in Multimodal Large Language Models with Multiple Vision Encoders",
    "summary": "arXiv:2507.03262v3 Announce Type: replace-cross Abstract: Recent multimodal large language models (MLLMs) increasingly integrate multiple vision encoders to improve performance on various benchmarks, assuming that diverse pretraining objectives yield complementary visual signals. However, we show this assumption often fails in practice. Through sys",
    "url": "https://arxiv.org/abs/2507.03262",
    "source": "Arxiv AI"
  },
  {
    "title": "Unifying Re-Identification, Attribute Inference, and Data Reconstruction Risks in Differential Privacy",
    "summary": "arXiv:2507.06969v4 Announce Type: replace-cross Abstract: Differentially private (DP) mechanisms are difficult to interpret and calibrate because existing methods for mapping standard privacy parameters to concrete privacy risks -- re-identification, attribute inference, and data reconstruction -- are both overly pessimistic and inconsistent. In th",
    "url": "https://arxiv.org/abs/2507.06969",
    "source": "Arxiv AI"
  },
  {
    "title": "Neural Concept Verifier: Scaling Prover-Verifier Games via Concept Encodings",
    "summary": "arXiv:2507.07532v3 Announce Type: replace-cross Abstract: While Prover-Verifier Games (PVGs) offer a promising path toward verifiability in nonlinear classification models, they have not yet been applied to complex inputs such as high-dimensional images. Conversely, expressive concept encodings effectively allow to translate such data into interpre",
    "url": "https://arxiv.org/abs/2507.07532",
    "source": "Arxiv AI"
  },
  {
    "title": "DPO Unchained: Your Training Algorithm is Secretly Disentangled in Human Choice Theory",
    "summary": "arXiv:2507.07855v3 Announce Type: replace-cross Abstract: Normative theories allow one to elicit key parts of a ML algorithm from first principles, which is crucial at a time of championed scrutiny for ML work. Direct Preference Optimization (DPO) cleverly bypasses reward modeling by making an explicit link with a specific normative model of human ",
    "url": "https://arxiv.org/abs/2507.07855",
    "source": "Arxiv AI"
  },
  {
    "title": "PromotionGo at SemEval-2025 Task 11: A Feature-Centric Framework for Cross-Lingual Multi-Emotion Detection in Short Texts",
    "summary": "arXiv:2507.08499v2 Announce Type: replace-cross Abstract: This paper presents our system for SemEval 2025 Task 11: Bridging the Gap in Text-Based Emotion Detection (Track A), which focuses on multi-label emotion detection in short texts. We propose a feature-centric framework that dynamically adapts document representations and learning algorithms ",
    "url": "https://arxiv.org/abs/2507.08499",
    "source": "Arxiv AI"
  },
  {
    "title": "Multiple Choice Learning of Low-Rank Adapters for Language Modeling",
    "summary": "arXiv:2507.10419v2 Announce Type: replace-cross Abstract: We propose LoRA-MCL, a training scheme that extends next-token prediction in language models with a method designed to decode diverse, plausible sentence continuations at inference time. Traditional language modeling is an intrinsically ill-posed problem: given a context, multiple ``futures'",
    "url": "https://arxiv.org/abs/2507.10419",
    "source": "Arxiv AI"
  },
  {
    "title": "Reading Between the Lines: Combining Pause Dynamics and Semantic Coherence for Automated Assessment of Thought Disorder",
    "summary": "arXiv:2507.13551v2 Announce Type: replace-cross Abstract: Formal thought disorder (FTD), a hallmark of schizophrenia spectrum disorders, manifests as incoherent speech and poses challenges for clinical assessment. Traditional clinical rating scales, though validated, are resource-intensive and lack scalability. Automated speech recognition (ASR) al",
    "url": "https://arxiv.org/abs/2507.13551",
    "source": "Arxiv AI"
  },
  {
    "title": "The Invisible Leash: Why RLVR May or May Not Escape Its Origin",
    "summary": "arXiv:2507.14843v4 Announce Type: replace-cross Abstract: Recent advances highlight Reinforcement Learning with Verifiable Rewards (RLVR) as a promising method for enhancing LLMs' capabilities. However, it remains unclear whether the current practice of RLVR truly expands a model's reasoning boundary or mainly amplifies high-reward outputs that the",
    "url": "https://arxiv.org/abs/2507.14843",
    "source": "Arxiv AI"
  },
  {
    "title": "Quantization-Aware Neuromorphic Architecture for Skin Disease Classification on Resource-Constrained Devices",
    "summary": "arXiv:2507.15958v4 Announce Type: replace-cross Abstract: On-device skin lesion analysis is constrained by the compute and energy cost of conventional CNN inference and by the need to update models as new patient data become available. Neuromorphic processors provide event-driven sparse computation and support on-chip incremental learning, yet depl",
    "url": "https://arxiv.org/abs/2507.15958",
    "source": "Arxiv AI"
  },
  {
    "title": "Analysis of Fourier Neural Operators via Effective Field Theory",
    "summary": "arXiv:2507.21833v3 Announce Type: replace-cross Abstract: Fourier Neural Operators (FNOs) have emerged as leading surrogates for solver operators for various functional problems, yet their stability, generalization and frequency behavior lack a principled explanation. We present a systematic effective field theory analysis of FNOs in an infinite-di",
    "url": "https://arxiv.org/abs/2507.21833",
    "source": "Arxiv AI"
  },
  {
    "title": "When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with Benign Inputs",
    "summary": "arXiv:2508.03365v3 Announce Type: replace-cross Abstract: As large language models (LLMs) become increasingly integrated into daily life, audio has emerged as a key interface for human-AI interaction. However, this convenience also introduces new vulnerabilities, making audio a potential attack surface for adversaries. Our research introduces Whisp",
    "url": "https://arxiv.org/abs/2508.03365",
    "source": "Arxiv AI"
  },
  {
    "title": "Towards Universal Neural Likelihood Inference",
    "summary": "arXiv:2508.09100v2 Announce Type: replace-cross Abstract: We introduce universal neural likelihood inference (UNLI): enabling a single model to provide data-grounded, conditional likelihood predictions for arbitrary targets given any collection of observed features, across diverse domains and tasks. To achieve UNLI over heterogeneous tabular data, ",
    "url": "https://arxiv.org/abs/2508.09100",
    "source": "Arxiv AI"
  },
  {
    "title": "Mutually Assured Deregulation",
    "summary": "arXiv:2508.12300v3 Announce Type: replace-cross Abstract: We have convinced ourselves that the way to make AI safe is to make it unsafe. Since 2022, policymakers worldwide have embraced the Regulation Sacrifice - the belief that dismantling safety oversight will deliver security through AI dominance. Fearing China or USA will gain advantage, nation",
    "url": "https://arxiv.org/abs/2508.12300",
    "source": "Arxiv AI"
  },
  {
    "title": "Input-Time Scaling: Adding Noise and Irrelevance into Less-Is-More Drastically Improves Reasoning Performance and Efficiency",
    "summary": "arXiv:2508.13654v5 Announce Type: replace-cross Abstract: Large Language Models (LLMs) excel at reasoning, traditionally requiring high-quality large-scale data and extensive training. Recent works reveal a very appealing Less-Is-More phenomenon where very small, carefully curated high-quality datasets match resource-intensive approaches. In this w",
    "url": "https://arxiv.org/abs/2508.13654",
    "source": "Arxiv AI"
  },
  {
    "title": "Toward Substantive Intersectional Algorithmic Fairness: Desiderata for a Feminist Approach",
    "summary": "arXiv:2508.17944v2 Announce Type: replace-cross Abstract: People's experiences of discrimination are often shaped by multiple intersecting factors, yet algorithmic fairness research rarely reflects this complexity. While intersectionality offers tools for understanding how forms of oppression interact, current approaches to intersectional algorithm",
    "url": "https://arxiv.org/abs/2508.17944",
    "source": "Arxiv AI"
  },
  {
    "title": "UNO: Unifying One-stage Video Scene Graph Generation via Object-Centric Visual Representation Learning",
    "summary": "arXiv:2509.06165v5 Announce Type: replace-cross Abstract: Video Scene Graph Generation (VidSGG) aims to represent dynamic visual content by detecting objects and modeling their temporal interactions as structured graphs. Prior studies typically target either coarse-grained box-level or fine-grained panoptic pixel-level VidSGG, often requiring task-",
    "url": "https://arxiv.org/abs/2509.06165",
    "source": "Arxiv AI"
  },
  {
    "title": "Thermal Imaging-based Real-time Fall Detection using Motion Flow and Attention-enhanced Convolutional Recurrent Architecture",
    "summary": "arXiv:2509.16479v2 Announce Type: replace-cross Abstract: Falls among seniors are a major public health issue. Existing solutions using wearable sensors, ambient sensors, and RGB-based vision systems face challenges in reliability, user compliance, and practicality. Studies indicate that stakeholders, such as older adults and eldercare facilities, ",
    "url": "https://arxiv.org/abs/2509.16479",
    "source": "Arxiv AI"
  },
  {
    "title": "MapCoder-Lite: Distilling Multi-Agent Coding into a Single Small LLM",
    "summary": "arXiv:2509.17489v2 Announce Type: replace-cross Abstract: Large language models (LLMs) have advanced code generation from single-function tasks to competitive-programming problems, but existing multi-agent solutions either rely on costly large-scale (>30B) models or collapse when downsized to small open-source models. We present MapCoder-Lite, a fr",
    "url": "https://arxiv.org/abs/2509.17489",
    "source": "Arxiv AI"
  },
  {
    "title": "Anticipatory Evaluation of Language Models",
    "summary": "arXiv:2509.20645v3 Announce Type: replace-cross Abstract: Progress in large language models is increasingly constrained by an evaluation bottleneck: benchmarks must be built and models run before iteration can begin. We investigate whether evaluation outcomes can be forecast before any experiments are conducted. Specifically, we study text-only per",
    "url": "https://arxiv.org/abs/2509.20645",
    "source": "Arxiv AI"
  },
  {
    "title": "Less Precise Can Be More Reliable: A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy",
    "summary": "arXiv:2509.21173v4 Announce Type: replace-cross Abstract: Vision-Language Models (VLMs) such as CLIP have revolutionized zero-shot classification and safety-critical tasks, including Out-of-Distribution (OOD) detection. However, their high computational cost hinders efficient real-world deployment. While quantization is a standard solution for effi",
    "url": "https://arxiv.org/abs/2509.21173",
    "source": "Arxiv AI"
  },
  {
    "title": "Look Back to Reason Forward: Revisitable Memory for Long-Context LLM Agents",
    "summary": "arXiv:2509.23040v3 Announce Type: replace-cross Abstract: Large language models face challenges in long-context question answering, where key evidence of a query may be dispersed across millions of tokens. Existing works equip large language models with a memory buffer that is dynamically updated via a linear document scan, also known as the \"memor",
    "url": "https://arxiv.org/abs/2509.23040",
    "source": "Arxiv AI"
  },
  {
    "title": "Vid-LLM: A Compact Video-based 3D Multimodal LLM with Reconstruction-Reasoning Synergy",
    "summary": "arXiv:2509.24385v2 Announce Type: replace-cross Abstract: Recent developments in Multimodal Large Language Models (MLLMs) have significantly improved Vision-Language (VL) reasoning in 2D domains. However, extending these capabilities to 3D scene understanding remains a major challenge. Existing 3D Multimodal Large Language Models (3D-MLLMs) often d",
    "url": "https://arxiv.org/abs/2509.24385",
    "source": "Arxiv AI"
  },
  {
    "title": "Causal-Adapter: Taming Text-to-Image Diffusion for Faithful Counterfactual Generation",
    "summary": "arXiv:2509.24798v5 Announce Type: replace-cross Abstract: We present Causal-Adapter, a modular framework that adapts frozen text-to-image diffusion backbones for counterfactual image generation. Our method supports causal interventions on target attributes and consistently propagates their effects to causal dependents while preserving the core iden",
    "url": "https://arxiv.org/abs/2509.24798",
    "source": "Arxiv AI"
  },
  {
    "title": "EMO-TTA: Improving Test-Time Adaptation of Audio-Language Models for Speech Emotion Recognition",
    "summary": "arXiv:2509.25495v2 Announce Type: replace-cross Abstract: Speech emotion recognition (SER) with audio-language models (ALMs) remains vulnerable to distribution shifts at test time, leading to performance degradation in out-of-domain scenarios. Test-time adaptation (TTA) provides a promising solution but often relies on gradient-based updates or pro",
    "url": "https://arxiv.org/abs/2509.25495",
    "source": "Arxiv AI"
  },
  {
    "title": "Breaking the MoE LLM Trilemma: Dynamic Expert Clustering with Structured Compression",
    "summary": "arXiv:2510.02345v3 Announce Type: replace-cross Abstract: Mixture-of-Experts (MoE) Large Language Models (LLMs) face a trilemma of load imbalance, parameter redundancy, and communication overhead. We introduce a unified framework based on dynamic expert clustering and structured compression to address these issues cohesively. Our method employs an ",
    "url": "https://arxiv.org/abs/2510.02345",
    "source": "Arxiv AI"
  },
  {
    "title": "Time-To-Inconsistency: A Survival Analysis of Large Language Model Robustness to Adversarial Attacks",
    "summary": "arXiv:2510.02712v4 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have revolutionized conversational AI, yet their robustness in extended multi-turn dialogues remains poorly understood. Existing evaluation frameworks focus on static benchmarks and single-turn assessments, failing to capture the temporal dynamics of conversation",
    "url": "https://arxiv.org/abs/2510.02712",
    "source": "Arxiv AI"
  },
  {
    "title": "Cooperative Flexibility Exchange: Fair and Comfort-Aware Decentralized Resource Allocation",
    "summary": "arXiv:2510.04192v2 Announce Type: replace-cross Abstract: The growing electricity demand and use of smart appliances are placing pressure on power grids, making efficient energy management more important than ever. The existing energy management systems often prioritize system efficiency (balanced energy demand and supply) at the expense of consume",
    "url": "https://arxiv.org/abs/2510.04192",
    "source": "Arxiv AI"
  },
  {
    "title": "When Do Credal Sets Stabilize? Fixed-Point Theorems for Credal Set Updates",
    "summary": "arXiv:2510.04769v2 Announce Type: replace-cross Abstract: Many machine learning algorithms rely on iterative updates of uncertainty representations, ranging from variational inference and expectation-maximization, to reinforcement learning, continual learning, and multi-agent learning. In the presence of imprecision and ambiguity, credal sets -- cl",
    "url": "https://arxiv.org/abs/2510.04769",
    "source": "Arxiv AI"
  },
  {
    "title": "Group-Adaptive Adversarial Learning for Robust Fake News Detection Against Malicious Comments",
    "summary": "arXiv:2510.09712v3 Announce Type: replace-cross Abstract: Online fake news profoundly distorts public judgment and erodes trust in social platforms. While existing detectors achieve competitive performance on benchmark datasets, they remain notably vulnerable to malicious comments designed specifically to induce misclassification. This evolving thr",
    "url": "https://arxiv.org/abs/2510.09712",
    "source": "Arxiv AI"
  },
  {
    "title": "Y-Shaped Generative Flows",
    "summary": "arXiv:2510.11955v3 Announce Type: replace-cross Abstract: Modern continuous-time generative models typically induce \\emph{V-shaped} flows: each sample travels independently along a nearly straight trajectory from the prior to the data. Although effective, this independent movement overlooks the hierarchical structures that exist in real-world data.",
    "url": "https://arxiv.org/abs/2510.11955",
    "source": "Arxiv AI"
  },
  {
    "title": "Guarding the Guardrails: A Taxonomy-Driven Approach to Jailbreak Detection",
    "summary": "arXiv:2510.13893v2 Announce Type: replace-cross Abstract: Jailbreaking techniques pose a significant threat to the safety of Large Language Models (LLMs). Existing defenses typically focus on single-turn attacks, lack coverage across languages, and rely on limited taxonomies that either fail to capture the full diversity of attack strategies or emp",
    "url": "https://arxiv.org/abs/2510.13893",
    "source": "Arxiv AI"
  },
  {
    "title": "LiDAR-based 3D Change Detection at City Scale",
    "summary": "arXiv:2510.21112v2 Announce Type: replace-cross Abstract: High-definition 3D city maps enable city planning and change detection, which is essential for municipal compliance, map maintenance, and asset monitoring, including both built structures and urban greenery. Conventional Digital Surface Model (DSM) and image differencing are sensitive to ver",
    "url": "https://arxiv.org/abs/2510.21112",
    "source": "Arxiv AI"
  },
  {
    "title": "A Research Roadmap for Augmenting Software Engineering Processes and Software Products with Generative AI",
    "summary": "arXiv:2510.26275v3 Announce Type: replace-cross Abstract: Generative AI (GenAI) is rapidly transforming software engineering (SE) practices, influencing how SE processes are executed, as well as how software systems are developed, operated, and evolved. This paper applies design science research to build a roadmap for GenAI-augmented SE. The proces",
    "url": "https://arxiv.org/abs/2510.26275",
    "source": "Arxiv AI"
  },
  {
    "title": "Comparing Task-Agnostic Embedding Models for Tabular Data",
    "summary": "arXiv:2511.14276v2 Announce Type: replace-cross Abstract: Recent foundation models for tabular data achieve strong task-specific performance via in-context learning. Nevertheless, they focus on direct prediction by encapsulating both representation learning and task-specific inference inside a single, resource-intensive network. This work specifica",
    "url": "https://arxiv.org/abs/2511.14276",
    "source": "Arxiv AI"
  },
  {
    "title": "Semantics as a Shield: Label Disguise Defense (LDD) against Prompt Injection in LLM Sentiment Classification",
    "summary": "arXiv:2511.21752v2 Announce Type: replace-cross Abstract: Large language models are increasingly used for text classification tasks such as sentiment analysis, yet their reliance on natural language prompts exposes them to prompt injection attacks. In particular, class-directive injections exploit knowledge of the model's label set (e.g., positive ",
    "url": "https://arxiv.org/abs/2511.21752",
    "source": "Arxiv AI"
  },
  {
    "title": "EAG3R: Event-Augmented 3D Geometry Estimation for Dynamic and Extreme-Lighting Scenes",
    "summary": "arXiv:2512.00771v2 Announce Type: replace-cross Abstract: Robust 3D geometry estimation from videos is critical for applications such as autonomous navigation, SLAM, and 3D scene reconstruction. Recent methods like DUSt3R demonstrate that regressing dense pointmaps from image pairs enables accurate and efficient pose-free reconstruction. However, e",
    "url": "https://arxiv.org/abs/2512.00771",
    "source": "Arxiv AI"
  },
  {
    "title": "GSAE: Graph-Regularized Sparse Autoencoders for Robust LLM Safety Steering",
    "summary": "arXiv:2512.06655v2 Announce Type: replace-cross Abstract: Large language models (LLMs) face critical safety challenges, as they can be manipulated to generate harmful content through adversarial prompts and jailbreak attacks. Many defenses are typically either black-box guardrails that filter outputs, or internals-based methods that steer hidden ac",
    "url": "https://arxiv.org/abs/2512.06655",
    "source": "Arxiv AI"
  },
  {
    "title": "Near--Real-Time Conflict-Related Fire Detection Using Unsupervised Deep Learning and Satellite Imagery",
    "summary": "arXiv:2512.07925v2 Announce Type: replace-cross Abstract: Ongoing armed conflict in Sudan highlights the need for rapid monitoring of conflict-related fire damage. Recent advances in deep learning and high-frequency satellite imagery enable near--real-time assessment of active fires and burn scars in war zones. This study presents a near--real-time",
    "url": "https://arxiv.org/abs/2512.07925",
    "source": "Arxiv AI"
  },
  {
    "title": "InfoTok: Adaptive Discrete Video Tokenizer via Information-Theoretic Compression",
    "summary": "arXiv:2512.16975v2 Announce Type: replace-cross Abstract: Accurate and efficient discrete video tokenization is essential for long video sequences processing. Yet, the inherent complexity and variable information density of videos present a significant bottleneck for current tokenizers, which rigidly compress all content at a fixed rate, leading to",
    "url": "https://arxiv.org/abs/2512.16975",
    "source": "Arxiv AI"
  },
  {
    "title": "DIVER-1 : Deep Integration of Vast Electrophysiological Recordings at Scale",
    "summary": "arXiv:2512.19097v2 Announce Type: replace-cross Abstract: Unifying the vast heterogeneity of brain signals into a single foundation model is a longstanding challenge in neuroscience. Yet, even as large-scale pretraining becomes feasible, the field lacks principled guidance on how to scale electrophysiological foundation models under realistic data ",
    "url": "https://arxiv.org/abs/2512.19097",
    "source": "Arxiv AI"
  },
  {
    "title": "Synergizing Kolmogorov-Arnold Networks with Dynamic Adaptive Weighting for High-Frequency and Multi-Scale PDE Solutions",
    "summary": "arXiv:2512.22283v2 Announce Type: replace-cross Abstract: PINNs enhance scientific computing by incorporating physical laws into neural network structures, leading to significant advancements in scientific computing. However, PINNs struggle with multi-scale and high-frequency problems due to pathological gradient flow and spectral bias, which sever",
    "url": "https://arxiv.org/abs/2512.22283",
    "source": "Arxiv AI"
  },
  {
    "title": "AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents",
    "summary": "arXiv:2512.22387v2 Announce Type: replace-cross Abstract: The rise of Large Language Models (LLMs) as coding agents promises to accelerate software development, but their impact on generated code reproducibility remains largely unexplored. This paper presents an empirical study investigating whether LLM-generated code can be executed successfully i",
    "url": "https://arxiv.org/abs/2512.22387",
    "source": "Arxiv AI"
  },
  {
    "title": "CogFlow: Bridging Perception and Reasoning through Knowledge Internalization for Visual Mathematical Problem Solving",
    "summary": "arXiv:2601.01874v2 Announce Type: replace-cross Abstract: Despite significant progress, multimodal large language models continue to struggle with visual mathematical problem solving. Some recent works recognize that visual perception is a bottleneck in visual mathematical reasoning, but their solutions are limited to improving the extraction and i",
    "url": "https://arxiv.org/abs/2601.01874",
    "source": "Arxiv AI"
  },
  {
    "title": "The World is Not Mono: Enabling Spatial Understanding in Large Audio-Language Models",
    "summary": "arXiv:2601.02954v2 Announce Type: replace-cross Abstract: Existing large audio-language models perceive the world as \"mono\"-a single stream of audio that ignores the critical spatial dimension (\"where\") required for universal audio scene analysis (ASA). To bridge this gap, we first introduce a hierarchical framework for audio scene analysis. Guided",
    "url": "https://arxiv.org/abs/2601.02954",
    "source": "Arxiv AI"
  },
  {
    "title": "GPU-Accelerated ANNS: Quantized for Speed, Built for Change",
    "summary": "arXiv:2601.07048v3 Announce Type: replace-cross Abstract: Approximate nearest neighbor search (ANNS) is a core problem in machine learning and information retrieval applications. GPUs offer a promising path to high-performance ANNS: they provide massive parallelism for distance computations, are readily available, and can co-locate with downstream ",
    "url": "https://arxiv.org/abs/2601.07048",
    "source": "Arxiv AI"
  },
  {
    "title": "Attention Consistency Regularization for Interpretable Early-Exit Neural Networks",
    "summary": "arXiv:2601.08891v2 Announce Type: replace-cross Abstract: Early-exit neural networks enable adaptive inference by allowing predictions at intermediate layers, reducing computational cost. However, early exits often lack interpretability and may focus on different features than deeper layers, limiting trust and explainability. This paper presents Ex",
    "url": "https://arxiv.org/abs/2601.08891",
    "source": "Arxiv AI"
  },
  {
    "title": "Bridging Cognitive Neuroscience and Graph Intelligence: Hippocampus-Inspired Multi-View Hypergraph Learning for Web Finance Fraud",
    "summary": "arXiv:2601.11073v2 Announce Type: replace-cross Abstract: Online financial services constitute an essential component of contemporary web ecosystems, yet their openness introduces substantial exposure to fraud that harms vulnerable users and weakens trust in digital finance. Such threats have become a significant web harm that erodes societal fairn",
    "url": "https://arxiv.org/abs/2601.11073",
    "source": "Arxiv AI"
  },
  {
    "title": "ConceptCaps: a Distilled Concept Dataset for Interpretability in Music Models",
    "summary": "arXiv:2601.14157v3 Announce Type: replace-cross Abstract: Concept-based interpretability methods like TCAV require clean, well-separated positive and negative examples for each concept. Existing music datasets lack this structure: tags are sparse, noisy, or ill-defined. We introduce ConceptCaps, a dataset of 21k music-caption-tags triplets with exp",
    "url": "https://arxiv.org/abs/2601.14157",
    "source": "Arxiv AI"
  },
  {
    "title": "Attention Is Not Retention: The Orthogonality Constraint in Infinite-Context Architectures",
    "summary": "arXiv:2601.15313v2 Announce Type: replace-cross Abstract: Biological memory solves a problem that eludes current AI: storing specific episodic facts without corrupting general semantic knowledge. Complementary Learning Systems theory explains this through two subsystems - a fast hippocampal system using sparse, pattern-separated representations for",
    "url": "https://arxiv.org/abs/2601.15313",
    "source": "Arxiv AI"
  },
  {
    "title": "Low-Dimensional Adaptation of Rectified Flow: A Diffusion and Stochastic Localization Perspective",
    "summary": "arXiv:2601.15500v2 Announce Type: replace-cross Abstract: In recent years, Rectified flow (RF) has gained considerable popularity largely due to its generation efficiency and state-of-the-art performance. In this paper, we investigate the degree to which RF automatically adapts to the intrinsic low dimensionality of the support of the target distri",
    "url": "https://arxiv.org/abs/2601.15500",
    "source": "Arxiv AI"
  },
  {
    "title": "When Does Adaptation Win? Scaling Laws for Meta-Learning in Quantum Control",
    "summary": "arXiv:2601.18973v3 Announce Type: replace-cross Abstract: Quantum hardware suffers from intrinsic device heterogeneity and environmental drift, forcing practitioners to choose between suboptimal non-adaptive controllers or costly per-device recalibration. We derive a scaling law lower bound for meta-learning showing that the adaptation gain (expect",
    "url": "https://arxiv.org/abs/2601.18973",
    "source": "Arxiv AI"
  },
  {
    "title": "Stingy Context: 18:1 Hierarchical Code Compression for LLM Auto-Coding",
    "summary": "arXiv:2601.19929v2 Announce Type: replace-cross Abstract: We introduce Stingy Context, a hierarchical tree-based compression scheme achieving 18:1 reduction in LLM context for auto-coding tasks. Using our TREEFRAG exploit decomposition, we reduce a real source code base of 239k tokens to 11k tokens while preserving task fidelity. Empirical results ",
    "url": "https://arxiv.org/abs/2601.19929",
    "source": "Arxiv AI"
  },
  {
    "title": "CLEAR-Mamba:Towards Accurate, Adaptive and Trustworthy Multi-Sequence Ophthalmic Angiography Classification",
    "summary": "arXiv:2601.20601v2 Announce Type: replace-cross Abstract: Medical image classification is a core task in computer-aided diagnosis (CAD), playing a pivotal role in early disease detection, treatment planning, and patient prognosis assessment. In ophthalmic practice, fluorescein fundus angiography (FFA) and indocyanine green angiography (ICGA) provid",
    "url": "https://arxiv.org/abs/2601.20601",
    "source": "Arxiv AI"
  },
  {
    "title": "Zenith: Scaling up Ranking Models for Billion-scale Livestreaming Recommendation",
    "summary": "arXiv:2601.21285v3 Announce Type: replace-cross Abstract: Accurately capturing feature interactions is essential in recommender systems, and recent trends show that scaling up model capacity could be a key driver for next-level predictive performance. While prior work has explored various model architectures to capture multi-granularity feature int",
    "url": "https://arxiv.org/abs/2601.21285",
    "source": "Arxiv AI"
  },
  {
    "title": "Self-Improving Pretraining: using post-trained models to pretrain better models",
    "summary": "arXiv:2601.21343v2 Announce Type: replace-cross Abstract: Ensuring safety, factuality and overall quality in the generations of large language models is a critical challenge, especially as these models are increasingly deployed in real-world applications. The prevailing approach to addressing these issues involves collecting expensive, carefully cu",
    "url": "https://arxiv.org/abs/2601.21343",
    "source": "Arxiv AI"
  },
  {
    "title": "From Consistency to Complementarity: Aligned and Disentangled Multi-modal Learning for Time Series Understanding and Reasoning",
    "summary": "arXiv:2601.21436v2 Announce Type: replace-cross Abstract: Advances in multi-modal large language models (MLLMs) have inspired time series understanding and reasoning tasks, that enable natural language querying over time series, producing textual analyses of complex temporal dynamics. Recent attempts hybridize numerical time series with their visua",
    "url": "https://arxiv.org/abs/2601.21436",
    "source": "Arxiv AI"
  },
  {
    "title": "Optimization, Generalization and Differential Privacy Bounds for Gradient Descent on Kolmogorov-Arnold Networks",
    "summary": "arXiv:2601.22409v2 Announce Type: replace-cross Abstract: Kolmogorov--Arnold Networks (KANs) have recently emerged as a structured alternative to standard MLPs, yet a principled theory for their training dynamics, generalization, and privacy properties remains limited. In this paper, we analyze gradient descent (GD) for training two-layer KANs and ",
    "url": "https://arxiv.org/abs/2601.22409",
    "source": "Arxiv AI"
  },
  {
    "title": "Are LLM Evaluators Really Narcissists? Sanity Checking Self-Preference Evaluations",
    "summary": "arXiv:2601.22548v2 Announce Type: replace-cross Abstract: Recent research has shown that large language models (LLMs) favor their own outputs when acting as judges, undermining the integrity of automated post-training and evaluation workflows. However, it is difficult to disentangle which evaluation biases are explained by narcissism versus general",
    "url": "https://arxiv.org/abs/2601.22548",
    "source": "Arxiv AI"
  },
  {
    "title": "Beyond Fixed Frames: Dynamic Character-Aligned Speech Tokenization",
    "summary": "arXiv:2601.23174v2 Announce Type: replace-cross Abstract: Neural audio codecs are at the core of modern conversational speech technologies, converting continuous speech into sequences of discrete tokens that can be processed by LLMs. However, existing codecs typically operate at fixed frame rates, allocating tokens uniformly in time and producing u",
    "url": "https://arxiv.org/abs/2601.23174",
    "source": "Arxiv AI"
  },
  {
    "title": "ProDCARL: Reinforcement Learning-Aligned Diffusion Models for De Novo Antimicrobial Peptide Design",
    "summary": "arXiv:2602.00157v2 Announce Type: replace-cross Abstract: Antimicrobial resistance threatens healthcare sustainability and motivates low-cost computational discovery of antimicrobial peptides (AMPs). De novo peptide generation must optimize antimicrobial activity and safety through low predicted toxicity, but likelihood-trained generators do not en",
    "url": "https://arxiv.org/abs/2602.00157",
    "source": "Arxiv AI"
  },
  {
    "title": "RAPTOR: Ridge-Adaptive Logistic Probes",
    "summary": "arXiv:2602.00158v2 Announce Type: replace-cross Abstract: Probing studies what information is encoded in a frozen LLM's layer representations by training a lightweight predictor on top of them. Beyond analysis, probes are often used operationally in probe-then-steer pipelines: a learned concept vector is extracted from a probe and injected via addi",
    "url": "https://arxiv.org/abs/2602.00158",
    "source": "Arxiv AI"
  },
  {
    "title": "Hallucination is a Consequence of Space-Optimality: A Rate-Distortion Theorem for Membership Testing",
    "summary": "arXiv:2602.00906v4 Announce Type: replace-cross Abstract: Large language models often hallucinate with high confidence on \"random facts\" that lack inferable patterns. We formalize the memorization of such facts as a membership testing problem, unifying the discrete error metrics of Bloom filters with the continuous log-loss of LLMs. By analyzing th",
    "url": "https://arxiv.org/abs/2602.00906",
    "source": "Arxiv AI"
  },
  {
    "title": "LASS-ODE: Scaling ODE Computations to Connect Foundation Models with Dynamical Physical Systems",
    "summary": "arXiv:2602.01009v2 Announce Type: replace-cross Abstract: Foundation models have transformed language, vision, and time series data analysis, yet progress on dynamic predictions for physical systems remains limited. Given the complexity of physical constraints, two challenges stand out. $(i)$ Physics-computation scalability: physics-informed learni",
    "url": "https://arxiv.org/abs/2602.01009",
    "source": "Arxiv AI"
  },
  {
    "title": "TxRay: Agentic Postmortem of Live Blockchain Attacks",
    "summary": "arXiv:2602.01317v3 Announce Type: replace-cross Abstract: Decentralized Finance (DeFi) has turned blockchains into financial infrastructure, allowing anyone to trade, lend, and build protocols without intermediaries, but this openness exposes pools of value controlled by code. Within five years, the DeFi ecosystem has lost over 15.75B USD to report",
    "url": "https://arxiv.org/abs/2602.01317",
    "source": "Arxiv AI"
  },
  {
    "title": "Beyond Mode Elicitation: Diversity-Preserving Reinforcement Learning via Latent Diffusion Reasoner",
    "summary": "arXiv:2602.01705v2 Announce Type: replace-cross Abstract: Recent reinforcement learning (RL) methods improve LLM reasoning by optimizing discrete Chain-of-Thought (CoT) generation; however, exploration in token space often suffers from diversity collapse as policy entropy decreases due to mode elicitation behavior in discrete RL. To mitigate this i",
    "url": "https://arxiv.org/abs/2602.01705",
    "source": "Arxiv AI"
  },
  {
    "title": "Why Steering Works: Toward a Unified View of Language Model Parameter Dynamics",
    "summary": "arXiv:2602.02343v2 Announce Type: replace-cross Abstract: Methods for controlling large language models (LLMs), including local weight fine-tuning, LoRA-based adaptation, and activation-based interventions, are often studied in isolation, obscuring their connections and making comparison difficult. In this work, we present a unified view that frame",
    "url": "https://arxiv.org/abs/2602.02343",
    "source": "Arxiv AI"
  },
  {
    "title": "UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing",
    "summary": "arXiv:2602.02437v2 Announce Type: replace-cross Abstract: Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework tha",
    "url": "https://arxiv.org/abs/2602.02437",
    "source": "Arxiv AI"
  },
  {
    "title": "ProphetKV: User-Query-Driven Selective Recomputation for Efficient KV Cache Reuse in Retrieval-Augmented Generation",
    "summary": "arXiv:2602.02579v3 Announce Type: replace-cross Abstract: The prefill stage of long-context Retrieval-Augmented Generation (RAG) is severely bottlenecked by computational overhead. To mitigate this, recent methods assemble pre-calculated KV caches of retrieved RAG documents (by a user query) and reprocess selected tokens to recover cross-attention ",
    "url": "https://arxiv.org/abs/2602.02579",
    "source": "Arxiv AI"
  },
  {
    "title": "RAP: KV-Cache Compression via RoPE-Aligned Pruning",
    "summary": "arXiv:2602.02599v2 Announce Type: replace-cross Abstract: Long-context inference in large language models is increasingly bottlenecked by the memory and compute cost of the KV-Cache. Low-rank factorization compresses KV projections by writing $W \\approx A * B$, where A produces latent KV states and B can be absorbed into downstream weights. In mode",
    "url": "https://arxiv.org/abs/2602.02599",
    "source": "Arxiv AI"
  },
  {
    "title": "daVinci-Agency: Unlocking Long-Horizon Agency Data-Efficiently",
    "summary": "arXiv:2602.02619v2 Announce Type: replace-cross Abstract: While Large Language Models (LLMs) excel at short-term tasks, scaling them to long-horizon agentic workflows remains challenging. The core bottleneck lies in the scarcity of training data that captures authentic long-dependency structures and cross-stage evolutionary dynamics--existing synth",
    "url": "https://arxiv.org/abs/2602.02619",
    "source": "Arxiv AI"
  },
  {
    "title": "WAXAL: A Large-Scale Multilingual African Language Speech Corpus",
    "summary": "arXiv:2602.02734v2 Announce Type: replace-cross Abstract: The advancement of speech technology has predominantly favored high-resource languages, creating a significant digital divide for speakers of most Sub-Saharan African languages. To address this gap, we introduce WAXAL, a large-scale, openly accessible speech dataset for 21 languages represen",
    "url": "https://arxiv.org/abs/2602.02734",
    "source": "Arxiv AI"
  },
  {
    "title": "Tabula RASA: Exposing and Breaking the Relational Bottleneck in Transformers",
    "summary": "arXiv:2602.02834v2 Announce Type: replace-cross Abstract: Transformers achieve remarkable performance across many domains, yet struggle with tasks requiring multi-hop relational reasoning over structured data. We analyze this limitation through circuit complexity: standard transformers are $\\mathsf{TC}^0$-complete and cannot solve graph connectivit",
    "url": "https://arxiv.org/abs/2602.02834",
    "source": "Arxiv AI"
  },
  {
    "title": "CoBA-RL: Capability-Oriented Budget Allocation for Reinforcement Learning in LLMs",
    "summary": "arXiv:2602.03048v2 Announce Type: replace-cross Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a key approach for enhancing LLM reasoning. However, standard frameworks like Group Relative Policy Optimization (GRPO) typically employ a uniform rollout budget, leading to resource inefficiency. Moreover, existing adaptiv",
    "url": "https://arxiv.org/abs/2602.03048",
    "source": "Arxiv AI"
  },
  {
    "title": "\"I'm happy even though it's not real\": GenAI Photo Editing as a Remembering Experience",
    "summary": "arXiv:2602.03104v2 Announce Type: replace-cross Abstract: Generative Artificial Intelligence (GenAI) is increasingly integrated into photo applications on personal devices, making editing photographs easier than ever while potentially influencing the memories they represent. This study explores how and why people use GenAI to edit personal photos a",
    "url": "https://arxiv.org/abs/2602.03104",
    "source": "Arxiv AI"
  },
  {
    "title": "Not All Negative Samples Are Equal: LLMs Learn Better from Plausible Reasoning",
    "summary": "arXiv:2602.03516v2 Announce Type: replace-cross Abstract: Learning from negative samples holds great promise for improving Large Language Model (LLM) reasoning capability, yet existing methods treat all incorrect responses as equally informative, overlooking the crucial role of sample quality. To address this, we propose Plausible Negative Samples ",
    "url": "https://arxiv.org/abs/2602.03516",
    "source": "Arxiv AI"
  },
  {
    "title": "Rethinking imitation learning with Predictive Inverse Dynamics Models",
    "summary": "This research looks at why Predictive Inverse Dynamics Models often outperform standard Behavior Cloning in imitation learning. By using simple predictions of what happens next, PIDMs reduce ambiguity and learn from far fewer demonstrations. The post Rethinking imitation learning with Predictive Inverse Dynamics Models appeared first on Microsoft R",
    "url": "https://www.microsoft.com/en-us/research/blog/rethinking-imitation-learning-with-predictive-inverse-dynamics-models/",
    "source": "Microsoft Research"
  },
  {
    "title": "Paza: Introducing automatic speech recognition benchmarks and models for low resource languages",
    "summary": "Microsoft Research unveils Paza, a human-centered speech pipeline, and PazaBench, the first leaderboard for low-resource languages. It covers 39 African languages and 52 models and is tested with communities in real settings. The post Paza: Introducing automatic speech recognition benchmarks and models for low resource languages appeared first on M",
    "url": "https://www.microsoft.com/en-us/research/blog/paza-introducing-automatic-speech-recognition-benchmarks-and-models-for-low-resource-languages/",
    "source": "Microsoft Research"
  },
  {
    "title": "UniRG: Scaling medical imaging report generation with multimodal reinforcement learning",
    "summary": "AI can help generate medical image reports, but today’s models struggle with varying reporting schemes. Learn how UniRG uses reinforcement learning to boost performance of medical vision-language models. The post UniRG: Scaling medical imaging report generation with multimodal reinforcement learning appeared first on Microsoft Research.",
    "url": "https://www.microsoft.com/en-us/research/blog/unirg-scaling-medical-imaging-report-generation-with-multimodal-reinforcement-learning/",
    "source": "Microsoft Research"
  },
  {
    "title": "Multimodal reinforcement learning with agentic verifier for AI agents",
    "summary": "Argos improves multimodal RL by evaluating whether an agent’s reasoning aligns with what it observes over time. The approach reduces visual hallucinations and produces more reliable, data-efficient agents for real-world applications. The post Multimodal reinforcement learning with agentic verifier for AI agents appeared first on Microsoft Research.",
    "url": "https://www.microsoft.com/en-us/research/blog/multimodal-reinforcement-learning-with-agentic-verifier-for-ai-agents/",
    "source": "Microsoft Research"
  },
  {
    "title": "OptiMind: A small language model with optimization expertise",
    "summary": "OptiMind is a small language model that converts business operation challenges, described naturally, into mathematical formulations that optimization software can solve. It reduces formulation time &#038; errors &#038; enables fast, privacy-preserving local use. The post OptiMind: A small language model with optimization expertise appeared first on",
    "url": "https://www.microsoft.com/en-us/research/blog/optimind-a-small-language-model-with-optimization-expertise/",
    "source": "Microsoft Research"
  },
  {
    "title": "Agent Lightning: Adding reinforcement learning to AI agents without code rewrites",
    "summary": "By decoupling how agents work from how they’re trained, Agent Lightning turns each step an agent takes into data for reinforcement learning. This makes it easy for developers to improve agent performance with almost zero code changes. The post Agent Lightning: Adding reinforcement learning to AI agents without code rewrites appeared first on Micros",
    "url": "https://www.microsoft.com/en-us/research/blog/agent-lightning-adding-reinforcement-learning-to-ai-agents-without-code-rewrites/",
    "source": "Microsoft Research"
  },
  {
    "title": "Promptions helps make AI prompting more precise with dynamic UI controls",
    "summary": "Promptions helps developers add dynamic, context-aware controls to chat interfaces so users can guide generative AI responses. It lets users shape outputs quickly without writing long instructions. The post Promptions helps make AI prompting more precise with dynamic UI controls appeared first on Microsoft Research.",
    "url": "https://www.microsoft.com/en-us/research/blog/promptions-helps-make-ai-prompting-more-precise-with-dynamic-ui-controls/",
    "source": "Microsoft Research"
  },
  {
    "title": "GigaTIME: Scaling tumor microenvironment modeling using virtual population generated by multimodal AI",
    "summary": "Using AI-generated virtual populations, Microsoft researchers uncovered hidden cellular patterns that could reshape how we understand and treat cancer. The post GigaTIME: Scaling tumor microenvironment modeling using virtual population generated by multimodal AI appeared first on Microsoft Research.",
    "url": "https://www.microsoft.com/en-us/research/blog/gigatime-scaling-tumor-microenvironment-modeling-using-virtual-population-generated-by-multimodal-ai/",
    "source": "Microsoft Research"
  },
  {
    "title": "Ideas: Community building, machine learning, and the future of AI",
    "summary": "As the Women in Machine Learning Workshop (WiML) marks its 20th annual gathering, cofounders, friends, and collaborators Jenn Wortman Vaughan and Hanna Wallach reflect on WiML’s evolution, navigating the field of ML, and their work in responsible AI. The post Ideas: Community building, machine learning, and the future of AI appeared first on Micros",
    "url": "https://www.microsoft.com/en-us/research/podcast/ideas-community-building-machine-learning-and-the-future-of-ai/",
    "source": "Microsoft Research"
  },
  {
    "title": "Reducing Privacy leaks in AI: Two approaches to contextual integrity",
    "summary": "New research explores two ways to give AI agents stronger privacy safeguards grounded in contextual integrity. One adds lightweight, inference-time checks; the other builds contextual awareness directly into models through reasoning and RL. The post Reducing Privacy leaks in AI: Two approaches to contextual integrity appeared first on Microsoft Res",
    "url": "https://www.microsoft.com/en-us/research/blog/reducing-privacy-leaks-in-ai-two-approaches-to-contextual-integrity/",
    "source": "Microsoft Research"
  },
  {
    "title": "Introducing SyGra Studio",
    "summary": "",
    "url": "https://huggingface.co/blog/ServiceNow-AI/sygra-studio",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Nemotron ColEmbed V2: Raising the Bar for Multimodal Retrieval with ViDoRe V3’s Top Model",
    "summary": "",
    "url": "https://huggingface.co/blog/nvidia/nemotron-colembed-v2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Community Evals: Because we're done trusting black-box leaderboards over the community",
    "summary": "",
    "url": "https://huggingface.co/blog/community-evals",
    "source": "Hugging Face Blog"
  },
  {
    "title": "H Company's new Holo2 model takes the lead in UI Localization",
    "summary": "",
    "url": "https://huggingface.co/blog/Hcompany/introducing-holo2-235b-a22b",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The Future of the Global Open-Source AI Ecosystem: From DeepSeek to AI+",
    "summary": "",
    "url": "https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-3",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Training Design for Text-to-Image Models: Lessons from Ablations",
    "summary": "",
    "url": "https://huggingface.co/blog/Photoroom/prx-part2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Daggr: Chain apps programmatically, inspect visually",
    "summary": "",
    "url": "https://huggingface.co/blog/daggr",
    "source": "Hugging Face Blog"
  },
  {
    "title": "We Got Claude to Build CUDA Kernels and teach open models!",
    "summary": "",
    "url": "https://huggingface.co/blog/upskill",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Architectural Choices in China's Open-Source AI Ecosystem: Building Beyond DeepSeek",
    "summary": "",
    "url": "https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Alyah ⭐️: Toward Robust Evaluation of Emirati Dialect Capabilities in Arabic LLMs",
    "summary": "",
    "url": "https://huggingface.co/blog/tiiuae/emirati-benchmarks",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Unlocking Agentic RL Training for GPT-OSS: A Practical Retrospective",
    "summary": "",
    "url": "https://huggingface.co/blog/LinkedIn/gpt-oss-agentic-rl",
    "source": "Hugging Face Blog"
  },
  {
    "title": "AssetOpsBench: Bridging the Gap Between AI Agent Benchmarks and Industrial Reality",
    "summary": "",
    "url": "https://huggingface.co/blog/ibm-research/assetopsbench-playground-on-hugging-face",
    "source": "Hugging Face Blog"
  },
  {
    "title": "One Year Since the “DeepSeek Moment”",
    "summary": "",
    "url": "https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Differential Transformer V2",
    "summary": "",
    "url": "https://huggingface.co/blog/microsoft/diff-attn-v2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Waypoint-1: Real-time interactive video diffusion from Overworld",
    "summary": "",
    "url": "https://huggingface.co/blog/waypoint-1",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Open Responses: What you need to know",
    "summary": "",
    "url": "https://huggingface.co/blog/open-responses",
    "source": "Hugging Face Blog"
  },
  {
    "title": "NVIDIA Cosmos Reason 2 Brings Advanced Reasoning To Physical AI",
    "summary": "",
    "url": "https://huggingface.co/blog/nvidia/nvidia-cosmos-reason-2-brings-advanced-reasoning",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Falcon-H1-Arabic: Pushing the Boundaries of Arabic Language AI with Hybrid Architecture",
    "summary": "",
    "url": "https://huggingface.co/blog/tiiuae/falcon-h1-arabic",
    "source": "Hugging Face Blog"
  },
  {
    "title": "NVIDIA brings agents to life with DGX Spark and Reachy Mini",
    "summary": "",
    "url": "https://huggingface.co/blog/nvidia-reachy-mini",
    "source": "Hugging Face Blog"
  },
  {
    "title": "AprielGuard: A Guardrail for Safety and Adversarial Robustness in Modern LLM Systems",
    "summary": "",
    "url": "https://huggingface.co/blog/ServiceNow-AI/aprielguard",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Tokenization in Transformers v5: Simpler, Clearer, and More Modular",
    "summary": "",
    "url": "https://huggingface.co/blog/tokenizers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The Open Evaluation Standard: Benchmarking NVIDIA Nemotron 3 Nano with NeMo Evaluator",
    "summary": "",
    "url": "https://huggingface.co/blog/nvidia/nemotron-3-nano-evaluation-recipe",
    "source": "Hugging Face Blog"
  },
  {
    "title": "CUGA on Hugging Face: Democratizing Configurable AI Agents",
    "summary": "",
    "url": "https://huggingface.co/blog/ibm-research/cuga-on-hugging-face",
    "source": "Hugging Face Blog"
  },
  {
    "title": "New in llama.cpp: Model Management",
    "summary": "",
    "url": "https://huggingface.co/blog/ggml-org/model-management-in-llamacpp",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Codex is Open Sourcing AI models",
    "summary": "",
    "url": "https://huggingface.co/blog/hf-skills-training-codex",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing swift-huggingface: The Complete Swift Client for Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/swift-huggingface",
    "source": "Hugging Face Blog"
  },
  {
    "title": "DeepMath: A lightweight math reasoning Agent with smolagents",
    "summary": "",
    "url": "https://huggingface.co/blog/intel-deepmath",
    "source": "Hugging Face Blog"
  },
  {
    "title": "We Got Claude to Fine-Tune an Open Source LLM",
    "summary": "",
    "url": "https://huggingface.co/blog/hf-skills-training",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Transformers v5: Simple model definitions powering the AI ecosystem",
    "summary": "",
    "url": "https://huggingface.co/blog/transformers-v5",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Diffusers welcomes FLUX-2",
    "summary": "",
    "url": "https://huggingface.co/blog/flux-2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Continuous batching from first principles",
    "summary": "",
    "url": "https://huggingface.co/blog/continuous_batching",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Building Deep Research: How we Achieved State of the Art",
    "summary": "",
    "url": "https://huggingface.co/blog/Tavily/tavily-deep-research",
    "source": "Hugging Face Blog"
  },
  {
    "title": "OVHcloud on Hugging Face Inference Providers 🔥",
    "summary": "",
    "url": "https://huggingface.co/blog/OVHcloud/inference-providers-ovhcloud",
    "source": "Hugging Face Blog"
  },
  {
    "title": "20x Faster TRL Fine-tuning with RapidFire AI",
    "summary": "",
    "url": "https://huggingface.co/blog/rapidfireai",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Open ASR Leaderboard: Trends and Insights with New Multilingual & Long-Form Tracks",
    "summary": "",
    "url": "https://huggingface.co/blog/open-asr-leaderboard",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing AnyLanguageModel: One API for Local and Remote LLMs on Apple Platforms",
    "summary": "",
    "url": "https://huggingface.co/blog/anylanguagemodel",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Apriel-H1: The Surprising Key to Distilling Efficient Reasoning Models",
    "summary": "",
    "url": "https://huggingface.co/blog/ServiceNow-AI/apriel-h1",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Easily Build and Share ROCm Kernels with Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/build-rocm-kernels",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Join the AMD Open Robotics Hackathon",
    "summary": "",
    "url": "https://huggingface.co/blog/amd/openroboticshackathon",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Building for an Open Future - our new partnership with Google Cloud",
    "summary": "",
    "url": "https://huggingface.co/blog/google-cloud",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Aligning to What? Rethinking Agent Generalization in MiniMax M2",
    "summary": "",
    "url": "https://huggingface.co/blog/MiniMax-AI/aligning-to-what",
    "source": "Hugging Face Blog"
  },
  {
    "title": "On the Shifting Global Compute Landscape",
    "summary": "",
    "url": "https://huggingface.co/blog/huggingface/shifting-compute-landscape",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Building a Healthcare Robot from Simulation to Deployment with NVIDIA Isaac",
    "summary": "",
    "url": "https://huggingface.co/blog/lerobotxnvidia-healthcare",
    "source": "Hugging Face Blog"
  },
  {
    "title": "How to Build a Healthcare Robot from Simulation to Deployment with NVIDIA Isaac for Healthcare",
    "summary": "",
    "url": "https://huggingface.co/blog/nvidia/nvidia-isaac-for-healthcare",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Granite 4.0 Nano: Just how small can you go?",
    "summary": "",
    "url": "https://huggingface.co/blog/ibm-granite/granite-4-nano",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Voice Cloning with Consent",
    "summary": "",
    "url": "https://huggingface.co/blog/voice-consent-gate",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Streaming datasets: 100x More Efficient",
    "summary": "",
    "url": "https://huggingface.co/blog/streaming-datasets",
    "source": "Hugging Face Blog"
  },
  {
    "title": "huggingface_hub v1.0: Five Years of Building the Foundation of Open Machine Learning",
    "summary": "",
    "url": "https://huggingface.co/blog/huggingface-hub-v1",
    "source": "Hugging Face Blog"
  },
  {
    "title": "LeRobot v0.4.0: Supercharging OSS Robot Learning",
    "summary": "",
    "url": "https://huggingface.co/blog/lerobot-release-v040",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Building the Open Agent Ecosystem Together: Introducing OpenEnv",
    "summary": "",
    "url": "https://huggingface.co/blog/openenv",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face and VirusTotal collaborate to strengthen AI security",
    "summary": "",
    "url": "https://huggingface.co/blog/virustotal",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Sentence Transformers is joining Hugging Face!",
    "summary": "",
    "url": "https://huggingface.co/blog/sentence-transformers-joins-hf",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Supercharge your OCR Pipelines with Open Models",
    "summary": "",
    "url": "https://huggingface.co/blog/ocr-open-models",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Unlock the power of images with AI Sheets",
    "summary": "",
    "url": "https://huggingface.co/blog/aisheets-unlock-images",
    "source": "Hugging Face Blog"
  },
  {
    "title": "AI for Food Allergies",
    "summary": "",
    "url": "https://huggingface.co/blog/hugging-science/ai-for-food-allergies",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Google Cloud C4 Brings a 70% TCO improvement on GPT OSS with Intel and Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/gpt-oss-on-intel-xeon",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Get your VLM running in 3 simple steps on Intel CPUs",
    "summary": "",
    "url": "https://huggingface.co/blog/openvino-vlm",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Nemotron-Personas-India: Synthesized Data for Sovereign AI",
    "summary": "",
    "url": "https://huggingface.co/blog/nvidia/nemotron-personas-india",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Arm will be @ PyTorch Conference, Join Us!",
    "summary": "",
    "url": "https://huggingface.co/blog/Arm/arm-at-pytorch-conference",
    "source": "Hugging Face Blog"
  },
  {
    "title": "BigCodeArena: Judging code generations end to end with code executions",
    "summary": "",
    "url": "https://huggingface.co/blog/bigcode/arena",
    "source": "Hugging Face Blog"
  },
  {
    "title": "SOTA OCR with Core ML and dots.ocr",
    "summary": "",
    "url": "https://huggingface.co/blog/dots-ocr-ne",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing RTEB: A New Standard for Retrieval Evaluation",
    "summary": "",
    "url": "https://huggingface.co/blog/rteb",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Accelerating Qwen3-8B Agent on Intel® Core™ Ultra with Depth-Pruned Draft Models",
    "summary": "",
    "url": "https://huggingface.co/blog/intel-qwen3-agent",
    "source": "Hugging Face Blog"
  },
  {
    "title": "VibeGame: Exploring Vibe Coding Games",
    "summary": "",
    "url": "https://huggingface.co/blog/vibegame",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Nemotron-Personas-Japan: ソブリン AI のための合成データセット",
    "summary": "",
    "url": "https://huggingface.co/blog/nvidia/nemotron-personas-japan-ja",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Swift Transformers Reaches 1.0 – and Looks to the Future",
    "summary": "",
    "url": "https://huggingface.co/blog/swift-transformers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Smol2Operator: Post-Training GUI Agents for Computer Use",
    "summary": "",
    "url": "https://huggingface.co/blog/smol2operator",
    "source": "Hugging Face Blog"
  },
  {
    "title": "SyGra: The One-Stop Framework for Building Data for LLMs and SLMs",
    "summary": "",
    "url": "https://huggingface.co/blog/ServiceNow-AI/sygra-data-gen-framework",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Gaia2 and ARE: Empowering the community to study agents",
    "summary": "",
    "url": "https://huggingface.co/blog/gaia2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Scaleway on Hugging Face Inference Providers 🔥",
    "summary": "",
    "url": "https://huggingface.co/blog/inference-providers-scaleway",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Democratizing AI Safety with RiskRubric.ai",
    "summary": "",
    "url": "https://huggingface.co/blog/riskrubric",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Public AI on Hugging Face Inference Providers 🔥",
    "summary": "",
    "url": "https://huggingface.co/blog/inference-providers-publicai",
    "source": "Hugging Face Blog"
  },
  {
    "title": "`LeRobotDataset:v3.0`: Bringing large-scale datasets to `lerobot`",
    "summary": "",
    "url": "https://huggingface.co/blog/lerobot-datasets-v3",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Visible Watermarking with Gradio",
    "summary": "",
    "url": "https://huggingface.co/blog/watermarking-with-gradio",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing the Palmyra-mini family: Powerful, lightweight, and ready to reason!",
    "summary": "",
    "url": "https://huggingface.co/blog/Writer/announcing-palmyra-mini",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Tricks from OpenAI gpt-oss YOU 🫵 can use with transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/faster-transformers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fine-tune Any LLM from the Hugging Face Hub with Together AI",
    "summary": "",
    "url": "https://huggingface.co/blog/togethercomputer/together-ft",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Jupyter Agents: training LLMs to reason with notebooks",
    "summary": "",
    "url": "https://huggingface.co/blog/jupyter-agent-2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "mmBERT: ModernBERT goes Multilingual",
    "summary": "",
    "url": "https://huggingface.co/blog/mmbert",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome EmbeddingGemma, Google's new efficient embedding model",
    "summary": "",
    "url": "https://huggingface.co/blog/embeddinggemma",
    "source": "Hugging Face Blog"
  },
  {
    "title": "SAIR: Accelerating Pharma R&D with AI-Powered Structural Intelligence",
    "summary": "",
    "url": "https://huggingface.co/blog/SandboxAQ/sair-data-accelerating-drug-discovery-with-ai",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Make your ZeroGPU Spaces go brrr with ahead-of-time compilation",
    "summary": "",
    "url": "https://huggingface.co/blog/zerogpu-aoti",
    "source": "Hugging Face Blog"
  },
  {
    "title": "NVIDIA Releases 6 Million Multi-Lingual Reasoning Dataset",
    "summary": "",
    "url": "https://huggingface.co/blog/nvidia/multilingual-reasoning-v1",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Generate Images with Claude and Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/claude-and-mcp",
    "source": "Hugging Face Blog"
  },
  {
    "title": "From Zero to GPU: A Guide to Building and Scaling Production-Ready CUDA Kernels",
    "summary": "",
    "url": "https://huggingface.co/blog/kernel-builder",
    "source": "Hugging Face Blog"
  },
  {
    "title": "MCP for Research: How to Connect AI to Research Tools",
    "summary": "",
    "url": "https://huggingface.co/blog/mcp-for-research",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Kimina-Prover-RL",
    "summary": "",
    "url": "https://huggingface.co/blog/AI-MO/kimina-prover-rl",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Arm & ExecuTorch 0.7: Bringing Generative AI to the masses",
    "summary": "",
    "url": "https://huggingface.co/blog/Arm/executorch-0-dot-7",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Neural Super Sampling is here!",
    "summary": "",
    "url": "https://huggingface.co/blog/Arm/neural-super-sampling",
    "source": "Hugging Face Blog"
  },
  {
    "title": "TextQuests: How Good are LLMs at Text-Based Video Games?",
    "summary": "",
    "url": "https://huggingface.co/blog/textquests",
    "source": "Hugging Face Blog"
  },
  {
    "title": "🇵🇭 FilBench - Can LLMs Understand and Generate Filipino?",
    "summary": "",
    "url": "https://huggingface.co/blog/filbench",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing AI Sheets: a tool to work with datasets using open AI models!",
    "summary": "",
    "url": "https://huggingface.co/blog/aisheets",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Accelerate ND-Parallel: A guide to Efficient Multi-GPU Training",
    "summary": "",
    "url": "https://huggingface.co/blog/accelerate-nd-parallel",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Vision Language Model Alignment in TRL ⚡️",
    "summary": "",
    "url": "https://huggingface.co/blog/trl-vlm-alignment",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome GPT OSS, the new open-source model family from OpenAI!",
    "summary": "",
    "url": "https://huggingface.co/blog/welcome-openai-gpt-oss",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Measuring Open-Source Llama Nemotron Models on DeepResearch Bench",
    "summary": "",
    "url": "https://huggingface.co/blog/nvidia/ai-q-top-ranking-open-portable-deep-research-agent",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Implementing MCP Servers in Python: An AI Shopping Assistant with Gradio",
    "summary": "",
    "url": "https://huggingface.co/blog/gradio-vton-mcp",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Trackio: A Lightweight Experiment Tracking Library from Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/trackio",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Say hello to `hf`: a faster, friendlier Hugging Face CLI ✨",
    "summary": "",
    "url": "https://huggingface.co/blog/hf-cli",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Parquet Content-Defined Chunking",
    "summary": "",
    "url": "https://huggingface.co/blog/parquet-cdc",
    "source": "Hugging Face Blog"
  },
  {
    "title": "TimeScope: How Long Can Your Video Large Multimodal Model Go?",
    "summary": "",
    "url": "https://huggingface.co/blog/timescope-video-lmm-benchmark",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fast LoRA inference for Flux with Diffusers and PEFT",
    "summary": "",
    "url": "https://huggingface.co/blog/lora-fast",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Accelerate a World of LLMs on Hugging Face with NVIDIA NIM",
    "summary": "",
    "url": "https://huggingface.co/blog/nvidia/multi-llm-nim",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Arc Virtual Cell Challenge: A Primer",
    "summary": "",
    "url": "https://huggingface.co/blog/virtual-cell-challenge",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Consilium: When Multiple LLMs Collaborate",
    "summary": "",
    "url": "https://huggingface.co/blog/consilium-multi-llm",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Back to The Future: Evaluating AI Agents on Predicting Future Events",
    "summary": "",
    "url": "https://huggingface.co/blog/futurebench",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Five Big Improvements to Gradio MCP Servers",
    "summary": "",
    "url": "https://huggingface.co/blog/gradio-mcp-updates",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Ettin Suite: SoTA Paired Encoders and Decoders",
    "summary": "",
    "url": "https://huggingface.co/blog/ettin",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Migrating the Hub from Git LFS to Xet",
    "summary": "",
    "url": "https://huggingface.co/blog/migrating-the-hub-to-xet",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Kimina-Prover: Applying Test-time RL Search on Large Formal Reasoning Models",
    "summary": "",
    "url": "https://huggingface.co/blog/AI-MO/kimina-prover",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Asynchronous Robot Inference: Decoupling Action Prediction and Execution",
    "summary": "",
    "url": "https://huggingface.co/blog/async-robot-inference",
    "source": "Hugging Face Blog"
  },
  {
    "title": "ScreenEnv: Deploy your full stack Desktop Agent",
    "summary": "",
    "url": "https://huggingface.co/blog/screenenv",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Building the Hugging Face MCP Server",
    "summary": "",
    "url": "https://huggingface.co/blog/building-hf-mcp",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Reachy Mini - The Open-Source Robot for Today's and Tomorrow's AI Builders",
    "summary": "",
    "url": "https://huggingface.co/blog/reachy-mini",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Creating custom kernels for the AMD MI300",
    "summary": "",
    "url": "https://huggingface.co/blog/mi300kernels",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Upskill your LLMs With Gradio MCP Servers",
    "summary": "",
    "url": "https://huggingface.co/blog/gradio-mcp-servers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "SmolLM3: smol, multilingual, long-context reasoner",
    "summary": "",
    "url": "https://huggingface.co/blog/smollm3",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Three Mighty Alerts Supporting Hugging Face’s Production Infrastructure",
    "summary": "",
    "url": "https://huggingface.co/blog/infrastructure-alerting",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Efficient MultiModal Data Pipeline",
    "summary": "",
    "url": "https://huggingface.co/blog/mmdp",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Announcing  NeurIPS 2025 E2LM Competition: Early Training Evaluation of Language Models",
    "summary": "",
    "url": "https://huggingface.co/blog/tiiuae/e2lm-competition",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Training and Finetuning Sparse Embedding Models with Sentence Transformers v5",
    "summary": "",
    "url": "https://huggingface.co/blog/train-sparse-encoder",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome the NVIDIA Llama Nemotron Nano VLM to Hugging Face Hub",
    "summary": "",
    "url": "https://huggingface.co/blog/nvidia/llama-nemotron-nano-vl",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Gemma 3n fully available in the open-source ecosystem!",
    "summary": "",
    "url": "https://huggingface.co/blog/gemma3n",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Transformers backend integration in SGLang",
    "summary": "",
    "url": "https://huggingface.co/blog/transformers-backend-sglang",
    "source": "Hugging Face Blog"
  },
  {
    "title": "(LoRA) Fine-Tuning FLUX.1-dev on Consumer Hardware",
    "summary": "",
    "url": "https://huggingface.co/blog/flux-qlora",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Groq on Hugging Face Inference Providers 🔥",
    "summary": "",
    "url": "https://huggingface.co/blog/inference-providers-groq",
    "source": "Hugging Face Blog"
  },
  {
    "title": "How Long Prompts Block Other Requests - Optimizing LLM Performance",
    "summary": "",
    "url": "https://huggingface.co/blog/tngtech/llm-performance-blocked-by-long-prompts",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Learn the Hugging Face Kernel Hub in 5 Minutes",
    "summary": "",
    "url": "https://huggingface.co/blog/hello-hf-kernels",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Featherless AI on Hugging Face Inference Providers 🔥",
    "summary": "",
    "url": "https://huggingface.co/blog/inference-providers-featherless",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Post-Training Isaac GR00T N1.5 for LeRobot SO-101 Arm",
    "summary": "",
    "url": "https://huggingface.co/blog/nvidia/gr00t-n1-5-so101-tuning",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Training Cluster as a Service - a new collaboration with NVIDIA",
    "summary": "",
    "url": "https://huggingface.co/blog/nvidia-training-cluster",
    "source": "Hugging Face Blog"
  },
  {
    "title": "ScreenSuite - The most comprehensive evaluation suite for GUI Agents!",
    "summary": "",
    "url": "https://huggingface.co/blog/screensuite",
    "source": "Hugging Face Blog"
  },
  {
    "title": "KV Cache from scratch in nanoVLM",
    "summary": "",
    "url": "https://huggingface.co/blog/kv-cache",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Real-Time AI Sound Generation on Arm: A Personal Tool for Creative Freedom",
    "summary": "",
    "url": "https://huggingface.co/blog/Arm/ai-sound-gen-on-arm",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Holo1: New family of GUI automation VLMs powering GUI agent Surfer-H",
    "summary": "",
    "url": "https://huggingface.co/blog/Hcompany/holo1",
    "source": "Hugging Face Blog"
  },
  {
    "title": "SmolVLA: Efficient Vision-Language-Action Model trained on Lerobot Community Data",
    "summary": "",
    "url": "https://huggingface.co/blog/smolvla",
    "source": "Hugging Face Blog"
  },
  {
    "title": "No GPU left behind: Unlocking Efficiency with Co-located vLLM in TRL",
    "summary": "",
    "url": "https://huggingface.co/blog/vllm-colocate",
    "source": "Hugging Face Blog"
  },
  {
    "title": "CodeAgents + Structure: A Better Way to Execute Actions",
    "summary": "",
    "url": "https://huggingface.co/blog/structured-codeagent",
    "source": "Hugging Face Blog"
  },
  {
    "title": "🐯 Liger GRPO meets TRL",
    "summary": "",
    "url": "https://huggingface.co/blog/liger-grpo",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Dell Enterprise Hub is all you need to build AI on premises",
    "summary": "",
    "url": "https://huggingface.co/blog/dell-ai-applications",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Tiny Agents in Python: a MCP-powered agent in ~70 lines of code",
    "summary": "",
    "url": "https://huggingface.co/blog/python-tiny-agents",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Falcon-H1: A Family of Hybrid-Head Language Models Redefining Efficiency and Performance",
    "summary": "",
    "url": "https://huggingface.co/blog/tiiuae/falcon-h1",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Falcon-Arabic: A Breakthrough in Arabic Language Models",
    "summary": "",
    "url": "https://huggingface.co/blog/tiiuae/falcon-arabic",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Exploring Quantization Backends in Diffusers",
    "summary": "",
    "url": "https://huggingface.co/blog/diffusers-quantization",
    "source": "Hugging Face Blog"
  },
  {
    "title": "nanoVLM: The simplest repository to train your VLM in pure PyTorch",
    "summary": "",
    "url": "https://huggingface.co/blog/nanovlm",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Microsoft and Hugging Face expand collaboration",
    "summary": "",
    "url": "https://huggingface.co/blog/azure-ai-foundry",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Falcon-Edge: A series of powerful, universal, fine-tunable 1.58bit language models.",
    "summary": "",
    "url": "https://huggingface.co/blog/tiiuae/falcon-edge",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The Transformers Library: standardizing model definitions",
    "summary": "",
    "url": "https://huggingface.co/blog/transformers-model-definition",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Improving Hugging Face Model Access for Kaggle Users",
    "summary": "",
    "url": "https://huggingface.co/blog/kaggle-integration",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Blazingly fast whisper transcriptions with Inference Endpoints",
    "summary": "",
    "url": "https://huggingface.co/blog/fast-whisper-endpoints",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Vision Language Models (Better, faster, stronger)",
    "summary": "",
    "url": "https://huggingface.co/blog/vlms-2025",
    "source": "Hugging Face Blog"
  },
  {
    "title": "LeRobot Community Datasets: The “ImageNet” of Robotics — When and How?",
    "summary": "",
    "url": "https://huggingface.co/blog/lerobot-datasets",
    "source": "Hugging Face Blog"
  },
  {
    "title": "How to Build an MCP Server with Gradio",
    "summary": "",
    "url": "https://huggingface.co/blog/gradio-mcp",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The 4 Things Qwen-3’s Chat Template Teaches Us",
    "summary": "",
    "url": "https://huggingface.co/blog/qwen-3-chat-template-deep-dive",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcoming Llama Guard 4 on Hugging Face Hub",
    "summary": "",
    "url": "https://huggingface.co/blog/llama-guard-4",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing AutoRound: Intel’s Advanced Quantization for LLMs and VLMs",
    "summary": "",
    "url": "https://huggingface.co/blog/autoround",
    "source": "Hugging Face Blog"
  },
  {
    "title": "PipelineRL",
    "summary": "",
    "url": "https://huggingface.co/blog/ServiceNow/pipelinerl",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Tiny Agents: an MCP-powered agent in 50 lines of code",
    "summary": "",
    "url": "https://huggingface.co/blog/tiny-agents",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Finetuning olmOCR to be a faithful OCR-Engine",
    "summary": "",
    "url": "https://huggingface.co/blog/tngtech/finetuning-olmocr-to-be-a-faithful-ocr-engine",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Prefill and Decode for Concurrent Requests - Optimizing LLM Performance",
    "summary": "",
    "url": "https://huggingface.co/blog/tngtech/llm-performance-prefill-decode-concurrent-requests",
    "source": "Hugging Face Blog"
  },
  {
    "title": "17 Reasons Why Gradio Isn't Just Another UI Library",
    "summary": "",
    "url": "https://huggingface.co/blog/why-gradio-stands-out",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Cohere on Hugging Face Inference Providers 🔥",
    "summary": "",
    "url": "https://huggingface.co/blog/inference-providers-cohere",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing HELMET: Holistically Evaluating Long-context Language Models",
    "summary": "",
    "url": "https://huggingface.co/blog/helmet",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face to sell open-source robots thanks to Pollen Robotics acquisition 🤖",
    "summary": "",
    "url": "https://huggingface.co/blog/hugging-face-pollen-robotics-acquisition",
    "source": "Hugging Face Blog"
  },
  {
    "title": "4M Models Scanned: Protect AI + Hugging Face 6 Months In",
    "summary": "",
    "url": "https://huggingface.co/blog/pai-6-month",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Visual Salamandra: Pushing the Boundaries of Multimodal Understanding",
    "summary": "",
    "url": "https://huggingface.co/blog/BSC-LT/visualsalamandra7b",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face and Cloudflare Partner to Make Real-Time Speech and Video Seamless with FastRTC",
    "summary": "",
    "url": "https://huggingface.co/blog/fastrtc-cloudflare",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Arabic Leaderboards: Introducing Arabic Instruction Following, Updating AraGen, and More",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-3c3h-aragen-ifeval",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome Llama 4 Maverick & Scout on Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/llama4-release",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Journey to 1 Million Gradio Users!",
    "summary": "",
    "url": "https://huggingface.co/blog/gradio-1m",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The NLP Course is becoming the LLM Course",
    "summary": "",
    "url": "https://huggingface.co/blog/llm-course",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Efficient Request Queueing – Optimizing LLM Performance",
    "summary": "",
    "url": "https://huggingface.co/blog/tngtech/llm-performance-request-queueing",
    "source": "Hugging Face Blog"
  },
  {
    "title": "How Hugging Face Scaled Secrets Management for AI Infrastructure",
    "summary": "",
    "url": "https://huggingface.co/blog/scaling-secrets-management",
    "source": "Hugging Face Blog"
  },
  {
    "title": "🚀 Accelerating LLM Inference with TGI on Intel Gaudi",
    "summary": "",
    "url": "https://huggingface.co/blog/intel-gaudi-backend-for-tgi",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Open R1: Update #4",
    "summary": "",
    "url": "https://huggingface.co/blog/open-r1/update-4",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Training and Finetuning Reranker Models with Sentence Transformers v4",
    "summary": "",
    "url": "https://huggingface.co/blog/train-reranker",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Gradio's new Dataframe!",
    "summary": "",
    "url": "https://huggingface.co/blog/gradio-dataframe-upgrade",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The New and Fresh analytics in Inference Endpoints",
    "summary": "",
    "url": "https://huggingface.co/blog/endpoint-analytics",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Open R1: How to use OlympicCoder locally for coding",
    "summary": "",
    "url": "https://huggingface.co/blog/olympic-coder-lmstudio",
    "source": "Hugging Face Blog"
  },
  {
    "title": "AI Policy @🤗: Response to the White House AI Action Plan RFI",
    "summary": "",
    "url": "https://huggingface.co/blog/ai-action-wh-2025",
    "source": "Hugging Face Blog"
  },
  {
    "title": "NVIDIA's GTC 2025 Announcement for Physical AI Developers: New Open Models and Datasets",
    "summary": "",
    "url": "https://huggingface.co/blog/nvidia-physical-ai",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Xet is on the Hub",
    "summary": "",
    "url": "https://huggingface.co/blog/xet-on-the-hub",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome Gemma 3: Google's all new multimodal, multilingual, long context open LLM",
    "summary": "",
    "url": "https://huggingface.co/blog/gemma3",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Open R1: Update #3",
    "summary": "",
    "url": "https://huggingface.co/blog/open-r1/update-3",
    "source": "Hugging Face Blog"
  },
  {
    "title": "LeRobot goes to driving school: World’s largest open-source self-driving dataset",
    "summary": "",
    "url": "https://huggingface.co/blog/lerobot-goes-to-driving-school",
    "source": "Hugging Face Blog"
  },
  {
    "title": "LLM Inference on Edge: A Fun and Easy Guide to run LLMs via React Native on your Phone!",
    "summary": "",
    "url": "https://huggingface.co/blog/llm-inference-on-edge",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face and JFrog partner to make AI Security more transparent",
    "summary": "",
    "url": "https://huggingface.co/blog/jfrog",
    "source": "Hugging Face Blog"
  },
  {
    "title": "A Deepdive into Aya Vision: Advancing the Frontier of Multilingual Multimodality",
    "summary": "",
    "url": "https://huggingface.co/blog/aya-vision",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Trace & Evaluate your Agent with Arize Phoenix",
    "summary": "",
    "url": "https://huggingface.co/blog/smolagents-phoenix",
    "source": "Hugging Face Blog"
  },
  {
    "title": "HuggingFace, IISc partner to supercharge model building on India's diverse languages",
    "summary": "",
    "url": "https://huggingface.co/blog/iisc-huggingface-collab",
    "source": "Hugging Face Blog"
  },
  {
    "title": "FastRTC: The Real-Time Communication Library for Python",
    "summary": "",
    "url": "https://huggingface.co/blog/fastrtc",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Remote VAEs for decoding with Inference Endpoints 🤗",
    "summary": "",
    "url": "https://huggingface.co/blog/remote_vae",
    "source": "Hugging Face Blog"
  },
  {
    "title": "SigLIP 2: A better multilingual vision language encoder",
    "summary": "",
    "url": "https://huggingface.co/blog/siglip2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "SmolVLM2: Bringing Video Understanding to Every Device",
    "summary": "",
    "url": "https://huggingface.co/blog/smolvlm2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "PaliGemma 2 Mix - New Instruction Vision Language Models by Google",
    "summary": "",
    "url": "https://huggingface.co/blog/paligemma2mix",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Three New Serverless Inference Providers: Hyperbolic, Nebius AI Studio, and Novita 🔥",
    "summary": "",
    "url": "https://huggingface.co/blog/inference-providers-nebius-novita-hyperbolic",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome Fireworks.ai on the Hub 🎆",
    "summary": "",
    "url": "https://huggingface.co/blog/fireworks-ai",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fixing Open LLM Leaderboard with Math-Verify",
    "summary": "",
    "url": "https://huggingface.co/blog/math_verify_leaderboard",
    "source": "Hugging Face Blog"
  },
  {
    "title": "1 Billion Classifications",
    "summary": "",
    "url": "https://huggingface.co/blog/billion-classifications",
    "source": "Hugging Face Blog"
  },
  {
    "title": "From Chunks to Blocks: Accelerating Uploads and Downloads on the Hub",
    "summary": "",
    "url": "https://huggingface.co/blog/from-chunks-to-blocks",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Build awesome datasets for video generation",
    "summary": "",
    "url": "https://huggingface.co/blog/vid_ds_scripts",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Open R1: Update #2",
    "summary": "",
    "url": "https://huggingface.co/blog/open-r1/update-2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The Open Arabic LLM Leaderboard 2",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-arabic-v2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Open-source DeepResearch – Freeing our search agents",
    "summary": "",
    "url": "https://huggingface.co/blog/open-deep-research",
    "source": "Hugging Face Blog"
  },
  {
    "title": "π0 and π0-FAST: Vision-Language-Action Models for General Robot Control",
    "summary": "",
    "url": "https://huggingface.co/blog/pi0",
    "source": "Hugging Face Blog"
  },
  {
    "title": "DABStep: Data Agent Benchmark for Multi-step Reasoning",
    "summary": "",
    "url": "https://huggingface.co/blog/dabstep",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Open-R1: Update #1",
    "summary": "",
    "url": "https://huggingface.co/blog/open-r1/update-1",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Mini-R1: Reproduce Deepseek R1 „aha moment“ a RL tutorial",
    "summary": "",
    "url": "https://huggingface.co/blog/open-r1/mini-r1-contdown-game",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The AI tools for Art Newsletter - Issue 1",
    "summary": "",
    "url": "https://huggingface.co/blog/ai-art-newsletter-jan-25",
    "source": "Hugging Face Blog"
  },
  {
    "title": "How to deploy and fine-tune DeepSeek models on AWS",
    "summary": "",
    "url": "https://huggingface.co/blog/deepseek-r1-aws",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome to Inference Providers on the Hub 🔥",
    "summary": "",
    "url": "https://huggingface.co/blog/inference-providers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Open-R1: a fully open reproduction of DeepSeek-R1",
    "summary": "",
    "url": "https://huggingface.co/blog/open-r1",
    "source": "Hugging Face Blog"
  },
  {
    "title": "State of open video generation models in Diffusers",
    "summary": "",
    "url": "https://huggingface.co/blog/video_gen",
    "source": "Hugging Face Blog"
  },
  {
    "title": "We now support VLMs in smolagents!",
    "summary": "",
    "url": "https://huggingface.co/blog/smolagents-can-see",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Mastering Long Contexts in LLMs with KVPress",
    "summary": "",
    "url": "https://huggingface.co/blog/nvidia/kvpress",
    "source": "Hugging Face Blog"
  },
  {
    "title": "SmolVLM Grows Smaller – Introducing the 256M & 500M Models!",
    "summary": "",
    "url": "https://huggingface.co/blog/smolervlm",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face and FriendliAI partner to supercharge model deployment on the Hub",
    "summary": "",
    "url": "https://huggingface.co/blog/friendliai-partnership",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Yay! Organizations can now publish blog Articles",
    "summary": "",
    "url": "https://huggingface.co/blog/huggingface/blog-articles-for-orgs",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Timm ❤️ Transformers: Use any timm model with transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/timm-transformers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing multi-backends (TRT-LLM, vLLM) support for Text Generation Inference",
    "summary": "",
    "url": "https://huggingface.co/blog/tgi-multi-backend",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Train 400x faster Static Embedding Models with Sentence Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/static-embeddings",
    "source": "Hugging Face Blog"
  },
  {
    "title": "AI Agents Are Here. What Now?",
    "summary": "",
    "url": "https://huggingface.co/blog/ethics-soc-7",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Visual Document Retrieval Goes Multilingual",
    "summary": "",
    "url": "https://huggingface.co/blog/vdr-2b-multilingual",
    "source": "Hugging Face Blog"
  },
  {
    "title": "CO₂ Emissions and Models Performance: Insights from the Open LLM Leaderboard",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-emissions-analysis",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing smolagents: simple agents that write actions in code.",
    "summary": "",
    "url": "https://huggingface.co/blog/smolagents",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Visualize and understand GPU memory in PyTorch",
    "summary": "",
    "url": "https://huggingface.co/blog/train_memory",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Controlling Language Model Generation with NVIDIA's LogitsProcessorZoo",
    "summary": "",
    "url": "https://huggingface.co/blog/logits-processor-zoo",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Evaluating Audio Reasoning with Big Bench Audio",
    "summary": "",
    "url": "https://huggingface.co/blog/big-bench-audio-release",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Finally, a Replacement for BERT: Introducing ModernBERT",
    "summary": "",
    "url": "https://huggingface.co/blog/modernbert",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Bamba: Inference-Efficient Hybrid Mamba2 Model",
    "summary": "",
    "url": "https://huggingface.co/blog/bamba",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome to the Falcon 3 Family of Open Models!",
    "summary": "",
    "url": "https://huggingface.co/blog/falcon3",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Benchmarking Language Model Performance on 5th Gen Xeon at GCP",
    "summary": "",
    "url": "https://huggingface.co/blog/intel-gcp-c4",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing the Synthetic Data Generator - Build Datasets with Natural Language",
    "summary": "",
    "url": "https://huggingface.co/blog/synthetic-data-generator",
    "source": "Hugging Face Blog"
  },
  {
    "title": "LeMaterial: an open source initiative to accelerate materials discovery and research",
    "summary": "",
    "url": "https://huggingface.co/blog/lematerial",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face models in Amazon Bedrock",
    "summary": "",
    "url": "https://huggingface.co/blog/bedrock-marketplace",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Open Preference Dataset for Text-to-Image Generation by the 🤗 Community",
    "summary": "",
    "url": "https://huggingface.co/blog/image-preferences",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome PaliGemma 2 – New vision language models by Google",
    "summary": "",
    "url": "https://huggingface.co/blog/paligemma2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "How good are LLMs at fixing their mistakes? A chatbot arena experiment with Keras and TPUs",
    "summary": "",
    "url": "https://huggingface.co/blog/keras-chatbot-arena",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Rethinking LLM Evaluation with 3C3H: AraGen Benchmark and Leaderboard",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-3c3h-aragen",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Investing in Performance: Fine-tune small models with LLM insights  - a CFM case study",
    "summary": "",
    "url": "https://huggingface.co/blog/cfm-case-study",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Open Source Developers Guide to the EU AI Act",
    "summary": "",
    "url": "https://huggingface.co/blog/eu-ai-act-for-oss-developers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Rearchitecting Hugging Face Uploads and Downloads",
    "summary": "",
    "url": "https://huggingface.co/blog/rearchitecting-uploads-and-downloads",
    "source": "Hugging Face Blog"
  },
  {
    "title": "SmolVLM - small yet mighty Vision Language Model",
    "summary": "",
    "url": "https://huggingface.co/blog/smolvlm",
    "source": "Hugging Face Blog"
  },
  {
    "title": "You could have designed state of the art positional encoding",
    "summary": "",
    "url": "https://huggingface.co/blog/designing-positional-encoding",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Letting Large Models Debate: The First Multilingual LLM Debate Competition",
    "summary": "",
    "url": "https://huggingface.co/blog/debate",
    "source": "Hugging Face Blog"
  },
  {
    "title": "From Files to Chunks: Improving HF Storage Efficiency",
    "summary": "",
    "url": "https://huggingface.co/blog/from-files-to-chunks",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Faster Text Generation with Self-Speculative Decoding",
    "summary": "",
    "url": "https://huggingface.co/blog/layerskip",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing the Open Leaderboard for Japanese LLMs!",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-japanese",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Judge Arena: Benchmarking LLMs as Evaluators",
    "summary": "",
    "url": "https://huggingface.co/blog/arena-atla",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Share your open ML datasets on Hugging Face Hub!",
    "summary": "",
    "url": "https://huggingface.co/blog/researcher-dataset-sharing",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face + PyCharm",
    "summary": "",
    "url": "https://huggingface.co/blog/pycharm-integration",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Argilla 2.4: Easily Build Fine-Tuning and Evaluation Datasets on the Hub — No Code Required",
    "summary": "",
    "url": "https://huggingface.co/blog/argilla-ui-hub",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Universal Assisted Generation: Faster Decoding with Any Assistant Model",
    "summary": "",
    "url": "https://huggingface.co/blog/universal_assisted_generation",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Expert Support case study: Bolstering a RAG app with LLM-as-a-Judge",
    "summary": "",
    "url": "https://huggingface.co/blog/digital-green-llm-judge",
    "source": "Hugging Face Blog"
  },
  {
    "title": "A Deepdive into Aya Expanse: Advancing the Frontier of Multilinguality",
    "summary": "",
    "url": "https://huggingface.co/blog/aya-expanse",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing SynthID Text",
    "summary": "",
    "url": "https://huggingface.co/blog/synthid-text",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing HUGS - Scale your AI with Open Models",
    "summary": "",
    "url": "https://huggingface.co/blog/hugs",
    "source": "Hugging Face Blog"
  },
  {
    "title": "CinePile 2.0 - making stronger datasets with adversarial refinement",
    "summary": "",
    "url": "https://huggingface.co/blog/cinepile2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face Teams Up with Protect AI: Enhancing Model Security for the ML Community",
    "summary": "",
    "url": "https://huggingface.co/blog/protectai",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Transformers.js v3: WebGPU Support, New Models & Tasks, and More…",
    "summary": "",
    "url": "https://huggingface.co/blog/transformersjs-v3",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Diffusers welcomes Stable Diffusion 3.5 Large",
    "summary": "",
    "url": "https://huggingface.co/blog/sd3-5",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Releasing Outlines-core 0.1.0: structured generation in Rust and Python",
    "summary": "",
    "url": "https://huggingface.co/blog/outlines-core",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Deploying Speech-to-Speech on Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/s2s_endpoint",
    "source": "Hugging Face Blog"
  },
  {
    "title": "“Llama 3.2 in Keras”",
    "summary": "",
    "url": "https://huggingface.co/blog/keras-llama-32",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fixing Gradient Accumulation",
    "summary": "",
    "url": "https://huggingface.co/blog/gradient_accumulation",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing the AMD 5th Gen EPYC™ CPU",
    "summary": "",
    "url": "https://huggingface.co/blog/huggingface-amd-turin",
    "source": "Hugging Face Blog"
  },
  {
    "title": "A Security Review of Gradio 5",
    "summary": "",
    "url": "https://huggingface.co/blog/gradio-5-security",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome, Gradio 5",
    "summary": "",
    "url": "https://huggingface.co/blog/gradio-5",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Scaling AI-based Data Processing with Hugging Face + Dask",
    "summary": "",
    "url": "https://huggingface.co/blog/dask-scaling",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Faster Assisted Generation with Dynamic Speculation",
    "summary": "",
    "url": "https://huggingface.co/blog/dynamic_speculation_lookahead",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Improving Parquet Dedupe on Hugging Face Hub",
    "summary": "",
    "url": "https://huggingface.co/blog/improve_parquet_dedupe",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing the Open FinLLM Leaderboard",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-finbench",
    "source": "Hugging Face Blog"
  },
  {
    "title": "A Short Summary of Chinese AI Global Expansion",
    "summary": "",
    "url": "https://huggingface.co/blog/chinese-ai-expansion",
    "source": "Hugging Face Blog"
  },
  {
    "title": "🇨🇿 BenCzechMark - Can your LLM Understand Czech?",
    "summary": "",
    "url": "https://huggingface.co/blog/benczechmark",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Converting Vertex-Colored Meshes to Textured Meshes",
    "summary": "",
    "url": "https://huggingface.co/blog/vertex-colored-to-textured-mesh",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Llama can now see and run on your device - welcome Llama 3.2",
    "summary": "",
    "url": "https://huggingface.co/blog/llama32",
    "source": "Hugging Face Blog"
  },
  {
    "title": "FineVideo: behind the scenes",
    "summary": "",
    "url": "https://huggingface.co/blog/fine-video",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Exploring the Daily Papers Page on Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/daily-papers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Optimize and deploy with Optimum-Intel and OpenVINO GenAI",
    "summary": "",
    "url": "https://huggingface.co/blog/deploy-with-openvino",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fine-tuning LLMs to 1.58bit: extreme quantization made easy",
    "summary": "",
    "url": "https://huggingface.co/blog/1_58_llm_extreme_quantization",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing the SQL Console on Datasets",
    "summary": "",
    "url": "https://huggingface.co/blog/sql-console",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Community Tools on HuggingChat",
    "summary": "",
    "url": "https://huggingface.co/blog/community-tools",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Accelerate 1.0.0",
    "summary": "",
    "url": "https://huggingface.co/blog/accelerate-v1",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face partners with TruffleHog to Scan for Secrets",
    "summary": "",
    "url": "https://huggingface.co/blog/trufflesecurity-partnership",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Scaling robotics datasets with video encoding",
    "summary": "",
    "url": "https://huggingface.co/blog/video-encoding",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The 5 Most Under-Rated Tools on Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/unsung-heroes",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Improving Hugging Face Training Efficiency Through Packing with Flash Attention 2",
    "summary": "",
    "url": "https://huggingface.co/blog/packing-with-FA2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Deploy Meta Llama 3.1 405B on Google Cloud Vertex AI",
    "summary": "",
    "url": "https://huggingface.co/blog/llama31-on-vertex-ai",
    "source": "Hugging Face Blog"
  },
  {
    "title": "A failed experiment: Infini-Attention, and why we should keep trying?",
    "summary": "",
    "url": "https://huggingface.co/blog/infini-attention",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introduction to ggml",
    "summary": "",
    "url": "https://huggingface.co/blog/introduction-to-ggml",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome Falcon Mamba: The first strong attention-free 7B model",
    "summary": "",
    "url": "https://huggingface.co/blog/falconmamba",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Tool Use, Unified",
    "summary": "",
    "url": "https://huggingface.co/blog/unified-tool-use",
    "source": "Hugging Face Blog"
  },
  {
    "title": "XetHub is joining Hugging Face!",
    "summary": "",
    "url": "https://huggingface.co/blog/xethub-joins-hf",
    "source": "Hugging Face Blog"
  },
  {
    "title": "2024 Security Feature Highlights",
    "summary": "",
    "url": "https://huggingface.co/blog/2024-security-features",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing TextImage Augmentation for Document Images",
    "summary": "",
    "url": "https://huggingface.co/blog/doc_aug_hf_alb",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Google releases Gemma 2 2B, ShieldGemma and Gemma Scope",
    "summary": "",
    "url": "https://huggingface.co/blog/gemma-july-update",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Memory-efficient Diffusion Transformers with Quanto and Diffusers",
    "summary": "",
    "url": "https://huggingface.co/blog/quanto-diffusers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Serverless Inference with Hugging Face and NVIDIA NIM",
    "summary": "",
    "url": "https://huggingface.co/blog/inference-dgx-cloud",
    "source": "Hugging Face Blog"
  },
  {
    "title": "LAVE: Zero-shot VQA Evaluation on Docmatix with LLMs - Do We Still Need Fine-Tuning?",
    "summary": "",
    "url": "https://huggingface.co/blog/zero-shot-vqa-docmatix",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Llama 3.1 - 405B, 70B & 8B with multilinguality and long context",
    "summary": "",
    "url": "https://huggingface.co/blog/llama31",
    "source": "Hugging Face Blog"
  },
  {
    "title": "WWDC 24: Running Mistral 7B with Core ML",
    "summary": "",
    "url": "https://huggingface.co/blog/mistral-coreml",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Docmatix - a huge dataset for Document Visual Question Answering",
    "summary": "",
    "url": "https://huggingface.co/blog/docmatix",
    "source": "Hugging Face Blog"
  },
  {
    "title": "TGI Multi-LoRA: Deploy Once, Serve 30 Models",
    "summary": "",
    "url": "https://huggingface.co/blog/multi-lora-serving",
    "source": "Hugging Face Blog"
  },
  {
    "title": "SmolLM - blazingly fast and remarkably powerful",
    "summary": "",
    "url": "https://huggingface.co/blog/smollm",
    "source": "Hugging Face Blog"
  },
  {
    "title": "How we leveraged distilabel to create an Argilla 2.0 Chatbot",
    "summary": "",
    "url": "https://huggingface.co/blog/argilla-chatbot",
    "source": "Hugging Face Blog"
  },
  {
    "title": "How NuminaMath Won the 1st AIMO Progress Prize",
    "summary": "",
    "url": "https://huggingface.co/blog/winning-aimo-progress-prize",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Announcing New Hugging Face and KerasHub integration",
    "summary": "",
    "url": "https://huggingface.co/blog/keras-hub-integration",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Experimenting with Automatic PII Detection on the Hub using Presidio",
    "summary": "",
    "url": "https://huggingface.co/blog/presidio-pii-detection",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Preference Optimization for Vision Language Models",
    "summary": "",
    "url": "https://huggingface.co/blog/dpo_vlm",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Google Cloud TPUs made available to Hugging Face users",
    "summary": "",
    "url": "https://huggingface.co/blog/tpu-inference-endpoints-spaces",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Banque des Territoires (CDC Group) x Polyconseil x Hugging Face: Enhancing a Major French Environmental Program with a Sovereign Data Solution",
    "summary": "",
    "url": "https://huggingface.co/blog/sovereign-data-solution-case-study",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Announcing New Dataset Search Features",
    "summary": "",
    "url": "https://huggingface.co/blog/datasets-filters",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Accelerating Protein Language Model ProtST on Intel Gaudi 2",
    "summary": "",
    "url": "https://huggingface.co/blog/intel-protein-language-model-protst",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Our Transformers Code Agent beats the GAIA benchmark 🏅",
    "summary": "",
    "url": "https://huggingface.co/blog/beating-gaia",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome Gemma 2 - Google’s new open LLM",
    "summary": "",
    "url": "https://huggingface.co/blog/gemma2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "XLSCOUT Unveils ParaEmbed 2.0: a Powerful Embedding Model Tailored for Patents and IP with Expert Support from Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/xlscout-case-study",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fine-tuning Florence-2 - Microsoft's Cutting-edge Vision Language Models",
    "summary": "",
    "url": "https://huggingface.co/blog/finetune-florence2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Ethics and Society Newsletter #6: Building Better AI: The Importance of Data Quality",
    "summary": "",
    "url": "https://huggingface.co/blog/ethics-soc-6",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Data Is Better Together: A Look Back and Forward",
    "summary": "",
    "url": "https://huggingface.co/blog/dibt",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Going multimodal: How Prezi is leveraging the Hub and the Expert Support Program to accelerate their ML roadmap",
    "summary": "",
    "url": "https://huggingface.co/blog/prezi-case-study",
    "source": "Hugging Face Blog"
  },
  {
    "title": "BigCodeBench: The Next Generation of HumanEval",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-bigcodebench",
    "source": "Hugging Face Blog"
  },
  {
    "title": "From DeepSpeed to FSDP and Back Again with Hugging Face Accelerate",
    "summary": "",
    "url": "https://huggingface.co/blog/deepspeed-to-fsdp-and-back",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Diffusers welcomes Stable Diffusion 3",
    "summary": "",
    "url": "https://huggingface.co/blog/sd3",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Putting RL back in RLHF",
    "summary": "",
    "url": "https://huggingface.co/blog/putting_rl_back_in_rlhf_with_rloo",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Making sense of this mess",
    "summary": "",
    "url": "https://huggingface.co/blog/transformers-docs-redesign",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing the Hugging Face Embedding Container for Amazon SageMaker",
    "summary": "",
    "url": "https://huggingface.co/blog/sagemaker-huggingface-embedding",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Launching the Artificial Analysis Text to Image Leaderboard & Arena",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-artificial-analysis2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing NPC-Playground, a 3D playground to interact with LLM-powered NPCs",
    "summary": "",
    "url": "https://huggingface.co/blog/npc-gigax-cubzh",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Faster assisted generation support for Intel Gaudi",
    "summary": "",
    "url": "https://huggingface.co/blog/assisted-generation-support-gaudi",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Space secrets security update",
    "summary": "",
    "url": "https://huggingface.co/blog/space-secrets-disclosure",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Benchmarking Text Generation Inference",
    "summary": "",
    "url": "https://huggingface.co/blog/tgi-benchmarking",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Training and Finetuning Embedding Models with Sentence Transformers v3",
    "summary": "",
    "url": "https://huggingface.co/blog/train-sentence-transformers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Falcon 2: An 11B parameter pretrained language model and VLM, trained on over 5000B tokens and 11 languages",
    "summary": "",
    "url": "https://huggingface.co/blog/falcon2-11b",
    "source": "Hugging Face Blog"
  },
  {
    "title": "CyberSecEval 2 - A Comprehensive Evaluation Framework for Cybersecurity Risks and Capabilities of Large Language Models",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-llamaguard",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Deploy models on AWS Inferentia2 from Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/inferentia-inference-endpoints",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Spaces Dev Mode for a seamless developer experience",
    "summary": "",
    "url": "https://huggingface.co/blog/spaces-dev-mode",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Build AI on premise with Dell Enterprise Hub",
    "summary": "",
    "url": "https://huggingface.co/blog/dell-enterprise-hub",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face on AMD Instinct MI300 GPU",
    "summary": "",
    "url": "https://huggingface.co/blog/huggingface-amd-mi300",
    "source": "Hugging Face Blog"
  },
  {
    "title": "From cloud to developers: Hugging Face and Microsoft Deepen Collaboration",
    "summary": "",
    "url": "https://huggingface.co/blog/microsoft-collaboration",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Unlocking Longer Generation with Key-Value Cache Quantization",
    "summary": "",
    "url": "https://huggingface.co/blog/kv-cache-quantization",
    "source": "Hugging Face Blog"
  },
  {
    "title": "PaliGemma – Google's Cutting-Edge Open Vision Language Model",
    "summary": "",
    "url": "https://huggingface.co/blog/paligemma",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face x LangChain : A new partner package",
    "summary": "",
    "url": "https://huggingface.co/blog/langchain",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing the Open Arabic LLM Leaderboard",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-arabic",
    "source": "Hugging Face Blog"
  },
  {
    "title": "License to Call: Introducing Transformers Agents 2.0",
    "summary": "",
    "url": "https://huggingface.co/blog/agents",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Subscribe to Enterprise Hub with your AWS Account",
    "summary": "",
    "url": "https://huggingface.co/blog/enterprise-hub-aws-marketplace",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Building Cost-Efficient Enterprise RAG applications with Intel Gaudi 2 and Intel Xeon",
    "summary": "",
    "url": "https://huggingface.co/blog/cost-efficient-rag-applications-with-intel",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing the Open Leaderboard for Hebrew LLMs!",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-hebrew",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Bringing the Artificial Analysis LLM Performance Leaderboard to Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-artificial-analysis",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Powerful ASR + diarization + speculative decoding with Hugging Face Inference Endpoints",
    "summary": "",
    "url": "https://huggingface.co/blog/asr-diarization",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Improving Prompt Consistency with Structured Generations",
    "summary": "",
    "url": "https://huggingface.co/blog/evaluation-structured-outputs",
    "source": "Hugging Face Blog"
  },
  {
    "title": "StarCoder2-Instruct: Fully Transparent and Permissive Self-Alignment for Code Generation",
    "summary": "",
    "url": "https://huggingface.co/blog/sc2-instruct",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing the Open Chain of Thought Leaderboard",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-cot",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Jack of All Trades, Master of Some, a Multi-Purpose Transformer Agent",
    "summary": "",
    "url": "https://huggingface.co/blog/jat",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The Open Medical-LLM Leaderboard: Benchmarking Large Language Models in Healthcare",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-medicalllm",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome Llama 3 - Meta's new open LLM",
    "summary": "",
    "url": "https://huggingface.co/blog/llama3",
    "source": "Hugging Face Blog"
  },
  {
    "title": "AI Apps in a Flash with Gradio's Reload Mode",
    "summary": "",
    "url": "https://huggingface.co/blog/gradio-reload",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing the LiveCodeBench Leaderboard - Holistic and Contamination-Free Evaluation of Code LLMs",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-livecodebench",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Running Privacy-Preserving Inferences on Hugging Face Endpoints",
    "summary": "",
    "url": "https://huggingface.co/blog/fhe-endpoints",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Ryght’s Journey to Empower Healthcare and Life Sciences with Expert Support from Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/ryght-case-study",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Idefics2: A Powerful 8B Vision-Language Model for the community",
    "summary": "",
    "url": "https://huggingface.co/blog/idefics2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Vision Language Models Explained",
    "summary": "",
    "url": "https://huggingface.co/blog/vlms",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Making thousands of open LLMs bloom in the Vertex AI Model Garden",
    "summary": "",
    "url": "https://huggingface.co/blog/google-cloud-model-garden",
    "source": "Hugging Face Blog"
  },
  {
    "title": "CodeGemma - an official Google release for code LLMs",
    "summary": "",
    "url": "https://huggingface.co/blog/codegemma",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Public Policy at Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/policy-blog",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face partners with Wiz Research to Improve AI Security",
    "summary": "",
    "url": "https://huggingface.co/blog/hugging-face-wiz-security-blog",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Text2SQL using Hugging Face Dataset Viewer API and Motherduck DuckDB-NSQL-7B",
    "summary": "",
    "url": "https://huggingface.co/blog/duckdb-nsql-7b",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Blazing Fast SetFit Inference with 🤗 Optimum Intel on Xeon",
    "summary": "",
    "url": "https://huggingface.co/blog/setfit-optimum-intel",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Bringing serverless GPU inference to Hugging Face users",
    "summary": "",
    "url": "https://huggingface.co/blog/cloudflare-workers-ai",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Pollen-Vision: Unified interface for Zero-Shot vision models in robotics",
    "summary": "",
    "url": "https://huggingface.co/blog/pollen-vision",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Total noob’s intro to Hugging Face Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/noob_intro_transformers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Binary and Scalar Embedding Quantization for Significantly Faster & Cheaper Retrieval",
    "summary": "",
    "url": "https://huggingface.co/blog/embedding-quantization",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing the Chatbot Guardrails Arena",
    "summary": "",
    "url": "https://huggingface.co/blog/arena-lighthouz",
    "source": "Hugging Face Blog"
  },
  {
    "title": "A Chatbot on your Laptop: Phi-2 on Intel Meteor Lake",
    "summary": "",
    "url": "https://huggingface.co/blog/phi2-intel-meteor-lake",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Cosmopedia: how to create large-scale synthetic data for pre-training Large Language Models",
    "summary": "",
    "url": "https://huggingface.co/blog/cosmopedia",
    "source": "Hugging Face Blog"
  },
  {
    "title": "GaLore: Advancing Large Model Training on Consumer-grade Hardware",
    "summary": "",
    "url": "https://huggingface.co/blog/galore",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Easily Train Models with H100 GPUs on NVIDIA DGX Cloud",
    "summary": "",
    "url": "https://huggingface.co/blog/train-dgx-cloud",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Quanto: a PyTorch quantization backend for Optimum",
    "summary": "",
    "url": "https://huggingface.co/blog/quanto-introduction",
    "source": "Hugging Face Blog"
  },
  {
    "title": "CPU Optimized Embeddings with 🤗 Optimum Intel and fastRAG",
    "summary": "",
    "url": "https://huggingface.co/blog/intel-fast-embedding",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Unlocking the conversion of Web Screenshots into HTML Code with the WebSight Dataset",
    "summary": "",
    "url": "https://huggingface.co/blog/websight",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing ConTextual: How well can your Multimodal model jointly reason over text and image in text-rich scenes?",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-contextual",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Data is better together: Enabling communities to collectively build better datasets together using Argilla and Hugging Face Spaces",
    "summary": "",
    "url": "https://huggingface.co/blog/community-datasets",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Text-Generation Pipeline on Intel® Gaudi® 2 AI Accelerator",
    "summary": "",
    "url": "https://huggingface.co/blog/textgen-pipe-gaudi",
    "source": "Hugging Face Blog"
  },
  {
    "title": "StarCoder2 and The Stack v2",
    "summary": "",
    "url": "https://huggingface.co/blog/starcoder2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "TTS Arena: Benchmarking Text-to-Speech Models in the Wild",
    "summary": "",
    "url": "https://huggingface.co/blog/arena-tts",
    "source": "Hugging Face Blog"
  },
  {
    "title": "AI Watermarking 101: Tools and Techniques",
    "summary": "",
    "url": "https://huggingface.co/blog/watermarking",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fine-Tuning Gemma Models in Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/gemma-peft",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing the Red-Teaming Resistance Leaderboard",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-haizelab",
    "source": "Hugging Face Blog"
  },
  {
    "title": "🪆 Introduction to Matryoshka Embedding Models",
    "summary": "",
    "url": "https://huggingface.co/blog/matryoshka",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome Gemma - Google’s new open LLM",
    "summary": "",
    "url": "https://huggingface.co/blog/gemma",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing the Open Ko-LLM Leaderboard: Leading the Korean LLM Evaluation Ecosystem",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-upstage",
    "source": "Hugging Face Blog"
  },
  {
    "title": "🤗 PEFT welcomes new merging methods",
    "summary": "",
    "url": "https://huggingface.co/blog/peft_merging",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Synthetic data: save money, time and carbon with open source",
    "summary": "",
    "url": "https://huggingface.co/blog/synthetic-data-save-costs",
    "source": "Hugging Face Blog"
  },
  {
    "title": "AMD Pervasive AI Developer Contest!",
    "summary": "",
    "url": "https://huggingface.co/blog/amd_pervasive_developer_ai_contest",
    "source": "Hugging Face Blog"
  },
  {
    "title": "From OpenAI to Open LLMs with Messages API on Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/tgi-messages-api",
    "source": "Hugging Face Blog"
  },
  {
    "title": "SegMoE: Segmind Mixture of Diffusion Experts",
    "summary": "",
    "url": "https://huggingface.co/blog/segmoe",
    "source": "Hugging Face Blog"
  },
  {
    "title": "NPHardEval Leaderboard: Unveiling the Reasoning Abilities of Large Language Models through Complexity Classes and Dynamic Updates",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-nphardeval",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Constitutional AI with Open LLMs",
    "summary": "",
    "url": "https://huggingface.co/blog/constitutional_ai",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face Text Generation Inference available for AWS Inferentia2",
    "summary": "",
    "url": "https://huggingface.co/blog/text-generation-inference-on-inferentia2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Patch Time Series Transformer in Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/patchtst",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing the Enterprise Scenarios Leaderboard: a Leaderboard for Real World Use Cases",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-patronus",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Accelerate StarCoder with 🤗 Optimum Intel on Xeon: Q8/Q4 and Speculative Decoding",
    "summary": "",
    "url": "https://huggingface.co/blog/intel-starcoder-quantization",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The Hallucinations Leaderboard, an Open Effort to Measure Hallucinations in Large Language Models",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-hallucinations",
    "source": "Hugging Face Blog"
  },
  {
    "title": "An Introduction to AI Secure LLM Safety Leaderboard",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-decodingtrust",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face and Google partner for open AI collaboration",
    "summary": "",
    "url": "https://huggingface.co/blog/gcp-partnership",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Open-source LLMs as LangChain Agents",
    "summary": "",
    "url": "https://huggingface.co/blog/open-source-llms-as-agents",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fine-Tune W2V2-Bert for low-resource ASR with 🤗 Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/fine-tune-w2v2-bert",
    "source": "Hugging Face Blog"
  },
  {
    "title": "PatchTSMixer in HuggingFace",
    "summary": "",
    "url": "https://huggingface.co/blog/patchtsmixer",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Preference Tuning LLMs with Direct Preference Optimization Methods",
    "summary": "",
    "url": "https://huggingface.co/blog/pref-tuning",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Accelerating SD Turbo and SDXL Turbo Inference with ONNX Runtime and Olive",
    "summary": "",
    "url": "https://huggingface.co/blog/sdxl_ort_inference",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Run ComfyUI workflows for free with Gradio on Hugging Face Spaces",
    "summary": "",
    "url": "https://huggingface.co/blog/run-comfyui-workflows-on-spaces",
    "source": "Hugging Face Blog"
  },
  {
    "title": "A guide to setting up your own Hugging Face leaderboard: an end-to-end example with Vectara's hallucination leaderboard",
    "summary": "",
    "url": "https://huggingface.co/blog/leaderboard-vectara",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Make LLM Fine-tuning 2x faster with Unsloth and 🤗 TRL",
    "summary": "",
    "url": "https://huggingface.co/blog/unsloth-trl",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome aMUSEd: Efficient Text-to-Image Generation",
    "summary": "",
    "url": "https://huggingface.co/blog/amused",
    "source": "Hugging Face Blog"
  },
  {
    "title": "LoRA training scripts of the world, unite!",
    "summary": "",
    "url": "https://huggingface.co/blog/sdxl_lora_advanced_script",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Speculative Decoding for 2x Faster Whisper Inference",
    "summary": "",
    "url": "https://huggingface.co/blog/whisper-speculative-decoding",
    "source": "Hugging Face Blog"
  },
  {
    "title": "2023, year of open LLMs",
    "summary": "",
    "url": "https://huggingface.co/blog/2023-in-llms",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome Mixtral - a SOTA Mixture of Experts on Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/mixtral",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Mixture of Experts Explained",
    "summary": "",
    "url": "https://huggingface.co/blog/moe",
    "source": "Hugging Face Blog"
  },
  {
    "title": "SetFitABSA: Few-Shot Aspect Based Sentiment Analysis using SetFit",
    "summary": "",
    "url": "https://huggingface.co/blog/setfit-absa",
    "source": "Hugging Face Blog"
  },
  {
    "title": "AMD + 🤗: Large Language Models Out-of-the-Box Acceleration with AMD GPU",
    "summary": "",
    "url": "https://huggingface.co/blog/huggingface-and-optimum-amd",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Optimum-NVIDIA Unlocking blazingly fast LLM inference in just 1 line of code",
    "summary": "",
    "url": "https://huggingface.co/blog/optimum-nvidia",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Goodbye cold boot - how we made LoRA Inference 300% faster",
    "summary": "",
    "url": "https://huggingface.co/blog/lora-adapters-dynamic-loading",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Open LLM Leaderboard: DROP deep dive",
    "summary": "",
    "url": "https://huggingface.co/blog/open-llm-leaderboard-drop",
    "source": "Hugging Face Blog"
  },
  {
    "title": "SDXL in 4 steps with Latent Consistency LoRAs",
    "summary": "",
    "url": "https://huggingface.co/blog/lcm_lora",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Make your llama generation time fly with AWS Inferentia2",
    "summary": "",
    "url": "https://huggingface.co/blog/inferentia-llama2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Prodigy-HF: a direct integration with Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/prodigy-hf",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Comparing the Performance of LLMs: A Deep Dive into Roberta, Llama 2, and Mistral for Disaster Tweets Analysis with Lora",
    "summary": "",
    "url": "https://huggingface.co/blog/Lora-for-sequence-classification-with-Roberta-Llama-Mistral",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Storage Regions on the HF Hub",
    "summary": "",
    "url": "https://huggingface.co/blog/regions",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Personal Copilot: Train Your Own Coding Assistant",
    "summary": "",
    "url": "https://huggingface.co/blog/personal-copilot",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Interactively explore your Huggingface dataset with one line of code",
    "summary": "",
    "url": "https://huggingface.co/blog/scalable-data-inspection",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Deploy Embedding Models with Hugging Face Inference Endpoints",
    "summary": "",
    "url": "https://huggingface.co/blog/inference-endpoints-embeddings",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The N Implementation Details of RLHF with PPO",
    "summary": "",
    "url": "https://huggingface.co/blog/the_n_implementation_details_of_rlhf_with_ppo",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Exploring simple optimizations for SDXL",
    "summary": "",
    "url": "https://huggingface.co/blog/simple_sdxl_optimizations",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Gradio-Lite: Serverless Gradio Running Entirely in Your Browser",
    "summary": "",
    "url": "https://huggingface.co/blog/gradio-lite",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Accelerating over 130,000 Hugging Face models with ONNX Runtime",
    "summary": "",
    "url": "https://huggingface.co/blog/ort-accelerating-hf-models",
    "source": "Hugging Face Blog"
  },
  {
    "title": "🧨 Accelerating Stable Diffusion XL Inference with JAX on Cloud TPU v5e",
    "summary": "",
    "url": "https://huggingface.co/blog/sdxl_jax",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Chat Templates: An End to the Silent Performance Killer",
    "summary": "",
    "url": "https://huggingface.co/blog/chat-templates",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Deploying the AI Comic Factory using the Inference API",
    "summary": "",
    "url": "https://huggingface.co/blog/ai-comic-factory",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Ethics and Society Newsletter #5: Hugging Face Goes To Washington and Other Summer 2023 Musings",
    "summary": "",
    "url": "https://huggingface.co/blog/ethics-soc-5",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Finetune Stable Diffusion Models with DDPO via TRL",
    "summary": "",
    "url": "https://huggingface.co/blog/trl-ddpo",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Non-engineers guide: Train a LLaMA 2 chatbot",
    "summary": "",
    "url": "https://huggingface.co/blog/Llama2-for-non-engineers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Llama 2 on Amazon SageMaker a Benchmark",
    "summary": "",
    "url": "https://huggingface.co/blog/llama-sagemaker-benchmark",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Inference for PROs",
    "summary": "",
    "url": "https://huggingface.co/blog/inference-pro",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Rocket Money x Hugging Face: Scaling Volatile ML Models in Production​",
    "summary": "",
    "url": "https://huggingface.co/blog/rocketmoney-case-study",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introduction to 3D Gaussian Splatting",
    "summary": "",
    "url": "https://huggingface.co/blog/gaussian-splatting",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Object Detection Leaderboard",
    "summary": "",
    "url": "https://huggingface.co/blog/object-detection-leaderboard",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Optimizing your LLM in production",
    "summary": "",
    "url": "https://huggingface.co/blog/optimize-llm",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Würstchen: Fast Diffusion for Image Generation",
    "summary": "",
    "url": "https://huggingface.co/blog/wuerstchen",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fine-tuning Llama 2 70B using PyTorch FSDP",
    "summary": "",
    "url": "https://huggingface.co/blog/ram-efficient-pytorch-fsdp",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Overview of natively supported quantization schemes in 🤗 Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/overview-quantization-transformers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "SafeCoder vs. Closed-source Code Assistants",
    "summary": "",
    "url": "https://huggingface.co/blog/safecoder-vs-closed-source-code-assistants",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Efficient Controllable Generation for SDXL with T2I-Adapters",
    "summary": "",
    "url": "https://huggingface.co/blog/t2i-sdxl-adapters",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Spread Your Wings: Falcon 180B is here",
    "summary": "",
    "url": "https://huggingface.co/blog/falcon-180b",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fetch Cuts ML Processing Latency by 50% Using Amazon SageMaker & Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/fetch-case-study",
    "source": "Hugging Face Blog"
  },
  {
    "title": "AudioLDM 2, but faster ⚡️",
    "summary": "",
    "url": "https://huggingface.co/blog/audioldm2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Code Llama: Llama 2 learns to code",
    "summary": "",
    "url": "https://huggingface.co/blog/codellama",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Deprecation of Git Authentication using password",
    "summary": "",
    "url": "https://huggingface.co/blog/password-git-deprecation",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Making LLMs lighter with AutoGPTQ and transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/gptq-integration",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing SafeCoder",
    "summary": "",
    "url": "https://huggingface.co/blog/safecoder",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing IDEFICS: An Open Reproduction of State-of-the-art Visual Langage Model",
    "summary": "",
    "url": "https://huggingface.co/blog/idefics",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face Hub on the AWS Marketplace: Pay with your AWS Account",
    "summary": "",
    "url": "https://huggingface.co/blog/aws-marketplace",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Optimizing Bark using 🤗 Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/optimizing-bark",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Deploying Hugging Face Models with BentoML: DeepFloyd IF in Action",
    "summary": "",
    "url": "https://huggingface.co/blog/deploy-deepfloydif-using-bentoml",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fine-tune Llama 2 with DPO",
    "summary": "",
    "url": "https://huggingface.co/blog/dpo-trl",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Releasing Swift Transformers: Run On-Device LLMs in Apple Devices",
    "summary": "",
    "url": "https://huggingface.co/blog/swift-coreml-llm",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Deploy MusicGen in no time with Inference Endpoints",
    "summary": "",
    "url": "https://huggingface.co/blog/run-musicgen-as-an-api",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Huggy Lingo: Using Machine Learning to Improve Language Metadata on the Hugging Face Hub",
    "summary": "",
    "url": "https://huggingface.co/blog/huggy-lingo",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Towards Encrypted Large Language Models with FHE",
    "summary": "",
    "url": "https://huggingface.co/blog/encrypted-llm",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Practical 3D Asset Generation: A Step-by-Step Guide",
    "summary": "",
    "url": "https://huggingface.co/blog/3d-assets",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Open-sourcing Knowledge Distillation Code and Weights of SD-Small and SD-Tiny",
    "summary": "",
    "url": "https://huggingface.co/blog/sd_distillation",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Stable Diffusion XL on Mac with Advanced Core ML Quantization",
    "summary": "",
    "url": "https://huggingface.co/blog/stable-diffusion-xl-coreml",
    "source": "Hugging Face Blog"
  },
  {
    "title": "AI Policy @🤗: Open ML Considerations in the EU AI Act",
    "summary": "",
    "url": "https://huggingface.co/blog/eu-ai-act-oss",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Agents.js: Give tools to your LLMs using JavaScript",
    "summary": "",
    "url": "https://huggingface.co/blog/agents-js",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Results of the Open Source AI Game Jam",
    "summary": "",
    "url": "https://huggingface.co/blog/game-jam-first-edition-results",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Happy 1st anniversary 🤗 Diffusers!",
    "summary": "",
    "url": "https://huggingface.co/blog/diffusers-turns-1",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Llama 2 is here - get it on Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/llama2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Building an AI WebTV",
    "summary": "",
    "url": "https://huggingface.co/blog/ai-webtv",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Open-Source Text Generation & LLM Ecosystem at Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/os-llms",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fine-tuning Stable Diffusion models on Intel CPUs",
    "summary": "",
    "url": "https://huggingface.co/blog/stable-diffusion-finetuning-intel",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Making ML-powered web games with Transformers.js",
    "summary": "",
    "url": "https://huggingface.co/blog/ml-web-games",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Deploy LLMs with Hugging Face Inference Endpoints",
    "summary": "",
    "url": "https://huggingface.co/blog/inference-endpoints-llm",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Making a web app generator with open ML models",
    "summary": "",
    "url": "https://huggingface.co/blog/text-to-webapp",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Leveraging Hugging Face for complex generative AI use cases",
    "summary": "",
    "url": "https://huggingface.co/blog/writer-case-study",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Accelerating Vision-Language Models: BridgeTower on Habana Gaudi2",
    "summary": "",
    "url": "https://huggingface.co/blog/bridgetower",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Ethics and Society Newsletter #4: Bias in Text-to-Image Models",
    "summary": "",
    "url": "https://huggingface.co/blog/ethics-soc-4",
    "source": "Hugging Face Blog"
  },
  {
    "title": "What's going on with the Open LLM Leaderboard?",
    "summary": "",
    "url": "https://huggingface.co/blog/open-llm-leaderboard-mmlu",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Panel on Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/panel-on-hugging-face",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fine-Tune MMS Adapter Models for low-resource ASR",
    "summary": "",
    "url": "https://huggingface.co/blog/mms_adapters",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Yes, Transformers are Effective for Time Series Forecasting (+ Autoformer)",
    "summary": "",
    "url": "https://huggingface.co/blog/autoformer",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Faster Stable Diffusion with Core ML on iPhone, iPad, and Mac",
    "summary": "",
    "url": "https://huggingface.co/blog/fast-diffusers-coreml",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Deploy Livebook notebooks as apps to Hugging Face Spaces",
    "summary": "",
    "url": "https://huggingface.co/blog/livebook-app-deployment",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Announcing our new Content Guidelines and Policy",
    "summary": "",
    "url": "https://huggingface.co/blog/content-guidelines-update",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face and AMD partner on accelerating state-of-the-art models for CPU and GPU platforms",
    "summary": "",
    "url": "https://huggingface.co/blog/huggingface-and-amd",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Can foundation models label data like humans?",
    "summary": "",
    "url": "https://huggingface.co/blog/open-llm-leaderboard-rlhf",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The Hugging Face Hub for Galleries, Libraries, Archives and Museums",
    "summary": "",
    "url": "https://huggingface.co/blog/hf-hub-glam-guide",
    "source": "Hugging Face Blog"
  },
  {
    "title": "DuckDB: analyze 50,000+ datasets stored on the Hugging Face Hub",
    "summary": "",
    "url": "https://huggingface.co/blog/hub-duckdb",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome fastText to the Hugging Face Hub",
    "summary": "",
    "url": "https://huggingface.co/blog/fasttext",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The Falcon has landed in the Hugging Face ecosystem",
    "summary": "",
    "url": "https://huggingface.co/blog/falcon",
    "source": "Hugging Face Blog"
  },
  {
    "title": "AI Speech Recognition in Unity",
    "summary": "",
    "url": "https://huggingface.co/blog/unity-asr",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Announcing the Open Source AI Game Jam 🎮",
    "summary": "",
    "url": "https://huggingface.co/blog/game-jam",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing the Hugging Face LLM Inference Container for Amazon SageMaker",
    "summary": "",
    "url": "https://huggingface.co/blog/sagemaker-huggingface-llm",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing BERTopic Integration with the Hugging Face Hub",
    "summary": "",
    "url": "https://huggingface.co/blog/bertopic",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Optimizing Stable Diffusion for Intel CPUs with NNCF and 🤗 Optimum",
    "summary": "",
    "url": "https://huggingface.co/blog/train-optimize-sd-intel",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Making LLMs even more accessible with bitsandbytes, 4-bit quantization and QLoRA",
    "summary": "",
    "url": "https://huggingface.co/blog/4bit-transformers-bitsandbytes",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face Collaborates with Microsoft to launch Hugging Face Model Catalog on Azure",
    "summary": "",
    "url": "https://huggingface.co/blog/hugging-face-endpoints-on-azure",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face and IBM partner on watsonx.ai, the next-generation enterprise studio for AI builders",
    "summary": "",
    "url": "https://huggingface.co/blog/huggingface-and-ibm",
    "source": "Hugging Face Blog"
  },
  {
    "title": "🐶Safetensors audited as really safe and becoming the default",
    "summary": "",
    "url": "https://huggingface.co/blog/safetensors-security-audit",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Instruction-tuning Stable Diffusion with InstructPix2Pix",
    "summary": "",
    "url": "https://huggingface.co/blog/instruction-tuning-sd",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Large-scale Near-deduplication Behind BigCode",
    "summary": "",
    "url": "https://huggingface.co/blog/dedup",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Smaller is better: Q8-Chat, an efficient generative AI experience on Xeon",
    "summary": "",
    "url": "https://huggingface.co/blog/generative-ai-models-on-intel-cpu",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face Selected for the French Data Protection Agency Enhanced Support Program",
    "summary": "",
    "url": "https://huggingface.co/blog/cnil",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Run a Chatgpt-like Chatbot on a Single GPU with ROCm",
    "summary": "",
    "url": "https://huggingface.co/blog/chatbot-amd-gpu",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing RWKV - An RNN with the advantages of a transformer",
    "summary": "",
    "url": "https://huggingface.co/blog/rwkv",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Assisted Generation: a new direction toward low-latency text generation",
    "summary": "",
    "url": "https://huggingface.co/blog/assisted-generation",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Creating a Coding Assistant with StarCoder",
    "summary": "",
    "url": "https://huggingface.co/blog/starchat-alpha",
    "source": "Hugging Face Blog"
  },
  {
    "title": "A Dive into Text-to-Video Models",
    "summary": "",
    "url": "https://huggingface.co/blog/text-to-video",
    "source": "Hugging Face Blog"
  },
  {
    "title": "StarCoder: A State-of-the-Art LLM for Code",
    "summary": "",
    "url": "https://huggingface.co/blog/starcoder",
    "source": "Hugging Face Blog"
  },
  {
    "title": "How to Install and Use the Hugging Face Unity API",
    "summary": "",
    "url": "https://huggingface.co/blog/unity-api",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Training a language model with 🤗 Transformers using TensorFlow and TPUs",
    "summary": "",
    "url": "https://huggingface.co/blog/tf_tpu",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Running IF with 🧨 diffusers on a Free Tier Google Colab",
    "summary": "",
    "url": "https://huggingface.co/blog/if",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Databricks ❤️ Hugging Face: up to 40% faster training and tuning of Large Language Models",
    "summary": "",
    "url": "https://huggingface.co/blog/databricks-case-study",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing HuggingFace blog for Chinese speakers: Fostering Collaboration with the Chinese AI community",
    "summary": "",
    "url": "https://huggingface.co/blog/chinese-language-blog",
    "source": "Hugging Face Blog"
  },
  {
    "title": "How to host a Unity game in a Space",
    "summary": "",
    "url": "https://huggingface.co/blog/unity-in-spaces",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Accelerating Hugging Face Transformers with AWS Inferentia2",
    "summary": "",
    "url": "https://huggingface.co/blog/accelerate-transformers-with-inferentia2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Graph Classification with Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/graphml-classification",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Creating Privacy Preserving AI with Substra",
    "summary": "",
    "url": "https://huggingface.co/blog/owkin-substra",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Snorkel AI x Hugging Face: unlock foundation models for enterprises",
    "summary": "",
    "url": "https://huggingface.co/blog/snorkel-case-study",
    "source": "Hugging Face Blog"
  },
  {
    "title": "StackLLaMA: A hands-on guide to train LLaMA with RLHF",
    "summary": "",
    "url": "https://huggingface.co/blog/stackllama",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Ethics and Society Newsletter #3: Ethical Openness at Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/ethics-soc-3",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fast Inference on Large Language Models: BLOOMZ on Habana Gaudi2 Accelerator",
    "summary": "",
    "url": "https://huggingface.co/blog/habana-gaudi-2-bloom",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Accelerating Stable Diffusion Inference on Intel CPUs",
    "summary": "",
    "url": "https://huggingface.co/blog/stable-diffusion-inference-intel",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Federated Learning using Hugging Face and Flower",
    "summary": "",
    "url": "https://huggingface.co/blog/fl-with-flower",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Train your ControlNet with diffusers",
    "summary": "",
    "url": "https://huggingface.co/blog/train-your-controlnet",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Jupyter X Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/notebooks-hub",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Multivariate Probabilistic Time Series Forecasting with Informer",
    "summary": "",
    "url": "https://huggingface.co/blog/informer",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU",
    "summary": "",
    "url": "https://huggingface.co/blog/trl-peft",
    "source": "Hugging Face Blog"
  },
  {
    "title": "New ViT and ALIGN Models From Kakao Brain",
    "summary": "",
    "url": "https://huggingface.co/blog/vit-align",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Using Machine Learning to Aid Survivors and Race through Time",
    "summary": "",
    "url": "https://huggingface.co/blog/using-ml-for-disasters",
    "source": "Hugging Face Blog"
  },
  {
    "title": "ControlNet in 🧨 Diffusers",
    "summary": "",
    "url": "https://huggingface.co/blog/controlnet",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Ethical Guidelines for developing the Diffusers library",
    "summary": "",
    "url": "https://huggingface.co/blog/ethics-diffusers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "How Hugging Face Accelerated Development of Witty Works Writing Assistant",
    "summary": "",
    "url": "https://huggingface.co/blog/classification-use-cases",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Red-Teaming Large Language Models",
    "summary": "",
    "url": "https://huggingface.co/blog/red-teaming",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Swift 🧨Diffusers - Fast Stable Diffusion for Mac",
    "summary": "",
    "url": "https://huggingface.co/blog/fast-mac-diffusers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fetch Consolidates AI Tools and Saves 30% Development Time with Hugging Face on AWS",
    "summary": "",
    "url": "https://huggingface.co/blog/fetch-eap-case-study",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face and AWS partner to make AI more accessible",
    "summary": "",
    "url": "https://huggingface.co/blog/aws-partnership",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Zero-shot image-to-text generation with BLIP-2",
    "summary": "",
    "url": "https://huggingface.co/blog/blip-2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Why we’re switching to Hugging Face Inference Endpoints, and maybe you should too",
    "summary": "",
    "url": "https://huggingface.co/blog/mantis-case-study",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Parameter-Efficient Fine-Tuning using 🤗 PEFT",
    "summary": "",
    "url": "https://huggingface.co/blog/peft",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Speech Synthesis, Recognition, and More With SpeechT5",
    "summary": "",
    "url": "https://huggingface.co/blog/speecht5",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Generating Stories: AI for Game Development #5",
    "summary": "",
    "url": "https://huggingface.co/blog/ml-for-games-5",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing ⚔️ AI vs. AI ⚔️ a deep reinforcement learning multi-agents competition system",
    "summary": "",
    "url": "https://huggingface.co/blog/aivsai",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Accelerating PyTorch Transformers with Intel Sapphire Rapids - part 2",
    "summary": "",
    "url": "https://huggingface.co/blog/intel-sapphire-rapids-inference",
    "source": "Hugging Face Blog"
  },
  {
    "title": "A Dive into Vision-Language Models",
    "summary": "",
    "url": "https://huggingface.co/blog/vision_language_pretraining",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The State of Computer Vision at Hugging Face 🤗",
    "summary": "",
    "url": "https://huggingface.co/blog/cv_state",
    "source": "Hugging Face Blog"
  },
  {
    "title": "2D Asset Generation: AI for Game Development #4",
    "summary": "",
    "url": "https://huggingface.co/blog/ml-for-games-4",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Using LoRA for Efficient Stable Diffusion Fine-Tuning",
    "summary": "",
    "url": "https://huggingface.co/blog/lora",
    "source": "Hugging Face Blog"
  },
  {
    "title": "What Makes a Dialog Agent Useful?",
    "summary": "",
    "url": "https://huggingface.co/blog/dialog-agents",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Optimum+ONNX Runtime - Easier, Faster training for your Hugging Face models",
    "summary": "",
    "url": "https://huggingface.co/blog/optimum-onnxruntime-training",
    "source": "Hugging Face Blog"
  },
  {
    "title": "3D Asset Generation: AI for Game Development #3",
    "summary": "",
    "url": "https://huggingface.co/blog/ml-for-games-3",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Universal Image Segmentation with Mask2Former and OneFormer",
    "summary": "",
    "url": "https://huggingface.co/blog/mask2former",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome PaddlePaddle to the Hugging Face Hub",
    "summary": "",
    "url": "https://huggingface.co/blog/paddlepaddle",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Image Similarity with Hugging Face Datasets and Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/image-similarity",
    "source": "Hugging Face Blog"
  },
  {
    "title": "AI for Game Development: Creating a Farming Game in 5 Days. Part 2",
    "summary": "",
    "url": "https://huggingface.co/blog/ml-for-games-2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introduction to Graph Machine Learning",
    "summary": "",
    "url": "https://huggingface.co/blog/intro-graphml",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Zero-shot image segmentation with CLIPSeg",
    "summary": "",
    "url": "https://huggingface.co/blog/clipseg-zero-shot",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Model Cards",
    "summary": "",
    "url": "https://huggingface.co/blog/model-cards",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Let's talk about biases in machine learning! Ethics and Society Newsletter #2",
    "summary": "",
    "url": "https://huggingface.co/blog/ethics-soc-2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "A Complete Guide to Audio Datasets",
    "summary": "",
    "url": "https://huggingface.co/blog/audio-datasets",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Faster Training and Inference: Habana Gaudi®2 vs Nvidia A100 80GB",
    "summary": "",
    "url": "https://huggingface.co/blog/habana-gaudi-2-benchmark",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Illustrating Reinforcement Learning from Human Feedback (RLHF)",
    "summary": "",
    "url": "https://huggingface.co/blog/rlhf",
    "source": "Hugging Face Blog"
  },
  {
    "title": "From GPT2 to Stable Diffusion: Hugging Face arrives to the Elixir community",
    "summary": "",
    "url": "https://huggingface.co/blog/elixir-bumblebee",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Deep Learning with Proteins",
    "summary": "",
    "url": "https://huggingface.co/blog/deep-learning-with-proteins",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Using Stable Diffusion with Core ML on Apple Silicon",
    "summary": "",
    "url": "https://huggingface.co/blog/diffusers-coreml",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Probabilistic Time Series Forecasting with 🤗 Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/time-series-transformers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "VQ-Diffusion",
    "summary": "",
    "url": "https://huggingface.co/blog/vq-diffusion",
    "source": "Hugging Face Blog"
  },
  {
    "title": "We are hiring interns!",
    "summary": "",
    "url": "https://huggingface.co/blog/interns-2023",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Diffusion Models Live Event",
    "summary": "",
    "url": "https://huggingface.co/blog/diffusion-models-event",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Director of Machine Learning Insights [Part 4]",
    "summary": "",
    "url": "https://huggingface.co/blog/ml-director-insights-4",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Accelerating Document AI",
    "summary": "",
    "url": "https://huggingface.co/blog/document-ai",
    "source": "Hugging Face Blog"
  },
  {
    "title": "An overview of inference solutions on Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/inference-update",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face Machine Learning Demos on arXiv",
    "summary": "",
    "url": "https://huggingface.co/blog/arxiv",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Sentiment Analysis on Encrypted Data with Homomorphic Encryption",
    "summary": "",
    "url": "https://huggingface.co/blog/sentiment-analysis-fhe",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Generating Human-level Text with Contrastive Search in Transformers 🤗",
    "summary": "",
    "url": "https://huggingface.co/blog/introducing-csearch",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing our new pricing",
    "summary": "",
    "url": "https://huggingface.co/blog/pricing-update",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Training Stable Diffusion with Dreambooth using Diffusers",
    "summary": "",
    "url": "https://huggingface.co/blog/dreambooth",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fine-Tune Whisper For Multilingual ASR with 🤗 Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/fine-tune-whisper",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Accelerate your models with 🤗 Optimum Intel and OpenVINO",
    "summary": "",
    "url": "https://huggingface.co/blog/openvino",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Evaluating Language Model Bias with 🤗 Evaluate",
    "summary": "",
    "url": "https://huggingface.co/blog/evaluating-llm-bias",
    "source": "Hugging Face Blog"
  },
  {
    "title": "From PyTorch DDP to Accelerate to Trainer, mastery of distributed training with ease",
    "summary": "",
    "url": "https://huggingface.co/blog/pytorch-ddp-accelerate-transformers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "MTEB: Massive Text Embedding Benchmark",
    "summary": "",
    "url": "https://huggingface.co/blog/mteb",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Getting Started with Hugging Face Inference Endpoints",
    "summary": "",
    "url": "https://huggingface.co/blog/inference-endpoints",
    "source": "Hugging Face Blog"
  },
  {
    "title": "🧨 Stable Diffusion  in JAX / Flax !",
    "summary": "",
    "url": "https://huggingface.co/blog/stable_diffusion_jax",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Optimization story: Bloom inference",
    "summary": "",
    "url": "https://huggingface.co/blog/bloom-inference-optimization",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing DOI: the Digital Object Identifier to Datasets and Models",
    "summary": "",
    "url": "https://huggingface.co/blog/introducing-doi",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Japanese Stable Diffusion",
    "summary": "",
    "url": "https://huggingface.co/blog/japanese-stable-diffusion",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Very Large Language Models and How to Evaluate Them",
    "summary": "",
    "url": "https://huggingface.co/blog/zero-shot-eval-on-the-hub",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Image Classification with AutoTrain",
    "summary": "",
    "url": "https://huggingface.co/blog/autotrain-image-classification",
    "source": "Hugging Face Blog"
  },
  {
    "title": "How 🤗 Accelerate runs very large models thanks to PyTorch",
    "summary": "",
    "url": "https://huggingface.co/blog/accelerate-large-models",
    "source": "Hugging Face Blog"
  },
  {
    "title": "SetFit: Efficient Few-Shot Learning Without Prompts",
    "summary": "",
    "url": "https://huggingface.co/blog/setfit",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Ethics and Society Newsletter #1",
    "summary": "",
    "url": "https://huggingface.co/blog/ethics-soc-1",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Incredibly Fast BLOOM Inference with DeepSpeed and Accelerate",
    "summary": "",
    "url": "https://huggingface.co/blog/bloom-inference-pytorch-scripts",
    "source": "Hugging Face Blog"
  },
  {
    "title": "What's new in Diffusers? 🎨",
    "summary": "",
    "url": "https://huggingface.co/blog/diffusers-2nd-month",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Train your first Decision Transformer",
    "summary": "",
    "url": "https://huggingface.co/blog/train-decision-transformers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "How to train a Language Model with Megatron-LM",
    "summary": "",
    "url": "https://huggingface.co/blog/megatron-training",
    "source": "Hugging Face Blog"
  },
  {
    "title": "OpenRAIL: Towards open and responsible AI licensing frameworks",
    "summary": "",
    "url": "https://huggingface.co/blog/open_rail",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Visualize proteins on Hugging Face Spaces",
    "summary": "",
    "url": "https://huggingface.co/blog/spaces_3dmoljs",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Stable Diffusion with 🧨 Diffusers",
    "summary": "",
    "url": "https://huggingface.co/blog/stable_diffusion",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Pre-Train BERT with Hugging Face Transformers and Habana Gaudi",
    "summary": "",
    "url": "https://huggingface.co/blog/pretraining-bert",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Deploying 🤗 ViT on Vertex AI",
    "summary": "",
    "url": "https://huggingface.co/blog/deploy-vertex-ai",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Deep Dive: Vision Transformers On Hugging Face Optimum Graphcore",
    "summary": "",
    "url": "https://huggingface.co/blog/vision-transformers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using transformers, accelerate and bitsandbytes",
    "summary": "",
    "url": "https://huggingface.co/blog/hf-bitsandbytes-integration",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Skops",
    "summary": "",
    "url": "https://huggingface.co/blog/skops",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face's TensorFlow Philosophy",
    "summary": "",
    "url": "https://huggingface.co/blog/tensorflow-philosophy",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Deploying 🤗 ViT on Kubernetes with TF Serving",
    "summary": "",
    "url": "https://huggingface.co/blog/deploy-tfserving-kubernetes",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Train and Fine-Tune Sentence Transformers Models",
    "summary": "",
    "url": "https://huggingface.co/blog/how-to-train-sentence-transformers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Proximal Policy Optimization (PPO)",
    "summary": "",
    "url": "https://huggingface.co/blog/deep-rl-ppo",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing the Private Hub: A New Way to Build With Machine Learning",
    "summary": "",
    "url": "https://huggingface.co/blog/introducing-private-hub",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Nyströmformer: Approximating self-attention in linear time and memory via the Nyström method",
    "summary": "",
    "url": "https://huggingface.co/blog/nystromformer",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Comments on U.S. National AI Research Resource Interim Report",
    "summary": "",
    "url": "https://huggingface.co/blog/us-national-ai-research-resource",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing new audio and vision documentation in 🤗 Datasets",
    "summary": "",
    "url": "https://huggingface.co/blog/datasets-docs-update",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Faster Text Generation with TensorFlow and XLA",
    "summary": "",
    "url": "https://huggingface.co/blog/tf-xla-generate",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Deploying TensorFlow Vision Models in Hugging Face with TF Serving",
    "summary": "",
    "url": "https://huggingface.co/blog/tf-serving-vision",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Advantage Actor Critic (A2C)",
    "summary": "",
    "url": "https://huggingface.co/blog/deep-rl-a2c",
    "source": "Hugging Face Blog"
  },
  {
    "title": "How to train your model dynamically using adversarial data",
    "summary": "",
    "url": "https://huggingface.co/blog/mnist-adversarial",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The Technology Behind BLOOM Training",
    "summary": "",
    "url": "https://huggingface.co/blog/bloom-megatron-deepspeed",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Building a Playlist Generator with Sentence Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/playlist-generator",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing The World's Largest Open Multilingual Language Model: BLOOM",
    "summary": "",
    "url": "https://huggingface.co/blog/bloom",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Getting Started with Sentiment Analysis on Twitter",
    "summary": "",
    "url": "https://huggingface.co/blog/sentiment-analysis-twitter",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Policy Gradient with PyTorch",
    "summary": "",
    "url": "https://huggingface.co/blog/deep-rl-pg",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Liftoff! How to get started with your first ML project 🚀",
    "summary": "",
    "url": "https://huggingface.co/blog/your-first-ml-project",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Accelerate Large Model Training using DeepSpeed",
    "summary": "",
    "url": "https://huggingface.co/blog/accelerate-deepspeed",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Announcing Evaluation on the Hub",
    "summary": "",
    "url": "https://huggingface.co/blog/eval-on-the-hub",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Getting Started With Embeddings",
    "summary": "",
    "url": "https://huggingface.co/blog/getting-started-with-embeddings",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Convert Transformers to ONNX with Hugging Face Optimum",
    "summary": "",
    "url": "https://huggingface.co/blog/convert-transformers-to-onnx",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Intel and Hugging Face Partner to Democratize Machine Learning Hardware Acceleration",
    "summary": "",
    "url": "https://huggingface.co/blog/intel",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The Annotated Diffusion Model",
    "summary": "",
    "url": "https://huggingface.co/blog/annotated-diffusion",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Deep Q-Learning with Space Invaders",
    "summary": "",
    "url": "https://huggingface.co/blog/deep-rl-dqn",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Graphcore and Hugging Face Launch New Lineup of IPU-Ready Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/graphcore-update",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Pull Requests and Discussions 🥳",
    "summary": "",
    "url": "https://huggingface.co/blog/community-update",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Efficient Table Pre-training without Real Data: An Introduction to TAPEX",
    "summary": "",
    "url": "https://huggingface.co/blog/tapex",
    "source": "Hugging Face Blog"
  },
  {
    "title": "An Introduction to Q-Learning Part 2/2",
    "summary": "",
    "url": "https://huggingface.co/blog/deep-rl-q-part2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "How Sempre Health is leveraging the Expert Acceleration Program to accelerate their ML roadmap",
    "summary": "",
    "url": "https://huggingface.co/blog/sempre-health-eap-case-study",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Putting ethical principles at the core of the research lifecycle",
    "summary": "",
    "url": "https://huggingface.co/blog/ethical-charter-multimodal",
    "source": "Hugging Face Blog"
  },
  {
    "title": "An Introduction to Q-Learning Part 1",
    "summary": "",
    "url": "https://huggingface.co/blog/deep-rl-q-part1",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Machine Learning Experts - Sasha Luccioni",
    "summary": "",
    "url": "https://huggingface.co/blog/sasha-luccioni-interview",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Announcing the Hugging Face Fellowship Program",
    "summary": "",
    "url": "https://huggingface.co/blog/fellowship",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Gradio 3.0 is Out!",
    "summary": "",
    "url": "https://huggingface.co/blog/gradio-blocks",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Student Ambassador Program’s call for applications is open!",
    "summary": "",
    "url": "https://huggingface.co/blog/ambassadors",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Accelerated Inference with Optimum and Transformers Pipelines",
    "summary": "",
    "url": "https://huggingface.co/blog/optimum-inference",
    "source": "Hugging Face Blog"
  },
  {
    "title": "We Raised $100 Million for Open & Collaborative Machine Learning 🚀",
    "summary": "",
    "url": "https://huggingface.co/blog/series-c",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome fastai to the Hugging Face Hub",
    "summary": "",
    "url": "https://huggingface.co/blog/fastai",
    "source": "Hugging Face Blog"
  },
  {
    "title": "An Introduction to Deep Reinforcement Learning",
    "summary": "",
    "url": "https://huggingface.co/blog/deep-rl-intro",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Accelerate Large Model Training using PyTorch Fully Sharded Data Parallel",
    "summary": "",
    "url": "https://huggingface.co/blog/pytorch-fsdp",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Opinion Classification with Kili and HuggingFace AutoTrain",
    "summary": "",
    "url": "https://huggingface.co/blog/opinion-classification-with-kili",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Director of Machine Learning Insights",
    "summary": "",
    "url": "https://huggingface.co/blog/ml-director-insights",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Getting Started with Transformers on Habana Gaudi",
    "summary": "",
    "url": "https://huggingface.co/blog/getting-started-habana",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Hugging Face for Education 🤗",
    "summary": "",
    "url": "https://huggingface.co/blog/education",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Supercharged Customer Service with Machine Learning",
    "summary": "",
    "url": "https://huggingface.co/blog/supercharge-customer-service-with-machine-learning",
    "source": "Hugging Face Blog"
  },
  {
    "title": "CO2 Emissions and the 🤗 Hub: Leading the Charge",
    "summary": "",
    "url": "https://huggingface.co/blog/carbon-emissions-on-the-hub",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Machine Learning Experts - Lewis Tunstall",
    "summary": "",
    "url": "https://huggingface.co/blog/lewis-tunstall-interview",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Habana Labs and Hugging Face Partner to Accelerate Transformer Model Training",
    "summary": "",
    "url": "https://huggingface.co/blog/habana",
    "source": "Hugging Face Blog"
  },
  {
    "title": "~Don't~ Repeat Yourself",
    "summary": "",
    "url": "https://huggingface.co/blog/transformers-design-philosophy",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Decision Transformers on Hugging Face 🤗",
    "summary": "",
    "url": "https://huggingface.co/blog/decision-transformers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Machine Learning Experts - Margaret Mitchell",
    "summary": "",
    "url": "https://huggingface.co/blog/meg-mitchell-interview",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Announcing the 🤗 AI Research Residency Program",
    "summary": "",
    "url": "https://huggingface.co/blog/ai-residency",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fine-Tune a Semantic Segmentation Model with a Custom Dataset",
    "summary": "",
    "url": "https://huggingface.co/blog/fine-tune-segformer",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Accelerate BERT inference with Hugging Face Transformers and AWS Inferentia",
    "summary": "",
    "url": "https://huggingface.co/blog/bert-inferentia-sagemaker",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Image search with 🤗 datasets",
    "summary": "",
    "url": "https://huggingface.co/blog/image-search-datasets",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Guiding Text Generation with Constrained Beam Search in 🤗 Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/constrained-beam-search",
    "source": "Hugging Face Blog"
  },
  {
    "title": "BERT 101 - State Of The Art NLP Model Explained",
    "summary": "",
    "url": "https://huggingface.co/blog/bert-101",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fine-Tune ViT for Image Classification with 🤗 Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/fine-tune-vit",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Getting Started with Sentiment Analysis using Python",
    "summary": "",
    "url": "https://huggingface.co/blog/sentiment-analysis-python",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Making automatic speech recognition work on large files with Wav2Vec2 in 🤗 Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/asr-chunking",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Supercharged Searching on the 🤗 Hub",
    "summary": "",
    "url": "https://huggingface.co/blog/searching-the-hub",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome Stable-baselines3 to the Hugging Face Hub 🤗",
    "summary": "",
    "url": "https://huggingface.co/blog/sb3",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Case Study: Millisecond Latency using Hugging Face Infinity and modern CPUs",
    "summary": "",
    "url": "https://huggingface.co/blog/infinity-cpu-performance",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Boosting Wav2Vec2 with n-grams in 🤗 Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/wav2vec2-with-ngram",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Deploy GPT-J 6B for inference using  Hugging Face Transformers and Amazon SageMaker",
    "summary": "",
    "url": "https://huggingface.co/blog/gptj-sagemaker",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Active Learning with AutoNLP and Prodigy",
    "summary": "",
    "url": "https://huggingface.co/blog/autonlp-prodigy",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Gradio is joining Hugging Face!",
    "summary": "",
    "url": "https://huggingface.co/blog/gradio-joins-hf",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Perceiver IO: a scalable, fully-attentional model that works on any modality",
    "summary": "",
    "url": "https://huggingface.co/blog/perceiver",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Training CodeParrot 🦜 from Scratch",
    "summary": "",
    "url": "https://huggingface.co/blog/codeparrot",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Snowball Fight ☃️, our first ML-Agents environment",
    "summary": "",
    "url": "https://huggingface.co/blog/snowball-fight",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Getting Started with Hugging Face Transformers for IPUs with Optimum",
    "summary": "",
    "url": "https://huggingface.co/blog/graphcore-getting-started",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing the Data Measurements Tool: an Interactive Tool for Looking at Datasets",
    "summary": "",
    "url": "https://huggingface.co/blog/data-measurements-tool",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Accelerating PyTorch distributed fine-tuning with Intel technologies",
    "summary": "",
    "url": "https://huggingface.co/blog/accelerating-pytorch",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fine-Tune XLSR-Wav2Vec2 for low-resource ASR with 🤗 Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/fine-tune-xlsr-wav2vec2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Scaling up BERT-like model Inference on modern CPU  - Part 2",
    "summary": "",
    "url": "https://huggingface.co/blog/bert-cpu-scaling-part-2",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Course Launch Community Event",
    "summary": "",
    "url": "https://huggingface.co/blog/course-launch-event",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Large Language Models: A New Moore's Law?",
    "summary": "",
    "url": "https://huggingface.co/blog/large-language-models",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Train a Sentence Embedding Model with 1B Training Pairs",
    "summary": "",
    "url": "https://huggingface.co/blog/1b-sentence-embeddings",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The Age of Machine Learning As Code Has Arrived",
    "summary": "",
    "url": "https://huggingface.co/blog/the-age-of-ml-as-code",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fine tuning CLIP with Remote Sensing (Satellite) images and captions",
    "summary": "",
    "url": "https://huggingface.co/blog/fine-tune-clip-rsicd",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hosting your Models and Datasets on Hugging Face Spaces using Streamlit",
    "summary": "",
    "url": "https://huggingface.co/blog/streamlit-spaces",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Showcase Your Projects in Spaces using Gradio",
    "summary": "",
    "url": "https://huggingface.co/blog/gradio-spaces",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Summer at Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/summer-at-huggingface",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face and Graphcore partner for IPU-optimized Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/graphcore",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing Optimum: The Optimization Toolkit for Transformers at Scale",
    "summary": "",
    "url": "https://huggingface.co/blog/hardware-partners-program",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Deep Learning over the Internet: Training Language Models Collaboratively",
    "summary": "",
    "url": "https://huggingface.co/blog/collaborative-training",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Welcome spaCy to the Hugging Face Hub",
    "summary": "",
    "url": "https://huggingface.co/blog/spacy",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Deploy Hugging Face models easily with Amazon SageMaker",
    "summary": "",
    "url": "https://huggingface.co/blog/deploy-hugging-face-models-easily-with-amazon-sagemaker",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Sentence Transformers in the Hugging Face Hub",
    "summary": "",
    "url": "https://huggingface.co/blog/sentence-transformers-in-the-hub",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Few-shot learning in practice: GPT-Neo and the 🤗 Accelerated Inference API",
    "summary": "",
    "url": "https://huggingface.co/blog/few-shot-learning-gpt-neo-and-inference-api",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Using & Mixing Hugging Face Models with Gradio 2.0",
    "summary": "",
    "url": "https://huggingface.co/blog/gradio",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Scaling-up BERT Inference on CPU (Part 1)",
    "summary": "",
    "url": "https://huggingface.co/blog/bert-cpu-scaling-part-1",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Introducing 🤗 Accelerate",
    "summary": "",
    "url": "https://huggingface.co/blog/accelerate-library",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Distributed Training: Train BART/T5 for Summarization using 🤗 Transformers and Amazon SageMaker",
    "summary": "",
    "url": "https://huggingface.co/blog/sagemaker-distributed-training-seq2seq",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Understanding BigBird's Block Sparse Attention",
    "summary": "",
    "url": "https://huggingface.co/blog/big-bird",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The Partnership: Amazon SageMaker and Hugging Face",
    "summary": "",
    "url": "https://huggingface.co/blog/the-partnership-amazon-sagemaker-and-hugging-face",
    "source": "Hugging Face Blog"
  },
  {
    "title": "My Journey to a serverless transformers pipeline on Google Cloud",
    "summary": "",
    "url": "https://huggingface.co/blog/how-to-deploy-a-pipeline-to-google-clouds",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fine-Tune Wav2Vec2 for English ASR in Hugging Face with 🤗 Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/fine-tune-wav2vec2-english",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face Reads, Feb. 2021 - Long-range Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/long-range-transformers",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Simple considerations for simple people building fancy neural networks",
    "summary": "",
    "url": "https://huggingface.co/blog/simple-considerations",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Retrieval Augmented Generation with Huggingface Transformers and Ray",
    "summary": "",
    "url": "https://huggingface.co/blog/ray-rag",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hugging Face on PyTorch / XLA TPUs",
    "summary": "",
    "url": "https://huggingface.co/blog/pytorch-xla",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Faster TensorFlow models in Hugging Face Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/tf-serving",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Fit More and Train Faster With ZeRO via DeepSpeed and FairScale",
    "summary": "",
    "url": "https://huggingface.co/blog/zero-deepspeed-fairscale",
    "source": "Hugging Face Blog"
  },
  {
    "title": "How we sped up transformer inference 100x for 🤗 API customers",
    "summary": "",
    "url": "https://huggingface.co/blog/accelerated-inference",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Leveraging Pre-trained Language Model Checkpoints for Encoder-Decoder Models",
    "summary": "",
    "url": "https://huggingface.co/blog/warm-starting-encoder-decoder",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Porting fairseq wmt19 translation system to transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/porting-fsmt",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Hyperparameter Search with Transformers and Ray Tune",
    "summary": "",
    "url": "https://huggingface.co/blog/ray-tune",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Transformer-based Encoder-Decoder Models",
    "summary": "",
    "url": "https://huggingface.co/blog/encoder-decoder",
    "source": "Hugging Face Blog"
  },
  {
    "title": "Block Sparse Matrices for Smaller and Faster Language Models",
    "summary": "",
    "url": "https://huggingface.co/blog/pytorch_block_sparse",
    "source": "Hugging Face Blog"
  },
  {
    "title": "The Reformer - Pushing the limits of language modeling",
    "summary": "",
    "url": "https://huggingface.co/blog/reformer",
    "source": "Hugging Face Blog"
  },
  {
    "title": "How to generate text: using different decoding methods for language generation with Transformers",
    "summary": "",
    "url": "https://huggingface.co/blog/how-to-generate",
    "source": "Hugging Face Blog"
  },
  {
    "title": "How to train a new language model from scratch using Transformers and Tokenizers",
    "summary": "",
    "url": "https://huggingface.co/blog/how-to-train",
    "source": "Hugging Face Blog"
  }
]