[
  {
    "title": "DMCD: Semantic-Statistical Framework for Causal Discovery",
    "summary": "arXiv:2602.20333v1 Announce Type: new Abstract: We present DMCD (DataMap Causal Discovery), a two-phase causal discovery framework that integrates LLM-based semantic drafting from variable metadata with statistical validation on observational data. In Phase I, a large language model proposes a sparse draft DAG, serving as a semantically informed pr",
    "url": "https://arxiv.org/abs/2602.20333",
    "source": "Arxiv AI",
    "published_at": "2026-02-25T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-26T03:19:00.977217+00:00"
  },
  {
    "title": "PyVision-RL: Forging Open Agentic Vision Models via RL",
    "summary": "arXiv:2602.20739v1 Announce Type: new Abstract: Reinforcement learning for agentic multimodal models often suffers from interaction collapse, where models learn to reduce tool usage and multi-turn reasoning, limiting the benefits of agentic behavior. We introduce PyVision-RL, a reinforcement learning framework for open-weight multimodal models that",
    "url": "https://arxiv.org/abs/2602.20739",
    "source": "Arxiv AI",
    "published_at": "2026-02-25T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-26T03:19:00.977217+00:00"
  },
  {
    "title": "Evaluating the Reliability of Digital Forensic Evidence Discovered by Large Language Model: A Case Study",
    "summary": "arXiv:2602.20202v1 Announce Type: cross Abstract: The growing reliance on AI-identified digital evidence raises significant concerns about its reliability, particularly as large language models (LLMs) are increasingly integrated into forensic investigations. This paper proposes a structured framework that automates forensic artifact extraction, ref",
    "url": "https://arxiv.org/abs/2602.20202",
    "source": "Arxiv AI",
    "published_at": "2026-02-25T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-26T03:19:00.977217+00:00"
  },
  {
    "title": "KnapSpec: Self-Speculative Decoding via Adaptive Layer Selection as a Knapsack Problem",
    "summary": "arXiv:2602.20217v1 Announce Type: cross Abstract: Self-speculative decoding (SSD) accelerates LLM inference by skipping layers to create an efficient draft model, yet existing methods often rely on static heuristics that ignore the dynamic computational overhead of attention in long-context scenarios. We propose KnapSpec, a training-free framework ",
    "url": "https://arxiv.org/abs/2602.20217",
    "source": "Arxiv AI",
    "published_at": "2026-02-25T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-26T03:19:00.977217+00:00"
  },
  {
    "title": "An Approach to Combining Video and Speech with Large Language Models in Human-Robot Interaction",
    "summary": "arXiv:2602.20219v1 Announce Type: cross Abstract: Interpreting human intent accurately is a central challenge in human-robot interaction (HRI) and a key requirement for achieving more natural and intuitive collaboration between humans and machines. This work presents a novel multimodal HRI framework that combines advanced vision-language models, sp",
    "url": "https://arxiv.org/abs/2602.20219",
    "source": "Arxiv AI",
    "published_at": "2026-02-25T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-26T03:19:00.977217+00:00"
  },
  {
    "title": "Circuit Tracing in Vision-Language Models: Understanding the Internal Mechanisms of Multimodal Thinking",
    "summary": "arXiv:2602.20330v1 Announce Type: cross Abstract: Vision-language models (VLMs) are powerful but remain opaque black boxes. We introduce the first framework for transparent circuit tracing in VLMs to systematically analyze multimodal reasoning. By utilizing transcoders, attribution graphs, and attention-based methods, we uncover how VLMs hierarchic",
    "url": "https://arxiv.org/abs/2602.20330",
    "source": "Arxiv AI",
    "published_at": "2026-02-25T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-26T03:19:00.977217+00:00"
  },
  {
    "title": "Protein Language Models Diverge from Natural Language: Comparative Analysis and Improved Inference",
    "summary": "arXiv:2602.20449v1 Announce Type: cross Abstract: Modern Protein Language Models (PLMs) apply transformer-based model architectures from natural language processing to biological sequences, predicting a variety of protein functions and properties. However, protein language has key differences from natural language, such as a rich functional space d",
    "url": "https://arxiv.org/abs/2602.20449",
    "source": "Arxiv AI",
    "published_at": "2026-02-25T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-26T03:19:00.977217+00:00"
  },
  {
    "title": "Communication-Inspired Tokenization for Structured Image Representations",
    "summary": "arXiv:2602.20731v1 Announce Type: cross Abstract: Discrete image tokenizers have emerged as a key component of modern vision and multimodal systems, providing a sequential interface for transformer-based architectures. However, most existing approaches remain primarily optimized for reconstruction and compression, often yielding tokens that capture",
    "url": "https://arxiv.org/abs/2602.20731",
    "source": "Arxiv AI",
    "published_at": "2026-02-25T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-26T03:19:00.977217+00:00"
  },
  {
    "title": "CrystaL: Spontaneous Emergence of Visual Latents in MLLMs",
    "summary": "arXiv:2602.20980v1 Announce Type: cross Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable performance by integrating powerful language backbones with large-scale visual encoders. Among these, latent Chain-of-Thought (CoT) methods enable implicit reasoning in continuous hidden states, facilitating seamless vision-language i",
    "url": "https://arxiv.org/abs/2602.20980",
    "source": "Arxiv AI",
    "published_at": "2026-02-25T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-26T03:19:00.977217+00:00"
  },
  {
    "title": "BrowseComp-$V^3$: A Visual, Vertical, and Verifiable Benchmark for Multimodal Browsing Agents",
    "summary": "arXiv:2602.12876v2 Announce Type: replace Abstract: Multimodal large language models (MLLMs), equipped with increasingly advanced planning and tool-use capabilities, are evolving into autonomous agents capable of performing multimodal web browsing and deep search in open-world environments. However, existing benchmarks for multimodal browsing remai",
    "url": "https://arxiv.org/abs/2602.12876",
    "source": "Arxiv AI",
    "published_at": "2026-02-25T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-26T03:19:00.977217+00:00"
  },
  {
    "title": "HSSBench: Benchmarking Humanities and Social Sciences Ability for Multimodal Large Language Models",
    "summary": "arXiv:2506.03922v2 Announce Type: replace-cross Abstract: Multimodal Large Language Models (MLLMs) have demonstrated significant potential to advance a broad range of domains. However, current benchmarks for evaluating MLLMs primarily emphasize general knowledge and vertical step-by-step reasoning typical of STEM disciplines, while overlooking the ",
    "url": "https://arxiv.org/abs/2506.03922",
    "source": "Arxiv AI",
    "published_at": "2026-02-25T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-26T03:19:00.977217+00:00"
  },
  {
    "title": "K-Function: Joint Pronunciation Transcription and Feedback for Evaluating Kids Language Function",
    "summary": "arXiv:2507.03043v3 Announce Type: replace-cross Abstract: Evaluating young children's language is challenging for automatic speech recognizers due to high-pitched voices, prolonged sounds, and limited data. We introduce K-Function, a framework that combines accurate sub-word transcription with objective, Large Language Model (LLM)-driven scoring. I",
    "url": "https://arxiv.org/abs/2507.03043",
    "source": "Arxiv AI",
    "published_at": "2026-02-25T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-26T03:19:00.977217+00:00"
  },
  {
    "title": "Characterizing State Space Model and Hybrid Language Model Performance with Long Context",
    "summary": "arXiv:2507.12442v3 Announce Type: replace-cross Abstract: Emerging applications such as AR are driving demands for machine intelligence capable of processing continuous and/or long-context inputs on local devices. However, currently dominant models based on Transformer architecture suffers from the quadratic computational and memory overhead, which",
    "url": "https://arxiv.org/abs/2507.12442",
    "source": "Arxiv AI",
    "published_at": "2026-02-25T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-26T03:19:00.977217+00:00"
  },
  {
    "title": "Silent Inconsistency in Data-Parallel Full Fine-Tuning: Diagnosing Worker-Level Optimization Misalignment",
    "summary": "arXiv:2602.14462v2 Announce Type: replace-cross Abstract: Data-parallel (DP) training with synchronous all-reduce is a dominant paradigm for full-parameter fine-tuning of large language models (LLMs). While parameter synchronization guarantees numerical equivalence of model weights after each iteration, it does not necessarily imply alignment of wo",
    "url": "https://arxiv.org/abs/2602.14462",
    "source": "Arxiv AI",
    "published_at": "2026-02-25T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-26T03:19:00.977217+00:00"
  },
  {
    "title": "From Logs to Language: Learning Optimal Verbalization for LLM-Based Recommendation in Production",
    "summary": "arXiv:2602.20558v1 Announce Type: new Abstract: Large language models (LLMs) are promising backbones for generative recommender systems, yet a key challenge remains underexplored: verbalization, i.e., converting structured user interaction logs into effective natural language inputs. Existing methods rely on rigid templates that simply concatenate ",
    "url": "https://arxiv.org/abs/2602.20558",
    "source": "Arxiv AI",
    "published_at": "2026-02-25T05:00:00+00:00",
    "score": 6,
    "archived_at": "2026-02-26T03:19:00.977217+00:00"
  }
]