[
  {
    "title": "Mobility-Aware Cache Framework for Scalable LLM-Based Human Mobility Simulation",
    "summary": "arXiv:2602.16727v1 Announce Type: new Abstract: Large-scale human mobility simulation is critical for applications such as urban planning, epidemiology, and transportation analysis. Recent works treat large language models (LLMs) as human agents to simulate realistic mobility behaviors using structured reasoning, but their high computational cost l",
    "url": "https://arxiv.org/abs/2602.16727",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-21T03:09:31.599259+00:00"
  },
  {
    "title": "Mechanistic Interpretability of Cognitive Complexity in LLMs via Linear Probing using Bloom's Taxonomy",
    "summary": "arXiv:2602.17229v1 Announce Type: new Abstract: The black-box nature of Large Language Models necessitates novel evaluation frameworks that transcend surface-level performance metrics. This study investigates the internal neural representations of cognitive complexity using Bloom's Taxonomy as a hierarchical lens. By analyzing high-dimensional acti",
    "url": "https://arxiv.org/abs/2602.17229",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-21T03:09:31.599259+00:00"
  },
  {
    "title": "ODESteer: A Unified ODE-Based Steering Framework for LLM Alignment",
    "summary": "arXiv:2602.17560v1 Announce Type: new Abstract: Activation steering, or representation engineering, offers a lightweight approach to align large language models (LLMs) by manipulating their internal activations at inference time. However, current methods suffer from two key limitations: \\textit{(i)} the lack of a unified theoretical framework for g",
    "url": "https://arxiv.org/abs/2602.17560",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-21T03:09:31.599259+00:00"
  },
  {
    "title": "MALLVI: a multi agent framework for integrated generalized robotics manipulation",
    "summary": "arXiv:2602.16898v1 Announce Type: cross Abstract: Task planning for robotic manipulation with large language models (LLMs) is an emerging area. Prior approaches rely on specialized models, fine tuning, or prompt tuning, and often operate in an open loop manner without robust environmental feedback, making them fragile in dynamic settings.We present",
    "url": "https://arxiv.org/abs/2602.16898",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-21T03:09:31.599259+00:00"
  },
  {
    "title": "Beyond Pipelines: A Fundamental Study on the Rise of Generative-Retrieval Architectures in Web Research",
    "summary": "arXiv:2602.17450v1 Announce Type: cross Abstract: Web research and practices have evolved significantly over time, offering users diverse and accessible solutions across a wide range of tasks. While advanced concepts such as Web 4.0 have emerged from mature technologies, the introduction of large language models (LLMs) has profoundly influenced bot",
    "url": "https://arxiv.org/abs/2602.17450",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-21T03:09:31.599259+00:00"
  },
  {
    "title": "A Scalable Framework for Evaluating Health Language Models",
    "summary": "arXiv:2503.23339v3 Announce Type: replace Abstract: Large language models (LLMs) have emerged as powerful tools for analyzing complex datasets. Recent studies demonstrate their potential to generate useful, personalized responses when provided with patient-specific health information that encompasses lifestyle, biomarkers, and context. As LLM-drive",
    "url": "https://arxiv.org/abs/2503.23339",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-21T03:09:31.599259+00:00"
  },
  {
    "title": "Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for MLLMs",
    "summary": "arXiv:2510.09201v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have shown remarkable success, and their multimodal expansions (MLLMs) further unlock capabilities spanning images, videos, and other modalities beyond text. However, despite this shift, prompt optimization approaches, designed to reduce the burden of manual prom",
    "url": "https://arxiv.org/abs/2510.09201",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-21T03:09:31.599259+00:00"
  },
  {
    "title": "SoK: DARPA's AI Cyber Challenge (AIxCC): Competition Design, Architectures, and Lessons Learned",
    "summary": "arXiv:2602.07666v2 Announce Type: replace-cross Abstract: DARPA's AI Cyber Challenge (AIxCC, 2023--2025) is the largest competition to date for building fully autonomous cyber reasoning systems (CRSs) that leverage recent advances in AI -- particularly large language models (LLMs) -- to discover and remediate vulnerabilities in real-world open-sour",
    "url": "https://arxiv.org/abs/2602.07666",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-21T03:09:31.599259+00:00"
  },
  {
    "title": "The Chicken and Egg Dilemma: Co-optimizing Data and Model Configurations for LLMs",
    "summary": "arXiv:2602.08351v2 Announce Type: replace-cross Abstract: Co-optimizing data and model configurations for training LLMs presents a classic chicken-and-egg dilemma: The best training data configuration (e.g., data mixture) for a downstream task depends on the chosen model configuration (e.g., model architecture), and vice versa. However, jointly opt",
    "url": "https://arxiv.org/abs/2602.08351",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-21T03:09:31.599259+00:00"
  },
  {
    "title": "VisPhyWorld: Probing Physical Reasoning via Code-Driven Video Reconstruction",
    "summary": "arXiv:2602.13294v2 Announce Type: replace-cross Abstract: Evaluating whether Multimodal Large Language Models (MLLMs) genuinely reason about physical dynamics remains challenging. Most existing benchmarks rely on recognition-style protocols such as Visual Question Answering (VQA) and Violation of Expectation (VoE), which can often be answered witho",
    "url": "https://arxiv.org/abs/2602.13294",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-21T03:09:31.599259+00:00"
  },
  {
    "title": "IndicJR: A Judge-Free Benchmark of Jailbreak Robustness in South Asian Languages",
    "summary": "arXiv:2602.16832v1 Announce Type: new Abstract: Safety alignment of large language models (LLMs) is mostly evaluated in English and contract-bound, leaving multilingual vulnerabilities understudied. We introduce \\textbf{Indic Jailbreak Robustness (IJR)}, a judge-free benchmark for adversarial safety across 12 Indic and South Asian languages (2.1 Bi",
    "url": "https://arxiv.org/abs/2602.16832",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00",
    "score": 6,
    "archived_at": "2026-02-21T03:09:31.599259+00:00"
  },
  {
    "title": "LLM-WikiRace: Benchmarking Long-term Planning and Reasoning over Real-World Knowledge Graphs",
    "summary": "arXiv:2602.16902v1 Announce Type: new Abstract: We introduce LLM-Wikirace, a benchmark for evaluating planning, reasoning, and world knowledge in large language models (LLMs). In LLM-Wikirace, models must efficiently navigate Wikipedia hyperlinks step by step to reach a target page from a given source, requiring look-ahead planning and the ability ",
    "url": "https://arxiv.org/abs/2602.16902",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00",
    "score": 6,
    "archived_at": "2026-02-21T03:09:31.599259+00:00"
  },
  {
    "title": "Narrow fine-tuning erodes safety alignment in vision-language agents",
    "summary": "arXiv:2602.16931v1 Announce Type: new Abstract: Lifelong multimodal agents must continuously adapt to new tasks through post-training, but this creates fundamental tension between acquiring capabilities and preserving safety alignment. We demonstrate that fine-tuning aligned vision-language models on narrow-domain harmful datasets induces severe em",
    "url": "https://arxiv.org/abs/2602.16931",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00",
    "score": 6,
    "archived_at": "2026-02-21T03:09:31.599259+00:00"
  },
  {
    "title": "DeepContext: Stateful Real-Time Detection of Multi-Turn Adversarial Intent Drift in LLMs",
    "summary": "arXiv:2602.16935v1 Announce Type: new Abstract: While Large Language Model (LLM) capabilities have scaled, safety guardrails remain largely stateless, treating multi-turn dialogues as a series of disconnected events. This lack of temporal awareness facilitates a \"Safety Gap\" where adversarial tactics, like Crescendo and ActorAttack, slowly bleed ma",
    "url": "https://arxiv.org/abs/2602.16935",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00",
    "score": 6,
    "archived_at": "2026-02-21T03:09:31.599259+00:00"
  },
  {
    "title": "SourceBench: Can AI Answers Reference Quality Web Sources?",
    "summary": "arXiv:2602.16942v1 Announce Type: new Abstract: Large language models (LLMs) increasingly answer queries by citing web sources, but existing evaluations emphasize answer correctness rather than evidence quality. We introduce SourceBench, a benchmark for measuring the quality of cited web sources across 100 real-world queries spanning informational,",
    "url": "https://arxiv.org/abs/2602.16942",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00",
    "score": 6,
    "archived_at": "2026-02-21T03:09:31.599259+00:00"
  }
]