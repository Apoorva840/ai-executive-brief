[
  {
    "title": "Latent Context Compilation: Distilling Long Context into Compact Portable Memory",
    "summary": "arXiv:2602.21221v1 Announce Type: cross Abstract: Efficient long-context LLM deployment is stalled by a dichotomy between amortized compression, which struggles with out-of-distribution generalization, and Test-Time Training, which incurs prohibitive synthetic data costs and requires modifying model weights, creating stateful parameters that compli",
    "url": "https://arxiv.org/abs/2602.21221",
    "source": "Arxiv AI",
    "published_at": "2026-02-26T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-27T03:16:01.376058+00:00"
  },
  {
    "title": "A General Equilibrium Theory of Orchestrated AI Agent Systems",
    "summary": "arXiv:2602.21255v1 Announce Type: cross Abstract: We establish a general equilibrium theory for systems of large language model (LLM) agents operating under centralized orchestration. The framework is a production economy in the sense of Arrow-Debreu (1954), extended to infinite-dimensional commodity spaces following Bewley (1972). Each LLM agent i",
    "url": "https://arxiv.org/abs/2602.21255",
    "source": "Arxiv AI",
    "published_at": "2026-02-26T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-27T03:16:01.376058+00:00"
  },
  {
    "title": "Causal Decoding for Hallucination-Resistant Multimodal Large Language Models",
    "summary": "arXiv:2602.21441v1 Announce Type: cross Abstract: Multimodal Large Language Models (MLLMs) deliver detailed responses on vision-language tasks, yet remain susceptible to object hallucination (introducing objects not present in the image), undermining reliability in practice. Prior efforts often rely on heuristic penalties, post-hoc correction, or g",
    "url": "https://arxiv.org/abs/2602.21441",
    "source": "Arxiv AI",
    "published_at": "2026-02-26T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-27T03:16:01.376058+00:00"
  },
  {
    "title": "1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent Reasoning",
    "summary": "arXiv:2508.07667v3 Announce Type: replace Abstract: Addressing contextual privacy concerns remains challenging in interactive settings where large language models (LLMs) process information from multiple sources (e.g., summarizing meetings with private and public information). We introduce a multi-agent framework that decomposes privacy reasoning i",
    "url": "https://arxiv.org/abs/2508.07667",
    "source": "Arxiv AI",
    "published_at": "2026-02-26T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-27T03:16:01.376058+00:00"
  },
  {
    "title": "When Can Transformers Count to n?",
    "summary": "arXiv:2407.15160v3 Announce Type: replace-cross Abstract: Large language models based on the transformer architecture can solve highly complex tasks, yet their fundamental limitations on simple algorithmic problems remain poorly understood. In this work, we focus on basic counting tasks and investigate how the difficulty of these tasks scales with ",
    "url": "https://arxiv.org/abs/2407.15160",
    "source": "Arxiv AI",
    "published_at": "2026-02-26T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-27T03:16:01.376058+00:00"
  },
  {
    "title": "Compose and Fuse: Revisiting the Foundational Bottlenecks in Multimodal Reasoning",
    "summary": "arXiv:2509.23744v2 Announce Type: replace-cross Abstract: Multimodal large language models (MLLMs) promise enhanced reasoning by integrating diverse inputs such as text, vision, and audio. Yet cross-modal reasoning remains underexplored, with conflicting reports on whether added modalities help or harm performance. These inconsistencies stem from a",
    "url": "https://arxiv.org/abs/2509.23744",
    "source": "Arxiv AI",
    "published_at": "2026-02-26T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-27T03:16:01.376058+00:00"
  },
  {
    "title": "SciTS: Scientific Time Series Understanding and Generation with LLMs",
    "summary": "arXiv:2510.03255v2 Announce Type: replace-cross Abstract: The scientific reasoning ability of large language models (LLMs) has recently attracted significant attention. Time series, as a fundamental modality in scientific data, presents unique challenges that are often overlooked in current multimodal LLMs, which either encode numerical sequences a",
    "url": "https://arxiv.org/abs/2510.03255",
    "source": "Arxiv AI",
    "published_at": "2026-02-26T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-27T03:16:01.376058+00:00"
  },
  {
    "title": "TimeBlind: A Spatio-Temporal Compositionality Benchmark for Video LLMs",
    "summary": "arXiv:2602.00288v3 Announce Type: replace-cross Abstract: Fine-grained spatio-temporal understanding is essential for video reasoning and embodied AI. Yet, while Multimodal Large Language Models (MLLMs) master static semantics, their grasp of temporal dynamics remains brittle. We present TimeBlind, a diagnostic benchmark for compositional spatio-te",
    "url": "https://arxiv.org/abs/2602.00288",
    "source": "Arxiv AI",
    "published_at": "2026-02-26T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-27T03:16:01.376058+00:00"
  },
  {
    "title": "MALLVI: A Multi-Agent Framework for Integrated Generalized Robotics Manipulation",
    "summary": "arXiv:2602.16898v3 Announce Type: replace-cross Abstract: Task planning for robotic manipulation with large language models (LLMs) is an emerging area. Prior approaches rely on specialized models, fine tuning, or prompt tuning, and often operate in an open loop manner without robust environmental feedback, making them fragile in dynamic settings. M",
    "url": "https://arxiv.org/abs/2602.16898",
    "source": "Arxiv AI",
    "published_at": "2026-02-26T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-27T03:16:01.376058+00:00"
  },
  {
    "title": "Dual-Channel Attention Guidance for Training-Free Image Editing Control in Diffusion Transformers",
    "summary": "arXiv:2602.18022v2 Announce Type: replace-cross Abstract: Training-free control over editing intensity is a critical requirement for diffusion-based image editing models built on the Diffusion Transformer (DiT) architecture. Existing attention manipulation methods focus exclusively on the Key space to modulate attention routing, leaving the Value s",
    "url": "https://arxiv.org/abs/2602.18022",
    "source": "Arxiv AI",
    "published_at": "2026-02-26T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-27T03:16:01.376058+00:00"
  },
  {
    "title": "Google's Nano Banana 2 brings Pro-level image generation to Flash speeds at up to 40% lower API cost",
    "summary": "Google's new Nano Banana 2 image generation model pairs the capabilities of the pricier Pro model with Gemini Flash speed at nearly half the cost. It's now the default in the Gemini app. The article Google&#039;s Nano Banana 2 brings Pro-level image generation to Flash speeds at up to 40% lower API cost appeared first on The Decoder.",
    "url": "https://the-decoder.com/googles-nano-banana-2-brings-pro-level-image-generation-to-flash-speeds-at-up-to-40-lower-api-cost/",
    "source": "The Decoder",
    "published_at": "2026-02-26T18:45:03+00:00",
    "score": 7,
    "archived_at": "2026-02-27T03:16:01.376058+00:00"
  },
  {
    "title": "Alibaba's open Qwen 3.5 takes aim at GPT-5 mini and Claude Sonnet 4.5 at a fraction of the cost",
    "summary": "Alibaba has introduced the new Qwen 3.5 model series. It comprises four models: Qwen3.5-Flash, Qwen3.5-35B-A3B, Qwen3.5-122B-A10B and Qwen3.5-27B. The article Alibaba&#039;s open Qwen 3.5 takes aim at GPT-5 mini and Claude Sonnet 4.5 at a fraction of the cost appeared first on The Decoder.",
    "url": "https://the-decoder.com/alibabas-open-qwen-3-5-takes-aim-at-gpt-5-mini-and-claude-sonnet-4-5-at-a-fraction-of-the-cost/",
    "source": "The Decoder",
    "published_at": "2026-02-26T09:14:52+00:00",
    "score": 7,
    "archived_at": "2026-02-27T03:16:01.376058+00:00"
  },
  {
    "title": "A Dynamic Survey of Soft Set Theory and Its Extensions",
    "summary": "arXiv:2602.21268v1 Announce Type: new Abstract: Soft set theory provides a direct framework for parameterized decision modeling by assigning to each attribute (parameter) a subset of a given universe, thereby representing uncertainty in a structured way [1, 2]. Over the past decades, the theory has expanded into numerous variants-including hypersof",
    "url": "https://arxiv.org/abs/2602.21268",
    "source": "Arxiv AI",
    "published_at": "2026-02-26T05:00:00+00:00",
    "score": 6,
    "archived_at": "2026-02-27T03:16:01.376058+00:00"
  },
  {
    "title": "Beyond Refusal: Probing the Limits of Agentic Self-Correction for Semantic Sensitive Information",
    "summary": "arXiv:2602.21496v1 Announce Type: new Abstract: While defenses for structured PII are mature, Large Language Models (LLMs) pose a new threat: Semantic Sensitive Information (SemSI), where models infer sensitive identity attributes, generate reputation-harmful content, or hallucinate potentially wrong information. The capacity of LLMs to self-regula",
    "url": "https://arxiv.org/abs/2602.21496",
    "source": "Arxiv AI",
    "published_at": "2026-02-26T05:00:00+00:00",
    "score": 6,
    "archived_at": "2026-02-27T03:16:01.376058+00:00"
  },
  {
    "title": "The ASIR Courage Model: A Phase-Dynamic Framework for Truth Transitions in Human and AI Systems",
    "summary": "arXiv:2602.21745v1 Announce Type: new Abstract: We introduce the ASIR (Awakened Shared Intelligence Relationship) Courage Model, a phase-dynamic framework that formalizes truth-disclosure as a state transition rather than a personality trait. The mode characterizes the shift from suppression (S0) to expression (S1) as occurring when facilitative fo",
    "url": "https://arxiv.org/abs/2602.21745",
    "source": "Arxiv AI",
    "published_at": "2026-02-26T05:00:00+00:00",
    "score": 6,
    "archived_at": "2026-02-27T03:16:01.376058+00:00"
  }
]