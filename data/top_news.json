[
  {
    "title": "Dynamic Expert Quantization for Scalable Mixture-of-Experts Inference",
    "summary": "arXiv:2511.15015v3 Announce Type: replace-cross Abstract: Mixture-of-Experts (MoE) has become a practical architecture for scaling LLM capacity while keeping per-token compute modest, but deploying MoE models on a single, memory-limited GPU remains difficult because expert weights dominate the HBM footprint. Existing expert offloading and prefetchi",
    "url": "https://arxiv.org/abs/2511.15015",
    "source": "Arxiv AI",
    "published_at": "2026-02-09T05:00:00+00:00",
    "score": 8
  },
  {
    "title": "Understanding LLM Evaluator Behavior: A Structured Multi-Evaluator Framework for Merchant Risk Assessment",
    "summary": "arXiv:2602.05110v1 Announce Type: new Abstract: Large Language Models (LLMs) are increasingly used as evaluators of reasoning quality, yet their reliability and bias in payments-risk settings remain poorly understood. We introduce a structured multi-evaluator framework for assessing LLM reasoning in Merchant Category Code (MCC)-based merchant risk ",
    "url": "https://arxiv.org/abs/2602.05110",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-08T03:45:11.802210+00:00"
  },
  {
    "title": "Hallucination-Resistant Security Planning with a Large Language Model",
    "summary": "arXiv:2602.05279v1 Announce Type: new Abstract: Large language models (LLMs) are promising tools for supporting security management tasks, such as incident response planning. However, their unreliability and tendency to hallucinate remain significant challenges. In this paper, we address these challenges by introducing a principled framework for us",
    "url": "https://arxiv.org/abs/2602.05279",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-08T03:45:11.802210+00:00"
  },
  {
    "title": "ProAct: Agentic Lookahead in Interactive Environments",
    "summary": "arXiv:2602.05327v1 Announce Type: new Abstract: Existing Large Language Model (LLM) agents struggle in interactive environments requiring long-horizon planning, primarily due to compounding errors when simulating future states. To address this, we propose ProAct, a framework that enables agents to internalize accurate lookahead reasoning through a ",
    "url": "https://arxiv.org/abs/2602.05327",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-08T03:45:11.802210+00:00"
  },
  {
    "title": "AgentXRay: White-Boxing Agentic Systems via Workflow Reconstruction",
    "summary": "arXiv:2602.05353v1 Announce Type: new Abstract: Large Language Models have shown strong capabilities in complex problem solving, yet many agentic systems remain difficult to interpret and control due to opaque internal workflows. While some frameworks offer explicit architectures for collaboration, many deployed agentic systems operate as black box",
    "url": "https://arxiv.org/abs/2602.05353",
    "source": "Arxiv AI",
    "published_at": "2026-02-07T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-08T03:45:11.802210+00:00"
  }
]