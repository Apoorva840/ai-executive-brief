[
  {
    "title": "How to Hide Google’s AI Overviews From Your Search Results",
    "summary": "You can avoid Google’s AI summaries in your search results by simply adjusting your query. Or just switch search engines altogether.",
    "url": "https://www.wired.com/story/how-to-hide-google-ai-overviews-from-your-search-results/",
    "source": "Wired AI",
    "published_at": "2026-02-22T11:00:00+00:00",
    "score": 5
  },
  {
    "title": "Could AI Data Centers Be Moved to Outer Space?",
    "summary": "Massive data centers for generative AI are bad for the Earth. How about launching them into orbit?",
    "url": "https://www.wired.com/story/could-we-put-ai-data-centers-in-space/",
    "source": "Wired AI",
    "published_at": "2026-02-20T12:00:00+00:00",
    "score": 5,
    "archived_at": "2026-02-21T05:04:55.318982+00:00"
  },
  {
    "title": "Mobility-Aware Cache Framework for Scalable LLM-Based Human Mobility Simulation",
    "summary": "arXiv:2602.16727v1 Announce Type: new Abstract: Large-scale human mobility simulation is critical for applications such as urban planning, epidemiology, and transportation analysis. Recent works treat large language models (LLMs) as human agents to simulate realistic mobility behaviors using structured reasoning, but their high computational cost l",
    "url": "https://arxiv.org/abs/2602.16727",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-21T03:09:31.599259+00:00"
  },
  {
    "title": "Mechanistic Interpretability of Cognitive Complexity in LLMs via Linear Probing using Bloom's Taxonomy",
    "summary": "arXiv:2602.17229v1 Announce Type: new Abstract: The black-box nature of Large Language Models necessitates novel evaluation frameworks that transcend surface-level performance metrics. This study investigates the internal neural representations of cognitive complexity using Bloom's Taxonomy as a hierarchical lens. By analyzing high-dimensional acti",
    "url": "https://arxiv.org/abs/2602.17229",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-21T03:09:31.599259+00:00"
  },
  {
    "title": "ODESteer: A Unified ODE-Based Steering Framework for LLM Alignment",
    "summary": "arXiv:2602.17560v1 Announce Type: new Abstract: Activation steering, or representation engineering, offers a lightweight approach to align large language models (LLMs) by manipulating their internal activations at inference time. However, current methods suffer from two key limitations: \\textit{(i)} the lack of a unified theoretical framework for g",
    "url": "https://arxiv.org/abs/2602.17560",
    "source": "Arxiv AI",
    "published_at": "2026-02-20T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-21T03:09:31.599259+00:00"
  }
]