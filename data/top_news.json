[
  {
    "title": "XAI-CLIP: ROI-Guided Perturbation Framework for Explainable Medical Image Segmentation in Multimodal Vision-Language Models",
    "summary": "arXiv:2602.07017v1 Announce Type: cross Abstract: Medical image segmentation is a critical component of clinical workflows, enabling accurate diagnosis, treatment planning, and disease monitoring. However, despite the superior performance of transformer-based models over convolutional architectures, their limited interpretability remains a major ob",
    "url": "https://arxiv.org/abs/2602.07017",
    "source": "Arxiv AI",
    "published_at": "2026-02-11T05:00:00+00:00",
    "score": 8
  },
  {
    "title": "I Loved My OpenClaw AI Agent—Until It Turned on Me",
    "summary": "I used the viral AI helper to order groceries, sort emails, and negotiate deals. Then it decided to scam me.",
    "url": "https://www.wired.com/story/malevolent-ai-agent-openclaw-clawdbot/",
    "source": "Wired AI",
    "published_at": "2026-02-11T19:00:00+00:00",
    "score": 5
  },
  {
    "title": "CBP Signs Clearview AI Deal to Use Face Recognition for ‘Tactical Targeting’",
    "summary": "US Border Patrol intelligence units will gain access to a face recognition tool built on billions of images scraped from the internet.",
    "url": "https://www.wired.com/story/cbp-signs-clearview-ai-deal-to-use-face-recognition-for-tactical-targeting/",
    "source": "Wired AI",
    "published_at": "2026-02-11T16:32:27+00:00",
    "score": 5
  },
  {
    "title": "Is a secure AI assistant possible?",
    "summary": "AI agents are a risky business. Even when stuck inside the chatbox window, LLMs will make mistakes and behave badly. Once they have tools that they can use to interact with the outside world, such as web browsers and email addresses, the consequences of those mistakes become far more serious. That might explain why the&#8230;",
    "url": "https://www.technologyreview.com/2026/02/11/1132768/is-a-secure-ai-assistant-possible/",
    "source": "MIT Technology Review AI",
    "published_at": "2026-02-11T20:08:35+00:00",
    "score": 4
  },
  {
    "title": "TernaryLM: Memory-Efficient Language Modeling via Native 1-Bit Quantization with Adaptive Layer-wise Scaling",
    "summary": "arXiv:2602.07374v1 Announce Type: cross Abstract: Large language models (LLMs) achieve remarkable performance but demand substantial computational resources, limiting deployment on edge devices and resource-constrained environments. We present TernaryLM, a 132M parameter transformer architecture that employs native 1-bit ternary quantization {-1, 0",
    "url": "https://arxiv.org/abs/2602.07374",
    "source": "Arxiv AI",
    "published_at": "2026-02-10T05:00:00+00:00",
    "score": 8,
    "archived_at": "2026-02-11T03:33:27.528076+00:00"
  }
]