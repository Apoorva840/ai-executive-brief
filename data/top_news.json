[
  {
    "title": "MiniCPM-SALA: Hybridizing Sparse and Linear Attention for Efficient Long-Context Modeling",
    "summary": "arXiv:2602.11761v1 Announce Type: cross Abstract: The evolution of large language models (LLMs) towards applications with ultra-long contexts faces challenges posed by the high computational and memory costs of the Transformer architecture. While existing sparse and linear attention mechanisms attempt to mitigate these issues, they typically involv",
    "url": "https://arxiv.org/abs/2602.11761",
    "source": "Arxiv AI",
    "published_at": "2026-02-13T05:00:00+00:00",
    "score": 8,
    "archived_at": "2026-02-14T03:14:31.327080+00:00"
  },
  {
    "title": "Bi-Level Prompt Optimization for Multimodal LLM-as-a-Judge",
    "summary": "arXiv:2602.11340v1 Announce Type: new Abstract: Large language models (LLMs) have become widely adopted as automated judges for evaluating AI-generated content. Despite their success, aligning LLM-based evaluations with human judgments remains challenging. While supervised fine-tuning on human-labeled data can improve alignment, it is costly and in",
    "url": "https://arxiv.org/abs/2602.11340",
    "source": "Arxiv AI",
    "published_at": "2026-02-13T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-14T03:14:31.327080+00:00"
  },
  {
    "title": "Credit Where It is Due: Cross-Modality Connectivity Drives Precise Reinforcement Learning for MLLM Reasoning",
    "summary": "arXiv:2602.11455v1 Announce Type: new Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has significantly advanced the reasoning capabilities of Multimodal Large Language Models (MLLMs), yet how visual evidence is integrated during reasoning remains poorly understood. We explore multimodal RLVR through the lens of cross-modal attentio",
    "url": "https://arxiv.org/abs/2602.11455",
    "source": "Arxiv AI",
    "published_at": "2026-02-13T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-14T03:14:31.327080+00:00"
  },
  {
    "title": "scPilot: Large Language Model Reasoning Toward Automated Single-Cell Analysis and Discovery",
    "summary": "arXiv:2602.11609v1 Announce Type: new Abstract: We present scPilot, the first systematic framework to practice omics-native reasoning: a large language model (LLM) converses in natural language while directly inspecting single-cell RNA-seq data and on-demand bioinformatics tools. scPilot converts core single-cell analyses, i.e., cell-type annotatio",
    "url": "https://arxiv.org/abs/2602.11609",
    "source": "Arxiv AI",
    "published_at": "2026-02-13T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-14T03:14:31.327080+00:00"
  },
  {
    "title": "Do MLLMs Really Understand Space? A Mathematical Reasoning Evaluation",
    "summary": "arXiv:2602.11635v1 Announce Type: new Abstract: Multimodal large language models (MLLMs) have achieved strong performance on perception-oriented tasks, yet their ability to perform mathematical spatial reasoning, defined as the capacity to parse and manipulate two- and three-dimensional relations, remains unclear. Humans easily solve textbook-style",
    "url": "https://arxiv.org/abs/2602.11635",
    "source": "Arxiv AI",
    "published_at": "2026-02-13T05:00:00+00:00",
    "score": 7,
    "archived_at": "2026-02-14T03:14:31.327080+00:00"
  }
]